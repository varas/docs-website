{
  "/docs/query-your-data/explore-query-data/get-started/introduction-data-explorer": [
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "Transitioning from Insights",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-22T05:25:43Z",
      "updated_at": "2021-05-22T05:25:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. View dashboards across your organization using cross-account search. Chart all the events and attributes from everywhere across our platform. For more information, see Data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. Transitioning from Insights Switching to using New Relic One dashboards from our deprecated Insights dashboards? See our transition guide. If you're using the Insights Dashboard API, we have have a migration guide that will help you transition to using the new API. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.38687,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Organize <em>your</em> dashboards with tags",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " and understand the <em>data</em> you collect. <em>Explore</em> <em>your</em> <em>data</em> and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of <em>your</em> system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive"
      },
      "id": "603ec16028ccbc8d07eba78d"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-05-22T05:24:30Z",
      "updated_at": "2021-05-22T05:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Delete. Editing: To edit a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Edit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.3683,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> dashboards",
        "sections": "Add custom visualizations to <em>your</em> dashboards",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "Explore the Public API Performance dashboard",
        "Important",
        "Add the dashboard in New Relic",
        "Explore the dashboard",
        "More about dashboards and data"
      ],
      "title": "Explore the Public API Performance dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "71646dd30d63a0c7e343f4d81061bbb27eceeb86",
      "image": "https://docs.newrelic.com/static/2c9a2621107e0114a2c345fcbb22356f/8c557/Public-API-Performance-Dash-for-GPD.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/explore-public-api-performance-dashboard/",
      "published_at": "2021-05-22T05:25:43Z",
      "updated_at": "2021-05-16T10:24:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Public API Performance dashboard is a dashboard supported by New Relic’s Global Performance data sets. It’s an out-of-the-box dashboard included as part of your New Relic account. It provides both actionable general insights about the performance of public APIs and an opportunity for new customers to test-drive New Relic’s dashboarding capabilities before adding their own data. The dashboard works by showing real latencies experienced by an anonymized sampling of New Relic customers when accessing popular public APIs. Important Global Performance data sets are presented as-is. Global Performance data sets represent an aggregate of samples across a range of sources, and New Relic makes no effort to attempt to confirm the correctness, completeness, or veracity of the data. This data should not be relied on as the sole source of information for any purpose you may use it, and New Relic is not responsible for decisions made in reliance on this data. Global Performance data sets should not be viewed as either an endorsement or a recommendation by New Relic of the technologies represented in the data sets. Add the dashboard in New Relic If the Public API Performance dashboard isn't already visible in your UI, you can add it easily. Enable the dashboard from one.newrelic.com/: New customers: The dashboard is enabled by default and added to the favorites list for all new accounts. Existing customers: If the dashboard hasn't already been enabled, you can add it by clicking your avatar and selecting Add your data. Click the Public API Performance tile to open the account selector, then click Add and view pre-built dashboard On the Public API Performance dashboard page, start exploring! Click the ... at the corner of any pane to expand charts, view queries, and more. Public API Performance dashboard Explore the dashboard Below are some suggestions for how to explore the Public API Performance dashboard. Click … in the corner of any of the charts and select View query to view the NRQL query used to create the chart. Click … in the corner of any of the charts and select Get as image to view or download any chart as an image. Select specific domains from the bar chart or add a filter by clicking the text field along the at the top of the page. If you’ve already added your own data, experiment with copying queries and modifying them for your own use. Important The Public API Performance dashboard is not currently available to EU customers. Important The Public API Performance dashboard does not currently support alerts. More about dashboards and data For more information about the Global Performance data sets that power the Public Performance API dashboard, see New Relic Global Performance data sets. For more information about New Relic dashboards, see our dashboards introduction. Customers can also dive into this data set in greater depth using our new data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.52133,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Explore</em> the Public API Performance dashboard",
        "sections": "<em>Explore</em> the Public API Performance dashboard",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "The Public API Performance dashboard is a dashboard supported by New Relic’s Global Performance <em>data</em> sets. It’s an out-of-the-box dashboard included as part of <em>your</em> New Relic account. It provides both actionable general insights about the performance of public APIs and an opportunity for new"
      },
      "id": "603e97fa28ccbc013ceba7c1"
    }
  ],
  "/docs/query-your-data/explore-query-data/get-started/introduction-querying-new-relic-data": [
    {
      "sections": [
        "Metric data structure",
        "Metric types"
      ],
      "title": "Metric data structure",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "4f5724347af7e29f92fa2795c7eaf594e964b450",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/metric-data/metric-data-type/",
      "published_at": "2021-05-22T14:26:59Z",
      "updated_at": "2021-05-15T10:04:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform reports four main telemetry data types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric data, aka the Metric data type. To learn about how to query this type of data, see Query metrics. Metric types The metric type determines how the data is aggregated over longer time windows. It also determines which functions you can use to query the data. Metric types Description Available query functions count Measures the number of occurrences of an event. The count should be reset to 0 every time the metric is reported. Examples include cache hits per reporting interval and the number of threads created per reporting interval. You must specify a value for interval.ms when reporting the count metric type using the Metric API. The value must be a positive double. Generally, you want to take the rate of the sum: From Metric select rate(sum(myMetric), 1 minute) . . . sum distribution Tracks the statistical distribution on a numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type: supports statistical functions like percentile and histogram, and all functions supported by the summary type. is generated only via the event-to-metrics service. The distribution type uses the same algorithm as the percentile function. percentile histogram min max sum count average gauge Represents a value that can increase or decrease with time. Examples of gauges include the temperature, CPU usage, and memory. For example, there is always a temperature, but you are periodically taking the temperature and reporting it. The value must fit into the range of a Java double. latest min max sum count average summary Used to report pre-aggregated data, or information on aggregated discrete events. A summary includes a count, sum value, min value, and max value. The count value must be positive. Examples include transaction count/durations and queue count/ durations. You must specify a value for interval.ms when reporting the summary metric type using the Metric API. min max sum count average uniqueCount Tracks the number of unique values on a string or numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type is generated only via the event-to-metrics service. uniqueCount",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.1152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>data</em> structure",
        "sections": "Metric <em>data</em> structure",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic <em>platform</em> reports four main <em>telemetry</em> <em>data</em> types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric <em>data</em>, aka the Metric <em>data</em> type. To learn about how to query this type of <em>data</em>, see Query metrics. Metric types The metric type determines"
      },
      "id": "609f9cbfe7b9d205f0c3eb54"
    },
    {
      "sections": [
        "New Relic data types",
        "Get started",
        "Tip",
        "Metrics",
        "Metrics in the monitoring industry",
        "Metrics at New Relic",
        "Dimensional metrics (used by Metric API and many integrations)",
        "Metric timeslice data (used by APM, Browser, Mobile)",
        "Metric timeslice examples",
        "Metrics attached to events (used by Infrastructure, other products)",
        "Metrics as a computation of events (used in some charts and queries)",
        "Event data",
        "Events in the monitoring industry",
        "Events at New Relic",
        "Log data",
        "Logs in the monitoring industry",
        "Logs at New Relic",
        "Trace data",
        "Tracing in the monitoring industry",
        "Tracing at New Relic",
        "Query and send data",
        "Learn more"
      ],
      "title": "New Relic data types",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "0953dd677c1ed3c5a7f477f7b7872f89580df53c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/new-relic-data-types/",
      "published_at": "2021-05-21T16:47:51Z",
      "updated_at": "2021-05-15T09:11:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform is built around the four fundamental telemetry data types we believe are necessary for complete and effective system monitoring: metrics, events, logs, and traces. Get started This doc will give you a fairly technical explanation of our core data types, their structure, and how they're used in our features. You can use most of our features without needing to understand the underlying data structure. But having a better understanding of this can help you get data into New Relic, understand the data you see in our UI, and query your data. For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types. Another good way to understand your data is to just start querying it. Tip Access your data easily on one.newrelic.com: Click the Browse data dropdown menu and select the data type (metrics, events, logs, and traces) you want to explore. Metrics First, we’ll explain the definition of metrics from a monitoring industry perspective, and then we’ll explain how New Relic handles metrics. For a list of the metrics we collect, see our documentation on metrics. Metrics in the monitoring industry In the software monitoring industry, a metric means a numeric measurement of an application or system. Metrics are typically reported on a regular schedule. Two major types of metrics are: Aggregated data. For example: a count of events over one minute’s time, or the rate of some event per minute. A numeric status at a moment in time. For example: a CPU temperature reading, or a “CPU% used” status. Metrics are relatively easy to report and store because a single record can represent a range of time. They can also be aggregated more and more over time. For example, per-minute data may be “rolled up” to per-hour aggregations after some amount of time, and eventually may be rolled up to a per-day aggregation. This approach is efficient for long-term data storage. Metrics are a strong solution for storing data long-term, and understanding trends over time. One potential downside is that it can be difficult to do detailed analysis of older data that has been aggregated over time; when high detail is required about specific important actions, event data can be used. Metrics at New Relic Conceptually, \"metrics\" is a broad, general category. There are various ways New Relic measures and reports metrics but, in practice, when using the New Relic UI, you usually won't have to understand how exactly this happens. In our documentation, we typically will just refer to \"metrics,\" regardless of how that data is reported, unless there's a reason you need to know more (like understanding how to query your data). Here are some of the ways metrics are reported and stored across the New Relic platform: Dimensional metrics (used by Metric API and many integrations) In the monitoring industry, \"dimensional\" metrics refer to metric data that has a variety of attributes (dimensions) attached, such as duration-related attributes (start time, end time), entity ID, region, host, etc. This amount of detail allows for in-depth analysis and querying. At New Relic, this metric data is attached to the Metric data type and is sent from several sources: Some open-source integrations, like our Prometheus and OpenCensus exporters Our Telemetry SDKs Infrastructure services The Metric API (the underlying API used by the above tools) The events-to-metrics service To query this data and see its attributes (\"dimensions\"), you could use a NRQL query like: Select * from Metric Copy As time passes, these metrics are increasingly aggregated into larger time buckets. This is done to optimize your ability to query data over a long period of time. For more details about the metric data type, see our docs. To learn how this data is ingested and stored, see the Metric API documentation. For tips on querying, see Metric query examples. Metric timeslice data (used by APM, Browser, Mobile) New Relic's APM, Browser, and Mobile report and display metrics in a simple data format that we refer to as metric timeslice data. A metric timeslice consists of three parts: a metric name, the segment of time the metric represents (the \"timeslice\"), and a numeric value (the measurement). For example: an APM metric timeslice for time spent in a particular transaction is named WebTransaction/URI/foo, and might have a response time of 0.793 for a one-minute time slice from 10:20am to 10:21am. These metrics usually follow a pattern like <category>/<class>/<method>. Our agents (APM, Browser, and Mobile) can collect thousands of metric timeslices per minute for a variety of performance metrics. For example: error rate, bandwidth usage, and garbage collection time. You also have the ability to create custom metrics. Metric timeslice data is a lightweight data type and lacks the detail that dimensional metrics have. Ways to explore and query metric timeslice data: For APM: metric timeslice data is converted to dimensional metrics and can be queried via NRQL Use the REST API If you want to learn more about the structure of metric timeslice data and see some examples, expand the collapser below. Metric timeslice examples Here are some common metric timeslice data examples, with a focus on common ones used by Ruby applications. ActiveMerchant New Relic tracks a variety of metrics on ActiveMerchant transactions which can be used for business analytics as well as performance monitoring. The metrics are summarized by operation as well as by gateway. regex sample metric legend name ActiveMerchant/. * ActiveMerchant/PayJunctionGateway ActiveMerchant/gateway/. * ActiveMerchant/gateway/PayJunctionGateway/purchase PayJunctionGateway ActiveMerchant/operation/. * ActiveMerchant/operation/purchase purchase For more information, see the ActiveMerchant website. ActiveRecord ActiveRecord is the Object-Relational Mapping API used by Ruby on Rails applications. The metrics shown here measure the performance of ActiveRecord's find and save methods. regex sample metric legend name ActiveRecord/. * /find ActiveRecord/User/find User#find ActiveRecord/. * /save ActiveRecord/Product/save Product#save For more information, see the API documentation for ActiveRecord. Apdex Apdex is a measure of user satisfaction with page load times. Controller In Ruby on Rails applications, HTTP requests are handled by Controller actions. A Rails application has many controllers, each of which has one or more actions. When your rails application receives an http request, that request is routed to the appropriate controller and action, based on the URL of that request. That action then does whatever processing is neccesary to generate an http response, which is most often a web page, but could also be a page fragment, an xml document, or any other kind of data that is requested by the client. The following metrics track the performance of controller actions, regardless of routing, and without taking into account any network or web server effects. regex sample metric legend name Controller/. * Controller/Users/show /Users/show Controller/. * /(?! \\ (other \\ )). * Controller/Users/show /Users/show Controller$ Controller All Controller Actions ControllerCPU/ ControllerCPU/Users/Show /Users/show For more information, see the API documentation for ActionController. Errors This metric tracks the number of errors or exceptions raised while processing requests. regex sample metric legend name Errors/all Errors/all External services External service instrumentation captures calls to out-of-process services such as web services, resources in the cloud and any other network calls. It does not include other first class back-end components such as MemCache and the database. In Ruby applications we instrument the Net::Http library to capture all HTTP services. regex sample metric legend name External/ [ ^/]+/all$ External/service.example.com/all All service.example.com calls External/ External/host.aws.com/Net::Http : :POST Net::Http : :POST [ host.aws.com] External/all$ External/all External Services External/ [ ^/]+/(?!all)/ External/service.example.com/all All service.example.com calls HTTP dispatcher This metric represents a summary of the throughput and response time of all web requests. regex sample metric legend name ^HttpDispatcher$ HttpDispatcher HttpDispatcher MemCache MemCache is a popular technology that enables applications to access shared memory provided by any number of physical machines as a global cache. Applications that heavily use the database often use MemCache for performance and scalability benefits. These metrics measure the frequency and response time of calls to MemCache to read and write data from the cache. Response times should be low (less than 5 ms) for a well performing MemCache deployment. regex sample metric legend name MemCache/. * MemCache/read MemCache read operations MemCache/read MemCache/read MemCache read operations MemCache/write MemCache/write MemCache write operations Mongrel This metric measures the length of the mongrel queue, which holds pending http requests to be processed by mongrel. The HTTP Activity graph overlays the maximimum queue length for a given period. The value is zero if mongrel is processing a request but has no other requests waiting in its queue. When looking at this value across an aggregate cluster of mongrels, the queue lengths of all mongrels is added together, showing the sum of all queue lengths. A mongrel queue length should be at or near zero; if it is consistently at a higher level, then it indicates that your rails application is having trouble keeping up with its load requirements. regex sample metric legend name Mongrel/Queue Length Mongrel/Queue Length Queue Length View ActionView is a package in Rails that is used to render the output that is the response to an http request, such as an html page or an xml document. The View is rendered by the controller that is handling the request. If View metrics represent a large portion of your controller's response time, it could mean you are doing a lot of database operations inside the view template itself. regex sample metric legend name View/. * View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Partial View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Rendering View/Users/show.html.erb/Rendering Users/show.html.erb For more information, see the API documentation for ActionView. Metrics attached to events (used by Infrastructure, other products) Because event-type data can have any type of key-value pair data attached to it, one way metrics can be reported is as attributes attached to an event. A couple examples of this at New Relic: Our infrastructure monitoring reports many metrics that are attached to events. For example, we report a ProcessSample event, which has various sample-based metrics attached to it, like CPU percentage. To learn more about infrastructure monitoring data, see Infrastructure data. In APM, the Transaction event has several metrics attached to it, including databaseDuration. To learn more about this data and how to query it, see Events. Metrics as a computation of events (used in some charts and queries) Metrics can be formed by counting New Relic events, or doing some other mathematical calculation on those events. For example, if you wanted to measure the total number of Transaction events over the last half hour, you might run this NRQL query: Select count(*) from Transaction since 30 minutes ago Copy Another example: if you wanted to compute the average response time for your service, you might run a query like: FROM Transaction SELECT average(duration) SINCE 30 minutes ago Copy Some New Relic charts are generated with these kinds of queries. The downside of this approach is that there are limits on how many events a monitoring system (including ours) can report. This means that sometimes, for high-throughput systems, the count may not accurately represent the total activity on that system. To learn more about how this can be addressed, see Event limits and sampling. Want to report custom metrics? See Get data into New Relic. Event data First, we’ll explain the definition of events from a monitoring industry perspective, and then we’ll explain some specifics about how New Relic handles event data. Events in the monitoring industry In the software industry, events can be thought of as simply “things that occur in a system.” For example, a server setting being changed would be an event. Another example: a website user clicking a mouse. Some events will generate a stored record, and that record is typically also called an event. Event data represents discrete occurrences and typically will have a high level of detail, so event data is suited for detailed analysis and querying. The downside to the use of event data is that there are typically so many events reported that it can become difficult to query that large dataset over longer time ranges. Events at New Relic At New Relic, we report events to data objects also called events. These events have multiple attributes (key-value pairs) attached. Event data is used in some UI charts and tables, and you can also query it. How long event data remains available is determined by data retention rules. One example of an event: APM reports an event type named Transaction, which represents a logical unit of work in an application. To see the attributes attached to this event, you could use a NRQL query like: Select * from Transaction Copy For examples of querying event data, see Introduction to NRQL. Other details about New Relic event data: Events can have any type of attributes attached. Some events have attributes that report metric data. You can report custom events. To increase the availability of your event data for querying/charting, you can turn events into metrics. Some systems generate a large number of events that exceeds collection limits and results in incomplete query results. For more on this, see Event sampling. Because event is a general term, in some New Relic contexts it will refer to any data type that can be queried via NRQL. For example, when you run a NRQL query, it returns a count of inspected events: this is a count of all data types queried. Log data First, we’ll explain the definition of logs from a monitoring industry perspective, and then we’ll explain some specifics about how New Relic handles log reporting. Logs in the monitoring industry A log is a message about a system used to understand the activity of the system and to diagnose problems. Logs at New Relic New Relic's Logs gives you a centralized log management platform that connects your log data with other New Relic-monitored data. For example, you can see logs alongside your APM data. In New Relic, log data is reported with multiple attributes (key-value data) attached. To query your log data, you could use a NRQL query like: Select * from Log Copy To report custom log data, see the Log API. Trace data First, we’ll explain the definition of traces from a monitoring industry perspective, and then we’ll explain some specifics about how New Relic handles tracing. Tracing in the monitoring industry In the application/infrastructure-monitoring world, tracing is a general term used to refer to various ways to report information about how a program or system is operating. For example, a stack trace provides in-depth information about a program’s subroutines. For large modern systems, which are often distributed across many services and micro-services, “tracing” often refers to distributed tracing, which is a way to monitor requests as they propagate through a complex, distributed environment. Tracing at New Relic New Relic offers a distributed tracing feature that tracks requests across a distributed system, and provides a dedicated UI for understanding and analyzing your traces. In New Relic, trace data is reported as Span objects, with multiple attributes (key-value pairs) attached. To query your tracing data, you could use a NRQL query like: Select * from Span Copy To learn more about how distributed tracing works, see Understand distributed tracing. To report custom distributed tracing data, see the Trace API. Query and send data Understanding New Relic data types can help you: Query data in New Relic Send data to New Relic Learn more For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 320.80988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>data</em> types",
        "sections": "Query <em>and</em> send <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic <em>platform</em> is built around the four fundamental <em>telemetry</em> <em>data</em> types we believe are necessary for complete and effective system monitoring: metrics, events, logs, and traces. Get started This doc will give you a fairly technical explanation of our core <em>data</em> types, their structure"
      },
      "id": "6045280de7b9d266e1579a0f"
    },
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-05-21T14:33:29Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.68222,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric API limits <em>and</em> restricted attributes",
        "sections": "Max <em>data</em> points per minute (DPM)",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic <em>platform</em>. Any values submitted with these keys in the attributes section of a metric <em>data</em> point will cause the <em>data</em> point to be dropped, or the value to be omitted"
      },
      "id": "603ea95128ccbca08eeba7a6"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/introduction-query-builder": [
    {
      "sections": [
        "Introduction to the data explorer",
        "Tip",
        "Why it matters",
        "Query your data",
        "Use the data explorer",
        "Explore your events",
        "Explore your metrics",
        "Important",
        "Visualize and refine your exploration",
        "Querying area",
        "NRQL query display",
        "Chart area",
        "Share and export",
        "Use cases",
        "Discover your new data",
        "Validate your data",
        "Troubleshooting data issues"
      ],
      "title": "Introduction to the data explorer",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Explore data"
      ],
      "external_id": "9b8a2973c9d452ded5ee065240d210a7fd65d4b3",
      "image": "https://docs.newrelic.com/static/e31aec3eac2aa8c43b9e0332f87f033b/38cea/browse_data_explorer.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/get-started/introduction-data-explorer/",
      "published_at": "2021-05-22T05:31:57Z",
      "updated_at": "2021-05-22T05:31:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the data explorer you can navigate all your data visually, without any NRQL knowledge. Use the data explorer to access, query and customize your data, create visualizations, and make connections between your services in a consistent and curated experience. Tip To use the data explorer and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters Do you research the state of your systems? Do you need to plan resources, identify and respond to incidents, or troubleshoot faulty behaviors? The data explorer makes it easy to identify, fetch and visualize the data you are looking for through visual menus, without ever using NRQL or building queries. With the data explorer you can: Access events and metrics data in a quick, intuitive way. Exploit the dimensionality of data by making it visible and easily actionable upon. See data from different points of view: from raw data to different visualizations that provide insights on evolution, distribution, etc. Drill down into data with filters. Add your searches to a dashboard in a click. Understand how NRQL works: data explorer shows how queries are built while navigating the available data. Tip Want to switch to New Relic One from Insights? See our transition guide. Query your data To access the data explorer, go to one.newrelic.com and At the top of the page, click the Query your data icon. At the Browse data dropdown, select Events or Metrics. The data explorer is the portal to explore all the data you have in New Relic. You can explore events and metrics on the data explorer UI, or select the Logs and Traces query interfaces to explore those. You can also access the query builder any time by clicking on the tab. Use the data explorer The data explorer consists of a scoping section on the top (a), a data browsing area on the left (b), and a workspace (c). To use the data explorer: Define the scope of the exploration: select the account and data type (metric or event) you want to browse. Select the time range using the time picker. Use the blocks on the left to browse the available data for either events or metrics, and build your search. You can only select one element per block. Blocks are searchable. Explore your events Event type Lists all available events for the selected account. By default, events are sorted by Name. Plot Lists all the numeric attributes of the event previously selected. The first item on the list is count( * ), which is not an attribute. It calculates the count of the selected event. By default attributes are sorted by Name. Select the function that you want to plot. By default each attribute is set to the function Average. Dimensions Lists all the dimensions of the event and plot previously selected. Dimensions are string values that provide information on the event. They represent the cardinality, that is, the uniqueCount of the different values of that attribute in the selected time range. If there is only one element it shows the value of the attribute. By default, dimensions are sorted by Name. Explore your metrics To explore APM timeslice data, select AppID, AppName, or EntityGuid as dimensions (or group by those dimensions). Otherwise, you'll get aggregated data for all entities. Metric Lists all the metrics available for the selected account. By default, metrics are sorted by Name. Dimensions Lists all the dimensions of the metric previously selected. Dimensions are string values that provide information on the metric. They represent the cardinality, that is, the uniqueCount of the different values of that attribute in the selected time range. If there is only one element it shows the value of the attribute. By default, dimensions are by Name. Important We use the metric system (including metric SI prefixes) to display our units. Visualize and refine your exploration The result of your exploration is displayed in the working space on the right. Refine your exploration, or share your chart At the working space you can see: Querying area The querying area breaks down the query into its different constituents. Here you can easily read the result of your exploration as a NRQL query, and check the exact data being plotted. If you are not familiar with NRQL, check this area to learn how queries are built. The different parts of the query are: [ EVENTS ONLY]FROM: the event selected on the first block. SELECT: the plot or metric selected. This input plots only one value and one function. GROUP BY: represents the FACET clause, and groups the data by the selected dimension. LIMIT: type in the amount of values you want to see. WHERE: use this field to further filter results. This input plots n values. Each item can be deleted from the query by clicking on the x. NRQL query display You can see the full query, which is composed by the fields above and the time range selected with the time picker. Tip Need to do more advanced searches or customize your charts? From data explorer you can access query builder to edit the query. Chart area By default data is displayed on a line chart. You can easily change to Area chart, Pie chart, and Bar chart using the chart picker. You can also choose to see your results' raw data as a table, or as in JSON format. If you have selected a dimension, the chart is updated with the different facets. Below the chart you can see the facets' table with the list of facets and the value for each one. Use the facet table to drill down data. By clicking on a facet, it is applied as a filter. The table stays visible so you can easily select another facet to continue your exploration. Share and export You can get the chart as an image, share it as a link, or add it to a dashboard using the Options menu on the top right corner. You can also copy the URL and share your whole exploration with other New Relic users. Use cases See the following examples to learn how and when to use the data explorer. Discover your new data I’ve just connected new instrumentation and want to see if new data is available. Select the account and event or metric that's generating the new data. Use the different tools in the data explorer to toy around the new data that has become available: have a look at the raw data of that event or metric as a table, shape it as a list, or click to see it plotted as a chart. After selecting an event or metric, discover the shape of the data in its dimensions. Guided by cardinality, you can see the different points of view of any data. Found anything relevant? Save it to a dashboard or share it with a colleague. Validate your data I changed a custom event/metric and need to check if this change has been successful. In the data explorer tab, select the account, data type and event/metric you made changes to. Verify the entity is reporting data, and that all the attributes are being plotted. Find the attribute you made changes to and check the update was successful. Troubleshooting data issues I know there’s something off with an event/metric from an alert or dashboard. I need to know the root cause about the event/metric/attribute behavior. In the data explorer, use the menus to select the event or metric that's not behaving as expected and let the data explorer plot that chart. From there, you can drill down in the dimensions of that data and filter by those attributes that are relevant. You can also see that data from different perspectives: its distribution, ranking of values, or evolution over time. Found anything relevant? Save it to a dashboard or share it with a colleague.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 371.57748,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>data</em> <em>explorer</em>",
        "sections": "<em>Query</em> <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " <em>query</em> <em>builder</em> to edit the <em>query</em>. Chart area By default <em>data</em> is displayed on a line chart. You can easily change to Area chart, Pie chart, and Bar chart using the chart picker. You can also choose to see <em>your</em> results&#x27; raw <em>data</em> as a table, or as in JSON format. If you have selected a dimension, the chart"
      },
      "id": "603e962e28ccbc6a92eba7a8"
    },
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "Transitioning from Insights",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-22T05:25:43Z",
      "updated_at": "2021-05-22T05:25:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. View dashboards across your organization using cross-account search. Chart all the events and attributes from everywhere across our platform. For more information, see Data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. Transitioning from Insights Switching to using New Relic One dashboards from our deprecated Insights dashboards? See our transition guide. If you're using the Insights Dashboard API, we have have a migration guide that will help you transition to using the new API. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 360.0396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Organize <em>your</em> dashboards with tags",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " and understand the <em>data</em> you collect. <em>Explore</em> <em>your</em> <em>data</em> and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of <em>your</em> system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive"
      },
      "id": "603ec16028ccbc8d07eba78d"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-05-22T05:24:30Z",
      "updated_at": "2021-05-22T05:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Delete. Editing: To edit a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Edit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 317.43866,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> dashboards",
        "sections": "Add custom visualizations to <em>your</em> dashboards",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/query-builder-basic-mode": [
    {
      "sections": [
        "Introduction to the data explorer",
        "Tip",
        "Why it matters",
        "Query your data",
        "Use the data explorer",
        "Explore your events",
        "Explore your metrics",
        "Important",
        "Visualize and refine your exploration",
        "Querying area",
        "NRQL query display",
        "Chart area",
        "Share and export",
        "Use cases",
        "Discover your new data",
        "Validate your data",
        "Troubleshooting data issues"
      ],
      "title": "Introduction to the data explorer",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Explore data"
      ],
      "external_id": "9b8a2973c9d452ded5ee065240d210a7fd65d4b3",
      "image": "https://docs.newrelic.com/static/e31aec3eac2aa8c43b9e0332f87f033b/38cea/browse_data_explorer.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/get-started/introduction-data-explorer/",
      "published_at": "2021-05-22T05:31:57Z",
      "updated_at": "2021-05-22T05:31:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the data explorer you can navigate all your data visually, without any NRQL knowledge. Use the data explorer to access, query and customize your data, create visualizations, and make connections between your services in a consistent and curated experience. Tip To use the data explorer and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters Do you research the state of your systems? Do you need to plan resources, identify and respond to incidents, or troubleshoot faulty behaviors? The data explorer makes it easy to identify, fetch and visualize the data you are looking for through visual menus, without ever using NRQL or building queries. With the data explorer you can: Access events and metrics data in a quick, intuitive way. Exploit the dimensionality of data by making it visible and easily actionable upon. See data from different points of view: from raw data to different visualizations that provide insights on evolution, distribution, etc. Drill down into data with filters. Add your searches to a dashboard in a click. Understand how NRQL works: data explorer shows how queries are built while navigating the available data. Tip Want to switch to New Relic One from Insights? See our transition guide. Query your data To access the data explorer, go to one.newrelic.com and At the top of the page, click the Query your data icon. At the Browse data dropdown, select Events or Metrics. The data explorer is the portal to explore all the data you have in New Relic. You can explore events and metrics on the data explorer UI, or select the Logs and Traces query interfaces to explore those. You can also access the query builder any time by clicking on the tab. Use the data explorer The data explorer consists of a scoping section on the top (a), a data browsing area on the left (b), and a workspace (c). To use the data explorer: Define the scope of the exploration: select the account and data type (metric or event) you want to browse. Select the time range using the time picker. Use the blocks on the left to browse the available data for either events or metrics, and build your search. You can only select one element per block. Blocks are searchable. Explore your events Event type Lists all available events for the selected account. By default, events are sorted by Name. Plot Lists all the numeric attributes of the event previously selected. The first item on the list is count( * ), which is not an attribute. It calculates the count of the selected event. By default attributes are sorted by Name. Select the function that you want to plot. By default each attribute is set to the function Average. Dimensions Lists all the dimensions of the event and plot previously selected. Dimensions are string values that provide information on the event. They represent the cardinality, that is, the uniqueCount of the different values of that attribute in the selected time range. If there is only one element it shows the value of the attribute. By default, dimensions are sorted by Name. Explore your metrics To explore APM timeslice data, select AppID, AppName, or EntityGuid as dimensions (or group by those dimensions). Otherwise, you'll get aggregated data for all entities. Metric Lists all the metrics available for the selected account. By default, metrics are sorted by Name. Dimensions Lists all the dimensions of the metric previously selected. Dimensions are string values that provide information on the metric. They represent the cardinality, that is, the uniqueCount of the different values of that attribute in the selected time range. If there is only one element it shows the value of the attribute. By default, dimensions are by Name. Important We use the metric system (including metric SI prefixes) to display our units. Visualize and refine your exploration The result of your exploration is displayed in the working space on the right. Refine your exploration, or share your chart At the working space you can see: Querying area The querying area breaks down the query into its different constituents. Here you can easily read the result of your exploration as a NRQL query, and check the exact data being plotted. If you are not familiar with NRQL, check this area to learn how queries are built. The different parts of the query are: [ EVENTS ONLY]FROM: the event selected on the first block. SELECT: the plot or metric selected. This input plots only one value and one function. GROUP BY: represents the FACET clause, and groups the data by the selected dimension. LIMIT: type in the amount of values you want to see. WHERE: use this field to further filter results. This input plots n values. Each item can be deleted from the query by clicking on the x. NRQL query display You can see the full query, which is composed by the fields above and the time range selected with the time picker. Tip Need to do more advanced searches or customize your charts? From data explorer you can access query builder to edit the query. Chart area By default data is displayed on a line chart. You can easily change to Area chart, Pie chart, and Bar chart using the chart picker. You can also choose to see your results' raw data as a table, or as in JSON format. If you have selected a dimension, the chart is updated with the different facets. Below the chart you can see the facets' table with the list of facets and the value for each one. Use the facet table to drill down data. By clicking on a facet, it is applied as a filter. The table stays visible so you can easily select another facet to continue your exploration. Share and export You can get the chart as an image, share it as a link, or add it to a dashboard using the Options menu on the top right corner. You can also copy the URL and share your whole exploration with other New Relic users. Use cases See the following examples to learn how and when to use the data explorer. Discover your new data I’ve just connected new instrumentation and want to see if new data is available. Select the account and event or metric that's generating the new data. Use the different tools in the data explorer to toy around the new data that has become available: have a look at the raw data of that event or metric as a table, shape it as a list, or click to see it plotted as a chart. After selecting an event or metric, discover the shape of the data in its dimensions. Guided by cardinality, you can see the different points of view of any data. Found anything relevant? Save it to a dashboard or share it with a colleague. Validate your data I changed a custom event/metric and need to check if this change has been successful. In the data explorer tab, select the account, data type and event/metric you made changes to. Verify the entity is reporting data, and that all the attributes are being plotted. Find the attribute you made changes to and check the update was successful. Troubleshooting data issues I know there’s something off with an event/metric from an alert or dashboard. I need to know the root cause about the event/metric/attribute behavior. In the data explorer, use the menus to select the event or metric that's not behaving as expected and let the data explorer plot that chart. From there, you can drill down in the dimensions of that data and filter by those attributes that are relevant. You can also see that data from different perspectives: its distribution, ranking of values, or evolution over time. Found anything relevant? Save it to a dashboard or share it with a colleague.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 371.5772,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>data</em> <em>explorer</em>",
        "sections": "<em>Query</em> <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " <em>query</em> <em>builder</em> to edit the <em>query</em>. Chart area By default <em>data</em> is displayed on a line chart. You can easily change to Area chart, Pie chart, and Bar chart using the chart picker. You can also choose to see <em>your</em> results&#x27; raw <em>data</em> as a table, or as in JSON format. If you have selected a dimension, the chart"
      },
      "id": "603e962e28ccbc6a92eba7a8"
    },
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "Transitioning from Insights",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-22T05:25:43Z",
      "updated_at": "2021-05-22T05:25:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. View dashboards across your organization using cross-account search. Chart all the events and attributes from everywhere across our platform. For more information, see Data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. Transitioning from Insights Switching to using New Relic One dashboards from our deprecated Insights dashboards? See our transition guide. If you're using the Insights Dashboard API, we have have a migration guide that will help you transition to using the new API. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 360.03937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Organize <em>your</em> dashboards with tags",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " and understand the <em>data</em> you collect. <em>Explore</em> <em>your</em> <em>data</em> and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of <em>your</em> system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive"
      },
      "id": "603ec16028ccbc8d07eba78d"
    },
    {
      "sections": [
        "Introduction to the query builder",
        "Important",
        "Why it matters",
        "Get started",
        "Use the query builder: basic and advanced modes",
        "Tip",
        "Basic mode",
        "Advanced (NRQL) mode",
        "Advanced (PromQL-style) mode",
        "Use your charts"
      ],
      "title": "Introduction to the query builder",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "5d862557e0e3f4ef89dbd7da6ffdbe0d358790d2",
      "image": "https://docs.newrelic.com/static/30b623e8356b28b9361bedb0813db4c6/8c557/querybuilder04.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/introduction-query-builder/",
      "published_at": "2021-05-22T05:32:51Z",
      "updated_at": "2021-05-15T22:25:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the query builder, you can run queries of your data to create custom charts and other visualizations. You can also build custom dashboards containing multiple charts. Important Are you a New Relic Insights user? See our transition guide. Why it matters Modern business systems are a complex maze of data-generating elements. You need an easy, solid way to fetch, analyze, and visualize the never-ending stream of data flowing from your daily working activities. Use the query builder to: Quickly access your data and build customized charts to learn and understand the health of your infrastructure, applications, and other services. Add charts to your dashboards to obtain a complete real-time view of the state of your system. Share your charts with colleagues or users in just two clicks. Get acquainted with querying by using basic mode, then switch to advanced mode to refine your charts using NRQL. Get started Before querying, you may want to read Introduction to querying and how to explore your data. To find the query builder, go to one.newrelic.com and click Query your data. Use the query builder: basic and advanced modes The query builder has several modes: Basic mode Advanced (NRQL) mode Advanced (PromQL-style) mode Tip You can also switch to the Data explorer tab at any time to browse your data and create charts visually, without performing queries. Basic mode Basic mode doesn't require a query language, and so it's useful if you aren't familiar with NRQL or SQL. It's also a quick way to answer one-off questions, such as how many cities outside of the United States are accessing the shopping site for your company. one.newrelic.com > Query your data > Query builder > Basic mode Use basic mode to guide you through the process to specify data for a chart. With basic mode you can: Choose your data source. In basic mode, you start by selecting an event and then picking the attribute that corresponds to the information to show in your chart. Specify (filter) the data for your chart. You can narrow the results and choose an attribute to facet by. Select the time range to present in the chart. You can select a time range from the menu or use the custom option to create your own time range. See Use basic mode for more information about this feature. Advanced (NRQL) mode With the advanced (NRQL) mode you can create your own queries using the NRQL query language. NRQL queries may be simple or complex, depending on what data you want to use and how to display it in your chart. This example of the advanced mode shows the NRQL query with the same data as used in basic mode. one.newrelic.com > Query your data > Query builder > Advanced (NRQL). Use advanced (NRQL) mode to write a query that specifies data for a chart. Tip With APM's real time streaming, you can query and visualize your data for transactions, errors, and custom events in dashboards. See Use advanced (NRQL) mode for more information about using this feature. Advanced (PromQL-style) mode With the advanced (PromQL-style) mode you can run basic PromQL-style queries. You can switch between basic and advanced modes while defining your query in order to: customize some of the values. learn how NRQL queries are structured using the data you specified in basic mode. Important If you build your query in basic mode and update it using advanced mode, you cannot return to basic mode to edit that query. You must make any additional changes in advanced (NRQL) mode. Once you specify the data you want, your chart is ready to view. Your query automatically runs in basic mode as you make changes to the inputs. If using advanced (NRQL or PromQL-style) mode, run your query. Use your charts Once you have built your chart you can: Change the type of chart. Based on the data you specified, the query builder selects the chart type that displays your results most effectively. However, you can choose from other available chart types to present your data in the visual format that you want to use. Share your chart. Add your chart to a dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.58243,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>query</em> <em>builder</em>",
        "sections": "Use the <em>query</em> <em>builder</em>: basic <em>and</em> advanced modes",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " using NRQL. Get started Before querying, you may want to read Introduction to querying and how to <em>explore</em> <em>your</em> <em>data</em>. To find the <em>query</em> <em>builder</em>, go to one.newrelic.com and click <em>Query</em> <em>your</em> <em>data</em>. Use the <em>query</em> <em>builder</em>: basic and advanced modes The <em>query</em> <em>builder</em> has several modes: Basic mode Advanced"
      },
      "id": "603ec08f196a67f7b7a83dd2"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/use-advanced-nrql-mode-query-data": [
    {
      "sections": [
        "Introduction to the data explorer",
        "Tip",
        "Why it matters",
        "Query your data",
        "Use the data explorer",
        "Explore your events",
        "Explore your metrics",
        "Important",
        "Visualize and refine your exploration",
        "Querying area",
        "NRQL query display",
        "Chart area",
        "Share and export",
        "Use cases",
        "Discover your new data",
        "Validate your data",
        "Troubleshooting data issues"
      ],
      "title": "Introduction to the data explorer",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Explore data"
      ],
      "external_id": "9b8a2973c9d452ded5ee065240d210a7fd65d4b3",
      "image": "https://docs.newrelic.com/static/e31aec3eac2aa8c43b9e0332f87f033b/38cea/browse_data_explorer.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/get-started/introduction-data-explorer/",
      "published_at": "2021-05-22T05:31:57Z",
      "updated_at": "2021-05-22T05:31:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the data explorer you can navigate all your data visually, without any NRQL knowledge. Use the data explorer to access, query and customize your data, create visualizations, and make connections between your services in a consistent and curated experience. Tip To use the data explorer and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters Do you research the state of your systems? Do you need to plan resources, identify and respond to incidents, or troubleshoot faulty behaviors? The data explorer makes it easy to identify, fetch and visualize the data you are looking for through visual menus, without ever using NRQL or building queries. With the data explorer you can: Access events and metrics data in a quick, intuitive way. Exploit the dimensionality of data by making it visible and easily actionable upon. See data from different points of view: from raw data to different visualizations that provide insights on evolution, distribution, etc. Drill down into data with filters. Add your searches to a dashboard in a click. Understand how NRQL works: data explorer shows how queries are built while navigating the available data. Tip Want to switch to New Relic One from Insights? See our transition guide. Query your data To access the data explorer, go to one.newrelic.com and At the top of the page, click the Query your data icon. At the Browse data dropdown, select Events or Metrics. The data explorer is the portal to explore all the data you have in New Relic. You can explore events and metrics on the data explorer UI, or select the Logs and Traces query interfaces to explore those. You can also access the query builder any time by clicking on the tab. Use the data explorer The data explorer consists of a scoping section on the top (a), a data browsing area on the left (b), and a workspace (c). To use the data explorer: Define the scope of the exploration: select the account and data type (metric or event) you want to browse. Select the time range using the time picker. Use the blocks on the left to browse the available data for either events or metrics, and build your search. You can only select one element per block. Blocks are searchable. Explore your events Event type Lists all available events for the selected account. By default, events are sorted by Name. Plot Lists all the numeric attributes of the event previously selected. The first item on the list is count( * ), which is not an attribute. It calculates the count of the selected event. By default attributes are sorted by Name. Select the function that you want to plot. By default each attribute is set to the function Average. Dimensions Lists all the dimensions of the event and plot previously selected. Dimensions are string values that provide information on the event. They represent the cardinality, that is, the uniqueCount of the different values of that attribute in the selected time range. If there is only one element it shows the value of the attribute. By default, dimensions are sorted by Name. Explore your metrics To explore APM timeslice data, select AppID, AppName, or EntityGuid as dimensions (or group by those dimensions). Otherwise, you'll get aggregated data for all entities. Metric Lists all the metrics available for the selected account. By default, metrics are sorted by Name. Dimensions Lists all the dimensions of the metric previously selected. Dimensions are string values that provide information on the metric. They represent the cardinality, that is, the uniqueCount of the different values of that attribute in the selected time range. If there is only one element it shows the value of the attribute. By default, dimensions are by Name. Important We use the metric system (including metric SI prefixes) to display our units. Visualize and refine your exploration The result of your exploration is displayed in the working space on the right. Refine your exploration, or share your chart At the working space you can see: Querying area The querying area breaks down the query into its different constituents. Here you can easily read the result of your exploration as a NRQL query, and check the exact data being plotted. If you are not familiar with NRQL, check this area to learn how queries are built. The different parts of the query are: [ EVENTS ONLY]FROM: the event selected on the first block. SELECT: the plot or metric selected. This input plots only one value and one function. GROUP BY: represents the FACET clause, and groups the data by the selected dimension. LIMIT: type in the amount of values you want to see. WHERE: use this field to further filter results. This input plots n values. Each item can be deleted from the query by clicking on the x. NRQL query display You can see the full query, which is composed by the fields above and the time range selected with the time picker. Tip Need to do more advanced searches or customize your charts? From data explorer you can access query builder to edit the query. Chart area By default data is displayed on a line chart. You can easily change to Area chart, Pie chart, and Bar chart using the chart picker. You can also choose to see your results' raw data as a table, or as in JSON format. If you have selected a dimension, the chart is updated with the different facets. Below the chart you can see the facets' table with the list of facets and the value for each one. Use the facet table to drill down data. By clicking on a facet, it is applied as a filter. The table stays visible so you can easily select another facet to continue your exploration. Share and export You can get the chart as an image, share it as a link, or add it to a dashboard using the Options menu on the top right corner. You can also copy the URL and share your whole exploration with other New Relic users. Use cases See the following examples to learn how and when to use the data explorer. Discover your new data I’ve just connected new instrumentation and want to see if new data is available. Select the account and event or metric that's generating the new data. Use the different tools in the data explorer to toy around the new data that has become available: have a look at the raw data of that event or metric as a table, shape it as a list, or click to see it plotted as a chart. After selecting an event or metric, discover the shape of the data in its dimensions. Guided by cardinality, you can see the different points of view of any data. Found anything relevant? Save it to a dashboard or share it with a colleague. Validate your data I changed a custom event/metric and need to check if this change has been successful. In the data explorer tab, select the account, data type and event/metric you made changes to. Verify the entity is reporting data, and that all the attributes are being plotted. Find the attribute you made changes to and check the update was successful. Troubleshooting data issues I know there’s something off with an event/metric from an alert or dashboard. I need to know the root cause about the event/metric/attribute behavior. In the data explorer, use the menus to select the event or metric that's not behaving as expected and let the data explorer plot that chart. From there, you can drill down in the dimensions of that data and filter by those attributes that are relevant. You can also see that data from different perspectives: its distribution, ranking of values, or evolution over time. Found anything relevant? Save it to a dashboard or share it with a colleague.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 371.5772,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>data</em> <em>explorer</em>",
        "sections": "<em>Query</em> <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " <em>query</em> <em>builder</em> to edit the <em>query</em>. Chart area By default <em>data</em> is displayed on a line chart. You can easily change to Area chart, Pie chart, and Bar chart using the chart picker. You can also choose to see <em>your</em> results&#x27; raw <em>data</em> as a table, or as in JSON format. If you have selected a dimension, the chart"
      },
      "id": "603e962e28ccbc6a92eba7a8"
    },
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "Transitioning from Insights",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-22T05:25:43Z",
      "updated_at": "2021-05-22T05:25:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. View dashboards across your organization using cross-account search. Chart all the events and attributes from everywhere across our platform. For more information, see Data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. Transitioning from Insights Switching to using New Relic One dashboards from our deprecated Insights dashboards? See our transition guide. If you're using the Insights Dashboard API, we have have a migration guide that will help you transition to using the new API. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 360.03937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Organize <em>your</em> dashboards with tags",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " and understand the <em>data</em> you collect. <em>Explore</em> <em>your</em> <em>data</em> and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of <em>your</em> system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive"
      },
      "id": "603ec16028ccbc8d07eba78d"
    },
    {
      "sections": [
        "Introduction to the query builder",
        "Important",
        "Why it matters",
        "Get started",
        "Use the query builder: basic and advanced modes",
        "Tip",
        "Basic mode",
        "Advanced (NRQL) mode",
        "Advanced (PromQL-style) mode",
        "Use your charts"
      ],
      "title": "Introduction to the query builder",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "5d862557e0e3f4ef89dbd7da6ffdbe0d358790d2",
      "image": "https://docs.newrelic.com/static/30b623e8356b28b9361bedb0813db4c6/8c557/querybuilder04.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/introduction-query-builder/",
      "published_at": "2021-05-22T05:32:51Z",
      "updated_at": "2021-05-15T22:25:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the query builder, you can run queries of your data to create custom charts and other visualizations. You can also build custom dashboards containing multiple charts. Important Are you a New Relic Insights user? See our transition guide. Why it matters Modern business systems are a complex maze of data-generating elements. You need an easy, solid way to fetch, analyze, and visualize the never-ending stream of data flowing from your daily working activities. Use the query builder to: Quickly access your data and build customized charts to learn and understand the health of your infrastructure, applications, and other services. Add charts to your dashboards to obtain a complete real-time view of the state of your system. Share your charts with colleagues or users in just two clicks. Get acquainted with querying by using basic mode, then switch to advanced mode to refine your charts using NRQL. Get started Before querying, you may want to read Introduction to querying and how to explore your data. To find the query builder, go to one.newrelic.com and click Query your data. Use the query builder: basic and advanced modes The query builder has several modes: Basic mode Advanced (NRQL) mode Advanced (PromQL-style) mode Tip You can also switch to the Data explorer tab at any time to browse your data and create charts visually, without performing queries. Basic mode Basic mode doesn't require a query language, and so it's useful if you aren't familiar with NRQL or SQL. It's also a quick way to answer one-off questions, such as how many cities outside of the United States are accessing the shopping site for your company. one.newrelic.com > Query your data > Query builder > Basic mode Use basic mode to guide you through the process to specify data for a chart. With basic mode you can: Choose your data source. In basic mode, you start by selecting an event and then picking the attribute that corresponds to the information to show in your chart. Specify (filter) the data for your chart. You can narrow the results and choose an attribute to facet by. Select the time range to present in the chart. You can select a time range from the menu or use the custom option to create your own time range. See Use basic mode for more information about this feature. Advanced (NRQL) mode With the advanced (NRQL) mode you can create your own queries using the NRQL query language. NRQL queries may be simple or complex, depending on what data you want to use and how to display it in your chart. This example of the advanced mode shows the NRQL query with the same data as used in basic mode. one.newrelic.com > Query your data > Query builder > Advanced (NRQL). Use advanced (NRQL) mode to write a query that specifies data for a chart. Tip With APM's real time streaming, you can query and visualize your data for transactions, errors, and custom events in dashboards. See Use advanced (NRQL) mode for more information about using this feature. Advanced (PromQL-style) mode With the advanced (PromQL-style) mode you can run basic PromQL-style queries. You can switch between basic and advanced modes while defining your query in order to: customize some of the values. learn how NRQL queries are structured using the data you specified in basic mode. Important If you build your query in basic mode and update it using advanced mode, you cannot return to basic mode to edit that query. You must make any additional changes in advanced (NRQL) mode. Once you specify the data you want, your chart is ready to view. Your query automatically runs in basic mode as you make changes to the inputs. If using advanced (NRQL or PromQL-style) mode, run your query. Use your charts Once you have built your chart you can: Change the type of chart. Based on the data you specified, the query builder selects the chart type that displays your results most effectively. However, you can choose from other available chart types to present your data in the visual format that you want to use. Share your chart. Add your chart to a dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.58243,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>query</em> <em>builder</em>",
        "sections": "Use the <em>query</em> <em>builder</em>: basic <em>and</em> advanced modes",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " using NRQL. Get started Before querying, you may want to read Introduction to querying and how to <em>explore</em> <em>your</em> <em>data</em>. To find the <em>query</em> <em>builder</em>, go to one.newrelic.com and click <em>Query</em> <em>your</em> <em>data</em>. Use the <em>query</em> <em>builder</em>: basic and advanced modes The <em>query</em> <em>builder</em> has several modes: Basic mode Advanced"
      },
      "id": "603ec08f196a67f7b7a83dd2"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/use-advanced-promql-style-mode-query-data": [
    {
      "sections": [
        "Introduction to the data explorer",
        "Tip",
        "Why it matters",
        "Query your data",
        "Use the data explorer",
        "Explore your events",
        "Explore your metrics",
        "Important",
        "Visualize and refine your exploration",
        "Querying area",
        "NRQL query display",
        "Chart area",
        "Share and export",
        "Use cases",
        "Discover your new data",
        "Validate your data",
        "Troubleshooting data issues"
      ],
      "title": "Introduction to the data explorer",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Explore data"
      ],
      "external_id": "9b8a2973c9d452ded5ee065240d210a7fd65d4b3",
      "image": "https://docs.newrelic.com/static/e31aec3eac2aa8c43b9e0332f87f033b/38cea/browse_data_explorer.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/get-started/introduction-data-explorer/",
      "published_at": "2021-05-22T05:31:57Z",
      "updated_at": "2021-05-22T05:31:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the data explorer you can navigate all your data visually, without any NRQL knowledge. Use the data explorer to access, query and customize your data, create visualizations, and make connections between your services in a consistent and curated experience. Tip To use the data explorer and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters Do you research the state of your systems? Do you need to plan resources, identify and respond to incidents, or troubleshoot faulty behaviors? The data explorer makes it easy to identify, fetch and visualize the data you are looking for through visual menus, without ever using NRQL or building queries. With the data explorer you can: Access events and metrics data in a quick, intuitive way. Exploit the dimensionality of data by making it visible and easily actionable upon. See data from different points of view: from raw data to different visualizations that provide insights on evolution, distribution, etc. Drill down into data with filters. Add your searches to a dashboard in a click. Understand how NRQL works: data explorer shows how queries are built while navigating the available data. Tip Want to switch to New Relic One from Insights? See our transition guide. Query your data To access the data explorer, go to one.newrelic.com and At the top of the page, click the Query your data icon. At the Browse data dropdown, select Events or Metrics. The data explorer is the portal to explore all the data you have in New Relic. You can explore events and metrics on the data explorer UI, or select the Logs and Traces query interfaces to explore those. You can also access the query builder any time by clicking on the tab. Use the data explorer The data explorer consists of a scoping section on the top (a), a data browsing area on the left (b), and a workspace (c). To use the data explorer: Define the scope of the exploration: select the account and data type (metric or event) you want to browse. Select the time range using the time picker. Use the blocks on the left to browse the available data for either events or metrics, and build your search. You can only select one element per block. Blocks are searchable. Explore your events Event type Lists all available events for the selected account. By default, events are sorted by Name. Plot Lists all the numeric attributes of the event previously selected. The first item on the list is count( * ), which is not an attribute. It calculates the count of the selected event. By default attributes are sorted by Name. Select the function that you want to plot. By default each attribute is set to the function Average. Dimensions Lists all the dimensions of the event and plot previously selected. Dimensions are string values that provide information on the event. They represent the cardinality, that is, the uniqueCount of the different values of that attribute in the selected time range. If there is only one element it shows the value of the attribute. By default, dimensions are sorted by Name. Explore your metrics To explore APM timeslice data, select AppID, AppName, or EntityGuid as dimensions (or group by those dimensions). Otherwise, you'll get aggregated data for all entities. Metric Lists all the metrics available for the selected account. By default, metrics are sorted by Name. Dimensions Lists all the dimensions of the metric previously selected. Dimensions are string values that provide information on the metric. They represent the cardinality, that is, the uniqueCount of the different values of that attribute in the selected time range. If there is only one element it shows the value of the attribute. By default, dimensions are by Name. Important We use the metric system (including metric SI prefixes) to display our units. Visualize and refine your exploration The result of your exploration is displayed in the working space on the right. Refine your exploration, or share your chart At the working space you can see: Querying area The querying area breaks down the query into its different constituents. Here you can easily read the result of your exploration as a NRQL query, and check the exact data being plotted. If you are not familiar with NRQL, check this area to learn how queries are built. The different parts of the query are: [ EVENTS ONLY]FROM: the event selected on the first block. SELECT: the plot or metric selected. This input plots only one value and one function. GROUP BY: represents the FACET clause, and groups the data by the selected dimension. LIMIT: type in the amount of values you want to see. WHERE: use this field to further filter results. This input plots n values. Each item can be deleted from the query by clicking on the x. NRQL query display You can see the full query, which is composed by the fields above and the time range selected with the time picker. Tip Need to do more advanced searches or customize your charts? From data explorer you can access query builder to edit the query. Chart area By default data is displayed on a line chart. You can easily change to Area chart, Pie chart, and Bar chart using the chart picker. You can also choose to see your results' raw data as a table, or as in JSON format. If you have selected a dimension, the chart is updated with the different facets. Below the chart you can see the facets' table with the list of facets and the value for each one. Use the facet table to drill down data. By clicking on a facet, it is applied as a filter. The table stays visible so you can easily select another facet to continue your exploration. Share and export You can get the chart as an image, share it as a link, or add it to a dashboard using the Options menu on the top right corner. You can also copy the URL and share your whole exploration with other New Relic users. Use cases See the following examples to learn how and when to use the data explorer. Discover your new data I’ve just connected new instrumentation and want to see if new data is available. Select the account and event or metric that's generating the new data. Use the different tools in the data explorer to toy around the new data that has become available: have a look at the raw data of that event or metric as a table, shape it as a list, or click to see it plotted as a chart. After selecting an event or metric, discover the shape of the data in its dimensions. Guided by cardinality, you can see the different points of view of any data. Found anything relevant? Save it to a dashboard or share it with a colleague. Validate your data I changed a custom event/metric and need to check if this change has been successful. In the data explorer tab, select the account, data type and event/metric you made changes to. Verify the entity is reporting data, and that all the attributes are being plotted. Find the attribute you made changes to and check the update was successful. Troubleshooting data issues I know there’s something off with an event/metric from an alert or dashboard. I need to know the root cause about the event/metric/attribute behavior. In the data explorer, use the menus to select the event or metric that's not behaving as expected and let the data explorer plot that chart. From there, you can drill down in the dimensions of that data and filter by those attributes that are relevant. You can also see that data from different perspectives: its distribution, ranking of values, or evolution over time. Found anything relevant? Save it to a dashboard or share it with a colleague.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 371.57697,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>data</em> <em>explorer</em>",
        "sections": "<em>Query</em> <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " <em>query</em> <em>builder</em> to edit the <em>query</em>. Chart area By default <em>data</em> is displayed on a line chart. You can easily change to Area chart, Pie chart, and Bar chart using the chart picker. You can also choose to see <em>your</em> results&#x27; raw <em>data</em> as a table, or as in JSON format. If you have selected a dimension, the chart"
      },
      "id": "603e962e28ccbc6a92eba7a8"
    },
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "Transitioning from Insights",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-22T05:25:43Z",
      "updated_at": "2021-05-22T05:25:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. View dashboards across your organization using cross-account search. Chart all the events and attributes from everywhere across our platform. For more information, see Data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. Transitioning from Insights Switching to using New Relic One dashboards from our deprecated Insights dashboards? See our transition guide. If you're using the Insights Dashboard API, we have have a migration guide that will help you transition to using the new API. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 360.03912,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Organize <em>your</em> dashboards with tags",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " and understand the <em>data</em> you collect. <em>Explore</em> <em>your</em> <em>data</em> and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of <em>your</em> system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive"
      },
      "id": "603ec16028ccbc8d07eba78d"
    },
    {
      "sections": [
        "Introduction to the query builder",
        "Important",
        "Why it matters",
        "Get started",
        "Use the query builder: basic and advanced modes",
        "Tip",
        "Basic mode",
        "Advanced (NRQL) mode",
        "Advanced (PromQL-style) mode",
        "Use your charts"
      ],
      "title": "Introduction to the query builder",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "5d862557e0e3f4ef89dbd7da6ffdbe0d358790d2",
      "image": "https://docs.newrelic.com/static/30b623e8356b28b9361bedb0813db4c6/8c557/querybuilder04.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/introduction-query-builder/",
      "published_at": "2021-05-22T05:32:51Z",
      "updated_at": "2021-05-15T22:25:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the query builder, you can run queries of your data to create custom charts and other visualizations. You can also build custom dashboards containing multiple charts. Important Are you a New Relic Insights user? See our transition guide. Why it matters Modern business systems are a complex maze of data-generating elements. You need an easy, solid way to fetch, analyze, and visualize the never-ending stream of data flowing from your daily working activities. Use the query builder to: Quickly access your data and build customized charts to learn and understand the health of your infrastructure, applications, and other services. Add charts to your dashboards to obtain a complete real-time view of the state of your system. Share your charts with colleagues or users in just two clicks. Get acquainted with querying by using basic mode, then switch to advanced mode to refine your charts using NRQL. Get started Before querying, you may want to read Introduction to querying and how to explore your data. To find the query builder, go to one.newrelic.com and click Query your data. Use the query builder: basic and advanced modes The query builder has several modes: Basic mode Advanced (NRQL) mode Advanced (PromQL-style) mode Tip You can also switch to the Data explorer tab at any time to browse your data and create charts visually, without performing queries. Basic mode Basic mode doesn't require a query language, and so it's useful if you aren't familiar with NRQL or SQL. It's also a quick way to answer one-off questions, such as how many cities outside of the United States are accessing the shopping site for your company. one.newrelic.com > Query your data > Query builder > Basic mode Use basic mode to guide you through the process to specify data for a chart. With basic mode you can: Choose your data source. In basic mode, you start by selecting an event and then picking the attribute that corresponds to the information to show in your chart. Specify (filter) the data for your chart. You can narrow the results and choose an attribute to facet by. Select the time range to present in the chart. You can select a time range from the menu or use the custom option to create your own time range. See Use basic mode for more information about this feature. Advanced (NRQL) mode With the advanced (NRQL) mode you can create your own queries using the NRQL query language. NRQL queries may be simple or complex, depending on what data you want to use and how to display it in your chart. This example of the advanced mode shows the NRQL query with the same data as used in basic mode. one.newrelic.com > Query your data > Query builder > Advanced (NRQL). Use advanced (NRQL) mode to write a query that specifies data for a chart. Tip With APM's real time streaming, you can query and visualize your data for transactions, errors, and custom events in dashboards. See Use advanced (NRQL) mode for more information about using this feature. Advanced (PromQL-style) mode With the advanced (PromQL-style) mode you can run basic PromQL-style queries. You can switch between basic and advanced modes while defining your query in order to: customize some of the values. learn how NRQL queries are structured using the data you specified in basic mode. Important If you build your query in basic mode and update it using advanced mode, you cannot return to basic mode to edit that query. You must make any additional changes in advanced (NRQL) mode. Once you specify the data you want, your chart is ready to view. Your query automatically runs in basic mode as you make changes to the inputs. If using advanced (NRQL or PromQL-style) mode, run your query. Use your charts Once you have built your chart you can: Change the type of chart. Based on the data you specified, the query builder selects the chart type that displays your results most effectively. However, you can choose from other available chart types to present your data in the visual format that you want to use. Share your chart. Add your chart to a dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.58234,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>query</em> <em>builder</em>",
        "sections": "Use the <em>query</em> <em>builder</em>: basic <em>and</em> advanced modes",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " using NRQL. Get started Before querying, you may want to read Introduction to querying and how to <em>explore</em> <em>your</em> <em>data</em>. To find the <em>query</em> <em>builder</em>, go to one.newrelic.com and click <em>Query</em> <em>your</em> <em>data</em>. Use the <em>query</em> <em>builder</em>: basic and advanced modes The <em>query</em> <em>builder</em> has several modes: Basic mode Advanced"
      },
      "id": "603ec08f196a67f7b7a83dd2"
    }
  ],
  "/docs/query-your-data/explore-query-data/use-charts/chart-types": [
    {
      "sections": [
        "Use your charts",
        "Change the appearance of your chart",
        "Customize your charts",
        "Tip",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2021-05-22T17:36:05Z",
      "updated_at": "2021-05-15T21:00:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using basic mode to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. To this end, you can customize charts to display information at your convenience. Tip Customizations are available depending on the chart type. Format date and time Tip For table and billboard charts. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Tip For line and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Tip For line and area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Tip For bar and pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 628.91223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  your <em>charts</em> ",
        "sections": "Use your <em>charts</em>",
        "tags": "Use <em>charts</em>",
        "body": " basic mode to specify data, the query builder analyzes your data and applies a <em>chart</em> <em>type</em> that fits your data. For some queries, you&#x27;ll have several options of <em>chart</em> <em>types</em> to choose from. To change <em>chart</em> <em>type</em>, use the <em>Chart</em> <em>type</em> menu to the right of the current <em>chart</em>. Each <em>type</em> in the list has"
      },
      "id": "603ec29a196a67ef5da83d82"
    },
    {
      "sections": [
        "Customize your visualization with SDK components",
        "Course",
        "Tip",
        "Before you begin",
        "Create your visualization",
        "Set up your component state",
        "Add SegmentedControl components",
        "Connect your component's state to the SegmentedControl",
        "Implement a Treemap option",
        "Technical detail",
        "Switch between charts with your component's state",
        "Summary"
      ],
      "title": "Customize your visualization with SDK components",
      "type": "developer",
      "tags": [
        "nr1 cli",
        "NR One Catalog",
        "Subscribe visualizations"
      ],
      "external_id": "8317cf0361e92ab36c922dd87720e01a69530f9b",
      "image": "https://developer.newrelic.com/static/ae9d817689607337734a3d66e12d1dc4/ba3ac/radar-chart-with-segmented-control.png",
      "url": "https://developer.newrelic.com/build-apps/custom-visualizations-and-the-new-relic-one-sdk/",
      "published_at": "2021-05-23T01:43:45Z",
      "updated_at": "2021-05-13T01:45:29Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Customize your visualization",
      "body": "Course This lesson is part of a course that teaches you how to build a custom visualization in the New Relic One platform. Use New Relic One custom visualizations to display your data, whether it's from New Relic's database or an external source, in unique ways that are distinct from the charts offered by the New Relic platform. In this lesson, you build a visualization that displays your data in one of two chart types: RadarChart or Treemap. You then implement a SegmentedControl component from the New Relic One SDK, which allows you to alternate between the two chart types. Ultimately, this gives you freedom to view your data in a dynamic way that isn't possible with New Relic's base offerings. Tip If you get lost in the code project and would like to see what the files should look like when you're done with each lesson, check out the course project on Github. Before you begin Explore our custom visualization guides and build your first visualization. After you're done, you'll have a better foundation for building more complex visualizations, such as the one you'll build in this course. Finally, if you haven't already: Sign up for a New Relic account Install Node.js Complete the steps in the nr1 quick start to install and configure the CLI Create your visualization Step 1 of 2 Ensure you're working with the latest version of the New Relic One CLI: bash Copy $ nr1 update Step 2 of 2 Create a visualization, called radar-or-treemap, in a Nerdpack, called alternate-viz: bash Copy $ nr1 create --type visualization --name radar-or-treemap ✔ You’re trying to create a visualization outside of a Nerdpack. We’ll create a Nerdpack for you—what do you want to name it? … alternate-viz ✔ nerdpack created successfully! nerdpack alternate-viz is available at \"./alternate-viz\" ✔ visualization created successfully! visualization radar-or-treemap is available at \"./alternate-viz/visualizations/radar-or-treemap\" Tip If you receive a RequestError for a self-signed certificate when you run nr1 create, you may need to add a certificate to Node's certificate chain. Read more about this and other advanced configurations in Enable advanced configurations for your Nerdpack. As a result, you have a new visualizations/radar-or-treemap directory under alternate-viz: bash Copy $ cd alternate-viz $ ls visualizations/radar-or-treemap index.js nr1.json styles.scss Set up your component state Add component state to the default visualization template that nr1 created for you. Step 1 of 3 Navigate to alternate-viz/visualizations/radar-or-treemap/index.js. You'll work in here for the rest of this lesson. Step 2 of 3 Add a constant called CHART_TYPES: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import {Card, CardBody, HeadingText, NrqlQuery, Spinner, AutoSizer} from 'nr1'; 11 12 const CHART_TYPES = { 13 'Radar': 'radar', 14 'Treemap': 'treemap' 15 } 16 17 export default class RadarOrTreemapVisualization extends React.Component { 18 // Custom props you wish to be configurable in the UI must also be defined in 19 // the nr1.json file for the visualization. See docs for more details. 20 static propTypes = { 21 /** 22 * A fill color to override the default fill color. This is an example of 23 * a custom chart configuration. 24 */ 25 fill: PropTypes.string, 26 27 /** 28 * A stroke color to override the default stroke color. This is an example of 29 * a custom chart configuration. 30 */ 31 stroke: PropTypes.string, 32 /** 33 * An array of objects consisting of a nrql `query` and `accountId`. 34 * This should be a standard prop for any NRQL based visualizations. 35 */ 36 nrqlQueries: PropTypes.arrayOf( 37 PropTypes.shape({ 38 accountId: PropTypes.number, 39 query: PropTypes.string, 40 }) 41 ), 42 }; 43 44 /** 45 * Restructure the data for a non-time-series, facet-based NRQL query into a 46 * form accepted by the Recharts library's RadarChart. 47 * (https://recharts.org/api/RadarChart). 48 */ 49 transformData = (rawData) => { 50 return rawData.map((entry) => ({ 51 name: entry.metadata.name, 52 // Only grabbing the first data value because this is not time-series data. 53 value: entry.data[0].y, 54 })); 55 }; 56 57 /** 58 * Format the given axis tick's numeric value into a string for display. 59 */ 60 formatTick = (value) => { 61 return value.toLocaleString(); 62 }; 63 64 render() { 65 const {nrqlQueries, stroke, fill} = this.props; 66 67 const nrqlQueryPropsAvailable = 68 nrqlQueries && 69 nrqlQueries[0] && 70 nrqlQueries[0].accountId && 71 nrqlQueries[0].query; 72 73 if (!nrqlQueryPropsAvailable) { 74 return <EmptyState />; 75 } 76 77 return ( 78 <AutoSizer> 79 {({width, height}) => ( 80 <NrqlQuery 81 query={nrqlQueries[0].query} 82 accountId={parseInt(nrqlQueries[0].accountId)} 83 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 84 > 85 {({data, loading, error}) => { 86 if (loading) { 87 return <Spinner />; 88 } 89 90 if (error) { 91 return <ErrorState />; 92 } 93 94 const transformedData = this.transformData(data); 95 96 return ( 97 <RadarChart 98 width={width} 99 height={height} 100 data={transformedData} 101 > 102 <PolarGrid /> 103 <PolarAngleAxis dataKey=\"name\" /> 104 <PolarRadiusAxis tickFormatter={this.formatTick} /> 105 <Radar 106 dataKey=\"value\" 107 stroke={stroke || '#51C9B7'} 108 fill={fill || '#51C9B7'} 109 fillOpacity={0.6} 110 /> 111 </RadarChart> 112 ); 113 }} 114 </NrqlQuery> 115 )} 116 </AutoSizer> 117 ); 118 } 119 } 120 121 const EmptyState = () => ( 122 <Card className=\"EmptyState\"> 123 <CardBody className=\"EmptyState-cardBody\"> 124 <HeadingText 125 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 126 type={HeadingText.TYPE.HEADING_3} 127 > 128 Please provide at least one NRQL query & account ID pair 129 </HeadingText> 130 <HeadingText 131 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 132 type={HeadingText.TYPE.HEADING_4} 133 > 134 An example NRQL query you can try is: 135 </HeadingText> 136 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 137 </CardBody> 138 </Card> 139 ); 140 141 const ErrorState = () => ( 142 <Card className=\"ErrorState\"> 143 <CardBody className=\"ErrorState-cardBody\"> 144 <HeadingText 145 className=\"ErrorState-headingText\" 146 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 147 type={HeadingText.TYPE.HEADING_3} 148 > 149 Oops! Something went wrong. 150 </HeadingText> 151 </CardBody> 152 </Card> 153 ); visualizations/radar-or-treemap/index.js Copy CHART_TYPES enumerates the two chart types you'll alternate between in your visualization. Step 3 of 3 Initialize selectedChart in your component's state: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import {Card, CardBody, HeadingText, NrqlQuery, Spinner, AutoSizer} from 'nr1'; 11 12 const CHART_TYPES = { 13 'Radar': 'radar', 14 'Treemap': 'treemap' 15 } 16 17 export default class RadarOrTreemapVisualization extends React.Component { 18 // Custom props you wish to be configurable in the UI must also be defined in 19 // the nr1.json file for the visualization. See docs for more details. 20 static propTypes = { 21 /** 22 * A fill color to override the default fill color. This is an example of 23 * a custom chart configuration. 24 */ 25 fill: PropTypes.string, 26 27 /** 28 * A stroke color to override the default stroke color. This is an example of 29 * a custom chart configuration. 30 */ 31 stroke: PropTypes.string, 32 /** 33 * An array of objects consisting of a nrql `query` and `accountId`. 34 * This should be a standard prop for any NRQL based visualizations. 35 */ 36 nrqlQueries: PropTypes.arrayOf( 37 PropTypes.shape({ 38 accountId: PropTypes.number, 39 query: PropTypes.string, 40 }) 41 ), 42 }; 43 44 state = { 45 selectedChart: CHART_TYPES.Radar, 46 }; 47 48 /** 49 * Restructure the data for a non-time-series, facet-based NRQL query into a 50 * form accepted by the Recharts library's RadarChart. 51 * (https://recharts.org/api/RadarChart). 52 */ 53 transformData = (rawData) => { 54 return rawData.map((entry) => ({ 55 name: entry.metadata.name, 56 // Only grabbing the first data value because this is not time-series data. 57 value: entry.data[0].y, 58 })); 59 }; 60 61 /** 62 * Format the given axis tick's numeric value into a string for display. 63 */ 64 formatTick = (value) => { 65 return value.toLocaleString(); 66 }; 67 68 render() { 69 const {nrqlQueries, stroke, fill} = this.props; 70 71 const nrqlQueryPropsAvailable = 72 nrqlQueries && 73 nrqlQueries[0] && 74 nrqlQueries[0].accountId && 75 nrqlQueries[0].query; 76 77 if (!nrqlQueryPropsAvailable) { 78 return <EmptyState />; 79 } 80 81 return ( 82 <AutoSizer> 83 {({width, height}) => ( 84 <NrqlQuery 85 query={nrqlQueries[0].query} 86 accountId={parseInt(nrqlQueries[0].accountId)} 87 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 88 > 89 {({data, loading, error}) => { 90 if (loading) { 91 return <Spinner />; 92 } 93 94 if (error) { 95 return <ErrorState />; 96 } 97 98 const transformedData = this.transformData(data); 99 100 return ( 101 <RadarChart 102 width={width} 103 height={height} 104 data={transformedData} 105 > 106 <PolarGrid /> 107 <PolarAngleAxis dataKey=\"name\" /> 108 <PolarRadiusAxis tickFormatter={this.formatTick} /> 109 <Radar 110 dataKey=\"value\" 111 stroke={stroke || '#51C9B7'} 112 fill={fill || '#51C9B7'} 113 fillOpacity={0.6} 114 /> 115 </RadarChart> 116 ); 117 }} 118 </NrqlQuery> 119 )} 120 </AutoSizer> 121 ); 122 } 123 } 124 125 const EmptyState = () => ( 126 <Card className=\"EmptyState\"> 127 <CardBody className=\"EmptyState-cardBody\"> 128 <HeadingText 129 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 130 type={HeadingText.TYPE.HEADING_3} 131 > 132 Please provide at least one NRQL query & account ID pair 133 </HeadingText> 134 <HeadingText 135 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 136 type={HeadingText.TYPE.HEADING_4} 137 > 138 An example NRQL query you can try is: 139 </HeadingText> 140 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 141 </CardBody> 142 </Card> 143 ); 144 145 const ErrorState = () => ( 146 <Card className=\"ErrorState\"> 147 <CardBody className=\"ErrorState-cardBody\"> 148 <HeadingText 149 className=\"ErrorState-headingText\" 150 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 151 type={HeadingText.TYPE.HEADING_3} 152 > 153 Oops! Something went wrong. 154 </HeadingText> 155 </CardBody> 156 </Card> 157 ); visualizations/radar-or-treemap/index.js Copy This state value stores the chart type in which you want to show your data. Now that you've created an object which enumerates the chart type options for your visualization, and you've initialized state.selectedChart, you're ready to implement a control UI for switching between the two chart types. Add SegmentedControl components state.selectedChart isn't useful unless your visualization's users can actually select a chart type. Use SegmentedControl and SegmentedControlItem to switch between the two chart types. Tip To learn more about the components available in the New Relic One SDK, go to our Intro to New Relic One SDK. Step 1 of 7 Import SegmentedControl and SegmentedControlItem from nr1: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 render() { 78 const {nrqlQueries, stroke, fill} = this.props; 79 80 const nrqlQueryPropsAvailable = 81 nrqlQueries && 82 nrqlQueries[0] && 83 nrqlQueries[0].accountId && 84 nrqlQueries[0].query; 85 86 if (!nrqlQueryPropsAvailable) { 87 return <EmptyState />; 88 } 89 90 return ( 91 <AutoSizer> 92 {({width, height}) => ( 93 <NrqlQuery 94 query={nrqlQueries[0].query} 95 accountId={parseInt(nrqlQueries[0].accountId)} 96 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 97 > 98 {({data, loading, error}) => { 99 if (loading) { 100 return <Spinner />; 101 } 102 103 if (error) { 104 return <ErrorState />; 105 } 106 107 const transformedData = this.transformData(data); 108 109 return ( 110 <RadarChart 111 width={width} 112 height={height} 113 data={transformedData} 114 > 115 <PolarGrid /> 116 <PolarAngleAxis dataKey=\"name\" /> 117 <PolarRadiusAxis tickFormatter={this.formatTick} /> 118 <Radar 119 dataKey=\"value\" 120 stroke={stroke || '#51C9B7'} 121 fill={fill || '#51C9B7'} 122 fillOpacity={0.6} 123 /> 124 </RadarChart> 125 ); 126 }} 127 </NrqlQuery> 128 )} 129 </AutoSizer> 130 ); 131 } 132 } 133 134 const EmptyState = () => ( 135 <Card className=\"EmptyState\"> 136 <CardBody className=\"EmptyState-cardBody\"> 137 <HeadingText 138 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 139 type={HeadingText.TYPE.HEADING_3} 140 > 141 Please provide at least one NRQL query & account ID pair 142 </HeadingText> 143 <HeadingText 144 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 145 type={HeadingText.TYPE.HEADING_4} 146 > 147 An example NRQL query you can try is: 148 </HeadingText> 149 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 150 </CardBody> 151 </Card> 152 ); 153 154 const ErrorState = () => ( 155 <Card className=\"ErrorState\"> 156 <CardBody className=\"ErrorState-cardBody\"> 157 <HeadingText 158 className=\"ErrorState-headingText\" 159 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 160 type={HeadingText.TYPE.HEADING_3} 161 > 162 Oops! Something went wrong. 163 </HeadingText> 164 </CardBody> 165 </Card> 166 ); visualizations/radar-or-treemap/index.js Copy Step 2 of 7 In render(), wrap RadarChart in a React.Fragment: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 render() { 78 const {nrqlQueries, stroke, fill} = this.props; 79 80 const nrqlQueryPropsAvailable = 81 nrqlQueries && 82 nrqlQueries[0] && 83 nrqlQueries[0].accountId && 84 nrqlQueries[0].query; 85 86 if (!nrqlQueryPropsAvailable) { 87 return <EmptyState />; 88 } 89 90 return ( 91 <AutoSizer> 92 {({width, height}) => ( 93 <NrqlQuery 94 query={nrqlQueries[0].query} 95 accountId={parseInt(nrqlQueries[0].accountId)} 96 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 97 > 98 {({data, loading, error}) => { 99 if (loading) { 100 return <Spinner />; 101 } 102 103 if (error) { 104 return <ErrorState />; 105 } 106 107 const transformedData = this.transformData(data); 108 109 return ( 110 <React.Fragment> 111 <RadarChart 112 width={width} 113 height={height} 114 data={transformedData} 115 > 116 <PolarGrid /> 117 <PolarAngleAxis dataKey=\"name\" /> 118 <PolarRadiusAxis tickFormatter={this.formatTick} /> 119 <Radar 120 dataKey=\"value\" 121 stroke={stroke || '#51C9B7'} 122 fill={fill || '#51C9B7'} 123 fillOpacity={0.6} 124 /> 125 </RadarChart> 126 </React.Fragment> 127 ); 128 }} 129 </NrqlQuery> 130 )} 131 </AutoSizer> 132 ); 133 } 134 } 135 136 const EmptyState = () => ( 137 <Card className=\"EmptyState\"> 138 <CardBody className=\"EmptyState-cardBody\"> 139 <HeadingText 140 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 141 type={HeadingText.TYPE.HEADING_3} 142 > 143 Please provide at least one NRQL query & account ID pair 144 </HeadingText> 145 <HeadingText 146 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 147 type={HeadingText.TYPE.HEADING_4} 148 > 149 An example NRQL query you can try is: 150 </HeadingText> 151 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 152 </CardBody> 153 </Card> 154 ); 155 156 const ErrorState = () => ( 157 <Card className=\"ErrorState\"> 158 <CardBody className=\"ErrorState-cardBody\"> 159 <HeadingText 160 className=\"ErrorState-headingText\" 161 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 162 type={HeadingText.TYPE.HEADING_3} 163 > 164 Oops! Something went wrong. 165 </HeadingText> 166 </CardBody> 167 </Card> 168 ); visualizations/radar-or-treemap/index.js Copy This allows you to return multiple components from the same render(). Step 3 of 7 Add a SegmentedControl and two SegmentedControlItem components, each with a value and a label: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 render() { 78 const {nrqlQueries, stroke, fill} = this.props; 79 80 const nrqlQueryPropsAvailable = 81 nrqlQueries && 82 nrqlQueries[0] && 83 nrqlQueries[0].accountId && 84 nrqlQueries[0].query; 85 86 if (!nrqlQueryPropsAvailable) { 87 return <EmptyState />; 88 } 89 90 return ( 91 <AutoSizer> 92 {({width, height}) => ( 93 <NrqlQuery 94 query={nrqlQueries[0].query} 95 accountId={parseInt(nrqlQueries[0].accountId)} 96 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 97 > 98 {({data, loading, error}) => { 99 if (loading) { 100 return <Spinner />; 101 } 102 103 if (error) { 104 return <ErrorState />; 105 } 106 107 const transformedData = this.transformData(data); 108 109 return ( 110 <React.Fragment> 111 <SegmentedControl 112 onChange={(event, value) => console.log(value)} 113 > 114 <SegmentedControlItem 115 value={CHART_TYPES.Radar} 116 label=\"Radar chart\" 117 /> 118 <SegmentedControlItem 119 value={CHART_TYPES.Treemap} 120 label=\"Treemap chart\" 121 /> 122 </SegmentedControl> 123 <RadarChart 124 width={width} 125 height={height} 126 data={transformedData} 127 > 128 <PolarGrid /> 129 <PolarAngleAxis dataKey=\"name\" /> 130 <PolarRadiusAxis tickFormatter={this.formatTick} /> 131 <Radar 132 dataKey=\"value\" 133 stroke={stroke || '#51C9B7'} 134 fill={fill || '#51C9B7'} 135 fillOpacity={0.6} 136 /> 137 </RadarChart> 138 </React.Fragment> 139 ); 140 }} 141 </NrqlQuery> 142 )} 143 </AutoSizer> 144 ); 145 } 146 } 147 148 const EmptyState = () => ( 149 <Card className=\"EmptyState\"> 150 <CardBody className=\"EmptyState-cardBody\"> 151 <HeadingText 152 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 153 type={HeadingText.TYPE.HEADING_3} 154 > 155 Please provide at least one NRQL query & account ID pair 156 </HeadingText> 157 <HeadingText 158 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 159 type={HeadingText.TYPE.HEADING_4} 160 > 161 An example NRQL query you can try is: 162 </HeadingText> 163 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 164 </CardBody> 165 </Card> 166 ); 167 168 const ErrorState = () => ( 169 <Card className=\"ErrorState\"> 170 <CardBody className=\"ErrorState-cardBody\"> 171 <HeadingText 172 className=\"ErrorState-headingText\" 173 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 174 type={HeadingText.TYPE.HEADING_3} 175 > 176 Oops! Something went wrong. 177 </HeadingText> 178 </CardBody> 179 </Card> 180 ); visualizations/radar-or-treemap/index.js Copy Here, your SegmentedControl logs the SegmentedControlItem.value to the console when you change your selection. The values you've defined for your SegmentedControlItem components correspond to the two CHART_TYPES you created in a previous step. Step 4 of 7 Navigate to the root of your Nerdpack at alternate-viz. Step 5 of 7 Serve your Nerdpack locally: bash Copy $ nr1 nerdpack:serve Step 6 of 7 Open the link to your visualization that's shown in the terminal when the Node server starts: bash Copy Visualizations: ⁎ radar-or-treemap https://one.nr/012ab3cd4Ef Step 7 of 7 Configure your visualization with an account ID and a query: With some required data for your chart to process, you now see a RadarChart with the SegmentedControl at the top of the view. Look at your browser's console to see your SegmentedControl logs: Connect your component's state to the SegmentedControl Add a method to update state and connect that method with the SegmentedControl you added in the last section. Step 1 of 2 Add a component method, called updateSelectedChart(): index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 updateSelectedChart = (evt, value) => { 78 this.setState({ selectedChart: value }) 79 }; 80 81 render() { 82 const {nrqlQueries, stroke, fill} = this.props; 83 84 const nrqlQueryPropsAvailable = 85 nrqlQueries && 86 nrqlQueries[0] && 87 nrqlQueries[0].accountId && 88 nrqlQueries[0].query; 89 90 if (!nrqlQueryPropsAvailable) { 91 return <EmptyState />; 92 } 93 94 return ( 95 <AutoSizer> 96 {({width, height}) => ( 97 <NrqlQuery 98 query={nrqlQueries[0].query} 99 accountId={parseInt(nrqlQueries[0].accountId)} 100 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 101 > 102 {({data, loading, error}) => { 103 if (loading) { 104 return <Spinner />; 105 } 106 107 if (error) { 108 return <ErrorState />; 109 } 110 111 const transformedData = this.transformData(data); 112 113 return ( 114 <React.Fragment> 115 <SegmentedControl 116 onChange={(event, value) => console.log(value)} 117 > 118 <SegmentedControlItem 119 value={CHART_TYPES.Radar} 120 label=\"Radar chart\" 121 /> 122 <SegmentedControlItem 123 value={CHART_TYPES.Treemap} 124 label=\"Treemap chart\" 125 /> 126 </SegmentedControl> 127 <RadarChart 128 width={width} 129 height={height} 130 data={transformedData} 131 > 132 <PolarGrid /> 133 <PolarAngleAxis dataKey=\"name\" /> 134 <PolarRadiusAxis tickFormatter={this.formatTick} /> 135 <Radar 136 dataKey=\"value\" 137 stroke={stroke || '#51C9B7'} 138 fill={fill || '#51C9B7'} 139 fillOpacity={0.6} 140 /> 141 </RadarChart> 142 </React.Fragment> 143 ); 144 }} 145 </NrqlQuery> 146 )} 147 </AutoSizer> 148 ); 149 } 150 } 151 152 const EmptyState = () => ( 153 <Card className=\"EmptyState\"> 154 <CardBody className=\"EmptyState-cardBody\"> 155 <HeadingText 156 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 157 type={HeadingText.TYPE.HEADING_3} 158 > 159 Please provide at least one NRQL query & account ID pair 160 </HeadingText> 161 <HeadingText 162 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 163 type={HeadingText.TYPE.HEADING_4} 164 > 165 An example NRQL query you can try is: 166 </HeadingText> 167 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 168 </CardBody> 169 </Card> 170 ); 171 172 const ErrorState = () => ( 173 <Card className=\"ErrorState\"> 174 <CardBody className=\"ErrorState-cardBody\"> 175 <HeadingText 176 className=\"ErrorState-headingText\" 177 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 178 type={HeadingText.TYPE.HEADING_3} 179 > 180 Oops! Something went wrong. 181 </HeadingText> 182 </CardBody> 183 </Card> 184 ); visualizations/radar-or-treemap/index.js Copy This new method takes a value argument and sets state.selectedChart to that value. Step 2 of 2 Set SegmentedControl.onChange to updateSelectedChart(): index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 updateSelectedChart = (evt, value) => { 78 this.setState({ selectedChart: value }) 79 }; 80 81 render() { 82 const {nrqlQueries, stroke, fill} = this.props; 83 84 const nrqlQueryPropsAvailable = 85 nrqlQueries && 86 nrqlQueries[0] && 87 nrqlQueries[0].accountId && 88 nrqlQueries[0].query; 89 90 if (!nrqlQueryPropsAvailable) { 91 return <EmptyState />; 92 } 93 94 return ( 95 <AutoSizer> 96 {({width, height}) => ( 97 <NrqlQuery 98 query={nrqlQueries[0].query} 99 accountId={parseInt(nrqlQueries[0].accountId)} 100 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 101 > 102 {({data, loading, error}) => { 103 if (loading) { 104 return <Spinner />; 105 } 106 107 if (error) { 108 return <ErrorState />; 109 } 110 111 const transformedData = this.transformData(data); 112 113 return ( 114 <React.Fragment> 115 <SegmentedControl 116 onChange={this.updateSelectedChart} 117 > 118 <SegmentedControlItem 119 value={CHART_TYPES.Radar} 120 label=\"Radar chart\" 121 /> 122 <SegmentedControlItem 123 value={CHART_TYPES.Treemap} 124 label=\"Treemap chart\" 125 /> 126 </SegmentedControl> 127 <RadarChart 128 width={width} 129 height={height} 130 data={transformedData} 131 > 132 <PolarGrid /> 133 <PolarAngleAxis dataKey=\"name\" /> 134 <PolarRadiusAxis tickFormatter={this.formatTick} /> 135 <Radar 136 dataKey=\"value\" 137 stroke={stroke || '#51C9B7'} 138 fill={fill || '#51C9B7'} 139 fillOpacity={0.6} 140 /> 141 </RadarChart> 142 </React.Fragment> 143 ); 144 }} 145 </NrqlQuery> 146 )} 147 </AutoSizer> 148 ); 149 } 150 } 151 152 const EmptyState = () => ( 153 <Card className=\"EmptyState\"> 154 <CardBody className=\"EmptyState-cardBody\"> 155 <HeadingText 156 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 157 type={HeadingText.TYPE.HEADING_3} 158 > 159 Please provide at least one NRQL query & account ID pair 160 </HeadingText> 161 <HeadingText 162 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 163 type={HeadingText.TYPE.HEADING_4} 164 > 165 An example NRQL query you can try is: 166 </HeadingText> 167 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 168 </CardBody> 169 </Card> 170 ); 171 172 const ErrorState = () => ( 173 <Card className=\"ErrorState\"> 174 <CardBody className=\"ErrorState-cardBody\"> 175 <HeadingText 176 className=\"ErrorState-headingText\" 177 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 178 type={HeadingText.TYPE.HEADING_3} 179 > 180 Oops! Something went wrong. 181 </HeadingText> 182 </CardBody> 183 </Card> 184 ); visualizations/radar-or-treemap/index.js Copy Now, when you change your selection in the SegmentedControl, your selection will be set in state. Implement a Treemap option Add a Treemap to your visualization. This map will be an alternative to the existing RadarChart. Technical detail This guide uses Recharts components for third-party charts, but you can use any other JavaScript charting libraries that are compatible with the current React version when you build New Relic One visualizations and apps. Step 1 of 3 Import Treemap from recharts: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 'Radar': 'radar', 24 'Treemap': 'treemap' 25 } 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 state = { 55 selectedChart: CHART_TYPES.Radar, 56 }; 57 58 /** 59 * Restructure the data for a non-time-series, facet-based NRQL query into a 60 * form accepted by the Recharts library's RadarChart. 61 * (https://recharts.org/api/RadarChart). 62 */ 63 transformData = (rawData) => { 64 return rawData.map((entry) => ({ 65 name: entry.metadata.name, 66 // Only grabbing the first data value because this is not time-series data. 67 value: entry.data[0].y, 68 })); 69 }; 70 71 /** 72 * Format the given axis tick's numeric value into a string for display. 73 */ 74 formatTick = (value) => { 75 return value.toLocaleString(); 76 }; 77 78 updateSelectedChart = (evt, value) => { 79 this.setState({ selectedChart: value }) 80 }; 81 82 render() { 83 const {nrqlQueries, stroke, fill} = this.props; 84 85 const nrqlQueryPropsAvailable = 86 nrqlQueries && 87 nrqlQueries[0] && 88 nrqlQueries[0].accountId && 89 nrqlQueries[0].query; 90 91 if (!nrqlQueryPropsAvailable) { 92 return <EmptyState />; 93 } 94 95 return ( 96 <AutoSizer> 97 {({width, height}) => ( 98 <NrqlQuery 99 query={nrqlQueries[0].query} 100 accountId={parseInt(nrqlQueries[0].accountId)} 101 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 102 > 103 {({data, loading, error}) => { 104 if (loading) { 105 return <Spinner />; 106 } 107 108 if (error) { 109 return <ErrorState />; 110 } 111 112 const transformedData = this.transformData(data); 113 114 return ( 115 <React.Fragment> 116 <SegmentedControl 117 onChange={this.updateSelectedChart} 118 > 119 <SegmentedControlItem 120 value={CHART_TYPES.Radar} 121 label=\"Radar chart\" 122 /> 123 <SegmentedControlItem 124 value={CHART_TYPES.Treemap} 125 label=\"Treemap chart\" 126 /> 127 </SegmentedControl> 128 <RadarChart 129 width={width} 130 height={height} 131 data={transformedData} 132 > 133 <PolarGrid /> 134 <PolarAngleAxis dataKey=\"name\" /> 135 <PolarRadiusAxis tickFormatter={this.formatTick} /> 136 <Radar 137 dataKey=\"value\" 138 stroke={stroke || '#51C9B7'} 139 fill={fill || '#51C9B7'} 140 fillOpacity={0.6} 141 /> 142 </RadarChart> 143 </React.Fragment> 144 ); 145 }} 146 </NrqlQuery> 147 )} 148 </AutoSizer> 149 ); 150 } 151 } 152 153 const EmptyState = () => ( 154 <Card className=\"EmptyState\"> 155 <CardBody className=\"EmptyState-cardBody\"> 156 <HeadingText 157 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 158 type={HeadingText.TYPE.HEADING_3} 159 > 160 Please provide at least one NRQL query & account ID pair 161 </HeadingText> 162 <HeadingText 163 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 164 type={HeadingText.TYPE.HEADING_4} 165 > 166 An example NRQL query you can try is: 167 </HeadingText> 168 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 169 </CardBody> 170 </Card> 171 ); 172 173 const ErrorState = () => ( 174 <Card className=\"ErrorState\"> 175 <CardBody className=\"ErrorState-cardBody\"> 176 <HeadingText 177 className=\"ErrorState-headingText\" 178 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 179 type={HeadingText.TYPE.HEADING_3} 180 > 181 Oops! Something went wrong. 182 </HeadingText> 183 </CardBody> 184 </Card> 185 ); visualizations/radar-or-treemap/index.js Copy Now, you can use Treemap in your visualization component. Step 2 of 3 In render(), add a Treemap component: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 'Radar': 'radar', 24 'Treemap': 'treemap' 25 } 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 state = { 55 selectedChart: CHART_TYPES.Radar, 56 }; 57 58 /** 59 * Restructure the data for a non-time-series, facet-based NRQL query into a 60 * form accepted by the Recharts library's RadarChart. 61 * (https://recharts.org/api/RadarChart). 62 */ 63 transformData = (rawData) => { 64 return rawData.map((entry) => ({ 65 name: entry.metadata.name, 66 // Only grabbing the first data value because this is not time-series data. 67 value: entry.data[0].y, 68 })); 69 }; 70 71 /** 72 * Format the given axis tick's numeric value into a string for display. 73 */ 74 formatTick = (value) => { 75 return value.toLocaleString(); 76 }; 77 78 updateSelectedChart = (evt, value) => { 79 this.setState({ selectedChart: value }) 80 }; 81 82 render() { 83 const {nrqlQueries, stroke, fill} = this.props; 84 85 const nrqlQueryPropsAvailable = 86 nrqlQueries && 87 nrqlQueries[0] && 88 nrqlQueries[0].accountId && 89 nrqlQueries[0].query; 90 91 if (!nrqlQueryPropsAvailable) { 92 return <EmptyState />; 93 } 94 95 return ( 96 <AutoSizer> 97 {({width, height}) => ( 98 <NrqlQuery 99 query={nrqlQueries[0].query} 100 accountId={parseInt(nrqlQueries[0].accountId)} 101 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 102 > 103 {({data, loading, error}) => { 104 if (loading) { 105 return <Spinner />; 106 } 107 108 if (error) { 109 return <ErrorState />; 110 } 111 112 const transformedData = this.transformData(data); 113 114 return ( 115 <React.Fragment> 116 <SegmentedControl 117 onChange={this.updateSelectedChart} 118 > 119 <SegmentedControlItem 120 value={CHART_TYPES.Radar} 121 label=\"Radar chart\" 122 /> 123 <SegmentedControlItem 124 value={CHART_TYPES.Treemap} 125 label=\"Treemap chart\" 126 /> 127 </SegmentedControl> 128 <RadarChart 129 width={width} 130 height={height} 131 data={transformedData} 132 > 133 <PolarGrid /> 134 <PolarAngleAxis dataKey=\"name\" /> 135 <PolarRadiusAxis tickFormatter={this.formatTick} /> 136 <Radar 137 dataKey=\"value\" 138 stroke={stroke || '#51C9B7'} 139 fill={fill || '#51C9B7'} 140 fillOpacity={0.6} 141 /> 142 </RadarChart> 143 <Treemap 144 width={width} 145 height={height} 146 data={transformedData} 147 dataKey=\"value\" 148 ratio={4 / 3} 149 stroke={stroke || '#000000'} 150 fill={fill || '#51C9B7'} 151 /> 152 </React.Fragment> 153 ); 154 }} 155 </NrqlQuery> 156 )} 157 </AutoSizer> 158 ); 159 } 160 } 161 162 const EmptyState = () => ( 163 <Card className=\"EmptyState\"> 164 <CardBody className=\"EmptyState-cardBody\"> 165 <HeadingText 166 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 167 type={HeadingText.TYPE.HEADING_3} 168 > 169 Please provide at least one NRQL query & account ID pair 170 </HeadingText> 171 <HeadingText 172 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 173 type={HeadingText.TYPE.HEADING_4} 174 > 175 An example NRQL query you can try is: 176 </HeadingText> 177 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 178 </CardBody> 179 </Card> 180 ); 181 182 const ErrorState = () => ( 183 <Card className=\"ErrorState\"> 184 <CardBody className=\"ErrorState-cardBody\"> 185 <HeadingText 186 className=\"ErrorState-headingText\" 187 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 188 type={HeadingText.TYPE.HEADING_3} 189 > 190 Oops! Something went wrong. 191 </HeadingText> 192 </CardBody> 193 </Card> 194 ); visualizations/radar-or-treemap/index.js Copy Here, you've defined a new Treemap component with some props, including height, width, fill, and stroke. Step 3 of 3 With your Nerdpack served locally, view your visualization. The SegmentedControl and RadarChart are at the top of the view, but if you scroll down, you'll see your new Treemap: Switch between charts with your component's state Use state.selectedChart to determine which chart to show: the RadarChart or the Treemap. Step 1 of 1 Destructure this.state to access selectedChart as a separate constant. Then, compare selectedChart to CHART_TYPES.Radar. If they are the same, render a RadarChart. Otherwise, render a Treemap: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 'Radar': 'radar', 24 'Treemap': 'treemap' 25 } 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 state = { 55 selectedChart: CHART_TYPES.Radar, 56 }; 57 58 /** 59 * Restructure the data for a non-time-series, facet-based NRQL query into a 60 * form accepted by the Recharts library's RadarChart. 61 * (https://recharts.org/api/RadarChart). 62 */ 63 transformData = (rawData) => { 64 return rawData.map((entry) => ({ 65 name: entry.metadata.name, 66 // Only grabbing the first data value because this is not time-series data. 67 value: entry.data[0].y, 68 })); 69 }; 70 71 /** 72 * Format the given axis tick's numeric value into a string for display. 73 */ 74 formatTick = (value) => { 75 return value.toLocaleString(); 76 }; 77 78 updateSelectedChart = (evt, value) => { 79 this.setState({ selectedChart: value }) 80 }; 81 82 render() { 83 const {nrqlQueries, stroke, fill} = this.props; 84 const {selectedChart} = this.state; 85 86 const nrqlQueryPropsAvailable = 87 nrqlQueries && 88 nrqlQueries[0] && 89 nrqlQueries[0].accountId && 90 nrqlQueries[0].query; 91 92 if (!nrqlQueryPropsAvailable) { 93 return <EmptyState />; 94 } 95 96 return ( 97 <AutoSizer> 98 {({width, height}) => ( 99 <NrqlQuery 100 query={nrqlQueries[0].query} 101 accountId={parseInt(nrqlQueries[0].accountId)} 102 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 103 > 104 {({data, loading, error}) => { 105 if (loading) { 106 return <Spinner />; 107 } 108 109 if (error) { 110 return <ErrorState />; 111 } 112 113 const transformedData = this.transformData(data); 114 115 return ( 116 <React.Fragment> 117 <SegmentedControl 118 onChange={this.updateSelectedChart} 119 > 120 <SegmentedControlItem 121 value={CHART_TYPES.Radar} 122 label=\"Radar chart\" 123 /> 124 <SegmentedControlItem 125 value={CHART_TYPES.Treemap} 126 label=\"Treemap chart\" 127 /> 128 </SegmentedControl> 129 {selectedChart === CHART_TYPES.Radar ? ( 130 <RadarChart 131 width={width} 132 height={height} 133 data={transformedData} 134 > 135 <PolarGrid /> 136 <PolarAngleAxis dataKey=\"name\" /> 137 <PolarRadiusAxis tickFormatter={this.formatTick} /> 138 <Radar 139 dataKey=\"value\" 140 stroke={stroke || '#51C9B7'} 141 fill={fill || '#51C9B7'} 142 fillOpacity={0.6} 143 /> 144 </RadarChart> 145 ) : ( 146 <Treemap 147 width={width} 148 height={height} 149 data={transformedData} 150 dataKey=\"value\" 151 ratio={4 / 3} 152 stroke={stroke || '#000000'} 153 fill={fill || '#51C9B7'} 154 /> 155 )} 156 </React.Fragment> 157 ); 158 }} 159 </NrqlQuery> 160 )} 161 </AutoSizer> 162 ); 163 } 164 } 165 166 const EmptyState = () => ( 167 <Card className=\"EmptyState\"> 168 <CardBody className=\"EmptyState-cardBody\"> 169 <HeadingText 170 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 171 type={HeadingText.TYPE.HEADING_3} 172 > 173 Please provide at least one NRQL query & account ID pair 174 </HeadingText> 175 <HeadingText 176 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 177 type={HeadingText.TYPE.HEADING_4} 178 > 179 An example NRQL query you can try is: 180 </HeadingText> 181 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 182 </CardBody> 183 </Card> 184 ); 185 186 const ErrorState = () => ( 187 <Card className=\"ErrorState\"> 188 <CardBody className=\"ErrorState-cardBody\"> 189 <HeadingText 190 className=\"ErrorState-headingText\" 191 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 192 type={HeadingText.TYPE.HEADING_3} 193 > 194 Oops! Something went wrong. 195 </HeadingText> 196 </CardBody> 197 </Card> 198 ); visualizations/radar-or-treemap/index.js Copy Here, you used a ternary expression to render a RadarChart or a Treemap. The rendered chart is determined by the value of selectedChart. With your Nerdpack served locally, view your visualization. Select Radar chart from the SegmentedControl: Select Treemap chart from the SegmentedControl: Summary Congratulations! In this lesson, you learned how to: Customize your visualization using New Relic One SDK components Add a new chart type to your visualization Create a user interaction in your visualization Course This lesson is part of a course that teaches you how to build a custom visualization in the New Relic One platform. When you're ready, continue on to the next lesson: Customize visualizations with configuration.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 578.68414,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Switch between <em>charts</em> with your component&#x27;s state",
        "body": " spacing<em>Type</em>={[HeadingText.SPACING_<em>TYPE</em>.LARGE]} 147 <em>type</em>={HeadingText.<em>TYPE</em>.HEADING_3} 148 &gt; 149 Oops! Something went wrong. 150 &lt;&#x2F;HeadingText&gt; 151 &lt;&#x2F;CardBody&gt; 152 &lt;&#x2F;Card&gt; 153 ); visualizations&#x2F;radar-or-treemap&#x2F;index.js Copy <em>CHART_TYPES</em> enumerates the two <em>chart</em> <em>types</em> you&#x27;ll alternate between in your"
      },
      "id": "6091fa3b196a679beed52a6b"
    },
    {
      "sections": [
        "Customize your visualization with configuration options",
        "Course",
        "Tip",
        "Add a new configuration option",
        "Replace your SegmentedControl with the configurable property",
        "Summary"
      ],
      "title": "Customize your visualization with configuration options",
      "type": "developer",
      "tags": [
        "nr1 cli",
        "NR One Catalog",
        "visualizations"
      ],
      "external_id": "9028e58f383ea362d2c9d3a7ecd6404dbfeac87c",
      "image": "https://developer.newrelic.com/static/64ef0a5585a2f035fdd69ab5ff628375/ba3ac/nav-to-apps.png",
      "url": "https://developer.newrelic.com/build-apps/customize-visualizations-with-configuration/",
      "published_at": "2021-05-23T01:44:51Z",
      "updated_at": "2021-05-05T01:51:53Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Customize your visualization using configuration",
      "body": "Course This lesson is part of a course that teaches you how to build a custom visualization in the New Relic One platform. Each lesson in the course builds upon the last, so make sure you've completed the last lesson, Custom visualizations and the New Relic One SDK, before starting this one. In the previous lesson, you built a custom visualization that shows queried data in one of two chart types: RadarChart Treemap You used a SegmentedControl to switch between the two chart types in the visualization UI. This implementation takes up space in the visualization, but it offers your users the choice to switch between two chart types even after you've created an instance of your chart. But what if you only need to be able to select an option once, when initializing the visualization? In this lesson you'll learn how to add a configuration option to your visualization which replaces the SegmentedControl. Tip If you get lost in the code project and would like to see what the files should look like when you're done with each lesson, check out the course project on Github. Add a new configuration option Step 1 of 8 In your visualization's nr1.json file, add an enum configuration object for selectedChart: index.js nr1.json 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 'Radar': 'radar', 24 'Treemap': 'treemap' 25 } 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 state = { 55 selectedChart: CHART_TYPES.Radar, 56 }; 57 58 /** 59 * Restructure the data for a non-time-series, facet-based NRQL query into a 60 * form accepted by the Recharts library's RadarChart. 61 * (https://recharts.org/api/RadarChart). 62 */ 63 transformData = (rawData) => { 64 return rawData.map((entry) => ({ 65 name: entry.metadata.name, 66 // Only grabbing the first data value because this is not time-series data. 67 value: entry.data[0].y, 68 })); 69 }; 70 71 /** 72 * Format the given axis tick's numeric value into a string for display. 73 */ 74 formatTick = (value) => { 75 return value.toLocaleString(); 76 }; 77 78 updateSelectedChart = (evt, value) => { 79 this.setState({ selectedChart: value }) 80 }; 81 82 render() { 83 const {nrqlQueries, stroke, fill} = this.props; 84 const {selectedChart} = this.state; 85 86 const nrqlQueryPropsAvailable = 87 nrqlQueries && 88 nrqlQueries[0] && 89 nrqlQueries[0].accountId && 90 nrqlQueries[0].query; 91 92 if (!nrqlQueryPropsAvailable) { 93 return <EmptyState />; 94 } 95 96 return ( 97 <AutoSizer> 98 {({width, height}) => ( 99 <NrqlQuery 100 query={nrqlQueries[0].query} 101 accountId={parseInt(nrqlQueries[0].accountId)} 102 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 103 > 104 {({data, loading, error}) => { 105 if (loading) { 106 return <Spinner />; 107 } 108 109 if (error) { 110 return <ErrorState />; 111 } 112 113 const transformedData = this.transformData(data); 114 115 return ( 116 <React.Fragment> 117 <SegmentedControl 118 onChange={this.updateSelectedChart} 119 > 120 <SegmentedControlItem 121 value={CHART_TYPES.Radar} 122 label=\"Radar chart\" 123 /> 124 <SegmentedControlItem 125 value={CHART_TYPES.Treemap} 126 label=\"Treemap chart\" 127 /> 128 </SegmentedControl> 129 {selectedChart === CHART_TYPES.Radar ? ( 130 <RadarChart 131 width={width} 132 height={height} 133 data={transformedData} 134 > 135 <PolarGrid /> 136 <PolarAngleAxis dataKey=\"name\" /> 137 <PolarRadiusAxis tickFormatter={this.formatTick} /> 138 <Radar 139 dataKey=\"value\" 140 stroke={stroke || '#51C9B7'} 141 fill={fill || '#51C9B7'} 142 fillOpacity={0.6} 143 /> 144 </RadarChart> 145 ) : ( 146 <Treemap 147 width={width} 148 height={height} 149 data={transformedData} 150 dataKey=\"value\" 151 ratio={4 / 3} 152 stroke={stroke || '#000000'} 153 fill={fill || '#51C9B7'} 154 /> 155 )} 156 </React.Fragment> 157 ); 158 }} 159 </NrqlQuery> 160 )} 161 </AutoSizer> 162 ); 163 } 164 } 165 166 const EmptyState = () => ( 167 <Card className=\"EmptyState\"> 168 <CardBody className=\"EmptyState-cardBody\"> 169 <HeadingText 170 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 171 type={HeadingText.TYPE.HEADING_3} 172 > 173 Please provide at least one NRQL query & account ID pair 174 </HeadingText> 175 <HeadingText 176 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 177 type={HeadingText.TYPE.HEADING_4} 178 > 179 An example NRQL query you can try is: 180 </HeadingText> 181 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 182 </CardBody> 183 </Card> 184 ); 185 186 const ErrorState = () => ( 187 <Card className=\"ErrorState\"> 188 <CardBody className=\"ErrorState-cardBody\"> 189 <HeadingText 190 className=\"ErrorState-headingText\" 191 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 192 type={HeadingText.TYPE.HEADING_3} 193 > 194 Oops! Something went wrong. 195 </HeadingText> 196 </CardBody> 197 </Card> 198 ); visualizations/radar-or-treemap/index.js Copy 1 { 2 \"schemaType\": \"VISUALIZATION\", 3 \"id\": \"radar-or-treemap\", 4 \"displayName\": \"RadarOrTreemap\", 5 \"description\": \"\", 6 \"configuration\": [ 7 { 8 \"name\": \"selectedChart\", 9 \"title\": \"Select chart\", 10 \"description\": \"Select which chart to display\", 11 \"type\": \"enum\", 12 \"items\": [ 13 { 14 \"title\": \"Radar\", 15 \"value\": \"radar\" 16 }, 17 { 18 \"title\": \"Treemap\", 19 \"value\": \"treemap\" 20 } 21 ] 22 }, 23 { 24 \"name\": \"nrqlQueries\", 25 \"title\": \"NRQL Queries\", 26 \"type\": \"collection\", 27 \"items\": [ 28 { 29 \"name\": \"accountId\", 30 \"title\": \"Account ID\", 31 \"description\": \"Account ID to be associated with the query\", 32 \"type\": \"account-id\" 33 }, 34 { 35 \"name\": \"query\", 36 \"title\": \"Query\", 37 \"description\": \"NRQL query for visualization\", 38 \"type\": \"nrql\" 39 } 40 ] 41 }, 42 { 43 \"name\": \"fill\", 44 \"title\": \"Fill color\", 45 \"description\": \"A fill color to override the default fill color\", 46 \"type\": \"string\" 47 }, 48 { 49 \"name\": \"stroke\", 50 \"title\": \"Stroke color\", 51 \"description\": \"A stroke color to override the default stroke color\", 52 \"type\": \"string\" 53 } 54 ] 55 } visualizations/radar-or-treemap/nr1.json Copy Step 2 of 8 Navigate to the root of your Nerdpack at alternate-viz. Step 3 of 8 Serve your Nerdpack locally: bash Copy $ nr1 nerdpack:serve If you're still serving your Nerdpack from the last lesson, you need to stop it with CTRL-X and serve it again to reflect changes to nr1.json. Step 4 of 8 Go to https://one.newrelic.com/?nerdpacks=local. The nerdpacks=local query string directs the UI to load your visualization from the local server. Step 5 of 8 Open the Apps page: Step 6 of 8 Go to Custom Visualizations, which is favorited by default: Step 7 of 8 In Custom Visualizations, find and click your visualization: Step 8 of 8 Notice the new Select chart configuration option: Selecting a chart type doesn't effect your visualization. This is because you first need to introduce the selectedChart property to the visualization component. Then, you use selectedChart to determine the chart type to render. Replace your SegmentedControl with the configurable property Step 1 of 5 Open your visualization's index.js file. You'll be working here for the rest of the guide. Step 2 of 5 In render(), include selectedChart as a constant you get from destructuring props, and remove your component's state: index.js nr1.json 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 'Radar': 'radar', 24 'Treemap': 'treemap' 25 } 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 /** 55 * Restructure the data for a non-time-series, facet-based NRQL query into a 56 * form accepted by the Recharts library's RadarChart. 57 * (https://recharts.org/api/RadarChart). 58 */ 59 transformData = (rawData) => { 60 return rawData.map((entry) => ({ 61 name: entry.metadata.name, 62 // Only grabbing the first data value because this is not time-series data. 63 value: entry.data[0].y, 64 })); 65 }; 66 67 /** 68 * Format the given axis tick's numeric value into a string for display. 69 */ 70 formatTick = (value) => { 71 return value.toLocaleString(); 72 }; 73 74 render() { 75 const {nrqlQueries, stroke, fill, selectedChart} = this.props; 76 77 const nrqlQueryPropsAvailable = 78 nrqlQueries && 79 nrqlQueries[0] && 80 nrqlQueries[0].accountId && 81 nrqlQueries[0].query; 82 83 if (!nrqlQueryPropsAvailable) { 84 return <EmptyState />; 85 } 86 87 return ( 88 <AutoSizer> 89 {({width, height}) => ( 90 <NrqlQuery 91 query={nrqlQueries[0].query} 92 accountId={parseInt(nrqlQueries[0].accountId)} 93 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 94 > 95 {({data, loading, error}) => { 96 if (loading) { 97 return <Spinner />; 98 } 99 100 if (error) { 101 return <ErrorState />; 102 } 103 104 const transformedData = this.transformData(data); 105 106 return ( 107 <React.Fragment> 108 <SegmentedControl> 109 <SegmentedControlItem 110 value={CHART_TYPES.Radar} 111 label=\"Radar chart\" 112 /> 113 <SegmentedControlItem 114 value={CHART_TYPES.Treemap} 115 label=\"Treemap chart\" 116 /> 117 </SegmentedControl> 118 {selectedChart === CHART_TYPES.Radar ? ( 119 <RadarChart 120 width={width} 121 height={height} 122 data={transformedData} 123 > 124 <PolarGrid /> 125 <PolarAngleAxis dataKey=\"name\" /> 126 <PolarRadiusAxis tickFormatter={this.formatTick} /> 127 <Radar 128 dataKey=\"value\" 129 stroke={stroke || '#51C9B7'} 130 fill={fill || '#51C9B7'} 131 fillOpacity={0.6} 132 /> 133 </RadarChart> 134 ) : ( 135 <Treemap 136 width={width} 137 height={height} 138 data={transformedData} 139 dataKey=\"value\" 140 ratio={4 / 3} 141 stroke={stroke || '#000000'} 142 fill={fill || '#51C9B7'} 143 /> 144 )} 145 </React.Fragment> 146 ); 147 }} 148 </NrqlQuery> 149 )} 150 </AutoSizer> 151 ); 152 } 153 } 154 155 const EmptyState = () => ( 156 <Card className=\"EmptyState\"> 157 <CardBody className=\"EmptyState-cardBody\"> 158 <HeadingText 159 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 160 type={HeadingText.TYPE.HEADING_3} 161 > 162 Please provide at least one NRQL query & account ID pair 163 </HeadingText> 164 <HeadingText 165 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 166 type={HeadingText.TYPE.HEADING_4} 167 > 168 An example NRQL query you can try is: 169 </HeadingText> 170 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 171 </CardBody> 172 </Card> 173 ); 174 175 const ErrorState = () => ( 176 <Card className=\"ErrorState\"> 177 <CardBody className=\"ErrorState-cardBody\"> 178 <HeadingText 179 className=\"ErrorState-headingText\" 180 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 181 type={HeadingText.TYPE.HEADING_3} 182 > 183 Oops! Something went wrong. 184 </HeadingText> 185 </CardBody> 186 </Card> 187 ); visualizations/radar-or-treemap/index.js Copy 1 { 2 \"schemaType\": \"VISUALIZATION\", 3 \"id\": \"radar-or-treemap\", 4 \"displayName\": \"RadarOrTreemap\", 5 \"description\": \"\", 6 \"configuration\": [ 7 { 8 \"name\": \"selectedChart\", 9 \"title\": \"Select chart\", 10 \"description\": \"Select which chart to display\", 11 \"type\": \"enum\", 12 \"items\": [ 13 { 14 \"title\": \"Radar\", 15 \"value\": \"radar\" 16 }, 17 { 18 \"title\": \"Treemap\", 19 \"value\": \"treemap\" 20 } 21 ] 22 }, 23 { 24 \"name\": \"nrqlQueries\", 25 \"title\": \"NRQL Queries\", 26 \"type\": \"collection\", 27 \"items\": [ 28 { 29 \"name\": \"accountId\", 30 \"title\": \"Account ID\", 31 \"description\": \"Account ID to be associated with the query\", 32 \"type\": \"account-id\" 33 }, 34 { 35 \"name\": \"query\", 36 \"title\": \"Query\", 37 \"description\": \"NRQL query for visualization\", 38 \"type\": \"nrql\" 39 } 40 ] 41 }, 42 { 43 \"name\": \"fill\", 44 \"title\": \"Fill color\", 45 \"description\": \"A fill color to override the default fill color\", 46 \"type\": \"string\" 47 }, 48 { 49 \"name\": \"stroke\", 50 \"title\": \"Stroke color\", 51 \"description\": \"A stroke color to override the default stroke color\", 52 \"type\": \"string\" 53 } 54 ] 55 } visualizations/radar-or-treemap/nr1.json Copy Now that you're using selectedChart from the configuration options instead of component state, you can select a chart in the configuration panel and watch the visualization change. Unfortunately, there's a bug. The default chart option is Radar, but the initial render shows a Treemap. Step 3 of 5 Update your ternary expression to account for the case where there is no selectedChart: index.js nr1.json 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 'Radar': 'radar', 24 'Treemap': 'treemap' 25 } 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 /** 55 * Restructure the data for a non-time-series, facet-based NRQL query into a 56 * form accepted by the Recharts library's RadarChart. 57 * (https://recharts.org/api/RadarChart). 58 */ 59 transformData = (rawData) => { 60 return rawData.map((entry) => ({ 61 name: entry.metadata.name, 62 // Only grabbing the first data value because this is not time-series data. 63 value: entry.data[0].y, 64 })); 65 }; 66 67 /** 68 * Format the given axis tick's numeric value into a string for display. 69 */ 70 formatTick = (value) => { 71 return value.toLocaleString(); 72 }; 73 74 render() { 75 const {nrqlQueries, stroke, fill, selectedChart} = this.props; 76 77 const nrqlQueryPropsAvailable = 78 nrqlQueries && 79 nrqlQueries[0] && 80 nrqlQueries[0].accountId && 81 nrqlQueries[0].query; 82 83 if (!nrqlQueryPropsAvailable) { 84 return <EmptyState />; 85 } 86 87 return ( 88 <AutoSizer> 89 {({width, height}) => ( 90 <NrqlQuery 91 query={nrqlQueries[0].query} 92 accountId={parseInt(nrqlQueries[0].accountId)} 93 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 94 > 95 {({data, loading, error}) => { 96 if (loading) { 97 return <Spinner />; 98 } 99 100 if (error) { 101 return <ErrorState />; 102 } 103 104 const transformedData = this.transformData(data); 105 106 return ( 107 <React.Fragment> 108 <SegmentedControl> 109 <SegmentedControlItem 110 value={CHART_TYPES.Radar} 111 label=\"Radar chart\" 112 /> 113 <SegmentedControlItem 114 value={CHART_TYPES.Treemap} 115 label=\"Treemap chart\" 116 /> 117 </SegmentedControl> 118 {!selectedChart || selectedChart === CHART_TYPES.Radar ? ( 119 <RadarChart 120 width={width} 121 height={height} 122 data={transformedData} 123 > 124 <PolarGrid /> 125 <PolarAngleAxis dataKey=\"name\" /> 126 <PolarRadiusAxis tickFormatter={this.formatTick} /> 127 <Radar 128 dataKey=\"value\" 129 stroke={stroke || '#51C9B7'} 130 fill={fill || '#51C9B7'} 131 fillOpacity={0.6} 132 /> 133 </RadarChart> 134 ) : ( 135 <Treemap 136 width={width} 137 height={height} 138 data={transformedData} 139 dataKey=\"value\" 140 ratio={4 / 3} 141 stroke={stroke || '#000000'} 142 fill={fill || '#51C9B7'} 143 /> 144 )} 145 </React.Fragment> 146 ); 147 }} 148 </NrqlQuery> 149 )} 150 </AutoSizer> 151 ); 152 } 153 } 154 155 const EmptyState = () => ( 156 <Card className=\"EmptyState\"> 157 <CardBody className=\"EmptyState-cardBody\"> 158 <HeadingText 159 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 160 type={HeadingText.TYPE.HEADING_3} 161 > 162 Please provide at least one NRQL query & account ID pair 163 </HeadingText> 164 <HeadingText 165 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 166 type={HeadingText.TYPE.HEADING_4} 167 > 168 An example NRQL query you can try is: 169 </HeadingText> 170 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 171 </CardBody> 172 </Card> 173 ); 174 175 const ErrorState = () => ( 176 <Card className=\"ErrorState\"> 177 <CardBody className=\"ErrorState-cardBody\"> 178 <HeadingText 179 className=\"ErrorState-headingText\" 180 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 181 type={HeadingText.TYPE.HEADING_3} 182 > 183 Oops! Something went wrong. 184 </HeadingText> 185 </CardBody> 186 </Card> 187 ); visualizations/radar-or-treemap/index.js Copy 1 { 2 \"schemaType\": \"VISUALIZATION\", 3 \"id\": \"radar-or-treemap\", 4 \"displayName\": \"RadarOrTreemap\", 5 \"description\": \"\", 6 \"configuration\": [ 7 { 8 \"name\": \"selectedChart\", 9 \"title\": \"Select chart\", 10 \"description\": \"Select which chart to display\", 11 \"type\": \"enum\", 12 \"items\": [ 13 { 14 \"title\": \"Radar\", 15 \"value\": \"radar\" 16 }, 17 { 18 \"title\": \"Treemap\", 19 \"value\": \"treemap\" 20 } 21 ] 22 }, 23 { 24 \"name\": \"nrqlQueries\", 25 \"title\": \"NRQL Queries\", 26 \"type\": \"collection\", 27 \"items\": [ 28 { 29 \"name\": \"accountId\", 30 \"title\": \"Account ID\", 31 \"description\": \"Account ID to be associated with the query\", 32 \"type\": \"account-id\" 33 }, 34 { 35 \"name\": \"query\", 36 \"title\": \"Query\", 37 \"description\": \"NRQL query for visualization\", 38 \"type\": \"nrql\" 39 } 40 ] 41 }, 42 { 43 \"name\": \"fill\", 44 \"title\": \"Fill color\", 45 \"description\": \"A fill color to override the default fill color\", 46 \"type\": \"string\" 47 }, 48 { 49 \"name\": \"stroke\", 50 \"title\": \"Stroke color\", 51 \"description\": \"A stroke color to override the default stroke color\", 52 \"type\": \"string\" 53 } 54 ] 55 } visualizations/radar-or-treemap/nr1.json Copy Now, your data is rendered in a RadarChart if you haven't yet configured the option. Step 4 of 5 Remove SegmentedControl from render(): index.js nr1.json 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 Spinner, 18 } from 'nr1'; 19 20 const CHART_TYPES = { 21 'Radar': 'radar', 22 'Treemap': 'treemap' 23 } 24 25 export default class RadarOrTreemapVisualization extends React.Component { 26 // Custom props you wish to be configurable in the UI must also be defined in 27 // the nr1.json file for the visualization. See docs for more details. 28 static propTypes = { 29 /** 30 * A fill color to override the default fill color. This is an example of 31 * a custom chart configuration. 32 */ 33 fill: PropTypes.string, 34 35 /** 36 * A stroke color to override the default stroke color. This is an example of 37 * a custom chart configuration. 38 */ 39 stroke: PropTypes.string, 40 /** 41 * An array of objects consisting of a nrql `query` and `accountId`. 42 * This should be a standard prop for any NRQL based visualizations. 43 */ 44 nrqlQueries: PropTypes.arrayOf( 45 PropTypes.shape({ 46 accountId: PropTypes.number, 47 query: PropTypes.string, 48 }) 49 ), 50 }; 51 52 /** 53 * Restructure the data for a non-time-series, facet-based NRQL query into a 54 * form accepted by the Recharts library's RadarChart. 55 * (https://recharts.org/api/RadarChart). 56 */ 57 transformData = (rawData) => { 58 return rawData.map((entry) => ({ 59 name: entry.metadata.name, 60 // Only grabbing the first data value because this is not time-series data. 61 value: entry.data[0].y, 62 })); 63 }; 64 65 /** 66 * Format the given axis tick's numeric value into a string for display. 67 */ 68 formatTick = (value) => { 69 return value.toLocaleString(); 70 }; 71 72 render() { 73 const {nrqlQueries, stroke, fill, selectedChart} = this.props; 74 75 const nrqlQueryPropsAvailable = 76 nrqlQueries && 77 nrqlQueries[0] && 78 nrqlQueries[0].accountId && 79 nrqlQueries[0].query; 80 81 if (!nrqlQueryPropsAvailable) { 82 return <EmptyState />; 83 } 84 85 return ( 86 <AutoSizer> 87 {({width, height}) => ( 88 <NrqlQuery 89 query={nrqlQueries[0].query} 90 accountId={parseInt(nrqlQueries[0].accountId)} 91 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 92 > 93 {({data, loading, error}) => { 94 if (loading) { 95 return <Spinner />; 96 } 97 98 if (error) { 99 return <ErrorState />; 100 } 101 102 const transformedData = this.transformData(data); 103 104 return ( 105 <React.Fragment> 106 {!selectedChart || selectedChart === CHART_TYPES.Radar ? ( 107 <RadarChart 108 width={width} 109 height={height} 110 data={transformedData} 111 > 112 <PolarGrid /> 113 <PolarAngleAxis dataKey=\"name\" /> 114 <PolarRadiusAxis tickFormatter={this.formatTick} /> 115 <Radar 116 dataKey=\"value\" 117 stroke={stroke || '#51C9B7'} 118 fill={fill || '#51C9B7'} 119 fillOpacity={0.6} 120 /> 121 </RadarChart> 122 ) : ( 123 <Treemap 124 width={width} 125 height={height} 126 data={transformedData} 127 dataKey=\"value\" 128 ratio={4 / 3} 129 stroke={stroke || '#000000'} 130 fill={fill || '#51C9B7'} 131 /> 132 )} 133 </React.Fragment> 134 ); 135 }} 136 </NrqlQuery> 137 )} 138 </AutoSizer> 139 ); 140 } 141 } 142 143 const EmptyState = () => ( 144 <Card className=\"EmptyState\"> 145 <CardBody className=\"EmptyState-cardBody\"> 146 <HeadingText 147 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 148 type={HeadingText.TYPE.HEADING_3} 149 > 150 Please provide at least one NRQL query & account ID pair 151 </HeadingText> 152 <HeadingText 153 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 154 type={HeadingText.TYPE.HEADING_4} 155 > 156 An example NRQL query you can try is: 157 </HeadingText> 158 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 159 </CardBody> 160 </Card> 161 ); 162 163 const ErrorState = () => ( 164 <Card className=\"ErrorState\"> 165 <CardBody className=\"ErrorState-cardBody\"> 166 <HeadingText 167 className=\"ErrorState-headingText\" 168 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 169 type={HeadingText.TYPE.HEADING_3} 170 > 171 Oops! Something went wrong. 172 </HeadingText> 173 </CardBody> 174 </Card> 175 ); visualizations/radar-or-treemap/index.js Copy 1 { 2 \"schemaType\": \"VISUALIZATION\", 3 \"id\": \"radar-or-treemap\", 4 \"displayName\": \"RadarOrTreemap\", 5 \"description\": \"\", 6 \"configuration\": [ 7 { 8 \"name\": \"selectedChart\", 9 \"title\": \"Select chart\", 10 \"description\": \"Select which chart to display\", 11 \"type\": \"enum\", 12 \"items\": [ 13 { 14 \"title\": \"Radar\", 15 \"value\": \"radar\" 16 }, 17 { 18 \"title\": \"Treemap\", 19 \"value\": \"treemap\" 20 } 21 ] 22 }, 23 { 24 \"name\": \"nrqlQueries\", 25 \"title\": \"NRQL Queries\", 26 \"type\": \"collection\", 27 \"items\": [ 28 { 29 \"name\": \"accountId\", 30 \"title\": \"Account ID\", 31 \"description\": \"Account ID to be associated with the query\", 32 \"type\": \"account-id\" 33 }, 34 { 35 \"name\": \"query\", 36 \"title\": \"Query\", 37 \"description\": \"NRQL query for visualization\", 38 \"type\": \"nrql\" 39 } 40 ] 41 }, 42 { 43 \"name\": \"fill\", 44 \"title\": \"Fill color\", 45 \"description\": \"A fill color to override the default fill color\", 46 \"type\": \"string\" 47 }, 48 { 49 \"name\": \"stroke\", 50 \"title\": \"Stroke color\", 51 \"description\": \"A stroke color to override the default stroke color\", 52 \"type\": \"string\" 53 } 54 ] 55 } visualizations/radar-or-treemap/nr1.json Copy Step 5 of 5 Serve your Nerdpack locally, and view it in the Custom Visualizations app in New Relic. Select a chart type from the dropdown in the configuration sidebar, and see your visualization update to show the matching chart type: Summary Congratulations on completing this lesson! You've learned how to customize your visualization using nr1.json configuration. Course This lesson is part of a course that teaches you how to build a custom visualization in the New Relic One platform. When you're ready, continue on to the next lesson: Add custom visualizations to your dashboards.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 529.96674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ". In the previous lesson, you built a custom visualization that shows queried data in one of two <em>chart</em> <em>types</em>: Radar<em>Chart</em> Treemap You used a SegmentedControl to switch between the two <em>chart</em> <em>types</em> in the visualization UI. This implementation takes up space in the visualization, but it offers your users"
      },
      "id": "6091fa3ae7b9d2df595068c1"
    }
  ],
  "/docs/query-your-data/explore-query-data/use-charts/use-your-charts": [
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "Transitioning from Insights",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-22T05:25:43Z",
      "updated_at": "2021-05-22T05:25:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. View dashboards across your organization using cross-account search. Chart all the events and attributes from everywhere across our platform. For more information, see Data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. Transitioning from Insights Switching to using New Relic One dashboards from our deprecated Insights dashboards? See our transition guide. If you're using the Insights Dashboard API, we have have a migration guide that will help you transition to using the new API. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 317.4541,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Organize <em>your</em> dashboards with tags",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " and understand the <em>data</em> you collect. <em>Explore</em> <em>your</em> <em>data</em> and correlate connected sources with tailored, user-friendly <em>charts</em>, and quickly learn the state of <em>your</em> system and applications for faster, more efficient troubleshooting. <em>Use</em> dashboards to: Drive insight with custom, high-density interactive"
      },
      "id": "603ec16028ccbc8d07eba78d"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-05-22T05:24:30Z",
      "updated_at": "2021-05-22T05:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Delete. Editing: To edit a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Edit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 317.43802,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> dashboards",
        "sections": "Add custom visualizations to <em>your</em> dashboards",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "Introduction to the data explorer",
        "Tip",
        "Why it matters",
        "Query your data",
        "Use the data explorer",
        "Explore your events",
        "Explore your metrics",
        "Important",
        "Visualize and refine your exploration",
        "Querying area",
        "NRQL query display",
        "Chart area",
        "Share and export",
        "Use cases",
        "Discover your new data",
        "Validate your data",
        "Troubleshooting data issues"
      ],
      "title": "Introduction to the data explorer",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Explore data"
      ],
      "external_id": "9b8a2973c9d452ded5ee065240d210a7fd65d4b3",
      "image": "https://docs.newrelic.com/static/e31aec3eac2aa8c43b9e0332f87f033b/38cea/browse_data_explorer.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/get-started/introduction-data-explorer/",
      "published_at": "2021-05-22T05:31:57Z",
      "updated_at": "2021-05-22T05:31:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the data explorer you can navigate all your data visually, without any NRQL knowledge. Use the data explorer to access, query and customize your data, create visualizations, and make connections between your services in a consistent and curated experience. Tip To use the data explorer and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters Do you research the state of your systems? Do you need to plan resources, identify and respond to incidents, or troubleshoot faulty behaviors? The data explorer makes it easy to identify, fetch and visualize the data you are looking for through visual menus, without ever using NRQL or building queries. With the data explorer you can: Access events and metrics data in a quick, intuitive way. Exploit the dimensionality of data by making it visible and easily actionable upon. See data from different points of view: from raw data to different visualizations that provide insights on evolution, distribution, etc. Drill down into data with filters. Add your searches to a dashboard in a click. Understand how NRQL works: data explorer shows how queries are built while navigating the available data. Tip Want to switch to New Relic One from Insights? See our transition guide. Query your data To access the data explorer, go to one.newrelic.com and At the top of the page, click the Query your data icon. At the Browse data dropdown, select Events or Metrics. The data explorer is the portal to explore all the data you have in New Relic. You can explore events and metrics on the data explorer UI, or select the Logs and Traces query interfaces to explore those. You can also access the query builder any time by clicking on the tab. Use the data explorer The data explorer consists of a scoping section on the top (a), a data browsing area on the left (b), and a workspace (c). To use the data explorer: Define the scope of the exploration: select the account and data type (metric or event) you want to browse. Select the time range using the time picker. Use the blocks on the left to browse the available data for either events or metrics, and build your search. You can only select one element per block. Blocks are searchable. Explore your events Event type Lists all available events for the selected account. By default, events are sorted by Name. Plot Lists all the numeric attributes of the event previously selected. The first item on the list is count( * ), which is not an attribute. It calculates the count of the selected event. By default attributes are sorted by Name. Select the function that you want to plot. By default each attribute is set to the function Average. Dimensions Lists all the dimensions of the event and plot previously selected. Dimensions are string values that provide information on the event. They represent the cardinality, that is, the uniqueCount of the different values of that attribute in the selected time range. If there is only one element it shows the value of the attribute. By default, dimensions are sorted by Name. Explore your metrics To explore APM timeslice data, select AppID, AppName, or EntityGuid as dimensions (or group by those dimensions). Otherwise, you'll get aggregated data for all entities. Metric Lists all the metrics available for the selected account. By default, metrics are sorted by Name. Dimensions Lists all the dimensions of the metric previously selected. Dimensions are string values that provide information on the metric. They represent the cardinality, that is, the uniqueCount of the different values of that attribute in the selected time range. If there is only one element it shows the value of the attribute. By default, dimensions are by Name. Important We use the metric system (including metric SI prefixes) to display our units. Visualize and refine your exploration The result of your exploration is displayed in the working space on the right. Refine your exploration, or share your chart At the working space you can see: Querying area The querying area breaks down the query into its different constituents. Here you can easily read the result of your exploration as a NRQL query, and check the exact data being plotted. If you are not familiar with NRQL, check this area to learn how queries are built. The different parts of the query are: [ EVENTS ONLY]FROM: the event selected on the first block. SELECT: the plot or metric selected. This input plots only one value and one function. GROUP BY: represents the FACET clause, and groups the data by the selected dimension. LIMIT: type in the amount of values you want to see. WHERE: use this field to further filter results. This input plots n values. Each item can be deleted from the query by clicking on the x. NRQL query display You can see the full query, which is composed by the fields above and the time range selected with the time picker. Tip Need to do more advanced searches or customize your charts? From data explorer you can access query builder to edit the query. Chart area By default data is displayed on a line chart. You can easily change to Area chart, Pie chart, and Bar chart using the chart picker. You can also choose to see your results' raw data as a table, or as in JSON format. If you have selected a dimension, the chart is updated with the different facets. Below the chart you can see the facets' table with the list of facets and the value for each one. Use the facet table to drill down data. By clicking on a facet, it is applied as a filter. The table stays visible so you can easily select another facet to continue your exploration. Share and export You can get the chart as an image, share it as a link, or add it to a dashboard using the Options menu on the top right corner. You can also copy the URL and share your whole exploration with other New Relic users. Use cases See the following examples to learn how and when to use the data explorer. Discover your new data I’ve just connected new instrumentation and want to see if new data is available. Select the account and event or metric that's generating the new data. Use the different tools in the data explorer to toy around the new data that has become available: have a look at the raw data of that event or metric as a table, shape it as a list, or click to see it plotted as a chart. After selecting an event or metric, discover the shape of the data in its dimensions. Guided by cardinality, you can see the different points of view of any data. Found anything relevant? Save it to a dashboard or share it with a colleague. Validate your data I changed a custom event/metric and need to check if this change has been successful. In the data explorer tab, select the account, data type and event/metric you made changes to. Verify the entity is reporting data, and that all the attributes are being plotted. Find the attribute you made changes to and check the update was successful. Troubleshooting data issues I know there’s something off with an event/metric from an alert or dashboard. I need to know the root cause about the event/metric/attribute behavior. In the data explorer, use the menus to select the event or metric that's not behaving as expected and let the data explorer plot that chart. From there, you can drill down in the dimensions of that data and filter by those attributes that are relevant. You can also see that data from different perspectives: its distribution, ranking of values, or evolution over time. Found anything relevant? Save it to a dashboard or share it with a colleague.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 294.34332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>data</em> <em>explorer</em>",
        "sections": "<em>Use</em> the <em>data</em> <em>explorer</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "With the <em>data</em> explorer you can navigate all <em>your</em> <em>data</em> visually, without any NRQL knowledge. <em>Use</em> the <em>data</em> explorer to access, <em>query</em> and customize <em>your</em> <em>data</em>, create visualizations, and make connections between <em>your</em> services in a consistent and curated experience. Tip To <em>use</em> the <em>data</em> explorer"
      },
      "id": "603e962e28ccbc6a92eba7a8"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-22T12:42:47Z",
      "updated_at": "2021-05-22T12:42:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions Here is a listing of the available functions in NRQL. The definitions below contain example NRQL queries. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.80765,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> metric <em>data</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL math using SELECT",
        "Use math operators with SELECT",
        "Results with STRING or FLOAT",
        "Tip",
        "Advanced math functions",
        "abs",
        "round, floor, ceil(ing)",
        "clamp_max, clamp_min",
        "pow",
        "sqrt",
        "exp",
        "ln, log2, log10, log",
        "For more help"
      ],
      "title": "NRQL math using SELECT",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "99bfd8fb7663a1c589160ea026ff585acf9d4023",
      "image": "https://docs.newrelic.com/static/dbeb9b9f1fc039e9d5357d7c2206ad18/c1b63/floor-round-ceil.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select/",
      "published_at": "2021-05-22T17:36:56Z",
      "updated_at": "2021-03-16T10:24:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Query Language (NRQL) supports basic math functions within a SELECT clause. You can apply addition, subtraction, multiplication, and division on both individual attributes as well as the results of aggregator functions. Use math operators with SELECT To use basic math functions in NRQL, include operators within the SELECT clause: Addition: + Subtraction: - Multiplication: * Division: / Here are some examples: SELECT duration-databaseDuration FROM Transaction Copy SELECT count(*)/uniqueCount(session) FROM PageView Copy SELECT average(duration-databaseDuration) FROM Transaction Copy Results with STRING or FLOAT Here is how NRQL handles strings present in math calculations: Examples: sum(1+STRING) = 0 sum(1+MIXED) = skips records where MIXED is a string average(1+STRING) = 0 average(1+MIXED) = skips records where MIXED is a string NULL and zero both appear as 0 in the dashboard. To override NULL values with another numeric value, use the syntax: SELECT average(purchasePrice OR 0) Copy This will replace NULL values with 0 or any number specified. Tip This can also be used to test whether something returns NULL or zero. (zero) OR 1 returns 0. (NULL) OR 1 returns 1. Advanced math functions NRQL includes advanced mathematical functions that can be used for complex calculations and for processing data to display more effectively in the UI. abs abs(n) returns the absolute value of n. For non-negative n it returns n, and for negative n it returns the positive number -n. For example abs(2) = 2, and abs(-4) = 4. round, floor, ceil(ing) These three functions force decimal numbers to one of the neighboring integers. floor(n) returns the closest integer less than or equal to n. ceil(n) returns the closest integer greater than or equal to n. round(n) returns the closest integer to n in either direction. Sample graph showing raw data, with floor, round, and ceiling functions applied. clamp_max, clamp_min The clamping functions impose an upper or lower bound on values. For example, clamp_max(duration, 10) returns the duration, unless it exceeds 10, in which case 10 is returned. Similarly clamp_min(duration, 1) will not return any value lower than 1. The following chart shows the result of clamping both min and max to keep the value in the range 70-90. Sample graph showing raw data with clamp function applied. pow pow(n, m) computes n raised to the power m. (I.e. n * n * ... * n, with m copies of n) sqrt sqrt(n) returns the square root of n, that is, the number such that sqrt(n) * sqrt(n) = n. exp Computes the natural exponential function of the argument: exp(n) = pow(e, n). ln, log2, log10, log These functions compute the logarithm of the argument for various bases. ln(n) computes the natural logarithm: the logarithm base e. log2(n) computes the logarithm base 2. log10(n) computes the logarithm base 10. log(n, b) allows logarithms to be computed with an arbitrary base b. All logarithms satisfy the identity: log(pow(b, n), b) = n. Note that log(0) is undefined, for all bases. Be aware that if you take the logarithm of something that might be zero, you may end up getting \"No Value\" back from your query. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.39134,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> math using SELECT",
        "sections": "<em>NRQL</em> math using SELECT",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>) supports basic math functions within a SELECT clause. You can apply addition, subtraction, multiplication, and division on both individual attributes as well as the results of aggregator functions. Use math operators with SELECT To use basic math functions in <em>NRQL</em>"
      },
      "id": "603ec31864441f942b4e884c"
    },
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "Transitioning from Insights",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-22T05:25:43Z",
      "updated_at": "2021-05-22T05:25:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. View dashboards across your organization using cross-account search. Chart all the events and attributes from everywhere across our platform. For more information, see Data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. Transitioning from Insights Switching to using New Relic One dashboards from our deprecated Insights dashboards? See our transition guide. If you're using the Insights Dashboard API, we have have a migration guide that will help you transition to using the new API. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.06622,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Get</em> <em>started</em> with dashboards",
        "tags": "<em>Query</em> <em>your</em> <em>data</em>",
        "body": " and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core <em>New</em> <em>Relic</em> One features such as Search or <em>Query</em> <em>your</em> <em>data</em> that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name"
      },
      "id": "603ec16028ccbc8d07eba78d"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-22T12:42:47Z",
      "updated_at": "2021-05-22T12:42:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions Here is a listing of the available functions in NRQL. The definitions below contain example NRQL queries. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 375.80765,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> metric <em>data</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of Browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-05-22T17:36:59Z",
      "updated_at": "2021-03-11T03:19:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder: Advanced mode is a NRQL query interface Basic mode provides a simplified query experience that doesn't require knowledge of NRQL but that uses NRQL to generate results New Relic Insights NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in both New Relic One and New Relic Insights. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by New Relic APM, Browser, and Mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the basic mode of New Relic One query builder. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by New Relic APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of Browser data Here's a NRQL query of PageView data, which is reported by New Relic Browser. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for New Relic Browser PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.81308,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ", clauses, and functions. What is <em>NRQL</em>? <em>NRQL</em> is <em>New</em> <em>Relic</em>&#x27;s SQL-like <em>query</em> <em>language</em>. You can use <em>NRQL</em> to retrieve detailed <em>New</em> <em>Relic</em> <em>data</em> and <em>get</em> insight into <em>your</em> applications, hosts, and business-important activity. Reasons to use <em>NRQL</em> include: To answer a question for the purpose of troubleshooting"
      },
      "id": "60445a0e196a67cb09960f6e"
    },
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "Transitioning from Insights",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-22T05:25:43Z",
      "updated_at": "2021-05-22T05:25:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. View dashboards across your organization using cross-account search. Chart all the events and attributes from everywhere across our platform. For more information, see Data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. Transitioning from Insights Switching to using New Relic One dashboards from our deprecated Insights dashboards? See our transition guide. If you're using the Insights Dashboard API, we have have a migration guide that will help you transition to using the new API. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.06622,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Get</em> <em>started</em> with dashboards",
        "tags": "<em>Query</em> <em>your</em> <em>data</em>",
        "body": " and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core <em>New</em> <em>Relic</em> One features such as Search or <em>Query</em> <em>your</em> <em>data</em> that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name"
      },
      "id": "603ec16028ccbc8d07eba78d"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions": [
    {
      "sections": [
        "NRQL math using SELECT",
        "Use math operators with SELECT",
        "Results with STRING or FLOAT",
        "Tip",
        "Advanced math functions",
        "abs",
        "round, floor, ceil(ing)",
        "clamp_max, clamp_min",
        "pow",
        "sqrt",
        "exp",
        "ln, log2, log10, log",
        "For more help"
      ],
      "title": "NRQL math using SELECT",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "99bfd8fb7663a1c589160ea026ff585acf9d4023",
      "image": "https://docs.newrelic.com/static/dbeb9b9f1fc039e9d5357d7c2206ad18/c1b63/floor-round-ceil.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select/",
      "published_at": "2021-05-22T17:36:56Z",
      "updated_at": "2021-03-16T10:24:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Query Language (NRQL) supports basic math functions within a SELECT clause. You can apply addition, subtraction, multiplication, and division on both individual attributes as well as the results of aggregator functions. Use math operators with SELECT To use basic math functions in NRQL, include operators within the SELECT clause: Addition: + Subtraction: - Multiplication: * Division: / Here are some examples: SELECT duration-databaseDuration FROM Transaction Copy SELECT count(*)/uniqueCount(session) FROM PageView Copy SELECT average(duration-databaseDuration) FROM Transaction Copy Results with STRING or FLOAT Here is how NRQL handles strings present in math calculations: Examples: sum(1+STRING) = 0 sum(1+MIXED) = skips records where MIXED is a string average(1+STRING) = 0 average(1+MIXED) = skips records where MIXED is a string NULL and zero both appear as 0 in the dashboard. To override NULL values with another numeric value, use the syntax: SELECT average(purchasePrice OR 0) Copy This will replace NULL values with 0 or any number specified. Tip This can also be used to test whether something returns NULL or zero. (zero) OR 1 returns 0. (NULL) OR 1 returns 1. Advanced math functions NRQL includes advanced mathematical functions that can be used for complex calculations and for processing data to display more effectively in the UI. abs abs(n) returns the absolute value of n. For non-negative n it returns n, and for negative n it returns the positive number -n. For example abs(2) = 2, and abs(-4) = 4. round, floor, ceil(ing) These three functions force decimal numbers to one of the neighboring integers. floor(n) returns the closest integer less than or equal to n. ceil(n) returns the closest integer greater than or equal to n. round(n) returns the closest integer to n in either direction. Sample graph showing raw data, with floor, round, and ceiling functions applied. clamp_max, clamp_min The clamping functions impose an upper or lower bound on values. For example, clamp_max(duration, 10) returns the duration, unless it exceeds 10, in which case 10 is returned. Similarly clamp_min(duration, 1) will not return any value lower than 1. The following chart shows the result of clamping both min and max to keep the value in the range 70-90. Sample graph showing raw data with clamp function applied. pow pow(n, m) computes n raised to the power m. (I.e. n * n * ... * n, with m copies of n) sqrt sqrt(n) returns the square root of n, that is, the number such that sqrt(n) * sqrt(n) = n. exp Computes the natural exponential function of the argument: exp(n) = pow(e, n). ln, log2, log10, log These functions compute the logarithm of the argument for various bases. ln(n) computes the natural logarithm: the logarithm base e. log2(n) computes the logarithm base 2. log10(n) computes the logarithm base 10. log(n, b) allows logarithms to be computed with an arbitrary base b. All logarithms satisfy the identity: log(pow(b, n), b) = n. Note that log(0) is undefined, for all bases. Be aware that if you take the logarithm of something that might be zero, you may end up getting \"No Value\" back from your query. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.39134,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> math using SELECT",
        "sections": "<em>NRQL</em> math using SELECT",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>) supports basic math functions within a SELECT clause. You can apply addition, subtraction, multiplication, and division on both individual attributes as well as the results of aggregator functions. Use math operators with SELECT To use basic math functions in <em>NRQL</em>"
      },
      "id": "603ec31864441f942b4e884c"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of Browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-05-22T17:36:59Z",
      "updated_at": "2021-03-11T03:19:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder: Advanced mode is a NRQL query interface Basic mode provides a simplified query experience that doesn't require knowledge of NRQL but that uses NRQL to generate results New Relic Insights NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in both New Relic One and New Relic Insights. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by New Relic APM, Browser, and Mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the basic mode of New Relic One query builder. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by New Relic APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of Browser data Here's a NRQL query of PageView data, which is reported by New Relic Browser. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for New Relic Browser PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.81308,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ", clauses, and functions. What is <em>NRQL</em>? <em>NRQL</em> is <em>New</em> <em>Relic</em>&#x27;s SQL-like <em>query</em> <em>language</em>. You can use <em>NRQL</em> to retrieve detailed <em>New</em> <em>Relic</em> <em>data</em> and <em>get</em> insight into <em>your</em> applications, hosts, and business-important activity. Reasons to use <em>NRQL</em> include: To answer a question for the purpose of troubleshooting"
      },
      "id": "60445a0e196a67cb09960f6e"
    },
    {
      "sections": [
        "Introduction to dashboards",
        "Tip",
        "Why it matters",
        "Transitioning from Insights",
        "Get started with dashboards",
        "Create a dashboard",
        "Import a dashboard",
        "Clone a dashboard",
        "Delete a dashboard",
        "Mark a dashboard as favorite",
        "Search and sort dashboards",
        "Dashboard permissions",
        "Organize your dashboards with tags",
        "Key visual tools",
        "Consistent chart coloring",
        "Correlated needle",
        "Data scrubber",
        "Brush to zoom",
        "Custom visualizations"
      ],
      "title": "Introduction to dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "caf20070eae1529315d1e0642bd2f853e2872b77",
      "image": "https://docs.newrelic.com/static/c9724f76b9c3ad86f9a22abab501a2af/c1b63/dashboards_intro.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/",
      "published_at": "2021-05-22T05:25:43Z",
      "updated_at": "2021-05-22T05:25:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Envision your data as a complex system of roads: you need to navigate the signs and signals along the way to quickly see and make meaning of the information you collect. New Relic One dashboards gather and chart the specific data you want to see, the way you want to see it, from anywhere in the New Relic platform. Tip To use dashboards and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With New Relic One dashboards you can customize and understand the data you collect. Explore your data and correlate connected sources with tailored, user-friendly charts, and quickly learn the state of your system and applications for faster, more efficient troubleshooting. Use dashboards to: Drive insight with custom, high-density interactive visualizations with a consistent UI. View dashboards across your organization using cross-account search. Chart all the events and attributes from everywhere across our platform. For more information, see Data collection. Add custom attributes or send custom event types to most events in order to better understand your business, and see specific details about how your customers interact with your platform, such as page views, host transactions, etc. Manage your charts and dashboards easily using our quick-access CRUD menus and editing options. Explore and contextualize data with advanced tooltips and zoom-in functions to monitor what your systems are doing in real time. Search your dashboards for attributes and metrics. Send data to your dashboards using our APIs. Transitioning from Insights Switching to using New Relic One dashboards from our deprecated Insights dashboards? See our transition guide. If you're using the Insights Dashboard API, we have have a migration guide that will help you transition to using the new API. Get started with dashboards To access dashboards, go to one.newrelic.com and click on Dashboards on the top navigation menu. In the dashboards index, you can view all the dashboards and data apps associated with your New Relic account. This includes the dashboards you've created within the New Relic One platform as well as the dashboards built in Insights. From the top bar, quickly access our explorer as well as all New Relic capabilities, such as APM, Browser and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core New Relic One features such as Search or Query your data that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name: The name of the dashboard Account: The account the dashboard belongs to Created by: The user who created the dashboard Last edited: When the dashboard was last modified Created on: When the dashboard was created Here you can carry out the following actions: Create a dashboard You can easily create a dashboard in New Relic One from the dashboards index by selecting the + Create a dashboard button located at the top-right corner of the dashboards index. Name your dashboard. Names are searchable, so we recommend giving it a meaningful name (your service or application, for instance) using words that will help you locate your dashboard easily. Select the account the dashboard belongs to. Choose carefully because this action cannot be modified. Press Create to continue, or Cancel to return to the index. Tip By default a dashboard is created with Public - Read and write permissions. You can edit them from the settings menu once you access the dashboard. Alternatively, you can also create a new dashboard: By cloning an existing dashboard. From any chart: Copy any chart from any dashboard to a new or an existing dashboard. From the data explorer or the query builder: Add any chart you create from our querying features to a new or an existing dashboard. From the explorer: Take any custom view from the entity manager over to dashboards. To organize dashboards with multiple pages, see Add pages to a dashboard. Import a dashboard You can import a dashboard as JSON by selecting the Import a dashboard button located at the top-right corner of the dashboards index: Paste the JSON code. By default, the dashboard belongs to the same account as the original dashboard you’re importing. Select a different account if you want to change it. By default, the new dashboard has the same rights as the original dashboard you’re importing. Select different rights if you want to change them. Tip See how to obtain a dashboard’s JSON. Clone a dashboard Clone any dashboard by clicking the Clone dashboard button that appears when you hover over any dashboard row in the index. You can clone any dashboard regardless of your permission levels. The dashboard is automatically copied and the clone is added to the index. Access the new dashboard by clicking on the message that pops up on your screen. The cloned dashboard is named like the original dashboard followed by the word \"copy\". For example, if you clone a dashboard named this is my dashboard, the clone will be created as this is my dashboard copy. The clone has Public - Read and write permissions. You can edit the name and other properties of the dashboard, like the permissions, at any time. Tip The index displays dashboards according to sorting. To quickly find your cloned dashboard, sort the dashboards by creation date. The new dashboard appears on top. Delete a dashboard To delete a dashboard, hover over the dashboard row at the index until the Delete button appears. You can only delete a dashboard if you created it, or if it has Public - Read and write permissions. For more information, see the permissions information. You can also delete a dashboard from the settings panel of the dashboard. Mark a dashboard as favorite Clicking the star icon next to a dashboard toggles on or off the favorites. When you favorite a dashboard, it’s grouped with other favorite dashboards at the top of the list, and appears on the New Relic One home page. To remove a dashboard from your favorites, select the star icon again. New Relic One doesn’t retrieve favorited dashboards from Insights. Learn how to make the transition from Insights to New Relic One. Search and sort dashboards You can search dashboards by dashboard name and author using the search box above the index. You can also sort the dashboards in the index. By default, dashboards you edited recently are at the top of the index in both the favorited and non-favorited sections. To change this order, you can sort both sections by any of the columns in the index, your most recent sort is displayed next time you access New Relic One. Dashboard permissions Dashboards have three types of permissions: Public - Read and write: All users have full rights to the dashboard. Public - Read only: All users are able to see the dashboard, but only you have full rights to work with the dashboard. Other users can access the dashboard but are not able to edit or delete it, although they can clone it. Private: Only you can see the dashboard. When you create a dashboard using the Create a dashboard button or by cloning another dashboard, it will have Public - Read and write rights by default. Access the new dashboard to change this setting. Organize your dashboards with tags You can add tags using our NerdGraph, our tagging API. You can also filter your dashboards by tags, which you can use to identify users, accounts, locations, etc. Click on the tag filter to see the available tags, you can easily select one or more tags from the list to narrow down the dashboards in the index. Key visual tools Dashboards offer intuitive visualization features and tools for advanced data exploration and fast troubleshooting. Consistent chart coloring So that you can quickly see and correlate your data, facets that you apply to more than one chart in a dashboard have a consistent facet color across all the charts. Correlated needle When you mouse over one chart, the correlated needle overlays across all charts or data points in the dashboard at the same time. The tooltip provides the relevant data points from the selected facet, such as maximum and minimum values in a line chart. It also highlights the selected attribute in a pie chart. Data scrubber The chart scrubber helps you select a data point or facet in a chart when the chart is too crowded and facets are too close to each other. Mouse along the needle to smoothly select the adjacent facets and view their associated data points. You can also lighten a heavily populated chart by unselecting one or more of the attributes that appear in the UI. Brush to zoom Drag to select a time segment on any chart and you automatically zoom to that time period on all the charts in the dashboard. The time picker reflects the new period on display in the dashboard. You can return to the default or any other time settings at any time. Custom visualizations You can also make custom visualizations for your dashboards. These enable you to include information from any data source. To learn more about working with custom visualizations, see Build a custom visualization for dashboards and Add custom visualizations to your dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.0661,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Get</em> <em>started</em> with dashboards",
        "tags": "<em>Query</em> <em>your</em> <em>data</em>",
        "body": " and Infrastructure monitoring, Logs, or Applied Intelligence. You can also use the core <em>New</em> <em>Relic</em> One features such as Search or <em>Query</em> <em>your</em> <em>data</em> that are available across the platform. For each dashboard, the index displays the following information: Favorite status, indicated by a star Name"
      },
      "id": "603ec16028ccbc8d07eba78d"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/rate-limits-nrql-queries": [
    {
      "sections": [
        "Query system limits",
        "Important",
        "What happens when you reach a limit",
        "Tip",
        "Create a dashboard to view your limit status",
        "Resource Consumption Limits as a %",
        "Max % Consumption in an hour",
        "APM Agent API transaction events request per minute",
        "Trace API With limit line",
        "Impact FACET",
        "NrIntegrationError by limit",
        "Multi-Account limits (on time series charts only)",
        "Limit list and NrIntegrationError",
        "Limit metrics",
        "newrelic.resourceConsumption.limitValue",
        "newrelic.resourceConsumption.currentValue",
        "newrelic.resourceConsumption.impact",
        "Metric attributes",
        "Set alerts on resource metrics",
        "Limits faceted by LimitName and scoped by Timewindow",
        "Alert on a single limit",
        "Alert on limit impact faceted by dataType, impact, resource, and reason",
        "Alert on impact of a single dataType"
      ],
      "title": "Query system limits",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest data manage data",
        "Manage data",
        "Resource metrics",
        "system limits"
      ],
      "external_id": "f8ca2368c70e4e339cd838d0ad192dd2c40fac0a",
      "image": "https://docs.newrelic.com/static/16cb17d5244a118d794df354f67bab81/c1b63/limits-dashboard.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/query-limits/",
      "published_at": "2021-05-21T16:46:56Z",
      "updated_at": "2021-05-21T16:46:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has resource limits in place to protect your experience, our systems, and our other customers. These limits range from the maximum number of characters you can have in a query, to API request rates, to how many events your queries inspect, and more. This page describes the limit metrics and NrIntegrationError events that enable you to view your limits, your current data usage and overall resource consumption as compared to those limits, and the impact of experiencing a limit event. We also provide a handful of queries that, when compiled into a dashboard, can give you consistent insight into your limits status. Important While NrIntegrationError events cover many limits, resource metrics currently only cover request rate ingestion limits. What happens when you reach a limit Our response to reaching a limit depends on a handful of factors: the type of limit that’s reached, as well as the duration, frequency, and amount at which you exceed the limit. Exceeding a limit doesn’t always mean you experience a limit event, such as dropped data, rejected traffic, or having your data turned off for the rest of the day. We sometimes allow a small buffer before enforcing a limit. That said, any resource consumed above 100% is at risk for limit impact at any time. Many of our rate limits apply proportionally. That means if you’re barely exceeding the limit, we will take less action than if you're exceeding by 200%. Limit metrics are only visible if you're sending data in to a corresponding dataType or limitName API. For example, if you send in data via the Metric API, you’ll see the Metric API resource metrics, but if you don't send any APM data in, you won't see APM resource metrics. Tip Impact metrics will be generated regardless of impact; if there's no impact, you’ll see a 0. An NrIntegrationError is generated when you experience impact and is a good way to quickly see if you’re experiencing any limit events. See View System Limits for more information. Create a dashboard to view your limit status Using three limit metrics together on a dashboard, you can quickly see detailed visuals of your Ingest Resource Request Per Minute limits, and with NrIngrationError get a view into more limits. Dashboard displaying limits status using a handful of queries. We used the following queries to create this dashboard. To make a dashboard like this in New Relic One, select Dashboards, and then Create a dashboard. Then, add a new chart for each query you want to regularly monitor. The three limits metrics included in these queries are described in a separate section, below. From left to right, top to bottom: Resource Consumption Limits as a % FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) /latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName where limitTimeInterval = '1 minute' timeseries Copy Max % Consumption in an hour SELECT max(`usage`) FROM (FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 as 'usage' facet limitName timeseries ) facet limitName Copy APM Agent API transaction events request per minute FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) where limitName = 'APM Agent API transaction events requests per minute' TIMESERIES Copy Trace API With limit line FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) as 'usage', latest(newrelic.resourceConsumption.limitValue) as 'limit' where limitName = 'Trace API requests per minute' TIMESERIES Copy Impact FACET From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource TIMESERIES 1 minute Copy NrIntegrationError by limit FROM NrIntegrationError select count(*) facet limitName TIMESERIES MAX since 1 day ago limit max Copy Multi-Account limits (on time series charts only) If you want to see limits for multiple accounts on one chart: run this query from one of the accounts: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName, consumingAccountId where limitTimeInterval = '1 minute' timeseries limit max Copy Click Add another query. Select a different account. Then run this query again: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName, consumingAccountId where limitTimeInterval = '1 minute' timeseries limit max Copy Finally, save it. Limit list and NrIntegrationError FROM Metric, NrIntegrationError select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) as 'Per Minute Count',latest(newrelic.resourceConsumption.limitValue) as ' limit Value',(rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue)*100)as 'Percent Used', filter (count(*), where NrIntegrationError.limitValue is not null) as 'limit reached count' facet limitName limit 1000 Copy Limit metrics These metrics, used in the dashboard queries above, can hone in on a single limit or resource. Or, with the help of FACET limitName or resource provide a view across all your limits. newrelic.resourceConsumption.limitValue limitValue allows you to see the setting for a limit by limitName and understand more about what resource is linked to this limit. The following examples use the limit value metric in the query: Example for Metric API requests per minute. FROM Metric select latest(newrelic.resourceConsumption.limitValue) where limitName = 'Metric API requests per minute' limit 200 Copy To show all limits, add FACET limitName and consider grouping by limitTimeInterval. FROM Metric select latest(newrelic.resourceConsumption.limitValue) WHERE limitTimeInterval = '1 minute' FACET limitName limit 200 Copy newrelic.resourceConsumption.currentValue currentValue shows you how much of a given resource you’re currently consuming. To get a better glimpse into how our systems are viewing your consumption, use a rate() function with the time period that aligns with the limitTimeInterval. Limit 200. Example for Metric API request per minute: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue),1 minute) where limitName = 'Metric API requests per minute' limit 200 Copy To show all limits, add FACET limitName and consider grouping by limitTimeInterval. FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue),1 minute) where limitTimeInterval = '1 minute' FACET limitName limit 200 Copy newrelic.resourceConsumption.impact impact lets you know for any given resource what impact limit events are having. Zeros mean you are not currently impacted. The most granular we have is dataType. It is possible for multiple instances of limitName to impact a single type, such as Metric RPM and DPM. If we know, we will display limitName. From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, resource, impact, limitName TIMESERIES limit 200 Copy Metric attributes Attributes on newrelic.resourceConsumption.limitValue and newrelic.resourceConsumption.currentValue: limitName - The Name of the limit for the metric data, i.e RPM Metric API. dataType - What kind of data the metric is tracking, i.e Metric, Log, or APM. Resource - What resource is being consumed, i.e. Requests, or DPM. limitTimeInterval - What time window this resource is evaluated for limiting. consumingAccountId - The New Relic account where the resource is being consumed. Attributes on newrelic.resourceConsumption.impact dataType - The kind of data that is being impacted, i.e Metric, Log, APM. Resource - What resource is being impacted, i.e Request Rate. Impact - A count of what is happening when resource has exceeded set limit, i.e dropped requests. consumingAccountId - The New Relic account where the resource is being consumed. Set alerts on resource metrics While building a dashboard to see all your limits is handy, being able to automate it is even better. You can set alerts on your limit metrics to provide updates on limits changes. Tip Because we currently only have metrics on 1 minute time windows, setting TimeWindow = 1 minute, will cover them all. Eventually, we make more metrics available, you might want to set separate alerts for limits that are enforced by different time windows. You can use the following NRQL queries to create alerts. Learn about creating alerts with NRQL queries here. Limits faceted by LimitName and scoped by Timewindow From Metric select (rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue))*100 facet limitName Copy Alert on a single limit From Metric select (rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue))*100 where limitName = 'my limit' Copy Alert on limit impact faceted by dataType, impact, resource, and reason From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource, reason Copy Alert on impact of a single dataType From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource, reason WHERE dataType = 'important things' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.58609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> system <em>limits</em>",
        "sections": "<em>Query</em> system <em>limits</em>",
        "tags": "system <em>limits</em>",
        "body": " for <em>limits</em> that are enforced by different time windows. You can use the following <em>NRQL</em> <em>queries</em> to create alerts. Learn about creating alerts with <em>NRQL</em> <em>queries</em> here. <em>Limits</em> faceted by <em>Limit</em>Name and scoped by Timewindow From Metric select (<em>rate</em>(sum(newrelic.resourceConsumption.currentValue), 1 minute"
      },
      "id": "608abed9196a67a63064a7a6"
    },
    {
      "sections": [
        "View system limits",
        "Responses to limit violations",
        "System limits UI",
        "Troubleshooting limits",
        "For more information"
      ],
      "title": "View system limits",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "d6ff940e92c5d1a3ae34f391e9fa3be5dfa21c2f",
      "image": "https://docs.newrelic.com/static/8ee61e3091f6e044202cff92026afada/8c557/limits-graph.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/view-system-limits/",
      "published_at": "2021-05-21T16:46:56Z",
      "updated_at": "2021-05-15T10:05:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure our systems are always up and ready to support you, and to keep you from unintended use, we place limits on the amount of data you can send, query, and store. Responses to limit violations Limits are enforced per sub-account, and across our APIs. You might reach a limit if you start monitoring a new high-traffic application, or have a sudden data spike. When you do reach a limit, New Relic responds according to the type of data and the limit that’s reached. For example: We place a limit on the number of ingested requests per minute (RPM) per data type. When this limit is reached, we stop accepting data and return a 429 status code for the duration of the minute. For queries, we place limits on the number of records inspected (see query limits). When this limit is reached, New Relic will reject traffic from the source scanning the largest number of records and attempt to allow traffic from other sources. For metrics, we place a limit on the number of unique timeseries (cardinality) per account and per metric. When this limit is reached, aggregated data is turned off for the rest of the UTC day. For every major limit violation, New Relic creates an NrIntegrationError event for that account, which have these limit-related attributes: Attribute Description category 'RateLimit' or 'ApiLimit'. The 'RateLimit' category is used for limits based on a unit of time such as the number of requests ingested per minute. The 'ApiLimit' is used for constant limits, such as the number of attributes on a record. limitName The name of the limit. message Describes the limit and the impact. limitValue The limit reached. System limits UI The system Limits page (from the account dropdown, click Manage your data and click Limits on the left) displays when your account has encountered a rate limit in the specified time period. The page displays a default period of 24 hours; you can set a custom range from the top-right of the page. Non-limit-related NrIntegrationError events are not displayed here. In addition, this page does not display information about limits you have not hit, or how close you are to reaching a limit. For more on creating queries and alerts for data ingest and billing metrics, see Query billing/usage data. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a chart on the Limits UI page displaying a cardinality violation limit issue. To add more detail, or build a dashboard, click the View NRQL button on the chart to see the NRQL powering this view. The graph displays each unique limit type that was reached during the selected time-period. This can help you find any trends based on time. The Limits page also provides a table where you can find the limit name, the limit event message associated with it, and last occurrence time and date. If you click a limit in the table, you see more about what happened, and when. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a limit events table on the Limits UI page. Troubleshooting limits To troubleshoot limits when you reach them, click the limit info in the table, and then follow the docs link that's provided. Different limits have different solutions. For more information See Troubleshoot Metric API with NRIntegrationError events",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.0306,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View system <em>limits</em>",
        "sections": "View system <em>limits</em>",
        "body": " stop accepting data and return a 429 status code for the duration of the minute. For <em>queries</em>, we place <em>limits</em> on the number of records inspected (see query <em>limits</em>). When this <em>limit</em> is reached, New Relic will reject traffic from the source scanning the largest number of records and attempt to allow"
      },
      "id": "60446a7c64441f48d7378f2b"
    },
    {
      "sections": [
        "Insights query API",
        "Tip",
        "Requirements and recommendations",
        "1. Register an API key",
        "2. Create the API query request",
        "Linux",
        "Microsoft Windows",
        "3. Process the returned JSON",
        "Example",
        "Query, query API request, returned data",
        "Rate limiting guidelines"
      ],
      "title": "Insights query API",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Insights API"
      ],
      "external_id": "fa0e72f1345a7adde2418c08dc8950c970140a74",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/insights-apis/query-insights-event-data-api/",
      "published_at": "2021-05-21T16:21:49Z",
      "updated_at": "2021-05-15T10:03:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Insights query API is a REST API for making NRQL queries. Tip This API is no longer the preferred way to query New Relic data. Please use NerdGraph to do that. Requirements and recommendations This API is no longer the preferred way to query New Relic data. Please use NerdGraph to do that. Use of this API may be restricted by role-related user permissions. To add custom data to New Relic, you'd use our data ingest APIs. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. 1. Register an API key To use the Insights query API, you need a query key. You can have multiple query keys, and any query key can be used to initiate any Insights API query. If you have multiple systems querying Insights or different data destinations, New Relic recommends you use multiple query keys to enhance data security. For security reasons, query keys cannot be altered or read using the API. To change or read a query key, use the New Relic UI. Tip This API is no longer the preferred way to query New Relic data. Please use NerdGraph to do that. To create a new query key: Go to insights.newrelic.com > Manage data > API keys. Select the plus icon next to the Query keys heading. Enter a short description of the key. Select Save your notes. 2. Create the API query request When you create or edit a query key, you will see an example curl query that you can use as a template. The example query won't work unless you follow these query rules: The NRQL query string must be URL-encoded. The query string must be less than 4000 bytes. The URL must contain a valid account ID. The X-Query-Key must contain a valid query key. The Content-Type must be application/json. Linux Here is a curl example: curl -H \"Accept: application/json\" -H \"X-Query-Key: YOUR_QUERY_KEY\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/query?nrql=YOUR_URL_ENCODED_QUERY\" Copy Microsoft Windows You can use Powershell to query events via API: Invoke-WebRequest -Uri https://insights-api.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/query?nrql=YOUR_URL_ENCODED_QUERY -Headers @{\"X-Query-Key\"=\"YOUR_QUERY_KEY\"} -ContentType \"application/json\" -Method GET Copy 3. Process the returned JSON The query API returns results in JSON format. There is a limit of 2,000 results per request. The structure of the JSON data depends on the NRQL that you used in the request: Different combinations of SELECT statements, clauses, and functions each return an appropriate response. When writing your code to process the JSON, you should do a test run of your query and examine the resulting JSON. Example The Insights query API returns JSON data. Here's an example of a query, its query request format, and its returned data: Query, query API request, returned data Original NRQL query: SELECT count(appName) FROM PageView SINCE '2014-08-04 00:00:00+0500' Copy Query cURL request (with URL-encoded NRQL query): curl -H \"Accept: application/json\" -H \"X-Query-Key: YOUR_QUERY_KEY\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/query?nrql=SELECT+count%28appName%29+FROM+PageView+SINCE+%272014-08-04+00%3A00%3A00%2B0500%27\" Copy Returned JSON data: { \"results\": [ { \"count\": 80275388 } ], \"metadata\": { \"eventTypes\": [ \"PageView\" ], \"eventType\": \"PageView\", \"openEnded\": true, \"beginTime\": \"2014-08-03T19:00:00Z\", \"endTime\": \"2017-01-18T23:18:41Z\", \"beginTimeMillis=\": 1407092400000, \"endTimeMillis\": 1484781521198, \"rawSince\": \"'2014-08-04 00:00:00+0500'\", \"rawUntil\": \"`now`\", \"rawCompareWith\": \"\", \"clippedTimeWindows\": { \"Browser\": { \"beginTimeMillis\": 1483571921198, \"endTimeMillis\": 1484781521198, \"retentionMillis\": 1209600000 } }, \"messages\": [], \"contents\": [ { \"function\": \"count\", \"attribute\": \"appName\", \"simple\": true } ] } } Copy Rate limiting guidelines We have querying limits. You likely won't encounter these limits, especially if you follow these general guidelines: Limit the amount of requests with complex queries (for example, queries with FACET or TIMESERIES clauses, or queries of over a million events) run at the same time. Limit the amount of requests run concurrently over extended periods of time to a maximum of 5, especially if they include complex queries. If New Relic applies rate limits on your account, the query API returns a 503 error. Charts may display timeout error messages.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.01999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Insights <em>query</em> API",
        "sections": "<em>Rate</em> <em>limiting</em> guidelines",
        "body": ", especially if they include complex <em>queries</em>. If New Relic applies <em>rate</em> <em>limits</em> on your account, the query API returns a 503 error. Charts may display timeout error messages."
      },
      "id": "609f9c86196a67e93722b170"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/app-data-nrql-query-examples": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-22T12:42:47Z",
      "updated_at": "2021-05-22T12:42:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions Here is a listing of the available functions in NRQL. The definitions below contain example NRQL queries. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.49194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-22T17:39:22Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.9325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Create smoother charts with sliding windows",
        "When to use sliding windows",
        "Valid NRQL syntax for SLIDE BY",
        "Translation from PromQL-style queries",
        "Use SLIDE BY with MAX and AUTO",
        "Tip"
      ],
      "title": "Create smoother charts with sliding windows",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "97fe07b51e5f2c6a2868c924d1c829d82fd8f585",
      "image": "https://docs.newrelic.com/static/9d882293c1b7b04e65b4bcf6f3ae4bbf/e5166/SlidingWindow2.jpg",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows/",
      "published_at": "2021-05-22T17:38:35Z",
      "updated_at": "2021-03-16T13:22:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Sliding windows are a technique for generating charts using the SLIDE BY clause in conjunction with the TIMESERIES clause. With sliding windows, data is gathered in time \"windows\" that overlap with each other. For example, in the image below, a query gathers data with 5 minute windows. The windows \"slide\" by 1 minute. Each window overlaps with the previous window by 4 minutes. 5-minute windows with 1-minute \"slide\" In contrast, with \"tumbling\" or \"cascading\" windows, the windows do not overlap. For example, in this TIMESERIES 3 minutes NRQL query, the windows are 3 minutes in length, with each beginning when the other ends. There is no overlap in the measurement interval. 3-minute windows with no overlap or \"slide\". When to use sliding windows Sliding windows are helpful when you need to smooth out \"spiky\" charts. One common use case is to use sliding windows to smooth line graphs that have a lot of variation over short periods of time in cases where the rolling aggregate (for example a rolling mean) is more important than aggregates from narrow windows of time. In the example below, data varies greatly from one minute to another, so the 1-minute tumbling window chart shows many high peaks and low valleys. TIMESERIES query without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The query returns similar data but creates a much smoother chart. TIMESERIES query with SLIDE BY clause Valid NRQL syntax for SLIDE BY Valid NRQL syntax for the SLIDE BY clause will follow the format below. SELECT ... TIMESERIES integer1 units SLIDE BY integer2 units Copy integer1 specifies the sliding window width and integer2 specifies the SLIDE BY interval. units is a time unit, such as second, minute, hour, or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy Translation from PromQL-style queries When applicable, a PromQL-style query is translated into a NRQL sliding window query. For example, if your PromQL style query uses rate(request_count[5m]) for the past 60 minutes with a 1-minute window overlap, the NRQL translation would be the query below. SELECT rate(sum(request_count), 1 SECONDS) FROM Metric SINCE 3600 SECONDS AGO UNTIL NOW FACET dimensions() LIMIT 100 TIMESERIES 300000 SLIDE BY 60000 Copy In the translation output, the default unit of millisecond is used for TIMESERIES and SLIDE BY clauses. For TIMESERIES, 300000 ms is 300 seconds, or 5 minutes, specifying a window size of 5 minutes. For SLIDE BY, 60000 ms is 60 seconds, specifying a slide interval of 1 minute. Use SLIDE BY with MAX and AUTO You can combine SLIDE BY with MAX and AUTO arguments to further tailor query results, as shown in the examples below. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy Tip When paired with SLIDE BY, TIMESERIES does not support AUTO or MAX. The TIMESERIES value must be an integer time unit value. In other words, SLIDE BY AUTO or SLIDE BY MAX will work, but TIMESERIES AUTO or TIMESERIES MAX followed by SLIDE BY and MAX, AUTO, or a specific integer time unit is not supported. Tip The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which will show up as gaps and unexpected results. If you experience these issues with query results, consider checking for instances of SLIDE BY where the step interval exceeds the window size.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.14075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Valid <em>NRQL</em> syntax for SLIDE BY",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " high peaks and low valleys. TIMESERIES <em>query</em> without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The <em>query</em> returns similar <em>data</em> but creates a much smoother chart. TIMESERIES <em>query</em> with SLIDE BY clause Valid <em>NRQL</em>"
      },
      "id": "603e8a2528ccbc56e5eba774"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/browserspa-nrql-query-examples": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-22T12:42:47Z",
      "updated_at": "2021-05-22T12:42:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions Here is a listing of the available functions in NRQL. The definitions below contain example NRQL queries. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.49194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-22T17:39:22Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.9325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Create smoother charts with sliding windows",
        "When to use sliding windows",
        "Valid NRQL syntax for SLIDE BY",
        "Translation from PromQL-style queries",
        "Use SLIDE BY with MAX and AUTO",
        "Tip"
      ],
      "title": "Create smoother charts with sliding windows",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "97fe07b51e5f2c6a2868c924d1c829d82fd8f585",
      "image": "https://docs.newrelic.com/static/9d882293c1b7b04e65b4bcf6f3ae4bbf/e5166/SlidingWindow2.jpg",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows/",
      "published_at": "2021-05-22T17:38:35Z",
      "updated_at": "2021-03-16T13:22:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Sliding windows are a technique for generating charts using the SLIDE BY clause in conjunction with the TIMESERIES clause. With sliding windows, data is gathered in time \"windows\" that overlap with each other. For example, in the image below, a query gathers data with 5 minute windows. The windows \"slide\" by 1 minute. Each window overlaps with the previous window by 4 minutes. 5-minute windows with 1-minute \"slide\" In contrast, with \"tumbling\" or \"cascading\" windows, the windows do not overlap. For example, in this TIMESERIES 3 minutes NRQL query, the windows are 3 minutes in length, with each beginning when the other ends. There is no overlap in the measurement interval. 3-minute windows with no overlap or \"slide\". When to use sliding windows Sliding windows are helpful when you need to smooth out \"spiky\" charts. One common use case is to use sliding windows to smooth line graphs that have a lot of variation over short periods of time in cases where the rolling aggregate (for example a rolling mean) is more important than aggregates from narrow windows of time. In the example below, data varies greatly from one minute to another, so the 1-minute tumbling window chart shows many high peaks and low valleys. TIMESERIES query without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The query returns similar data but creates a much smoother chart. TIMESERIES query with SLIDE BY clause Valid NRQL syntax for SLIDE BY Valid NRQL syntax for the SLIDE BY clause will follow the format below. SELECT ... TIMESERIES integer1 units SLIDE BY integer2 units Copy integer1 specifies the sliding window width and integer2 specifies the SLIDE BY interval. units is a time unit, such as second, minute, hour, or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy Translation from PromQL-style queries When applicable, a PromQL-style query is translated into a NRQL sliding window query. For example, if your PromQL style query uses rate(request_count[5m]) for the past 60 minutes with a 1-minute window overlap, the NRQL translation would be the query below. SELECT rate(sum(request_count), 1 SECONDS) FROM Metric SINCE 3600 SECONDS AGO UNTIL NOW FACET dimensions() LIMIT 100 TIMESERIES 300000 SLIDE BY 60000 Copy In the translation output, the default unit of millisecond is used for TIMESERIES and SLIDE BY clauses. For TIMESERIES, 300000 ms is 300 seconds, or 5 minutes, specifying a window size of 5 minutes. For SLIDE BY, 60000 ms is 60 seconds, specifying a slide interval of 1 minute. Use SLIDE BY with MAX and AUTO You can combine SLIDE BY with MAX and AUTO arguments to further tailor query results, as shown in the examples below. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy Tip When paired with SLIDE BY, TIMESERIES does not support AUTO or MAX. The TIMESERIES value must be an integer time unit value. In other words, SLIDE BY AUTO or SLIDE BY MAX will work, but TIMESERIES AUTO or TIMESERIES MAX followed by SLIDE BY and MAX, AUTO, or a specific integer time unit is not supported. Tip The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which will show up as gaps and unexpected results. If you experience these issues with query results, consider checking for instances of SLIDE BY where the step interval exceeds the window size.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.14075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Valid <em>NRQL</em> syntax for SLIDE BY",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " high peaks and low valleys. TIMESERIES <em>query</em> without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The <em>query</em> returns similar <em>data</em> but creates a much smoother chart. TIMESERIES <em>query</em> with SLIDE BY clause Valid <em>NRQL</em>"
      },
      "id": "603e8a2528ccbc56e5eba774"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-22T12:42:47Z",
      "updated_at": "2021-05-22T12:42:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions Here is a listing of the available functions in NRQL. The definitions below contain example NRQL queries. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.4917,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-22T17:39:22Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.9325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Improvements to NRQL percentile()",
        "Error types and impacts on reported data",
        "Making percentile calculations more accurate",
        "Contrast ratio and relative error",
        "Negative numbers and zero",
        "Stable measurement",
        "Viewing relative error",
        "Result verification",
        "Tip"
      ],
      "title": "Improvements to NRQL percentile()",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "db5e977f25358df613f2030a5dcc37e642454e81",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/improvements-nrql-percentile/",
      "published_at": "2021-05-22T17:38:35Z",
      "updated_at": "2021-03-16T12:17:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In telemetry, percentile is an important statistical measurement with many applications. However, it also presents a challenge for those working with large data sets. This is because the standard method for computing percentile is also technically \"expensive\" due to the need to sort data. The new percentile() function works on arbitrarily large data sets, with minimal cost. It is also excellent for long tail distributions. Its relative error consistency is guaranteed across the board for percentiles from 0% to 100%. As a user, you don’t need to do anything to get the new algorithm. All your percentile() calls are automatically executed using it. But if you’d like to learn more about how the new percentile() function was developed and how it is superior to the previous method used, read on for a deep dive on New Relic’s changes and rationale. Error types and impacts on reported data Until recently, New Relic has relied on the method described in Quantiles over Data Streams: An Experimental Study. This method uses rank error, and with New Relic’s parameters applied, results in 0.3% rank error. But because rank error is calculated differently than relative or absolute error, this means there may be much wider variation between actual and reported values than is desirable. To better understand the impact of different error types, it’s helpful to take a closer look at error types in the context of percentile calculation percentile(p) = x. The table shows how error type impacts lower and upper bound of reported value. Error type Lower bound of reported_x Upper bound of reported_x absolute error actual_x - absolute_error actual_x + absolute_error relative error actual_x * (1 - relative_error) actual_x * (1 + relative_error) rank error percentile * (p - rank error) percentile * (p + rank error) As you can see in the table, for absolute error, reported value is within +/- range of actual value, and for relative error, reported value is within +/- percent of actual value. Rank error works a bit differently and is best described with a concrete example: If you request the 99th percentile of a data set and the reported value is 500 with 0.3% rank error, it means that the reported value is within the range of 98.7 and 99.3 percentile for the data set. Why is this important? Because, since the rank error is calculated relative to the percentile p and not the value x, there is no guarantee that the reported value will be particularly close to the actual value. In long tail telemetry distributions, the difference between actual and reported values may in fact be quite large. For example, when the value corresponding to 98.7 percentile is 1000, but the value corresponding to 99.3 percentile is 2000, any value reported between 1000 and 2000 meets the 0.3% rank error specification, creating a pretty large margin of error. As you can see from the example, the accuracy of the old method depends on how much the value varies within the percentile. While this method is usually adequate for the median (50%) and up to 90%, it often falls short for long tail distribution above 99%. Making percentile calculations more accurate In July 2020, New Relic rolled out a new way of calculating percentile() that uses a proprietary algorithm in what is known as the logarithmic scale equal-width histogram family. Like other methods in this family, it provides relative error guarantee. The typical relative error of the new method for most datasets is about 3%.This means that, regardless of the percentile you ask for being 1%, 99%, or 99.99%, the reported value is guaranteed to be within 3% of the actual value. This is particularly good for long tail tracking. No matter what percentile you ask for, the same 3% relative error holds. Contrast ratio and relative error Contrast ratios are calculated by dividing the largest number in the input data set by the smallest non-zero number in the input data set. If input has negative numbers, contrast ratio is computed separately on the positive number set and on the absolute values of the negative number set. The final contrast ratio is the larger of the positive and negative numbers’ contrast ratio. When the contrast of the data set is higher, the relative error is also higher. To control how \"costly\" the computations are in terms of data handling, the new algorithm limits the number of histogram buckets, with relative error at about 3% for data sets within the 1,000 to 1 million contrast ratio bucket. This should cover use cases for most customers. The table below shows how contrast ranges below 1,000 and above 1 million impact relative error and, for scale, the time duration a contrast ratio can represent. Contrast ratio Relative error Duration range example 32 to 1K 1.5635% 1 millisecond to 1 second 1K to 1M 3.125% 1 millisecond to 16 minutes 1M to 1T (2^40, about 10^12) 6.25% 1 millisecond to 31 years 1T to 2^80 (about 10^24) 12.5% 1 nanosecond to 31 million years Negative numbers and zero The new method covers any mixture of positive numbers, zero, and negative numbers. Relative error for negative numbers is defined based on absolute values. Zero is excluded in contrast calculation. Stable measurement The new method returns stable measurement. When changes in the measured data set is within error margin, the method returns the same number. This provides a clear signal to the user: If the number does not change, then there is no measurable change. If the number changes, there is measurable change. In comparison, the old method may return a different number even when there is no statistically significant change in the data set. The burden is on the user to determine if the difference in returned numbers represents a measurable change. A change is significant only when the difference is greater than the error margin. Viewing relative error The relative error of a percentile() call is returned in JSON results of NRQL queries via the relativeError field. If you are using a graphic UI, you will need to switch to JSON format to see the result metadata. Here’s an example of result metadata showing 3.125% relative error. \"contents\": [ { \"function\": \"percentile\", \"attribute\": \"wallClockTime\", \"relativeError\": 0.03125, \"thresholds\": [ 50, 99 ] } Copy Result verification To verify the accuracy of the new method, you can run the histogram() NRQL function to get an overall picture of the distribution. Looking at the histogram, you can tell if a reported percentile makes sense. For example, you can visually estimate if the population above a reported 99% percentile is close to the expected 1%. For precise verification of a percentile value and its relative error, you can use the following method (assuming positive numbers). Let the reported value be r, and the true value be t. Then relative error e can be defined as: e = absolute(r - t) / t Copy Using the formula above, we can express the range of r using t, then express the range of t using r as below: r > t * (1 - e) => t < r / (1 - e) r < t * (1 + e) => t > r / (1 + e) Copy Using r and e reported from a percentile query, we can compute the lower and upper bound of t, using a percentage() query like below. This is possible because the percentage() function does not use approximation. It always returns the exact result. from myEventType SELECT percentage(count(*), where wallClockTime < 188 / (1 + 0.03125)) as 'lower', percentage(count(*), where wallClockTime < 188 / (1 - .03125)) as 'upper' Copy In this example, 188 is the reported percentile of wallClockTime at 90%. Relative error is .03125. The query result returned is: lower: 89.54, upper: 90.23 Copy The result shows that 90% indeed falls within the range. In other words, the requested 90% percentile is within error margin. This verifies the accuracy of the reported value. Tip The same algorithm is used for the distribution metric type in events to metrics service. So whether you are directly querying events or querying via distribution metrics, your results will be equally accurate.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.12598,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Improvements to <em>NRQL</em> percentile()",
        "sections": "Improvements to <em>NRQL</em> percentile()",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " percentile() function works on arbitrarily large <em>data</em> sets, with minimal cost. It is also excellent for long tail distributions. Its relative error consistency is guaranteed across the board for percentiles from 0% to 100%. As a user, you don’t need to do anything to get the <em>new</em> algorithm. All <em>your</em>"
      },
      "id": "603e7668196a6745c2a83def"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/funnels-evaluate-data-series-related-events": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-22T12:42:47Z",
      "updated_at": "2021-05-22T12:42:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions Here is a listing of the available functions in NRQL. The definitions below contain example NRQL queries. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.4917,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-22T17:39:22Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.9325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Create smoother charts with sliding windows",
        "When to use sliding windows",
        "Valid NRQL syntax for SLIDE BY",
        "Translation from PromQL-style queries",
        "Use SLIDE BY with MAX and AUTO",
        "Tip"
      ],
      "title": "Create smoother charts with sliding windows",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "97fe07b51e5f2c6a2868c924d1c829d82fd8f585",
      "image": "https://docs.newrelic.com/static/9d882293c1b7b04e65b4bcf6f3ae4bbf/e5166/SlidingWindow2.jpg",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows/",
      "published_at": "2021-05-22T17:38:35Z",
      "updated_at": "2021-03-16T13:22:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Sliding windows are a technique for generating charts using the SLIDE BY clause in conjunction with the TIMESERIES clause. With sliding windows, data is gathered in time \"windows\" that overlap with each other. For example, in the image below, a query gathers data with 5 minute windows. The windows \"slide\" by 1 minute. Each window overlaps with the previous window by 4 minutes. 5-minute windows with 1-minute \"slide\" In contrast, with \"tumbling\" or \"cascading\" windows, the windows do not overlap. For example, in this TIMESERIES 3 minutes NRQL query, the windows are 3 minutes in length, with each beginning when the other ends. There is no overlap in the measurement interval. 3-minute windows with no overlap or \"slide\". When to use sliding windows Sliding windows are helpful when you need to smooth out \"spiky\" charts. One common use case is to use sliding windows to smooth line graphs that have a lot of variation over short periods of time in cases where the rolling aggregate (for example a rolling mean) is more important than aggregates from narrow windows of time. In the example below, data varies greatly from one minute to another, so the 1-minute tumbling window chart shows many high peaks and low valleys. TIMESERIES query without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The query returns similar data but creates a much smoother chart. TIMESERIES query with SLIDE BY clause Valid NRQL syntax for SLIDE BY Valid NRQL syntax for the SLIDE BY clause will follow the format below. SELECT ... TIMESERIES integer1 units SLIDE BY integer2 units Copy integer1 specifies the sliding window width and integer2 specifies the SLIDE BY interval. units is a time unit, such as second, minute, hour, or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy Translation from PromQL-style queries When applicable, a PromQL-style query is translated into a NRQL sliding window query. For example, if your PromQL style query uses rate(request_count[5m]) for the past 60 minutes with a 1-minute window overlap, the NRQL translation would be the query below. SELECT rate(sum(request_count), 1 SECONDS) FROM Metric SINCE 3600 SECONDS AGO UNTIL NOW FACET dimensions() LIMIT 100 TIMESERIES 300000 SLIDE BY 60000 Copy In the translation output, the default unit of millisecond is used for TIMESERIES and SLIDE BY clauses. For TIMESERIES, 300000 ms is 300 seconds, or 5 minutes, specifying a window size of 5 minutes. For SLIDE BY, 60000 ms is 60 seconds, specifying a slide interval of 1 minute. Use SLIDE BY with MAX and AUTO You can combine SLIDE BY with MAX and AUTO arguments to further tailor query results, as shown in the examples below. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy Tip When paired with SLIDE BY, TIMESERIES does not support AUTO or MAX. The TIMESERIES value must be an integer time unit value. In other words, SLIDE BY AUTO or SLIDE BY MAX will work, but TIMESERIES AUTO or TIMESERIES MAX followed by SLIDE BY and MAX, AUTO, or a specific integer time unit is not supported. Tip The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which will show up as gaps and unexpected results. If you experience these issues with query results, consider checking for instances of SLIDE BY where the step interval exceeds the window size.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.14075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Valid <em>NRQL</em> syntax for SLIDE BY",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " high peaks and low valleys. TIMESERIES <em>query</em> without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The <em>query</em> returns similar <em>data</em> but creates a much smoother chart. TIMESERIES <em>query</em> with SLIDE BY clause Valid <em>NRQL</em>"
      },
      "id": "603e8a2528ccbc56e5eba774"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/improvements-nrql-percentile": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-22T12:42:47Z",
      "updated_at": "2021-05-22T12:42:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions Here is a listing of the available functions in NRQL. The definitions below contain example NRQL queries. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.49146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-22T17:39:22Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.93248,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Create smoother charts with sliding windows",
        "When to use sliding windows",
        "Valid NRQL syntax for SLIDE BY",
        "Translation from PromQL-style queries",
        "Use SLIDE BY with MAX and AUTO",
        "Tip"
      ],
      "title": "Create smoother charts with sliding windows",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "97fe07b51e5f2c6a2868c924d1c829d82fd8f585",
      "image": "https://docs.newrelic.com/static/9d882293c1b7b04e65b4bcf6f3ae4bbf/e5166/SlidingWindow2.jpg",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows/",
      "published_at": "2021-05-22T17:38:35Z",
      "updated_at": "2021-03-16T13:22:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Sliding windows are a technique for generating charts using the SLIDE BY clause in conjunction with the TIMESERIES clause. With sliding windows, data is gathered in time \"windows\" that overlap with each other. For example, in the image below, a query gathers data with 5 minute windows. The windows \"slide\" by 1 minute. Each window overlaps with the previous window by 4 minutes. 5-minute windows with 1-minute \"slide\" In contrast, with \"tumbling\" or \"cascading\" windows, the windows do not overlap. For example, in this TIMESERIES 3 minutes NRQL query, the windows are 3 minutes in length, with each beginning when the other ends. There is no overlap in the measurement interval. 3-minute windows with no overlap or \"slide\". When to use sliding windows Sliding windows are helpful when you need to smooth out \"spiky\" charts. One common use case is to use sliding windows to smooth line graphs that have a lot of variation over short periods of time in cases where the rolling aggregate (for example a rolling mean) is more important than aggregates from narrow windows of time. In the example below, data varies greatly from one minute to another, so the 1-minute tumbling window chart shows many high peaks and low valleys. TIMESERIES query without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The query returns similar data but creates a much smoother chart. TIMESERIES query with SLIDE BY clause Valid NRQL syntax for SLIDE BY Valid NRQL syntax for the SLIDE BY clause will follow the format below. SELECT ... TIMESERIES integer1 units SLIDE BY integer2 units Copy integer1 specifies the sliding window width and integer2 specifies the SLIDE BY interval. units is a time unit, such as second, minute, hour, or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy Translation from PromQL-style queries When applicable, a PromQL-style query is translated into a NRQL sliding window query. For example, if your PromQL style query uses rate(request_count[5m]) for the past 60 minutes with a 1-minute window overlap, the NRQL translation would be the query below. SELECT rate(sum(request_count), 1 SECONDS) FROM Metric SINCE 3600 SECONDS AGO UNTIL NOW FACET dimensions() LIMIT 100 TIMESERIES 300000 SLIDE BY 60000 Copy In the translation output, the default unit of millisecond is used for TIMESERIES and SLIDE BY clauses. For TIMESERIES, 300000 ms is 300 seconds, or 5 minutes, specifying a window size of 5 minutes. For SLIDE BY, 60000 ms is 60 seconds, specifying a slide interval of 1 minute. Use SLIDE BY with MAX and AUTO You can combine SLIDE BY with MAX and AUTO arguments to further tailor query results, as shown in the examples below. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy Tip When paired with SLIDE BY, TIMESERIES does not support AUTO or MAX. The TIMESERIES value must be an integer time unit value. In other words, SLIDE BY AUTO or SLIDE BY MAX will work, but TIMESERIES AUTO or TIMESERIES MAX followed by SLIDE BY and MAX, AUTO, or a specific integer time unit is not supported. Tip The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which will show up as gaps and unexpected results. If you experience these issues with query results, consider checking for instances of SLIDE BY where the step interval exceeds the window size.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.14075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Valid <em>NRQL</em> syntax for SLIDE BY",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " high peaks and low valleys. TIMESERIES <em>query</em> without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The <em>query</em> returns similar <em>data</em> but creates a much smoother chart. TIMESERIES <em>query</em> with SLIDE BY clause Valid <em>NRQL</em>"
      },
      "id": "603e8a2528ccbc56e5eba774"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nested-aggregation-make-ordered-computations-single-query": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-22T12:42:47Z",
      "updated_at": "2021-05-22T12:42:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions Here is a listing of the available functions in NRQL. The definitions below contain example NRQL queries. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.49124,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-22T17:39:22Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.93246,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Create smoother charts with sliding windows",
        "When to use sliding windows",
        "Valid NRQL syntax for SLIDE BY",
        "Translation from PromQL-style queries",
        "Use SLIDE BY with MAX and AUTO",
        "Tip"
      ],
      "title": "Create smoother charts with sliding windows",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "97fe07b51e5f2c6a2868c924d1c829d82fd8f585",
      "image": "https://docs.newrelic.com/static/9d882293c1b7b04e65b4bcf6f3ae4bbf/e5166/SlidingWindow2.jpg",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows/",
      "published_at": "2021-05-22T17:38:35Z",
      "updated_at": "2021-03-16T13:22:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Sliding windows are a technique for generating charts using the SLIDE BY clause in conjunction with the TIMESERIES clause. With sliding windows, data is gathered in time \"windows\" that overlap with each other. For example, in the image below, a query gathers data with 5 minute windows. The windows \"slide\" by 1 minute. Each window overlaps with the previous window by 4 minutes. 5-minute windows with 1-minute \"slide\" In contrast, with \"tumbling\" or \"cascading\" windows, the windows do not overlap. For example, in this TIMESERIES 3 minutes NRQL query, the windows are 3 minutes in length, with each beginning when the other ends. There is no overlap in the measurement interval. 3-minute windows with no overlap or \"slide\". When to use sliding windows Sliding windows are helpful when you need to smooth out \"spiky\" charts. One common use case is to use sliding windows to smooth line graphs that have a lot of variation over short periods of time in cases where the rolling aggregate (for example a rolling mean) is more important than aggregates from narrow windows of time. In the example below, data varies greatly from one minute to another, so the 1-minute tumbling window chart shows many high peaks and low valleys. TIMESERIES query without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The query returns similar data but creates a much smoother chart. TIMESERIES query with SLIDE BY clause Valid NRQL syntax for SLIDE BY Valid NRQL syntax for the SLIDE BY clause will follow the format below. SELECT ... TIMESERIES integer1 units SLIDE BY integer2 units Copy integer1 specifies the sliding window width and integer2 specifies the SLIDE BY interval. units is a time unit, such as second, minute, hour, or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy Translation from PromQL-style queries When applicable, a PromQL-style query is translated into a NRQL sliding window query. For example, if your PromQL style query uses rate(request_count[5m]) for the past 60 minutes with a 1-minute window overlap, the NRQL translation would be the query below. SELECT rate(sum(request_count), 1 SECONDS) FROM Metric SINCE 3600 SECONDS AGO UNTIL NOW FACET dimensions() LIMIT 100 TIMESERIES 300000 SLIDE BY 60000 Copy In the translation output, the default unit of millisecond is used for TIMESERIES and SLIDE BY clauses. For TIMESERIES, 300000 ms is 300 seconds, or 5 minutes, specifying a window size of 5 minutes. For SLIDE BY, 60000 ms is 60 seconds, specifying a slide interval of 1 minute. Use SLIDE BY with MAX and AUTO You can combine SLIDE BY with MAX and AUTO arguments to further tailor query results, as shown in the examples below. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy Tip When paired with SLIDE BY, TIMESERIES does not support AUTO or MAX. The TIMESERIES value must be an integer time unit value. In other words, SLIDE BY AUTO or SLIDE BY MAX will work, but TIMESERIES AUTO or TIMESERIES MAX followed by SLIDE BY and MAX, AUTO, or a specific integer time unit is not supported. Tip The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which will show up as gaps and unexpected results. If you experience these issues with query results, consider checking for instances of SLIDE BY where the step interval exceeds the window size.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.14075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Valid <em>NRQL</em> syntax for SLIDE BY",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " high peaks and low valleys. TIMESERIES <em>query</em> without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The <em>query</em> returns similar <em>data</em> but creates a much smoother chart. TIMESERIES <em>query</em> with SLIDE BY clause Valid <em>NRQL</em>"
      },
      "id": "603e8a2528ccbc56e5eba774"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-22T12:42:47Z",
      "updated_at": "2021-05-22T12:42:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions Here is a listing of the available functions in NRQL. The definitions below contain example NRQL queries. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.49124,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Create smoother charts with sliding windows",
        "When to use sliding windows",
        "Valid NRQL syntax for SLIDE BY",
        "Translation from PromQL-style queries",
        "Use SLIDE BY with MAX and AUTO",
        "Tip"
      ],
      "title": "Create smoother charts with sliding windows",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "97fe07b51e5f2c6a2868c924d1c829d82fd8f585",
      "image": "https://docs.newrelic.com/static/9d882293c1b7b04e65b4bcf6f3ae4bbf/e5166/SlidingWindow2.jpg",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows/",
      "published_at": "2021-05-22T17:38:35Z",
      "updated_at": "2021-03-16T13:22:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Sliding windows are a technique for generating charts using the SLIDE BY clause in conjunction with the TIMESERIES clause. With sliding windows, data is gathered in time \"windows\" that overlap with each other. For example, in the image below, a query gathers data with 5 minute windows. The windows \"slide\" by 1 minute. Each window overlaps with the previous window by 4 minutes. 5-minute windows with 1-minute \"slide\" In contrast, with \"tumbling\" or \"cascading\" windows, the windows do not overlap. For example, in this TIMESERIES 3 minutes NRQL query, the windows are 3 minutes in length, with each beginning when the other ends. There is no overlap in the measurement interval. 3-minute windows with no overlap or \"slide\". When to use sliding windows Sliding windows are helpful when you need to smooth out \"spiky\" charts. One common use case is to use sliding windows to smooth line graphs that have a lot of variation over short periods of time in cases where the rolling aggregate (for example a rolling mean) is more important than aggregates from narrow windows of time. In the example below, data varies greatly from one minute to another, so the 1-minute tumbling window chart shows many high peaks and low valleys. TIMESERIES query without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The query returns similar data but creates a much smoother chart. TIMESERIES query with SLIDE BY clause Valid NRQL syntax for SLIDE BY Valid NRQL syntax for the SLIDE BY clause will follow the format below. SELECT ... TIMESERIES integer1 units SLIDE BY integer2 units Copy integer1 specifies the sliding window width and integer2 specifies the SLIDE BY interval. units is a time unit, such as second, minute, hour, or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy Translation from PromQL-style queries When applicable, a PromQL-style query is translated into a NRQL sliding window query. For example, if your PromQL style query uses rate(request_count[5m]) for the past 60 minutes with a 1-minute window overlap, the NRQL translation would be the query below. SELECT rate(sum(request_count), 1 SECONDS) FROM Metric SINCE 3600 SECONDS AGO UNTIL NOW FACET dimensions() LIMIT 100 TIMESERIES 300000 SLIDE BY 60000 Copy In the translation output, the default unit of millisecond is used for TIMESERIES and SLIDE BY clauses. For TIMESERIES, 300000 ms is 300 seconds, or 5 minutes, specifying a window size of 5 minutes. For SLIDE BY, 60000 ms is 60 seconds, specifying a slide interval of 1 minute. Use SLIDE BY with MAX and AUTO You can combine SLIDE BY with MAX and AUTO arguments to further tailor query results, as shown in the examples below. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy Tip When paired with SLIDE BY, TIMESERIES does not support AUTO or MAX. The TIMESERIES value must be an integer time unit value. In other words, SLIDE BY AUTO or SLIDE BY MAX will work, but TIMESERIES AUTO or TIMESERIES MAX followed by SLIDE BY and MAX, AUTO, or a specific integer time unit is not supported. Tip The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which will show up as gaps and unexpected results. If you experience these issues with query results, consider checking for instances of SLIDE BY where the step interval exceeds the window size.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.14075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Valid <em>NRQL</em> syntax for SLIDE BY",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " high peaks and low valleys. TIMESERIES <em>query</em> without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The <em>query</em> returns similar <em>data</em> but creates a much smoother chart. TIMESERIES <em>query</em> with SLIDE BY clause Valid <em>NRQL</em>"
      },
      "id": "603e8a2528ccbc56e5eba774"
    },
    {
      "sections": [
        "Improvements to NRQL percentile()",
        "Error types and impacts on reported data",
        "Making percentile calculations more accurate",
        "Contrast ratio and relative error",
        "Negative numbers and zero",
        "Stable measurement",
        "Viewing relative error",
        "Result verification",
        "Tip"
      ],
      "title": "Improvements to NRQL percentile()",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "db5e977f25358df613f2030a5dcc37e642454e81",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/improvements-nrql-percentile/",
      "published_at": "2021-05-22T17:38:35Z",
      "updated_at": "2021-03-16T12:17:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In telemetry, percentile is an important statistical measurement with many applications. However, it also presents a challenge for those working with large data sets. This is because the standard method for computing percentile is also technically \"expensive\" due to the need to sort data. The new percentile() function works on arbitrarily large data sets, with minimal cost. It is also excellent for long tail distributions. Its relative error consistency is guaranteed across the board for percentiles from 0% to 100%. As a user, you don’t need to do anything to get the new algorithm. All your percentile() calls are automatically executed using it. But if you’d like to learn more about how the new percentile() function was developed and how it is superior to the previous method used, read on for a deep dive on New Relic’s changes and rationale. Error types and impacts on reported data Until recently, New Relic has relied on the method described in Quantiles over Data Streams: An Experimental Study. This method uses rank error, and with New Relic’s parameters applied, results in 0.3% rank error. But because rank error is calculated differently than relative or absolute error, this means there may be much wider variation between actual and reported values than is desirable. To better understand the impact of different error types, it’s helpful to take a closer look at error types in the context of percentile calculation percentile(p) = x. The table shows how error type impacts lower and upper bound of reported value. Error type Lower bound of reported_x Upper bound of reported_x absolute error actual_x - absolute_error actual_x + absolute_error relative error actual_x * (1 - relative_error) actual_x * (1 + relative_error) rank error percentile * (p - rank error) percentile * (p + rank error) As you can see in the table, for absolute error, reported value is within +/- range of actual value, and for relative error, reported value is within +/- percent of actual value. Rank error works a bit differently and is best described with a concrete example: If you request the 99th percentile of a data set and the reported value is 500 with 0.3% rank error, it means that the reported value is within the range of 98.7 and 99.3 percentile for the data set. Why is this important? Because, since the rank error is calculated relative to the percentile p and not the value x, there is no guarantee that the reported value will be particularly close to the actual value. In long tail telemetry distributions, the difference between actual and reported values may in fact be quite large. For example, when the value corresponding to 98.7 percentile is 1000, but the value corresponding to 99.3 percentile is 2000, any value reported between 1000 and 2000 meets the 0.3% rank error specification, creating a pretty large margin of error. As you can see from the example, the accuracy of the old method depends on how much the value varies within the percentile. While this method is usually adequate for the median (50%) and up to 90%, it often falls short for long tail distribution above 99%. Making percentile calculations more accurate In July 2020, New Relic rolled out a new way of calculating percentile() that uses a proprietary algorithm in what is known as the logarithmic scale equal-width histogram family. Like other methods in this family, it provides relative error guarantee. The typical relative error of the new method for most datasets is about 3%.This means that, regardless of the percentile you ask for being 1%, 99%, or 99.99%, the reported value is guaranteed to be within 3% of the actual value. This is particularly good for long tail tracking. No matter what percentile you ask for, the same 3% relative error holds. Contrast ratio and relative error Contrast ratios are calculated by dividing the largest number in the input data set by the smallest non-zero number in the input data set. If input has negative numbers, contrast ratio is computed separately on the positive number set and on the absolute values of the negative number set. The final contrast ratio is the larger of the positive and negative numbers’ contrast ratio. When the contrast of the data set is higher, the relative error is also higher. To control how \"costly\" the computations are in terms of data handling, the new algorithm limits the number of histogram buckets, with relative error at about 3% for data sets within the 1,000 to 1 million contrast ratio bucket. This should cover use cases for most customers. The table below shows how contrast ranges below 1,000 and above 1 million impact relative error and, for scale, the time duration a contrast ratio can represent. Contrast ratio Relative error Duration range example 32 to 1K 1.5635% 1 millisecond to 1 second 1K to 1M 3.125% 1 millisecond to 16 minutes 1M to 1T (2^40, about 10^12) 6.25% 1 millisecond to 31 years 1T to 2^80 (about 10^24) 12.5% 1 nanosecond to 31 million years Negative numbers and zero The new method covers any mixture of positive numbers, zero, and negative numbers. Relative error for negative numbers is defined based on absolute values. Zero is excluded in contrast calculation. Stable measurement The new method returns stable measurement. When changes in the measured data set is within error margin, the method returns the same number. This provides a clear signal to the user: If the number does not change, then there is no measurable change. If the number changes, there is measurable change. In comparison, the old method may return a different number even when there is no statistically significant change in the data set. The burden is on the user to determine if the difference in returned numbers represents a measurable change. A change is significant only when the difference is greater than the error margin. Viewing relative error The relative error of a percentile() call is returned in JSON results of NRQL queries via the relativeError field. If you are using a graphic UI, you will need to switch to JSON format to see the result metadata. Here’s an example of result metadata showing 3.125% relative error. \"contents\": [ { \"function\": \"percentile\", \"attribute\": \"wallClockTime\", \"relativeError\": 0.03125, \"thresholds\": [ 50, 99 ] } Copy Result verification To verify the accuracy of the new method, you can run the histogram() NRQL function to get an overall picture of the distribution. Looking at the histogram, you can tell if a reported percentile makes sense. For example, you can visually estimate if the population above a reported 99% percentile is close to the expected 1%. For precise verification of a percentile value and its relative error, you can use the following method (assuming positive numbers). Let the reported value be r, and the true value be t. Then relative error e can be defined as: e = absolute(r - t) / t Copy Using the formula above, we can express the range of r using t, then express the range of t using r as below: r > t * (1 - e) => t < r / (1 - e) r < t * (1 + e) => t > r / (1 + e) Copy Using r and e reported from a percentile query, we can compute the lower and upper bound of t, using a percentage() query like below. This is possible because the percentage() function does not use approximation. It always returns the exact result. from myEventType SELECT percentage(count(*), where wallClockTime < 188 / (1 + 0.03125)) as 'lower', percentage(count(*), where wallClockTime < 188 / (1 - .03125)) as 'upper' Copy In this example, 188 is the reported percentile of wallClockTime at 90%. Relative error is .03125. The query result returned is: lower: 89.54, upper: 90.23 Copy The result shows that 90% indeed falls within the range. In other words, the requested 90% percentile is within error margin. This verifies the accuracy of the reported value. Tip The same algorithm is used for the distribution metric type in events to metrics service. So whether you are directly querying events or querying via distribution metrics, your results will be equally accurate.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.12596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Improvements to <em>NRQL</em> percentile()",
        "sections": "Improvements to <em>NRQL</em> percentile()",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " percentile() function works on arbitrarily large <em>data</em> sets, with minimal cost. It is also excellent for long tail distributions. Its relative error consistency is guaranteed across the board for percentiles from 0% to 100%. As a user, you don’t need to do anything to get the <em>new</em> algorithm. All <em>your</em>"
      },
      "id": "603e7668196a6745c2a83def"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-query-examples-mobile-monitoring": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-22T12:42:47Z",
      "updated_at": "2021-05-22T12:42:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions Here is a listing of the available functions in NRQL. The definitions below contain example NRQL queries. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.491,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-22T17:39:22Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.93246,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Create smoother charts with sliding windows",
        "When to use sliding windows",
        "Valid NRQL syntax for SLIDE BY",
        "Translation from PromQL-style queries",
        "Use SLIDE BY with MAX and AUTO",
        "Tip"
      ],
      "title": "Create smoother charts with sliding windows",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "97fe07b51e5f2c6a2868c924d1c829d82fd8f585",
      "image": "https://docs.newrelic.com/static/9d882293c1b7b04e65b4bcf6f3ae4bbf/e5166/SlidingWindow2.jpg",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows/",
      "published_at": "2021-05-22T17:38:35Z",
      "updated_at": "2021-03-16T13:22:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Sliding windows are a technique for generating charts using the SLIDE BY clause in conjunction with the TIMESERIES clause. With sliding windows, data is gathered in time \"windows\" that overlap with each other. For example, in the image below, a query gathers data with 5 minute windows. The windows \"slide\" by 1 minute. Each window overlaps with the previous window by 4 minutes. 5-minute windows with 1-minute \"slide\" In contrast, with \"tumbling\" or \"cascading\" windows, the windows do not overlap. For example, in this TIMESERIES 3 minutes NRQL query, the windows are 3 minutes in length, with each beginning when the other ends. There is no overlap in the measurement interval. 3-minute windows with no overlap or \"slide\". When to use sliding windows Sliding windows are helpful when you need to smooth out \"spiky\" charts. One common use case is to use sliding windows to smooth line graphs that have a lot of variation over short periods of time in cases where the rolling aggregate (for example a rolling mean) is more important than aggregates from narrow windows of time. In the example below, data varies greatly from one minute to another, so the 1-minute tumbling window chart shows many high peaks and low valleys. TIMESERIES query without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The query returns similar data but creates a much smoother chart. TIMESERIES query with SLIDE BY clause Valid NRQL syntax for SLIDE BY Valid NRQL syntax for the SLIDE BY clause will follow the format below. SELECT ... TIMESERIES integer1 units SLIDE BY integer2 units Copy integer1 specifies the sliding window width and integer2 specifies the SLIDE BY interval. units is a time unit, such as second, minute, hour, or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy Translation from PromQL-style queries When applicable, a PromQL-style query is translated into a NRQL sliding window query. For example, if your PromQL style query uses rate(request_count[5m]) for the past 60 minutes with a 1-minute window overlap, the NRQL translation would be the query below. SELECT rate(sum(request_count), 1 SECONDS) FROM Metric SINCE 3600 SECONDS AGO UNTIL NOW FACET dimensions() LIMIT 100 TIMESERIES 300000 SLIDE BY 60000 Copy In the translation output, the default unit of millisecond is used for TIMESERIES and SLIDE BY clauses. For TIMESERIES, 300000 ms is 300 seconds, or 5 minutes, specifying a window size of 5 minutes. For SLIDE BY, 60000 ms is 60 seconds, specifying a slide interval of 1 minute. Use SLIDE BY with MAX and AUTO You can combine SLIDE BY with MAX and AUTO arguments to further tailor query results, as shown in the examples below. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy Tip When paired with SLIDE BY, TIMESERIES does not support AUTO or MAX. The TIMESERIES value must be an integer time unit value. In other words, SLIDE BY AUTO or SLIDE BY MAX will work, but TIMESERIES AUTO or TIMESERIES MAX followed by SLIDE BY and MAX, AUTO, or a specific integer time unit is not supported. Tip The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which will show up as gaps and unexpected results. If you experience these issues with query results, consider checking for instances of SLIDE BY where the step interval exceeds the window size.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.14073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Valid <em>NRQL</em> syntax for SLIDE BY",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " high peaks and low valleys. TIMESERIES <em>query</em> without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The <em>query</em> returns similar <em>data</em> but creates a much smoother chart. TIMESERIES <em>query</em> with SLIDE BY clause Valid <em>NRQL</em>"
      },
      "id": "603e8a2528ccbc56e5eba774"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-segment-your-data-buckets": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-22T12:42:47Z",
      "updated_at": "2021-05-22T12:42:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions Here is a listing of the available functions in NRQL. The definitions below contain example NRQL queries. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.491,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-22T17:39:22Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.93246,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Create smoother charts with sliding windows",
        "When to use sliding windows",
        "Valid NRQL syntax for SLIDE BY",
        "Translation from PromQL-style queries",
        "Use SLIDE BY with MAX and AUTO",
        "Tip"
      ],
      "title": "Create smoother charts with sliding windows",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "97fe07b51e5f2c6a2868c924d1c829d82fd8f585",
      "image": "https://docs.newrelic.com/static/9d882293c1b7b04e65b4bcf6f3ae4bbf/e5166/SlidingWindow2.jpg",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows/",
      "published_at": "2021-05-22T17:38:35Z",
      "updated_at": "2021-03-16T13:22:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Sliding windows are a technique for generating charts using the SLIDE BY clause in conjunction with the TIMESERIES clause. With sliding windows, data is gathered in time \"windows\" that overlap with each other. For example, in the image below, a query gathers data with 5 minute windows. The windows \"slide\" by 1 minute. Each window overlaps with the previous window by 4 minutes. 5-minute windows with 1-minute \"slide\" In contrast, with \"tumbling\" or \"cascading\" windows, the windows do not overlap. For example, in this TIMESERIES 3 minutes NRQL query, the windows are 3 minutes in length, with each beginning when the other ends. There is no overlap in the measurement interval. 3-minute windows with no overlap or \"slide\". When to use sliding windows Sliding windows are helpful when you need to smooth out \"spiky\" charts. One common use case is to use sliding windows to smooth line graphs that have a lot of variation over short periods of time in cases where the rolling aggregate (for example a rolling mean) is more important than aggregates from narrow windows of time. In the example below, data varies greatly from one minute to another, so the 1-minute tumbling window chart shows many high peaks and low valleys. TIMESERIES query without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The query returns similar data but creates a much smoother chart. TIMESERIES query with SLIDE BY clause Valid NRQL syntax for SLIDE BY Valid NRQL syntax for the SLIDE BY clause will follow the format below. SELECT ... TIMESERIES integer1 units SLIDE BY integer2 units Copy integer1 specifies the sliding window width and integer2 specifies the SLIDE BY interval. units is a time unit, such as second, minute, hour, or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy Translation from PromQL-style queries When applicable, a PromQL-style query is translated into a NRQL sliding window query. For example, if your PromQL style query uses rate(request_count[5m]) for the past 60 minutes with a 1-minute window overlap, the NRQL translation would be the query below. SELECT rate(sum(request_count), 1 SECONDS) FROM Metric SINCE 3600 SECONDS AGO UNTIL NOW FACET dimensions() LIMIT 100 TIMESERIES 300000 SLIDE BY 60000 Copy In the translation output, the default unit of millisecond is used for TIMESERIES and SLIDE BY clauses. For TIMESERIES, 300000 ms is 300 seconds, or 5 minutes, specifying a window size of 5 minutes. For SLIDE BY, 60000 ms is 60 seconds, specifying a slide interval of 1 minute. Use SLIDE BY with MAX and AUTO You can combine SLIDE BY with MAX and AUTO arguments to further tailor query results, as shown in the examples below. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy Tip When paired with SLIDE BY, TIMESERIES does not support AUTO or MAX. The TIMESERIES value must be an integer time unit value. In other words, SLIDE BY AUTO or SLIDE BY MAX will work, but TIMESERIES AUTO or TIMESERIES MAX followed by SLIDE BY and MAX, AUTO, or a specific integer time unit is not supported. Tip The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which will show up as gaps and unexpected results. If you experience these issues with query results, consider checking for instances of SLIDE BY where the step interval exceeds the window size.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.14073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Valid <em>NRQL</em> syntax for SLIDE BY",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " high peaks and low valleys. TIMESERIES <em>query</em> without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The <em>query</em> returns similar <em>data</em> but creates a much smoother chart. TIMESERIES <em>query</em> with SLIDE BY clause Valid <em>NRQL</em>"
      },
      "id": "603e8a2528ccbc56e5eba774"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-05-22T12:42:47Z",
      "updated_at": "2021-05-22T12:42:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. You can specify a UTC timestamp or relative time range. You can specify a time zone for the query but not for the results. The returned results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE 'z.*|q.*'' z-app q-app hostname RLIKE 'ip-10-351-[0-2]?[0-9]-.*' ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Note: Slashes must be escaped in the Regex pattern. For example, \\d must be \\\\d. Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. If the Regex pattern contains a capture group, the group will be ignored. That is, the group will not be captured for use later in the query. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions Here is a listing of the available functions in NRQL. The definitions below contain example NRQL queries. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from complex metrics. It takes the following arguments: Metric type Supported fields summary count, total, max, min gauge count, total, max, min, latest distribution count, total, max, min counter count Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.49078,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL: Group results across time",
        "Facet your NRQL query time range",
        "Group results by month",
        "Other grouping examples with FACET clause"
      ],
      "title": "NRQL: Group results across time",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "90fa8030ed670866a9d8154e8b8f16fc04ba0abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time/",
      "published_at": "2021-05-22T17:39:22Z",
      "updated_at": "2021-04-17T02:08:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NRQL, you can create queries that group results across time. For example, you can group results together based on timestamps by separating them into buckets that cover a specified range of dates and times. When using time functions in NRQL queries, the results are returned in UTC. To adjust the results to your time zone, include the WITH TIMEZONE clause in your query. Facet your NRQL query time range To create your NRQL query, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET query, but instead of faceting by an attribute, facet by time. For example: SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy To perform multiple functions within the same query, use NRQL's multi-facet capability: SELECT count(*) FROM PageView SINCE 1 day ago FACET dateOf(account_created), monthOf(account_created) Copy Time-based functions Description yearOf(attr) Returns the year of a timestamp. quarterOf(attr) Returns the quarter of the year. The returned value includes both the quarter and the year. Example: Q1 2014 monthOf(attr) Returns the month and year of the timestamp. Example: July 2014 weekOf(attr) Returns the week the timestamp occurred by naming the month and day of that week's Monday. Example: Week of January 15. weekdayOf(attr) Returns the day of the week of the timestamp. The returned value loops back at the end of the week, allowing you to look at trends by weekday over time. dateOf(attr) Returns the date of the timestamp. The returned value includes month, day and year. Example: July 15, 2014 dayOfMonthOf(attr) Returns the numeric date within a single month of the timestamp, a value from 1 to 31. The returned value does not include the month. hourOf(attr) Returns the hour of the timestamp. The returned value does not include a prepended 0 for hours between 1am and 9am. This differs from functions and clauses such as SINCE, which accept these hours with a 0 at the start. Examples: 6:00, 12:00, 18:00 Group results by month To group all results based on the month, use the monthOf function. In this example, the NRQL query includes a function (count(*)), a data type (PageView), a time frame (SINCE 1 day ago), and a time facet (monthOf(attribute)). SELECT count(*) FROM PageView SINCE 1 day ago FACET monthOf(account_created) Copy Running the query returns a table of results by month. Other grouping examples with FACET clause You can run NRQL queries to group your data in other ways, not just time. For additional examples, see the NRQL FACET documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.93245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em>: Group results across time",
        "sections": "Facet <em>your</em> <em>NRQL</em> <em>query</em> time range",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " the results to <em>your</em> time zone, include the WITH TIMEZONE clause in <em>your</em> <em>query</em>. Facet <em>your</em> <em>NRQL</em> <em>query</em> time range To create <em>your</em> <em>NRQL</em> <em>query</em>, use a FACET clause with a bucket function that works with a timestamp attribute. Run a standard FACET <em>query</em>, but instead of faceting by an attribute, facet by time"
      },
      "id": "60445a61196a671ddf960f19"
    },
    {
      "sections": [
        "Create smoother charts with sliding windows",
        "When to use sliding windows",
        "Valid NRQL syntax for SLIDE BY",
        "Translation from PromQL-style queries",
        "Use SLIDE BY with MAX and AUTO",
        "Tip"
      ],
      "title": "Create smoother charts with sliding windows",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "97fe07b51e5f2c6a2868c924d1c829d82fd8f585",
      "image": "https://docs.newrelic.com/static/9d882293c1b7b04e65b4bcf6f3ae4bbf/e5166/SlidingWindow2.jpg",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows/",
      "published_at": "2021-05-22T17:38:35Z",
      "updated_at": "2021-03-16T13:22:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Sliding windows are a technique for generating charts using the SLIDE BY clause in conjunction with the TIMESERIES clause. With sliding windows, data is gathered in time \"windows\" that overlap with each other. For example, in the image below, a query gathers data with 5 minute windows. The windows \"slide\" by 1 minute. Each window overlaps with the previous window by 4 minutes. 5-minute windows with 1-minute \"slide\" In contrast, with \"tumbling\" or \"cascading\" windows, the windows do not overlap. For example, in this TIMESERIES 3 minutes NRQL query, the windows are 3 minutes in length, with each beginning when the other ends. There is no overlap in the measurement interval. 3-minute windows with no overlap or \"slide\". When to use sliding windows Sliding windows are helpful when you need to smooth out \"spiky\" charts. One common use case is to use sliding windows to smooth line graphs that have a lot of variation over short periods of time in cases where the rolling aggregate (for example a rolling mean) is more important than aggregates from narrow windows of time. In the example below, data varies greatly from one minute to another, so the 1-minute tumbling window chart shows many high peaks and low valleys. TIMESERIES query without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The query returns similar data but creates a much smoother chart. TIMESERIES query with SLIDE BY clause Valid NRQL syntax for SLIDE BY Valid NRQL syntax for the SLIDE BY clause will follow the format below. SELECT ... TIMESERIES integer1 units SLIDE BY integer2 units Copy integer1 specifies the sliding window width and integer2 specifies the SLIDE BY interval. units is a time unit, such as second, minute, hour, or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy Translation from PromQL-style queries When applicable, a PromQL-style query is translated into a NRQL sliding window query. For example, if your PromQL style query uses rate(request_count[5m]) for the past 60 minutes with a 1-minute window overlap, the NRQL translation would be the query below. SELECT rate(sum(request_count), 1 SECONDS) FROM Metric SINCE 3600 SECONDS AGO UNTIL NOW FACET dimensions() LIMIT 100 TIMESERIES 300000 SLIDE BY 60000 Copy In the translation output, the default unit of millisecond is used for TIMESERIES and SLIDE BY clauses. For TIMESERIES, 300000 ms is 300 seconds, or 5 minutes, specifying a window size of 5 minutes. For SLIDE BY, 60000 ms is 60 seconds, specifying a slide interval of 1 minute. Use SLIDE BY with MAX and AUTO You can combine SLIDE BY with MAX and AUTO arguments to further tailor query results, as shown in the examples below. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy Tip When paired with SLIDE BY, TIMESERIES does not support AUTO or MAX. The TIMESERIES value must be an integer time unit value. In other words, SLIDE BY AUTO or SLIDE BY MAX will work, but TIMESERIES AUTO or TIMESERIES MAX followed by SLIDE BY and MAX, AUTO, or a specific integer time unit is not supported. Tip The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which will show up as gaps and unexpected results. If you experience these issues with query results, consider checking for instances of SLIDE BY where the step interval exceeds the window size.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.14073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Valid <em>NRQL</em> syntax for SLIDE BY",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " high peaks and low valleys. TIMESERIES <em>query</em> without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The <em>query</em> returns similar <em>data</em> but creates a much smoother chart. TIMESERIES <em>query</em> with SLIDE BY clause Valid <em>NRQL</em>"
      },
      "id": "603e8a2528ccbc56e5eba774"
    }
  ],
  "/docs/recommended-alerts-aws-services": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Caution",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-05-22T06:54:39Z",
      "updated_at": "2021-05-22T06:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL (US Datacenter): https://aws-api.newrelic.com/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Caution The AWS Metric Streams integration is temporarily disabled for accounts hosted in the New Relic EU datacenter. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with “eu” then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and it’s not the case, please verify the following: Make sure there’s no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.843376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Missing metrics <em>for</em> certain <em>AWS</em> namespaces",
        "tags": "<em>AWS</em> integrations list",
        "body": " <em>alerts</em> and dashboards that use metrics that have a .Sum suffix. We <em>recommend</em> sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then <em>AWS</em> CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Configure with the New Relic license key (recommended)",
        "Configure with the New Relic Insert API key",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-05-22T16:44:18Z",
      "updated_at": "2021-05-22T16:44:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Choose one of the following options for adding a snippet to your vector.toml file (located in /etc/vector by default): Configure with the New Relic license key (recommended) Replace YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Configure with the New Relic Insert API key Replace YOUR_INSERT_KEY with the Insert API key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs insert_key = \"YOUR_INSERT_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.06176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink <em>for</em> log <em>forwarding</em>",
        "sections": "Configure with the New Relic license key (<em>recommended</em>)",
        "body": ": New Relic license key (<em>recommended</em>) or Insert API key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Choose one of the following options for adding a snippet to your vector.toml file (located in &#x2F;etc&#x2F;vector by default): Configure"
      },
      "id": "6045057664441f9a4a378f17"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-05-21T18:15:37Z",
      "updated_at": "2021-05-11T06:01:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT*' FACET `provider.budgetName` SINCE 1 day ago Copy * You can find New Relic's ID representing your cloud service account in the URL of any New Relic AWS dashboard. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT*' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy * You can find New Relic's ID representing your cloud service account in the URL of any New Relic AWS dashboard. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT*' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy * You can find New Relic's ID representing your cloud service account in the URL of any New Relic AWS dashboard. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT*' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT*' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy * You can find New Relic's ID representing your cloud service account in the URL of any New Relic AWS dashboard. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 86.255066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring integration",
        "sections": "Unaggregated account&#x2F;subaccount and <em>AWS</em> <em>service</em> costs",
        "tags": "<em>AWS</em> integrations list",
        "body": " applications and <em>AWS</em> accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and <em>services</em>, and also evaluates your <em>AWS</em> budgets in terms of actual spend and forecasted spend. This financial data is split"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/security/index": [
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 74.82884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em>",
        "body": "We understand that our customers are evaluating the impact of the SolarWinds <em>Security</em> Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised"
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 74.81537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em>",
        "body": "October 9, 2018 This is a summary of the 2018 <em>security</em> breach of the systems of Apollo.io and New Relic&#x27;s response. <em>Security</em> officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a <em>security</em> breach of their systems, which contained business"
      },
      "id": "60452301196a67e33e960f62"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-22T13:56:26Z",
      "updated_at": "2021-05-16T04:26:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits In the following table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 69.48576,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em>",
        "body": " the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/covid-19": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16653,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.8246,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77475,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16653,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.8246,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "image": "https://docs.newrelic.com/static/futurestack-registration-cf388ce323a82db74de9894bfbe3fb63.png",
      "url": "https://docs.newrelic.com/",
      "sections": [
        "Welcome to New Relic",
        "Create a free account",
        "Start collecting data",
        "Set up alerts",
        "Telemetry Data Platform",
        "Introduction to Telemetry Data Platform",
        "Data explorer",
        "Dashboards",
        "Log management",
        "APIs",
        "Manage data",
        "Build on New Relic One",
        "Full-Stack Observability",
        "Introduction to Full-Stack Observability",
        "APM",
        "Browser",
        "Distributed Tracing",
        "Infrastructure",
        "Logs in context",
        "Mobile",
        "Serverless",
        "Synthetics",
        "Workloads",
        "Alerts and Applied Intelligence (AI)",
        "Introduction to Alerts",
        "Introduction to Applied Intelligence",
        "Incident Intelligence",
        "Incident Workflows",
        "Proactive Detection",
        "New Relic integrations",
        "Back-end, front-end, and mobile applications",
        "Infrastructure and cloud platforms",
        "Open-source monitoring systems",
        "Security, privacy, and legal information",
        "Data privacy",
        "Security compliance",
        "Security bulletins",
        "Licenses"
      ],
      "published_at": "2021-05-23T01:37:22Z",
      "title": "New Relic Documentation",
      "updated_at": "2021-05-23T01:37:22Z",
      "type": "docs",
      "external_id": "807276d5fdd805ba0247a1ce1016af986fb31995",
      "popularity": 1,
      "body": "Welcome to New Relic If you're new, follow these three steps to create an account and get going. (It's free!) Scroll on for more about our Telemetry Data Platform, Full-Stack Observability, and Applied Intelligence. Or, to get a wider view of our platform's capabilities, read the Intro to New Relic, and use our solutions and best practices guides. Create a free account No credit card required. Start collecting data Our UI guides you through setup and install. Set up alerts Get notified quickly about changes in your system. Telemetry Data Platform Ingest, visualize, and alert on all your telemetry data in one place. Introduction to Telemetry Data Platform How to manage all your monitoring in one place. Data explorer Query and build charts with NRQL, our PromQL-style syntax, or our visual chart builder. Dashboards Combine data from anywhere in our platform into customized dashboards. Log management Get logs alongside your telemetry data with our fast, scalable log management. APIs Find APIs to send data in, get data out, or manage the New Relic platform. Manage data Monitor and control your data usage. Build on New Relic One Learn how to build custom apps on our platform at developer.newrelic.com Full-Stack Observability Analyze and troubleshoot problems easily across your entire software stack. Introduction to Full-Stack Observability Get deep insight into everything from infrastructure to server code to end-user apps. APM Get real-time and trending data about your app's performance and stability. Browser Measure website performance, track errors, and see how users interact with your site. Distributed Tracing Track requests through your distributed system to find trends and anomalies. Infrastructure Monitor your infrastructure—hosts, cloud providers, container services, backend services, orchestrators, and more. Logs in context Link your log data to APM agent data so you can pinpoint where things are going wrong. Mobile Understand user journeys in your Android and iOS apps and troubleshoot crashes. Serverless Monitor AWS Lambda, Azure Functions, and Google Cloud Functions. Synthetics Simulate user activity to detect outages and fix poor website performance. Workloads Group or monitor entities across your entire stack based on a team or a set of responsibilities. Alerts and Applied Intelligence (AI) Automatically detect anomalies, correlate issues, and reduce alert noise. Introduction to Alerts Get notified about important changes in your system based on any data you connect to New Relic. Introduction to Applied Intelligence Recognize issues sooner, resolve problems faster, and reduce noise for better incident management. Incident Intelligence Get an overview of all your incidents. See sources and related events, and find out how they all correlate. Incident Workflows Enrich your incidents with New Relic data before sending them to your notification platform. Proactive Detection Get notified by Slack or webhook of unusual app behavior. New Relic integrations Integrations connect the technologies in your stack to New Relic. Here are a few of our 370+ integrations: Back-end, front-end, and mobile applications Android Browser (JavaScript) C SDK Go iOS Java .NET Node.js PHP Python Ruby Synthetics Infrastructure and cloud platforms Apache AWS Azure Google Cloud Kafka Kubernetes Linux Microsoft SQL MongoDB MySQL NGINX PostgreSQL Redis Windows Open-source monitoring systems Dropwizard Istio JMX Kamon Micrometer OpenCensus OpenTelemetry Prometheus StatsD See all 360+ integrations Security, privacy, and legal information Find out how we ensure security, data privacy, and compliance, and find our terms of service. Data privacy New Relic takes your data privacy seriously. Our principles-based approach aims to go beyond the legal requirements for consent. Security compliance Whether your data is in transit to New Relic or at rest in our storage, strong encryption measures can help protect against unauthorized access or theft of valuable data. Security bulletins Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates. Licenses All about New Relic's licenses, Usage Plan, and policies. Find out what open source software we use in our products.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.67746,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Security</em>, <em>privacy</em>, <em>and</em> legal information",
        "body": " Azure Google Cloud Kafka Kubernetes Linux Microsoft SQL MongoDB MySQL NGINX PostgreSQL Redis Windows Open-source monitoring systems Dropwizard Istio JMX Kamon Micrometer OpenCensus OpenTelemetry Prometheus StatsD See all 360+ integrations <em>Security</em>, <em>privacy</em>, and legal information Find out how we ensure"
      },
      "id": "5be4e5d38e9c0f3585d72edf"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16647,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.8245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16647,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.8245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-03": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16647,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.8245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-04": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16644,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.8244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-05": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16644,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.8244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-06": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.8243,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.8243,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82422,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77438,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-03": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82422,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77438,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-04": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82413,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.7743,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-05": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82413,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.7743,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-06": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.1662,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.7742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-07": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.1662,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.7742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-08": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16617,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82394,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.7741,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-09": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16617,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82394,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.7741,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-10": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.1661,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77402,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-11": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.1661,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77402,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-12": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16608,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16608,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16602,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82367,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-03": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16602,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82367,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-04": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16595,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-05": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16595,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.82358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr20-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.1659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.8235,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77365,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr20-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.1659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.8235,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77365,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.8234,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.16583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.8234,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-heartbleed-vulnerability": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.1658,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.8233,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77347,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/solarwinds-orion": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.1658,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.77347,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    },
    {
      "image": "https://docs.newrelic.com/static/futurestack-registration-cf388ce323a82db74de9894bfbe3fb63.png",
      "url": "https://docs.newrelic.com/",
      "sections": [
        "Welcome to New Relic",
        "Create a free account",
        "Start collecting data",
        "Set up alerts",
        "Telemetry Data Platform",
        "Introduction to Telemetry Data Platform",
        "Data explorer",
        "Dashboards",
        "Log management",
        "APIs",
        "Manage data",
        "Build on New Relic One",
        "Full-Stack Observability",
        "Introduction to Full-Stack Observability",
        "APM",
        "Browser",
        "Distributed Tracing",
        "Infrastructure",
        "Logs in context",
        "Mobile",
        "Serverless",
        "Synthetics",
        "Workloads",
        "Alerts and Applied Intelligence (AI)",
        "Introduction to Alerts",
        "Introduction to Applied Intelligence",
        "Incident Intelligence",
        "Incident Workflows",
        "Proactive Detection",
        "New Relic integrations",
        "Back-end, front-end, and mobile applications",
        "Infrastructure and cloud platforms",
        "Open-source monitoring systems",
        "Security, privacy, and legal information",
        "Data privacy",
        "Security compliance",
        "Security bulletins",
        "Licenses"
      ],
      "published_at": "2021-05-23T01:37:22Z",
      "title": "New Relic Documentation",
      "updated_at": "2021-05-23T01:37:22Z",
      "type": "docs",
      "external_id": "807276d5fdd805ba0247a1ce1016af986fb31995",
      "popularity": 1,
      "body": "Welcome to New Relic If you're new, follow these three steps to create an account and get going. (It's free!) Scroll on for more about our Telemetry Data Platform, Full-Stack Observability, and Applied Intelligence. Or, to get a wider view of our platform's capabilities, read the Intro to New Relic, and use our solutions and best practices guides. Create a free account No credit card required. Start collecting data Our UI guides you through setup and install. Set up alerts Get notified quickly about changes in your system. Telemetry Data Platform Ingest, visualize, and alert on all your telemetry data in one place. Introduction to Telemetry Data Platform How to manage all your monitoring in one place. Data explorer Query and build charts with NRQL, our PromQL-style syntax, or our visual chart builder. Dashboards Combine data from anywhere in our platform into customized dashboards. Log management Get logs alongside your telemetry data with our fast, scalable log management. APIs Find APIs to send data in, get data out, or manage the New Relic platform. Manage data Monitor and control your data usage. Build on New Relic One Learn how to build custom apps on our platform at developer.newrelic.com Full-Stack Observability Analyze and troubleshoot problems easily across your entire software stack. Introduction to Full-Stack Observability Get deep insight into everything from infrastructure to server code to end-user apps. APM Get real-time and trending data about your app's performance and stability. Browser Measure website performance, track errors, and see how users interact with your site. Distributed Tracing Track requests through your distributed system to find trends and anomalies. Infrastructure Monitor your infrastructure—hosts, cloud providers, container services, backend services, orchestrators, and more. Logs in context Link your log data to APM agent data so you can pinpoint where things are going wrong. Mobile Understand user journeys in your Android and iOS apps and troubleshoot crashes. Serverless Monitor AWS Lambda, Azure Functions, and Google Cloud Functions. Synthetics Simulate user activity to detect outages and fix poor website performance. Workloads Group or monitor entities across your entire stack based on a team or a set of responsibilities. Alerts and Applied Intelligence (AI) Automatically detect anomalies, correlate issues, and reduce alert noise. Introduction to Alerts Get notified about important changes in your system based on any data you connect to New Relic. Introduction to Applied Intelligence Recognize issues sooner, resolve problems faster, and reduce noise for better incident management. Incident Intelligence Get an overview of all your incidents. See sources and related events, and find out how they all correlate. Incident Workflows Enrich your incidents with New Relic data before sending them to your notification platform. Proactive Detection Get notified by Slack or webhook of unusual app behavior. New Relic integrations Integrations connect the technologies in your stack to New Relic. Here are a few of our 370+ integrations: Back-end, front-end, and mobile applications Android Browser (JavaScript) C SDK Go iOS Java .NET Node.js PHP Python Ruby Synthetics Infrastructure and cloud platforms Apache AWS Azure Google Cloud Kafka Kubernetes Linux Microsoft SQL MongoDB MySQL NGINX PostgreSQL Redis Windows Open-source monitoring systems Dropwizard Istio JMX Kamon Micrometer OpenCensus OpenTelemetry Prometheus StatsD See all 360+ integrations Security, privacy, and legal information Find out how we ensure security, data privacy, and compliance, and find our terms of service. Data privacy New Relic takes your data privacy seriously. Our principles-based approach aims to go beyond the legal requirements for consent. Security compliance Whether your data is in transit to New Relic or at rest in our storage, strong encryption measures can help protect against unauthorized access or theft of valuable data. Security bulletins Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates. Licenses All about New Relic's licenses, Usage Plan, and policies. Find out what open source software we use in our products.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.67444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Security</em>, <em>privacy</em>, <em>and</em> legal information",
        "body": " Azure Google Cloud Kafka Kubernetes Linux Microsoft SQL MongoDB MySQL NGINX PostgreSQL Redis Windows Open-source monitoring systems Dropwizard Istio JMX Kamon Micrometer OpenCensus OpenTelemetry Prometheus StatsD See all 360+ integrations <em>Security</em>, <em>privacy</em>, and legal information Find out how we ensure"
      },
      "id": "5be4e5d38e9c0f3585d72edf"
    }
  ],
  "/docs/security/security-privacy/compliance/data-encryption": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-22T13:56:26Z",
      "updated_at": "2021-05-16T04:26:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits In the following table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.29846,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This list is current. Last updated 23 December 2020. This document describes New Relic&#x27;s products and services as they relate to regulatory framework <em>compliance</em> status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-05-22T13:55:29Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.97261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-22T13:58:31Z",
      "updated_at": "2021-05-09T18:12:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic for our generally available New Relic One platform goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team for our generally available New Relic One platform is assigned a security engineer charged with reviewing and advising on the security of New Relic products. In the requirements building phase the security engineer performs a risk assessment and then adds security requirements for the project. Privacy and compliance experts are added to the project teams as needed. Design During the design phase, the New Relic security engineer collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build Each product engineer receives secure coding training which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and process already in place at New Relic. In the build phase the engineering team implements appropriate security features in the project following secure coding standards at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the code repository. In addition to code scanning software automatically checking for vulnerabilities against security policies, security engineers verify that safeguards and controls recommended in design, requirements, and assessment phases were implemented when needed. New Relic performs static code and composition analysis to look for vulnerabilities in the code and dependencies. Deploy New Relic is in the process of including hashes and signatures. Anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular security scans, third party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.23691,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " charged with reviewing and advising on the <em>security</em> of New Relic products. In the requirements building phase the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. <em>Privacy</em> and <em>compliance</em> experts are added to the project teams as needed. Design During"
      },
      "id": "608d4b4728ccbcac5d51c173"
    }
  ],
  "/docs/security/security-privacy/compliance/fedramp-compliant-endpoints": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-22T13:56:26Z",
      "updated_at": "2021-05-16T04:26:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits In the following table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.29846,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This list is current. Last updated 23 December 2020. This document describes New Relic&#x27;s products and services as they relate to regulatory framework <em>compliance</em> status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-22T13:58:31Z",
      "updated_at": "2021-05-09T18:12:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic for our generally available New Relic One platform goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team for our generally available New Relic One platform is assigned a security engineer charged with reviewing and advising on the security of New Relic products. In the requirements building phase the security engineer performs a risk assessment and then adds security requirements for the project. Privacy and compliance experts are added to the project teams as needed. Design During the design phase, the New Relic security engineer collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build Each product engineer receives secure coding training which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and process already in place at New Relic. In the build phase the engineering team implements appropriate security features in the project following secure coding standards at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the code repository. In addition to code scanning software automatically checking for vulnerabilities against security policies, security engineers verify that safeguards and controls recommended in design, requirements, and assessment phases were implemented when needed. New Relic performs static code and composition analysis to look for vulnerabilities in the code and dependencies. Deploy New Relic is in the process of including hashes and signatures. Anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular security scans, third party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.23691,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " charged with reviewing and advising on the <em>security</em> of New Relic products. In the requirements building phase the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. <em>Privacy</em> and <em>compliance</em> experts are added to the project teams as needed. Design During"
      },
      "id": "608d4b4728ccbcac5d51c173"
    },
    {
      "image": "https://docs.newrelic.com/static/futurestack-registration-cf388ce323a82db74de9894bfbe3fb63.png",
      "url": "https://docs.newrelic.com/",
      "sections": [
        "Welcome to New Relic",
        "Create a free account",
        "Start collecting data",
        "Set up alerts",
        "Telemetry Data Platform",
        "Introduction to Telemetry Data Platform",
        "Data explorer",
        "Dashboards",
        "Log management",
        "APIs",
        "Manage data",
        "Build on New Relic One",
        "Full-Stack Observability",
        "Introduction to Full-Stack Observability",
        "APM",
        "Browser",
        "Distributed Tracing",
        "Infrastructure",
        "Logs in context",
        "Mobile",
        "Serverless",
        "Synthetics",
        "Workloads",
        "Alerts and Applied Intelligence (AI)",
        "Introduction to Alerts",
        "Introduction to Applied Intelligence",
        "Incident Intelligence",
        "Incident Workflows",
        "Proactive Detection",
        "New Relic integrations",
        "Back-end, front-end, and mobile applications",
        "Infrastructure and cloud platforms",
        "Open-source monitoring systems",
        "Security, privacy, and legal information",
        "Data privacy",
        "Security compliance",
        "Security bulletins",
        "Licenses"
      ],
      "published_at": "2021-05-23T01:37:22Z",
      "title": "New Relic Documentation",
      "updated_at": "2021-05-23T01:37:22Z",
      "type": "docs",
      "external_id": "807276d5fdd805ba0247a1ce1016af986fb31995",
      "popularity": 1,
      "body": "Welcome to New Relic If you're new, follow these three steps to create an account and get going. (It's free!) Scroll on for more about our Telemetry Data Platform, Full-Stack Observability, and Applied Intelligence. Or, to get a wider view of our platform's capabilities, read the Intro to New Relic, and use our solutions and best practices guides. Create a free account No credit card required. Start collecting data Our UI guides you through setup and install. Set up alerts Get notified quickly about changes in your system. Telemetry Data Platform Ingest, visualize, and alert on all your telemetry data in one place. Introduction to Telemetry Data Platform How to manage all your monitoring in one place. Data explorer Query and build charts with NRQL, our PromQL-style syntax, or our visual chart builder. Dashboards Combine data from anywhere in our platform into customized dashboards. Log management Get logs alongside your telemetry data with our fast, scalable log management. APIs Find APIs to send data in, get data out, or manage the New Relic platform. Manage data Monitor and control your data usage. Build on New Relic One Learn how to build custom apps on our platform at developer.newrelic.com Full-Stack Observability Analyze and troubleshoot problems easily across your entire software stack. Introduction to Full-Stack Observability Get deep insight into everything from infrastructure to server code to end-user apps. APM Get real-time and trending data about your app's performance and stability. Browser Measure website performance, track errors, and see how users interact with your site. Distributed Tracing Track requests through your distributed system to find trends and anomalies. Infrastructure Monitor your infrastructure—hosts, cloud providers, container services, backend services, orchestrators, and more. Logs in context Link your log data to APM agent data so you can pinpoint where things are going wrong. Mobile Understand user journeys in your Android and iOS apps and troubleshoot crashes. Serverless Monitor AWS Lambda, Azure Functions, and Google Cloud Functions. Synthetics Simulate user activity to detect outages and fix poor website performance. Workloads Group or monitor entities across your entire stack based on a team or a set of responsibilities. Alerts and Applied Intelligence (AI) Automatically detect anomalies, correlate issues, and reduce alert noise. Introduction to Alerts Get notified about important changes in your system based on any data you connect to New Relic. Introduction to Applied Intelligence Recognize issues sooner, resolve problems faster, and reduce noise for better incident management. Incident Intelligence Get an overview of all your incidents. See sources and related events, and find out how they all correlate. Incident Workflows Enrich your incidents with New Relic data before sending them to your notification platform. Proactive Detection Get notified by Slack or webhook of unusual app behavior. New Relic integrations Integrations connect the technologies in your stack to New Relic. Here are a few of our 370+ integrations: Back-end, front-end, and mobile applications Android Browser (JavaScript) C SDK Go iOS Java .NET Node.js PHP Python Ruby Synthetics Infrastructure and cloud platforms Apache AWS Azure Google Cloud Kafka Kubernetes Linux Microsoft SQL MongoDB MySQL NGINX PostgreSQL Redis Windows Open-source monitoring systems Dropwizard Istio JMX Kamon Micrometer OpenCensus OpenTelemetry Prometheus StatsD See all 360+ integrations Security, privacy, and legal information Find out how we ensure security, data privacy, and compliance, and find our terms of service. Data privacy New Relic takes your data privacy seriously. Our principles-based approach aims to go beyond the legal requirements for consent. Security compliance Whether your data is in transit to New Relic or at rest in our storage, strong encryption measures can help protect against unauthorized access or theft of valuable data. Security bulletins Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates. Licenses All about New Relic's licenses, Usage Plan, and policies. Find out what open source software we use in our products.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.77225,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Security</em>, <em>privacy</em>, <em>and</em> legal information",
        "body": " <em>security</em>, data <em>privacy</em>, and <em>compliance</em>, and find our terms of service. Data <em>privacy</em> New Relic takes your data <em>privacy</em> seriously. Our principles-based approach aims to go beyond the legal requirements for consent. <em>Security</em> <em>compliance</em> Whether your data is in transit to New Relic or at rest in our"
      },
      "id": "5be4e5d38e9c0f3585d72edf"
    }
  ],
  "/docs/security/security-privacy/compliance/key-management-encryption-rest": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-22T13:56:26Z",
      "updated_at": "2021-05-16T04:26:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits In the following table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.29837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This list is current. Last updated 23 December 2020. This document describes New Relic&#x27;s products and services as they relate to regulatory framework <em>compliance</em> status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-05-22T13:55:29Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.97258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-22T13:58:31Z",
      "updated_at": "2021-05-09T18:12:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic for our generally available New Relic One platform goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team for our generally available New Relic One platform is assigned a security engineer charged with reviewing and advising on the security of New Relic products. In the requirements building phase the security engineer performs a risk assessment and then adds security requirements for the project. Privacy and compliance experts are added to the project teams as needed. Design During the design phase, the New Relic security engineer collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build Each product engineer receives secure coding training which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and process already in place at New Relic. In the build phase the engineering team implements appropriate security features in the project following secure coding standards at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the code repository. In addition to code scanning software automatically checking for vulnerabilities against security policies, security engineers verify that safeguards and controls recommended in design, requirements, and assessment phases were implemented when needed. New Relic performs static code and composition analysis to look for vulnerabilities in the code and dependencies. Deploy New Relic is in the process of including hashes and signatures. Anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular security scans, third party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.23688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " charged with reviewing and advising on the <em>security</em> of New Relic products. In the requirements building phase the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. <em>Privacy</em> and <em>compliance</em> experts are added to the project teams as needed. Design During"
      },
      "id": "608d4b4728ccbcac5d51c173"
    }
  ],
  "/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services": [
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-05-22T13:55:29Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.97258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-22T13:58:31Z",
      "updated_at": "2021-05-09T18:12:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic for our generally available New Relic One platform goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team for our generally available New Relic One platform is assigned a security engineer charged with reviewing and advising on the security of New Relic products. In the requirements building phase the security engineer performs a risk assessment and then adds security requirements for the project. Privacy and compliance experts are added to the project teams as needed. Design During the design phase, the New Relic security engineer collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build Each product engineer receives secure coding training which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and process already in place at New Relic. In the build phase the engineering team implements appropriate security features in the project following secure coding standards at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the code repository. In addition to code scanning software automatically checking for vulnerabilities against security policies, security engineers verify that safeguards and controls recommended in design, requirements, and assessment phases were implemented when needed. New Relic performs static code and composition analysis to look for vulnerabilities in the code and dependencies. Deploy New Relic is in the process of including hashes and signatures. Anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular security scans, third party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.23688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " charged with reviewing and advising on the <em>security</em> of New Relic products. In the requirements building phase the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. <em>Privacy</em> and <em>compliance</em> experts are added to the project teams as needed. Design During"
      },
      "id": "608d4b4728ccbcac5d51c173"
    },
    {
      "image": "https://docs.newrelic.com/static/futurestack-registration-cf388ce323a82db74de9894bfbe3fb63.png",
      "url": "https://docs.newrelic.com/",
      "sections": [
        "Welcome to New Relic",
        "Create a free account",
        "Start collecting data",
        "Set up alerts",
        "Telemetry Data Platform",
        "Introduction to Telemetry Data Platform",
        "Data explorer",
        "Dashboards",
        "Log management",
        "APIs",
        "Manage data",
        "Build on New Relic One",
        "Full-Stack Observability",
        "Introduction to Full-Stack Observability",
        "APM",
        "Browser",
        "Distributed Tracing",
        "Infrastructure",
        "Logs in context",
        "Mobile",
        "Serverless",
        "Synthetics",
        "Workloads",
        "Alerts and Applied Intelligence (AI)",
        "Introduction to Alerts",
        "Introduction to Applied Intelligence",
        "Incident Intelligence",
        "Incident Workflows",
        "Proactive Detection",
        "New Relic integrations",
        "Back-end, front-end, and mobile applications",
        "Infrastructure and cloud platforms",
        "Open-source monitoring systems",
        "Security, privacy, and legal information",
        "Data privacy",
        "Security compliance",
        "Security bulletins",
        "Licenses"
      ],
      "published_at": "2021-05-23T01:37:22Z",
      "title": "New Relic Documentation",
      "updated_at": "2021-05-23T01:37:22Z",
      "type": "docs",
      "external_id": "807276d5fdd805ba0247a1ce1016af986fb31995",
      "popularity": 1,
      "body": "Welcome to New Relic If you're new, follow these three steps to create an account and get going. (It's free!) Scroll on for more about our Telemetry Data Platform, Full-Stack Observability, and Applied Intelligence. Or, to get a wider view of our platform's capabilities, read the Intro to New Relic, and use our solutions and best practices guides. Create a free account No credit card required. Start collecting data Our UI guides you through setup and install. Set up alerts Get notified quickly about changes in your system. Telemetry Data Platform Ingest, visualize, and alert on all your telemetry data in one place. Introduction to Telemetry Data Platform How to manage all your monitoring in one place. Data explorer Query and build charts with NRQL, our PromQL-style syntax, or our visual chart builder. Dashboards Combine data from anywhere in our platform into customized dashboards. Log management Get logs alongside your telemetry data with our fast, scalable log management. APIs Find APIs to send data in, get data out, or manage the New Relic platform. Manage data Monitor and control your data usage. Build on New Relic One Learn how to build custom apps on our platform at developer.newrelic.com Full-Stack Observability Analyze and troubleshoot problems easily across your entire software stack. Introduction to Full-Stack Observability Get deep insight into everything from infrastructure to server code to end-user apps. APM Get real-time and trending data about your app's performance and stability. Browser Measure website performance, track errors, and see how users interact with your site. Distributed Tracing Track requests through your distributed system to find trends and anomalies. Infrastructure Monitor your infrastructure—hosts, cloud providers, container services, backend services, orchestrators, and more. Logs in context Link your log data to APM agent data so you can pinpoint where things are going wrong. Mobile Understand user journeys in your Android and iOS apps and troubleshoot crashes. Serverless Monitor AWS Lambda, Azure Functions, and Google Cloud Functions. Synthetics Simulate user activity to detect outages and fix poor website performance. Workloads Group or monitor entities across your entire stack based on a team or a set of responsibilities. Alerts and Applied Intelligence (AI) Automatically detect anomalies, correlate issues, and reduce alert noise. Introduction to Alerts Get notified about important changes in your system based on any data you connect to New Relic. Introduction to Applied Intelligence Recognize issues sooner, resolve problems faster, and reduce noise for better incident management. Incident Intelligence Get an overview of all your incidents. See sources and related events, and find out how they all correlate. Incident Workflows Enrich your incidents with New Relic data before sending them to your notification platform. Proactive Detection Get notified by Slack or webhook of unusual app behavior. New Relic integrations Integrations connect the technologies in your stack to New Relic. Here are a few of our 370+ integrations: Back-end, front-end, and mobile applications Android Browser (JavaScript) C SDK Go iOS Java .NET Node.js PHP Python Ruby Synthetics Infrastructure and cloud platforms Apache AWS Azure Google Cloud Kafka Kubernetes Linux Microsoft SQL MongoDB MySQL NGINX PostgreSQL Redis Windows Open-source monitoring systems Dropwizard Istio JMX Kamon Micrometer OpenCensus OpenTelemetry Prometheus StatsD See all 360+ integrations Security, privacy, and legal information Find out how we ensure security, data privacy, and compliance, and find our terms of service. Data privacy New Relic takes your data privacy seriously. Our principles-based approach aims to go beyond the legal requirements for consent. Security compliance Whether your data is in transit to New Relic or at rest in our storage, strong encryption measures can help protect against unauthorized access or theft of valuable data. Security bulletins Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates. Licenses All about New Relic's licenses, Usage Plan, and policies. Find out what open source software we use in our products.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.7721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Security</em>, <em>privacy</em>, <em>and</em> legal information",
        "body": " <em>security</em>, data <em>privacy</em>, and <em>compliance</em>, and find our terms of service. Data <em>privacy</em> New Relic takes your data <em>privacy</em> seriously. Our principles-based approach aims to go beyond the legal requirements for consent. <em>Security</em> <em>compliance</em> Whether your data is in transit to New Relic or at rest in our"
      },
      "id": "5be4e5d38e9c0f3585d72edf"
    }
  ],
  "/docs/security/security-privacy/data-privacy/data-privacy-new-relic": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-22T13:56:26Z",
      "updated_at": "2021-05-16T04:26:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits In the following table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.50482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " endpoints: Customer must send its <em>data</em> only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic&#x27;s time frames for supported regulatory frameworks and annual audits include"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.4483,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “<em>data</em> processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ <em>data</em> is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.86948,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    }
  ],
  "/docs/security/security-privacy/data-privacy/new-relic-personal-data-requests": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-22T13:56:26Z",
      "updated_at": "2021-05-16T04:26:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits In the following table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.50482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " endpoints: Customer must send its <em>data</em> only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic&#x27;s time frames for supported regulatory frameworks and annual audits include"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.4483,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “<em>data</em> processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ <em>data</em> is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.86948,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    }
  ],
  "/docs/security/security-privacy/data-privacy/security-controls-privacy": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-05-22T13:56:26Z",
      "updated_at": "2021-05-16T04:26:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 23 December 2020. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits In the following table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.50476,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " endpoints: Customer must send its <em>data</em> only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic&#x27;s time frames for supported regulatory frameworks and annual audits include"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.44824,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “<em>data</em> processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ <em>data</em> is paramount, and we practice strict information <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    },
    {
      "sections": [
        "SolarWinds Orion",
        "New Relic and SolarWinds Orion"
      ],
      "title": "SolarWinds Orion",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "bdab7ff06c45b2dbeb46bfaf20dcb6c26add46d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/solarwinds-orion/",
      "published_at": "2021-05-22T13:55:30Z",
      "updated_at": "2021-05-16T14:19:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We understand that our customers are evaluating the impact of the SolarWinds Security Advisory to their business. To address the immediate concern: New Relic is not a customer of the SolarWinds Orion product and therefore New Relic and customers using New Relic are not impacted by the compromised SolarWinds product. New Relic and SolarWinds Orion New Relic Security is closely monitoring for updated information about the SolarWinds incident as it is released. As a proactive measure, New Relic security has conducted a review of our processes related to code integrity and software delivery. New Relic will take appropriate steps to implement improvements where needed. New Relic will also continue to evaluate our systems for indicators related to the SolarWinds incident. In accordance with our own vendor risk management program, New Relic has initiated communication with critical vendors to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The security and privacy of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.86942,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New Relic <em>and</em> SolarWinds Orion",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " to determine whether they use the SolarWinds product in any of the services they provide to us. Based on their response, New Relic will identify and take appropriate steps to mitigate the risk to our company and our customers. The <em>security</em> and <em>privacy</em> of our customers is our top priority, and we are continuing to follow the SolarWinds situation closely. We encourage customers with questions to contact us at support.newrelic.com&#x2F;."
      },
      "id": "60495931e7b9d22811de6dd6"
    }
  ],
  "/docs/security/security-privacy/information-security/report-security-vulnerabilities-hackerone": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.71631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> bulletins",
        "sections": "<em>Security</em> bulletins",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more <em>information</em>, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. Or subscribe to the RSS"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-22T13:58:31Z",
      "updated_at": "2021-05-09T18:12:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic for our generally available New Relic One platform goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team for our generally available New Relic One platform is assigned a security engineer charged with reviewing and advising on the security of New Relic products. In the requirements building phase the security engineer performs a risk assessment and then adds security requirements for the project. Privacy and compliance experts are added to the project teams as needed. Design During the design phase, the New Relic security engineer collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build Each product engineer receives secure coding training which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and process already in place at New Relic. In the build phase the engineering team implements appropriate security features in the project following secure coding standards at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the code repository. In addition to code scanning software automatically checking for vulnerabilities against security policies, security engineers verify that safeguards and controls recommended in design, requirements, and assessment phases were implemented when needed. New Relic performs static code and composition analysis to look for vulnerabilities in the code and dependencies. Deploy New Relic is in the process of including hashes and signatures. Anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular security scans, third party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.9512,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " charged with reviewing and advising on the <em>security</em> of New Relic products. In the requirements building phase the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. <em>Privacy</em> and compliance experts are added to the project teams as needed. Design During"
      },
      "id": "608d4b4728ccbcac5d51c173"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.22763,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict <em>information</em> <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    }
  ],
  "/docs/security/security-privacy/information-security/security-bulletins": [
    {
      "sections": [
        "Secure Software Development Lifecycle",
        "Requirements",
        "Design",
        "Build",
        "Verification",
        "Deploy"
      ],
      "title": "Secure Software Development Lifecycle",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "6db2309076e4a576303efd973dd7eeba808e75ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/software-development-lifecycle/",
      "published_at": "2021-05-22T13:58:31Z",
      "updated_at": "2021-05-09T18:12:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Software built at New Relic for our generally available New Relic One platform goes through these five phases. Software development phase Security control Requirements Risk assessment Design Threat modeling Development Secure coding standards and practices Verification Code review, security review, static code analysis, composition analysis, calculated hash, signed code Deploy Hacker One and the New Relic coordinated disclosure program, regular scans, third-party penetration tests Requirements Each project team for our generally available New Relic One platform is assigned a security engineer charged with reviewing and advising on the security of New Relic products. In the requirements building phase the security engineer performs a risk assessment and then adds security requirements for the project. Privacy and compliance experts are added to the project teams as needed. Design During the design phase, the New Relic security engineer collaborates with the stakeholders, engineering leaders, and architects to get a detailed shared understanding of the feature. Security engineers at New Relic contribute to the design process with stakeholders by creating a threat model documenting any acceptance criteria, features, or requirements to securely implement the feature. Using the threat model, the security engineer adds detailed specifications for the required controls to the project. Build Each product engineer receives secure coding training which includes topics such as the OWASP top 10, input sanitization, and using the secure frameworks and process already in place at New Relic. In the build phase the engineering team implements appropriate security features in the project following secure coding standards at New Relic. Verification Once feature complete, every pull request must be code reviewed by another engineer with write access to the code repository. In addition to code scanning software automatically checking for vulnerabilities against security policies, security engineers verify that safeguards and controls recommended in design, requirements, and assessment phases were implemented when needed. New Relic performs static code and composition analysis to look for vulnerabilities in the code and dependencies. Deploy New Relic is in the process of including hashes and signatures. Anyone downloading files published by New Relic will be able to confirm their downloaded file has not been tampered with and is identical to the one published by New Relic. Deployed code is monitored by stakeholders and product engineers in order to continue the iterative development process. The security team continues to evaluate the security of deployed code by performing regular security scans, third party penetration tests, and through the coordinated disclosure process via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.95117,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Secure</em> Software Development Lifecycle",
        "sections": "<em>Secure</em> Software Development Lifecycle",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " charged with reviewing and advising on the <em>security</em> of New Relic products. In the requirements building phase the <em>security</em> engineer performs a risk assessment and then adds <em>security</em> requirements for the project. <em>Privacy</em> and compliance experts are added to the project teams as needed. Design During"
      },
      "id": "608d4b4728ccbcac5d51c173"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.22754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict <em>information</em> <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    },
    {
      "sections": [
        "Report security vulnerabilities via HackerOne",
        "Coordinated disclosure program",
        "Customer security issues"
      ],
      "title": "Report security vulnerabilities via HackerOne",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "a4868e4bcfd149aae403a7cb20dfe9c7a375cd67",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/report-security-vulnerabilities-hackerone/",
      "published_at": "2021-05-22T11:51:21Z",
      "updated_at": "2021-03-16T18:23:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic is committed to the security of our customers and your data. We believe that engaging with security researchers through our coordinated disclosure program is an important measure to achieve our security goals. If you believe you have found a security vulnerability in one of our products or websites, we welcome and thank you for reporting it through our coordinated disclosure program, as explained in this document. If you have other concerns, see the information about other email or account issues. Coordinated disclosure program New Relic has partnered with HackerOne to make it as easy as possible for researchers to report security vulnerabilities to us. In recognition of the effort involved in finding these issues, we may provide bounties for eligible reports. For full details of our policies and to see previously disclosed reports, go to the coordinated disclosure page on HackerOne for New Relic. To participate in the coordinated disclosure program: Ensure that you're familiar with our policies with HackerOne before initiating any security testing. Only test against accounts you control. Customer security issues If you are a New Relic customer and have a password or account issue, do not use our coordinated disclosure program. Instead, please follow our standard troubleshooting procedures for password, email, and login problems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.62268,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report <em>security</em> vulnerabilities via HackerOne",
        "sections": "Report <em>security</em> vulnerabilities via HackerOne",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "New Relic is committed to the <em>security</em> of our customers and your data. We believe that engaging with <em>security</em> researchers through our coordinated disclosure program is an important measure to achieve our <em>security</em> goals. If you believe you have found a <em>security</em> vulnerability in one of our products"
      },
      "id": "603e967628ccbc8effeba753"
    }
  ],
  "/docs/security/security-privacy/information-security/software-development-lifecycle": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.71626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> bulletins",
        "sections": "<em>Security</em> bulletins",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more <em>information</em>, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. Or subscribe to the RSS"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Notification of Apollo.io security incident",
        "Security officer statement",
        "Summary of incident",
        "Update and resolution",
        "Our commitment to our customers"
      ],
      "title": "Notification of Apollo.io security incident",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletins"
      ],
      "external_id": "b18c5a7c19e976eeecd3cdfb690e644e4b1b4ad8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident/",
      "published_at": "2021-05-22T13:51:36Z",
      "updated_at": "2021-05-16T14:10:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "October 9, 2018 This is a summary of the 2018 security breach of the systems of Apollo.io and New Relic's response. Security officer statement Over the weekend, New Relic was alerted by a sales productivity tool vendor, Apollo.io, about a security breach of their systems, which contained business-card-like customer contact information such as name, email address, phone number, company name, and job title. We are actively investigating this issue, and at this time we believe that a subset of our customers’ and prospects’ contact info may have been included. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Please follow discuss.newrelic.com/c/security-notifications for additional information on this incident. - Shaun Gordon, VP, Chief Security Officer, New Relic Summary of incident Who is affected? We are currently investigating who is impacted, but we believe that the vendor’s breach was limited to business contact information. What happened? New Relic was recently notified by Apollo.io that personal data that we shared with them in accordance with our Privacy Policy was exposed by a breach. We then started our investigation to learn more about the scope of the data involved. Our privacy policy is described further at: newrelic.com/termsandconditions/privacy. New Relic did not sell the data to Apollo, but shared it solely to assist in providing services to New Relic. What data was compromised? We are continuing our investigation, but we believe that customer or potential customer email addresses, company names, business contact information, and the names of the customers to whom those emails relate were potentially exposed. We believe that no financial account information (e.g. credit card numbers, bank account numbers, etc.), government issued identification numbers (e.g. social security numbers or passport numbers) or sensitive categories of personal data as defined under GDPR (e.g. medical information, religious preference, etc.) was exposed. What action did New Relic take? We have reached out to Apollo.io requesting additional information and are continuing to investigate internally. What further actions will New Relic take? Based on our continuing investigation, we will provide further information as appropriate. Do you need to notify EU data protection authorities of this incident? No. As explained above, New Relic is the “data controller” of the contact information that was exposed as a result of this incident. Accordingly, and in keeping with our responsibilities as a “data controller” under the GDPR, we will submit a notice to our lead data protection authority. We will not disclose any customer information as part of this notice. Update and resolution November 5, 2018 Apollo.io, a sales intelligence vendor, was notified about a security breach of their systems by an external security researcher. The data involved contained business-card-like contact information such as name, email address, phone number, company name, and job title. After investigation of this issue, we determined that a specific set of New Relic customer and prospect contact info had been included but we have found no evidence of misuse. Per our request, all data from New Relic obtained by Apollo.io has been purged from their systems. New Relic did not sell the data to Apollo.io, but shared it solely as part of using the vendor service, which means that New Relic was the “data controller” of the impacted information and Apollo.io our “data processor” as defined by the General Data Protection Regulation 2016/679 (“GDPR”). No customer data from the New Relic product platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io 30’s services or was impacted. At New Relic, the security and privacy of our customers’ data is paramount, and we practice strict information security policies for engaging any third-party vendor. We are continuously evaluating our policies and processes across all vendors. Our commitment to our customers At New Relic, the security and privacy of our customers is paramount, and we practice strict information security policies for engaging any third-party vendor. We value our relationship with you. If you have any additional questions, we encourage customers to contact us at support.newrelic.com. For more information about our privacy policy, visit newrelic.com/termsandconditions/privacy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.22754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Notification of Apollo.io <em>security</em> incident",
        "sections": "Notification of Apollo.io <em>security</em> incident",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " platform (for which New Relic acts as “data processor”) was ever linked with Apollo.io’s services or was impacted. At New Relic, the <em>security</em> and <em>privacy</em> of our customers’ data is paramount, and we practice strict <em>information</em> <em>security</em> policies for engaging any third-party vendor. We are continuously"
      },
      "id": "60452301196a67e33e960f62"
    },
    {
      "sections": [
        "Report security vulnerabilities via HackerOne",
        "Coordinated disclosure program",
        "Customer security issues"
      ],
      "title": "Report security vulnerabilities via HackerOne",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "a4868e4bcfd149aae403a7cb20dfe9c7a375cd67",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/report-security-vulnerabilities-hackerone/",
      "published_at": "2021-05-22T11:51:21Z",
      "updated_at": "2021-03-16T18:23:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic is committed to the security of our customers and your data. We believe that engaging with security researchers through our coordinated disclosure program is an important measure to achieve our security goals. If you believe you have found a security vulnerability in one of our products or websites, we welcome and thank you for reporting it through our coordinated disclosure program, as explained in this document. If you have other concerns, see the information about other email or account issues. Coordinated disclosure program New Relic has partnered with HackerOne to make it as easy as possible for researchers to report security vulnerabilities to us. In recognition of the effort involved in finding these issues, we may provide bounties for eligible reports. For full details of our policies and to see previously disclosed reports, go to the coordinated disclosure page on HackerOne for New Relic. To participate in the coordinated disclosure program: Ensure that you're familiar with our policies with HackerOne before initiating any security testing. Only test against accounts you control. Customer security issues If you are a New Relic customer and have a password or account issue, do not use our coordinated disclosure program. Instead, please follow our standard troubleshooting procedures for password, email, and login problems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.62268,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report <em>security</em> vulnerabilities via HackerOne",
        "sections": "Report <em>security</em> vulnerabilities via HackerOne",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "New Relic is committed to the <em>security</em> of our customers and your data. We believe that engaging with <em>security</em> researchers through our coordinated disclosure program is an important measure to achieve our <em>security</em> goals. If you believe you have found a <em>security</em> vulnerability in one of our products"
      },
      "id": "603e967628ccbc8effeba753"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/account-linking": [
    {
      "sections": [
        "Instrument your own functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "title": "Instrument your own functions",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-09T22:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.6626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument your own <em>functions</em>",
        "sections": "Instrument your own <em>functions</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Important Because there are several steps to integration, it&#x27;s important that you test your <em>account</em> <em>link</em> by deploying and testing an example <em>function</em> before instrumenting your own code. Deployment strategies There are many different deployment strategies for <em>Lambda</em> functions. New Relic offers"
      },
      "id": "605aa8a064441f453b868bb9"
    },
    {
      "sections": [
        "Instrument a Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "title": "Instrument a Lambda function",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate Distributed Tracing into a non-trivial serverless application in our Distributed Tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.1192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument a <em>Lambda</em> <em>function</em>",
        "sections": "Instrument a <em>Lambda</em> <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "New Relic provides working minimal examples as a starting point for instrumenting your own <em>serverless</em> functions, so that you can become familiar with the necessary elements, test the <em>account</em> <em>link</em>, and use them as a reference for your own instrumentation. While there are many ways to manage"
      },
      "id": "605aa85628ccbcc6d13ae663"
    },
    {
      "sections": [
        "Update serverless monitoring for AWS Lambda",
        "Important",
        "Update our Lambda integration via CLI",
        "Update layers via CLI",
        "Update a manual Serverless application repository install",
        "Enabling log management",
        "Caution"
      ],
      "title": "Update serverless monitoring for AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "7075499bcc9b1ff1e346a705ab414adcca54fd09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/update-serverless-monitoring-aws-lambda/",
      "published_at": "2021-05-22T05:30:55Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After enabling our monitoring for AWS Lambda, you should occasionally update our Lambda function that's used to report AWS log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our Lambda monitoring using our CLI tool. Update via AWS Serverless Application Repository: Use this if you enabled using the manual procedure. Important These update procedures apply to our serverless monitoring for AWS Lambda, and not to our infrastructure monitoring for AWS Lambda integration. Update our Lambda integration via CLI This section describes how to update if your Lambda monitoring was enabled using our recommended CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region identifier (for example, us-west-2). newrelic-lambda integrations update \\ --aws-region YOUR_REGION Copy If you do not have our logs enabled, you'll also need to update your Amazon CloudWatch log subscription filters with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --aws-region YOUR_REGION Copy Update layers via CLI This section describes how to update your function's Layer if you installed it with our CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy Pass the --upgrade flag to the install command: newrelic-lambda layers install \\ --function installed \\ --nr-account-id NR_ACCOUNT_ID \\ --upgrade Copy Update a manual Serverless application repository install If you manually installed the ingest function from the AWS Serverless Application Repository (and didn't use the CLI), update using this procedure: Run the following, replacing YOUR_REGION with your region (for example, us-west-2). aws serverlessrepo create-cloud-formation-change-set \\ --application-id arn:aws:serverlessrepo:us-east-1:463657938898:applications/NewRelic-log-ingestion \\ --stack-name NewRelic-log-ingestion \\ --capabilities CAPABILITY_RESOURCE_POLICY \\ --region YOUR_REGION Copy This command outputs several fields, one of which is the ChangeSetId: an ARN for the change set that you just created. Copy that ARN. Use the ARN in this command, which executes the change set: aws cloudformation execute-change-set --change-set-name YOUR_CHANGE_SET_ARN Copy Enabling log management If you currently don't have New Relic's log management enabled, but would like to: Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region (for example, us-west-2). newrelic-lambda integrations update \\ --enable-logs \\ --aws-region YOUR_REGION Copy Then do either of the following: Update your Amazon CloudWatch log subscription filters for each region with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --filter-pattern \"\" \\ --aws-region YOUR_REGION Copy Or, you can send function logs to New Relic directly, bypassing CloudWatch and the newrelic-log-ingestion Lambda. To do this, set the environment variable NEW_RELIC_EXTENSION_SEND_FUNCTION_LOGS=true in your Lambda function configuration. After that, be sure to remove any existing New Relic log subscriptions for that function using this command: newrelic-lambda subscriptions uninstall \\ --function FUNCTION_NAME \\ --aws-region YOUR_REGION Copy If the log subscription is present while the extension is sending logs, logs will be sent twice, resulting in duplicate log records in New Relic. Optionally, if you'd like to avoid Amazon's charges for CloudWatch Log ingestion, you can also modify your function's execution role so that it doesn't grant the CloudWatch Log permissions. This will prevent your function from logging to CloudWatch. Caution CloudWatch Logs ingest fees can be considerable, but this step should be taken with caution. Make sure your New Relic log ingestion integration is working well and meeting your needs before disabling CloudWatch logs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.1192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "sections": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "After enabling our <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, you should occasionally update our <em>Lambda</em> <em>function</em> that&#x27;s used to report <em>AWS</em> log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our <em>Lambda</em> <em>monitoring</em> using our CLI tool. Update via <em>AWS</em> <em>Serverless</em>"
      },
      "id": "6045248c28ccbc98a82c606b"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/configure-serverless-monitoring-aws-lambda": [
    {
      "sections": [
        "Instrument your own functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "title": "Instrument your own functions",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-09T22:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.6626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument your own <em>functions</em>",
        "sections": "Instrument your own <em>functions</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ": AWSTemplateFormatVersion: &#x27;2010-09-09&#x27; Transform: <em>AWS</em>::<em>Serverless</em>-2016-10-31 Description: And example of a simple instrumented NodeJS <em>Lambda</em> Resources: NewRelicExample: Type: <em>AWS</em>::<em>Serverless</em>::<em>Function</em> Properties: # In this example, we&#x27;re using the SAM CLI to package and deploy our <em>lambda</em>. SAM"
      },
      "id": "605aa8a064441f453b868bb9"
    },
    {
      "sections": [
        "Instrument a Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "title": "Instrument a Lambda function",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate Distributed Tracing into a non-trivial serverless application in our Distributed Tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.1192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument a <em>Lambda</em> <em>function</em>",
        "sections": "Instrument a <em>Lambda</em> <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " and deploy <em>Lambda</em> functions, <em>AWS</em> CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates"
      },
      "id": "605aa85628ccbcc6d13ae663"
    },
    {
      "sections": [
        "Update serverless monitoring for AWS Lambda",
        "Important",
        "Update our Lambda integration via CLI",
        "Update layers via CLI",
        "Update a manual Serverless application repository install",
        "Enabling log management",
        "Caution"
      ],
      "title": "Update serverless monitoring for AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "7075499bcc9b1ff1e346a705ab414adcca54fd09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/update-serverless-monitoring-aws-lambda/",
      "published_at": "2021-05-22T05:30:55Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After enabling our monitoring for AWS Lambda, you should occasionally update our Lambda function that's used to report AWS log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our Lambda monitoring using our CLI tool. Update via AWS Serverless Application Repository: Use this if you enabled using the manual procedure. Important These update procedures apply to our serverless monitoring for AWS Lambda, and not to our infrastructure monitoring for AWS Lambda integration. Update our Lambda integration via CLI This section describes how to update if your Lambda monitoring was enabled using our recommended CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region identifier (for example, us-west-2). newrelic-lambda integrations update \\ --aws-region YOUR_REGION Copy If you do not have our logs enabled, you'll also need to update your Amazon CloudWatch log subscription filters with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --aws-region YOUR_REGION Copy Update layers via CLI This section describes how to update your function's Layer if you installed it with our CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy Pass the --upgrade flag to the install command: newrelic-lambda layers install \\ --function installed \\ --nr-account-id NR_ACCOUNT_ID \\ --upgrade Copy Update a manual Serverless application repository install If you manually installed the ingest function from the AWS Serverless Application Repository (and didn't use the CLI), update using this procedure: Run the following, replacing YOUR_REGION with your region (for example, us-west-2). aws serverlessrepo create-cloud-formation-change-set \\ --application-id arn:aws:serverlessrepo:us-east-1:463657938898:applications/NewRelic-log-ingestion \\ --stack-name NewRelic-log-ingestion \\ --capabilities CAPABILITY_RESOURCE_POLICY \\ --region YOUR_REGION Copy This command outputs several fields, one of which is the ChangeSetId: an ARN for the change set that you just created. Copy that ARN. Use the ARN in this command, which executes the change set: aws cloudformation execute-change-set --change-set-name YOUR_CHANGE_SET_ARN Copy Enabling log management If you currently don't have New Relic's log management enabled, but would like to: Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region (for example, us-west-2). newrelic-lambda integrations update \\ --enable-logs \\ --aws-region YOUR_REGION Copy Then do either of the following: Update your Amazon CloudWatch log subscription filters for each region with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --filter-pattern \"\" \\ --aws-region YOUR_REGION Copy Or, you can send function logs to New Relic directly, bypassing CloudWatch and the newrelic-log-ingestion Lambda. To do this, set the environment variable NEW_RELIC_EXTENSION_SEND_FUNCTION_LOGS=true in your Lambda function configuration. After that, be sure to remove any existing New Relic log subscriptions for that function using this command: newrelic-lambda subscriptions uninstall \\ --function FUNCTION_NAME \\ --aws-region YOUR_REGION Copy If the log subscription is present while the extension is sending logs, logs will be sent twice, resulting in duplicate log records in New Relic. Optionally, if you'd like to avoid Amazon's charges for CloudWatch Log ingestion, you can also modify your function's execution role so that it doesn't grant the CloudWatch Log permissions. This will prevent your function from logging to CloudWatch. Caution CloudWatch Logs ingest fees can be considerable, but this step should be taken with caution. Make sure your New Relic log ingestion integration is working well and meeting your needs before disabling CloudWatch logs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.1192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "sections": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "After enabling our <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, you should occasionally update our <em>Lambda</em> <em>function</em> that&#x27;s used to report <em>AWS</em> log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our <em>Lambda</em> <em>monitoring</em> using our CLI tool. Update via <em>AWS</em> <em>Serverless</em>"
      },
      "id": "6045248c28ccbc98a82c606b"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy": [
    {
      "sections": [
        "Instrument your own functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "title": "Instrument your own functions",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-09T22:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.66257,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument your own <em>functions</em>",
        "sections": "Instrument your own <em>functions</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ": AWSTemplateFormatVersion: &#x27;2010-09-09&#x27; Transform: <em>AWS</em>::<em>Serverless</em>-2016-10-31 Description: And example of a simple instrumented NodeJS <em>Lambda</em> Resources: NewRelicExample: Type: <em>AWS</em>::<em>Serverless</em>::<em>Function</em> Properties: # In this example, we&#x27;re using the SAM CLI to package and deploy our <em>lambda</em>. SAM"
      },
      "id": "605aa8a064441f453b868bb9"
    },
    {
      "sections": [
        "Instrument a Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "title": "Instrument a Lambda function",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate Distributed Tracing into a non-trivial serverless application in our Distributed Tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.11917,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument a <em>Lambda</em> <em>function</em>",
        "sections": "Instrument a <em>Lambda</em> <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " and deploy <em>Lambda</em> functions, <em>AWS</em> CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates"
      },
      "id": "605aa85628ccbcc6d13ae663"
    },
    {
      "sections": [
        "Update serverless monitoring for AWS Lambda",
        "Important",
        "Update our Lambda integration via CLI",
        "Update layers via CLI",
        "Update a manual Serverless application repository install",
        "Enabling log management",
        "Caution"
      ],
      "title": "Update serverless monitoring for AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "7075499bcc9b1ff1e346a705ab414adcca54fd09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/update-serverless-monitoring-aws-lambda/",
      "published_at": "2021-05-22T05:30:55Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After enabling our monitoring for AWS Lambda, you should occasionally update our Lambda function that's used to report AWS log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our Lambda monitoring using our CLI tool. Update via AWS Serverless Application Repository: Use this if you enabled using the manual procedure. Important These update procedures apply to our serverless monitoring for AWS Lambda, and not to our infrastructure monitoring for AWS Lambda integration. Update our Lambda integration via CLI This section describes how to update if your Lambda monitoring was enabled using our recommended CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region identifier (for example, us-west-2). newrelic-lambda integrations update \\ --aws-region YOUR_REGION Copy If you do not have our logs enabled, you'll also need to update your Amazon CloudWatch log subscription filters with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --aws-region YOUR_REGION Copy Update layers via CLI This section describes how to update your function's Layer if you installed it with our CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy Pass the --upgrade flag to the install command: newrelic-lambda layers install \\ --function installed \\ --nr-account-id NR_ACCOUNT_ID \\ --upgrade Copy Update a manual Serverless application repository install If you manually installed the ingest function from the AWS Serverless Application Repository (and didn't use the CLI), update using this procedure: Run the following, replacing YOUR_REGION with your region (for example, us-west-2). aws serverlessrepo create-cloud-formation-change-set \\ --application-id arn:aws:serverlessrepo:us-east-1:463657938898:applications/NewRelic-log-ingestion \\ --stack-name NewRelic-log-ingestion \\ --capabilities CAPABILITY_RESOURCE_POLICY \\ --region YOUR_REGION Copy This command outputs several fields, one of which is the ChangeSetId: an ARN for the change set that you just created. Copy that ARN. Use the ARN in this command, which executes the change set: aws cloudformation execute-change-set --change-set-name YOUR_CHANGE_SET_ARN Copy Enabling log management If you currently don't have New Relic's log management enabled, but would like to: Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region (for example, us-west-2). newrelic-lambda integrations update \\ --enable-logs \\ --aws-region YOUR_REGION Copy Then do either of the following: Update your Amazon CloudWatch log subscription filters for each region with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --filter-pattern \"\" \\ --aws-region YOUR_REGION Copy Or, you can send function logs to New Relic directly, bypassing CloudWatch and the newrelic-log-ingestion Lambda. To do this, set the environment variable NEW_RELIC_EXTENSION_SEND_FUNCTION_LOGS=true in your Lambda function configuration. After that, be sure to remove any existing New Relic log subscriptions for that function using this command: newrelic-lambda subscriptions uninstall \\ --function FUNCTION_NAME \\ --aws-region YOUR_REGION Copy If the log subscription is present while the extension is sending logs, logs will be sent twice, resulting in duplicate log records in New Relic. Optionally, if you'd like to avoid Amazon's charges for CloudWatch Log ingestion, you can also modify your function's execution role so that it doesn't grant the CloudWatch Log permissions. This will prevent your function from logging to CloudWatch. Caution CloudWatch Logs ingest fees can be considerable, but this step should be taken with caution. Make sure your New Relic log ingestion integration is working well and meeting your needs before disabling CloudWatch logs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.11917,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "sections": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "After enabling our <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, you should occasionally update our <em>Lambda</em> <em>function</em> that&#x27;s used to report <em>AWS</em> log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our <em>Lambda</em> <em>monitoring</em> using our CLI tool. Update via <em>AWS</em> <em>Serverless</em>"
      },
      "id": "6045248c28ccbc98a82c606b"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/index": [
    {
      "sections": [
        "Instrument your own functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "title": "Instrument your own functions",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-09T22:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.66257,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument your own <em>functions</em>",
        "sections": "Instrument your own <em>functions</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ": AWSTemplateFormatVersion: &#x27;2010-09-09&#x27; Transform: <em>AWS</em>::<em>Serverless</em>-2016-10-31 Description: And example of a simple instrumented NodeJS <em>Lambda</em> Resources: NewRelicExample: Type: <em>AWS</em>::<em>Serverless</em>::<em>Function</em> Properties: # In this example, we&#x27;re using the SAM CLI to package and deploy our <em>lambda</em>. SAM"
      },
      "id": "605aa8a064441f453b868bb9"
    },
    {
      "sections": [
        "Instrument a Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "title": "Instrument a Lambda function",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate Distributed Tracing into a non-trivial serverless application in our Distributed Tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.11917,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument a <em>Lambda</em> <em>function</em>",
        "sections": "Instrument a <em>Lambda</em> <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " and deploy <em>Lambda</em> functions, <em>AWS</em> CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates"
      },
      "id": "605aa85628ccbcc6d13ae663"
    },
    {
      "sections": [
        "Update serverless monitoring for AWS Lambda",
        "Important",
        "Update our Lambda integration via CLI",
        "Update layers via CLI",
        "Update a manual Serverless application repository install",
        "Enabling log management",
        "Caution"
      ],
      "title": "Update serverless monitoring for AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "7075499bcc9b1ff1e346a705ab414adcca54fd09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/update-serverless-monitoring-aws-lambda/",
      "published_at": "2021-05-22T05:30:55Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After enabling our monitoring for AWS Lambda, you should occasionally update our Lambda function that's used to report AWS log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our Lambda monitoring using our CLI tool. Update via AWS Serverless Application Repository: Use this if you enabled using the manual procedure. Important These update procedures apply to our serverless monitoring for AWS Lambda, and not to our infrastructure monitoring for AWS Lambda integration. Update our Lambda integration via CLI This section describes how to update if your Lambda monitoring was enabled using our recommended CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region identifier (for example, us-west-2). newrelic-lambda integrations update \\ --aws-region YOUR_REGION Copy If you do not have our logs enabled, you'll also need to update your Amazon CloudWatch log subscription filters with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --aws-region YOUR_REGION Copy Update layers via CLI This section describes how to update your function's Layer if you installed it with our CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy Pass the --upgrade flag to the install command: newrelic-lambda layers install \\ --function installed \\ --nr-account-id NR_ACCOUNT_ID \\ --upgrade Copy Update a manual Serverless application repository install If you manually installed the ingest function from the AWS Serverless Application Repository (and didn't use the CLI), update using this procedure: Run the following, replacing YOUR_REGION with your region (for example, us-west-2). aws serverlessrepo create-cloud-formation-change-set \\ --application-id arn:aws:serverlessrepo:us-east-1:463657938898:applications/NewRelic-log-ingestion \\ --stack-name NewRelic-log-ingestion \\ --capabilities CAPABILITY_RESOURCE_POLICY \\ --region YOUR_REGION Copy This command outputs several fields, one of which is the ChangeSetId: an ARN for the change set that you just created. Copy that ARN. Use the ARN in this command, which executes the change set: aws cloudformation execute-change-set --change-set-name YOUR_CHANGE_SET_ARN Copy Enabling log management If you currently don't have New Relic's log management enabled, but would like to: Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region (for example, us-west-2). newrelic-lambda integrations update \\ --enable-logs \\ --aws-region YOUR_REGION Copy Then do either of the following: Update your Amazon CloudWatch log subscription filters for each region with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --filter-pattern \"\" \\ --aws-region YOUR_REGION Copy Or, you can send function logs to New Relic directly, bypassing CloudWatch and the newrelic-log-ingestion Lambda. To do this, set the environment variable NEW_RELIC_EXTENSION_SEND_FUNCTION_LOGS=true in your Lambda function configuration. After that, be sure to remove any existing New Relic log subscriptions for that function using this command: newrelic-lambda subscriptions uninstall \\ --function FUNCTION_NAME \\ --aws-region YOUR_REGION Copy If the log subscription is present while the extension is sending logs, logs will be sent twice, resulting in duplicate log records in New Relic. Optionally, if you'd like to avoid Amazon's charges for CloudWatch Log ingestion, you can also modify your function's execution role so that it doesn't grant the CloudWatch Log permissions. This will prevent your function from logging to CloudWatch. Caution CloudWatch Logs ingest fees can be considerable, but this step should be taken with caution. Make sure your New Relic log ingestion integration is working well and meeting your needs before disabling CloudWatch logs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.11917,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "sections": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "After enabling our <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, you should occasionally update our <em>Lambda</em> <em>function</em> that&#x27;s used to report <em>AWS</em> log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our <em>Lambda</em> <em>monitoring</em> using our CLI tool. Update via <em>AWS</em> <em>Serverless</em>"
      },
      "id": "6045248c28ccbc98a82c606b"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example": [
    {
      "sections": [
        "Instrument your own functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "title": "Instrument your own functions",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-09T22:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 324.0877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Instrument</em> your own <em>functions</em>",
        "sections": "<em>Instrument</em> your own <em>functions</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ": AWSTemplateFormatVersion: &#x27;2010-09-09&#x27; Transform: <em>AWS</em>::<em>Serverless</em>-2016-10-31 Description: And example of a simple instrumented NodeJS <em>Lambda</em> Resources: NewRelicExample: Type: <em>AWS</em>::<em>Serverless</em>::<em>Function</em> Properties: # In this example, we&#x27;re using the SAM CLI to package and deploy our <em>lambda</em>. SAM"
      },
      "id": "605aa8a064441f453b868bb9"
    },
    {
      "sections": [
        "Legacy manual instrumentation",
        "Go",
        "Zip and upload recommendations",
        "Java",
        "Tip",
        ".NET Core",
        "Async handler function",
        "Inheriting from APIGatewayProxyFunction",
        "Important",
        "Using the SQS Wrapper",
        "Using the SNS Wrapper",
        "Node.js",
        "Python"
      ],
      "title": "Legacy manual instrumentation",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "694e22b2ce401a96d200ab2e12a08850532b3e5a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy/",
      "published_at": "2021-05-22T11:11:39Z",
      "updated_at": "2021-05-06T02:46:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On this page, you will learn how to manually instrument your lambda function. It is organized by runtime language. Go To instrument your Go-language Lambda: Download our Go agent package and place it in the same directory as your function. Install the agent: go get -u github.com/newrelic/go-agent. In your Lambda code, import our components, create an application, and update how you start your Lambda. See our GitHub repo for an example of an instrumented Lambda. Optional: Add custom events that will be associated with your Lambda invocation by using the RecordCustomEvent API. For example: func handler(ctx context.Context) { if txn := newrelic.FromContext(ctx); nil != txn { txn.Application().RecordCustomEvent(\"MyEvent\", map[string]interface{}{ \"zip\": \"zap\", }) } fmt.Println(\"hello world!\") } Copy Build and zip your Lambda function and upload it to AWS. Zip and upload recommendations Here are suggestions for zipping and uploading the Lambda: Build the binary for execution on Linux. This produces a binary file called main. You can use: $ GOOS=linux go build -o main Copy Zip the binary into a deployment package using: $ zip deployment.zip main Copy Upload the zip file to AWS using either the AWS Lambda console or the AWS CLI. Name the handler main (to match the name given during the binary build). The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this is the account ID for the root/parent account. Optional: To configure logging, see Go agent logging. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Java Monitoring for AWS Lambda in Java doesn't use our APM Java agent. Instead, it uses these two OpenTracing dependencies: AWS Lambda OpenTracing Java SDK: OpenTracing instrumentation for AWS Lambda RequestHandler and RequestStreamHandler. Our AWS Lambda OpenTracing Tracer: An OpenTracing Tracer implementation designed to monitor AWS Lambda. It generates spans, error events, transaction events, error traces, and provides distributed tracing support. Tip Supported OpenTracing Versions OpenTracing 0.31.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:1.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:1.0.0 OpenTracing 0.32.0, 0.33.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:2.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:2.1.0 To instrument your Java Lambda: In your project’s build.gradle file, include our OpenTracing AWS Lambda Tracer and the AWS Lambda OpenTracing SDK dependencies: dependencies { compile(\"com.newrelic.opentracing:java-aws-lambda:2.1.0\") compile(\"com.newrelic.opentracing:newrelic-java-lambda:2.1.1\") compile(\"io.opentracing:opentracing-util:0.33.0\") } Copy Implement the AWS Lambda RequestHandler interface as shown in the Java Lambda example and override the doHandleRequest method. In the doHandleRequest method, call the LambdaTracing.instrument(...) API to create a root span to trace the lambda function's execution. This is also where you will define your business logic for the lambda function. Register a LambdaTracer.INSTANCE as the OpenTracing Global tracer, as shown in the Java Lambda example. Create a ZIP deployment package and upload it to AWS Lambda. Or deploy it via other means. In the AWS Lambda console, set the handler. For the example Java Lambda, the handler would be com.handler.example.MyLambdaHandler::handleRequest. Because handleRequest is assumed, you could also use com.handler.example.MyLambdaHandler. The following AWS console environment variables are required if you want your Lambda function to be included in distributed tracing. This is recommended. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_PRIMARY_APPLICATION_ID. This is also your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this must be the account ID for the root/parent account. Optional: In the Lambda console, enable debug logging by adding this environment variable: NEW_RELIC_DEBUG is true. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Please see the AWS Lambda distributed tracing example for a complete project that illustrates common use cases such as: Distributed tracing between Lambda functions Manual span creation (aka custom instrumentation) Tracing external calls Adding custom attributes (aka Tags) to spans .NET Core Our monitoring of .NET Core-based AWS Lambda functions doesn't use our standard .NET Core APM agent. Instead, it uses a NuGet package. To instrument your .NET Core Lambda: In your Lambda Functions project, install the NewRelic.OpenTracing.AmazonLambda.Tracer NuGet package. Note: NewRelic.OpenTracing.AmazonLambda.Tracer depends on version 1.2.0+ of Amazon.Lambda.APIGatewayEvent NuGet package. If the environment already uses a lower version of Amazon.Lambda.APIGatewayEvent, the New Relic package may produce errors such as System.MissingMethodException . Import the NuGet package and OpenTracing utils: using OpenTracing.Util; using NewRelic.OpenTracing.AmazonLambda; Copy Instrument your function, as shown in this example: public class Function { static Function() { // Register The NewRelic Lambda Tracer Instance GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public object FunctionWrapper(ILambdaContext context) { // Instantiate NewRelic TracingWrapper and pass your FunctionHandler as // an argument return new TracingRequestHandler().LambdaWrapper(FunctionHandler, context); } /// <summary> /// A simple function that takes a string and does a ToUpper /// </summary> /// <param name=\"input\"></param> /// <param name=\"context\"></param> /// <returns></returns> public object FunctionHandler(ILambdaContext context) { ... } } Copy Tip The arguments passed to FunctionWrapper must match the signature of FunctionHandler. If your handler function returns a Task, the Lambda wrapper will block on the return task until it completes, so that it can measure the duration and capture exceptions, if any are present. In addition, you may also inherit from the APIGatewayProxyFunction. For an example, see below: Async handler function public override Task<int> FunctionHandlerAsync(ILambdaContext lambdaContext) { // This call will block by calling task.Result Task<int> task = new TracingRequestHandler().LambdaWrapper( ActualFunctionHandlerAsync, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(ILambdaContext lambdaContext) { // Function can make other async operations here ... } Copy Inheriting from APIGatewayProxyFunction public class LambdaFunction : APIGatewayProxyFunction { static LambdaFunction() { // Register The NewRelic Lambda Tracer Instance OpenTracing.Util.GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public override Task<APIGatewayProxyResponse> FunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { Task<APIGatewayProxyResponse> task = new TracingRequestHandler().LambdaWrapper(ActualFunctionHandlerAsync, request, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { return base.FunctionHandlerAsync(request, lambdaContext); } } Copy Optional for SQS and SNS: Starting in version 1.0 of our .NET Lambda Tracer, distributed tracing support has been added for SQS and SNS. To enable distributed tracing for SQS or SNS you will need to complete the items in this step as well as setup the environment variables in the step that follows this one. Important Enabling distributed tracing support for SQS and SNS will disable automatic instrumentation for both of SQS and SNS and require the use of these wrappers to instrument them. Set the NEW_RELIC_USE_DT_WRAPPER environment variable to true. To instrument SQS and SNS calls you will need to use the provided wrappers. Using the SQS Wrapper The SQS wrapper supports wrapping the following methods: Amazon.SQS.AmazonSQSClient.SendMessageAsync(...) Amazon.SQS.AmazonSQSClient.SendMessageBatchAsync(...) Examples // SQS Client AmazonSQSClient client = new AmazonSQSClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // SendMessageRequest SendMessageRequest sendRequest = new SendMessageRequest(\"QUEUE_URI_STRING\", \"An SQS Message\"); Task<SendMessageResponse> responseOne = SQSWrapper.WrapRequest(client.SendMessageAsync, sendRequest); // String-based Task<SendMessageResponse> responseTwo = SQSWrapper.WrapRequest(client.SendMessageAsync, \"QUEUE_URI_STRING\", \"Another SQS Message\"); // SendMessageBatchRequest List<SendMessageBatchRequestEntry> batchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id1\", \"First SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id2\", \"Second SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id3\", \"Third SQS Message\")); SendMessageBatchRequest sendBatchRequest = new SendMessageBatchRequest(QUEUE_URI, batchEntries); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, sendBatchRequest); // SendMessageBatchRequestEntry List List<SendMessageBatchRequestEntry> moreBatchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id4\", \"Fourth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id5\", \"Fifth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id6\", \"Sixth SQS Message\")); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, moreBatchEntries); Copy Using the SNS Wrapper The SNS wrapper supports wrapping the following methods: Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient.PublishAsync(...) Examples // SNS Client AmazonSimpleNotificationServiceClient client = new Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // PublishRequest - Phone Number PublishRequest phonePublishRequest = new PublishRequest(); phonePublishRequest.PhoneNumber = +1XXX5555100; phonePublishRequest.Message = \"An SNS Message for phones\"; Task<PublishResponse> phoneResponse = SNSWrapper.WrapRequest(client.PublishAsync, phonePublishRequest); // PublishRequest - ARN PublishRequest publishRequest = new PublishRequest(\"TOPIC_ARN\", \"An SNS Message\"); Task<PublishResponse> publishResponse = SNSWrapper.WrapRequest(client.PublishAsync, publishRequest); // String-based without subject Task<PublishResponse> ResponseOne = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Another SNS Message\"); // String-based with subject Task<PublishResponse> ResponseTwo = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Yet Another SNS Message\", \"A Subject\"); Copy The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS Lambda console: NEW_RELIC_ACCOUNT_ID: The account ID the Lambda is reporting to. NEW_RELIC_TRUSTED_ACCOUNT_KEY: This is also the account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Ensure that the wrapper function (FunctionWrapper in above example) is set up as the function handler. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Node.js To instrument your Node.js Lambda: Download our Node.js agent package and place it in the same directory as your function, ensuring the agent is installed as a dependency in the node_modules directory. Use the Node Package Manager: npm install newrelic --save Copy Install our AWS SDK module alongside the Node.js agent: npm install @newrelic/aws-sdk --save Copy In your Lambda code, require the agent module and the AWS SDK at the top of the file, and wrap the handler function. For example: const newrelic = require('newrelic'); require('@newrelic/aws-sdk'); // Other module loads go under the two require statements above module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { // This is your handler function code console.log('Lambda executed'); callback(); }); Copy Optional: You can also add custom events to your Lambda using the recordCustomEvent API. For example: module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { newrelic.recordCustomEvent(‘MyEventType’, {foo: ‘bar’}); console.log('Lambda executed'); callback(); }); Copy Zip your Lambda function and the Node.js agent folder together. Requirements and recommendations: The New Relic files outside the New Relic agent folder don't need to be included. If your Lambda function file name is, for example, lambda_function.node, we recommend naming your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set these environment variables: NEW_RELIC_NO_CONFIG_FILE. Set to true if not using a configuration file. NEW_RELIC_APP_NAME: Your application name. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Optional: To run the agent in serverless mode outside of AWS in a local environment, set the environment variable NEW_RELIC_SERVERLESS_MODE_ENABLED to true. (When executing this in an AWS Lambda environment, the agent will automatically run in serverless mode. Do not use this variable if you're running in AWS.) Optional: To enable logging in serverless mode, set these environment variables: Set NEW_RELIC_LOG_ENABLED to true. Set NEW_RELIC_LOG to stdout for output to CloudWatch, or set to any writeable file location. The log level is set to info by default. See other log levels. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Python To instrument your Python Lambda: Download our Python agent package and place it in the same directory as your function. To do this, use pip: pip install -t . newrelic Copy Important If you use Homebrew, you may get this error: DistutilsOptionError: must supply either home or prefix/exec-prefix -- not both. For details, see the Homebrew GitHub post. In your Lambda code, import the Python agent module and decorate the handler function using the New Relic decorator. The New Relic package must be imported first in your code. Here's an example: import newrelic.agent newrelic.agent.initialize() @newrelic.agent.lambda_handler() def handler(event, context): ... Copy Optional: You can also add custom events to your Lambda using the record_custom_event API. Here's an example: @newrelic.agent.lambda_handler() def handler(event, context): newrelic.agent.record_custom_event('CustomEvent', {'foo': 'bar'}) … Copy Zip your lambda_function.py and newrelic/ folder together using these guidelines: The New Relic files outside the newrelic/ folder don't need to be included. If your Lambda function file name is, for example, lambda_function.py, name your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set this environment variable: NEW_RELIC_SERVERLESS_MODE_ENABLED. Set to true The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED. Set to true. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Optional: To configure logging, use the NEW_RELIC_LOG and NEW_RELIC_LOG_LEVEL environment variables in the AWS Console. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. The New Relic decorator gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, configure CloudWatch to send those logs to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.6834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Legacy manual <em>instrumentation</em>",
        "sections": "Legacy manual <em>instrumentation</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ". In the <em>AWS</em> console, set this environment variable: NEW_RELIC_<em>SERVERLESS</em>_MODE_ENABLED. Set to true The following environment variables are not required for <em>Lambda</em> <em>monitoring</em> to <em>function</em> but they are required if you want your <em>Lambda</em> functions to be included in distributed traces. To <em>enable</em> distributed"
      },
      "id": "603ebbcb64441f800a4e8850"
    },
    {
      "sections": [
        "Update serverless monitoring for AWS Lambda",
        "Important",
        "Update our Lambda integration via CLI",
        "Update layers via CLI",
        "Update a manual Serverless application repository install",
        "Enabling log management",
        "Caution"
      ],
      "title": "Update serverless monitoring for AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "7075499bcc9b1ff1e346a705ab414adcca54fd09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/update-serverless-monitoring-aws-lambda/",
      "published_at": "2021-05-22T05:30:55Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After enabling our monitoring for AWS Lambda, you should occasionally update our Lambda function that's used to report AWS log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our Lambda monitoring using our CLI tool. Update via AWS Serverless Application Repository: Use this if you enabled using the manual procedure. Important These update procedures apply to our serverless monitoring for AWS Lambda, and not to our infrastructure monitoring for AWS Lambda integration. Update our Lambda integration via CLI This section describes how to update if your Lambda monitoring was enabled using our recommended CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region identifier (for example, us-west-2). newrelic-lambda integrations update \\ --aws-region YOUR_REGION Copy If you do not have our logs enabled, you'll also need to update your Amazon CloudWatch log subscription filters with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --aws-region YOUR_REGION Copy Update layers via CLI This section describes how to update your function's Layer if you installed it with our CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy Pass the --upgrade flag to the install command: newrelic-lambda layers install \\ --function installed \\ --nr-account-id NR_ACCOUNT_ID \\ --upgrade Copy Update a manual Serverless application repository install If you manually installed the ingest function from the AWS Serverless Application Repository (and didn't use the CLI), update using this procedure: Run the following, replacing YOUR_REGION with your region (for example, us-west-2). aws serverlessrepo create-cloud-formation-change-set \\ --application-id arn:aws:serverlessrepo:us-east-1:463657938898:applications/NewRelic-log-ingestion \\ --stack-name NewRelic-log-ingestion \\ --capabilities CAPABILITY_RESOURCE_POLICY \\ --region YOUR_REGION Copy This command outputs several fields, one of which is the ChangeSetId: an ARN for the change set that you just created. Copy that ARN. Use the ARN in this command, which executes the change set: aws cloudformation execute-change-set --change-set-name YOUR_CHANGE_SET_ARN Copy Enabling log management If you currently don't have New Relic's log management enabled, but would like to: Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region (for example, us-west-2). newrelic-lambda integrations update \\ --enable-logs \\ --aws-region YOUR_REGION Copy Then do either of the following: Update your Amazon CloudWatch log subscription filters for each region with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --filter-pattern \"\" \\ --aws-region YOUR_REGION Copy Or, you can send function logs to New Relic directly, bypassing CloudWatch and the newrelic-log-ingestion Lambda. To do this, set the environment variable NEW_RELIC_EXTENSION_SEND_FUNCTION_LOGS=true in your Lambda function configuration. After that, be sure to remove any existing New Relic log subscriptions for that function using this command: newrelic-lambda subscriptions uninstall \\ --function FUNCTION_NAME \\ --aws-region YOUR_REGION Copy If the log subscription is present while the extension is sending logs, logs will be sent twice, resulting in duplicate log records in New Relic. Optionally, if you'd like to avoid Amazon's charges for CloudWatch Log ingestion, you can also modify your function's execution role so that it doesn't grant the CloudWatch Log permissions. This will prevent your function from logging to CloudWatch. Caution CloudWatch Logs ingest fees can be considerable, but this step should be taken with caution. Make sure your New Relic log ingestion integration is working well and meeting your needs before disabling CloudWatch logs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.06674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "sections": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "After enabling our <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, you should occasionally update our <em>Lambda</em> <em>function</em> that&#x27;s used to report <em>AWS</em> log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our <em>Lambda</em> <em>monitoring</em> using our CLI tool. Update via <em>AWS</em> <em>Serverless</em>"
      },
      "id": "6045248c28ccbc98a82c606b"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own": [
    {
      "sections": [
        "Instrument a Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "title": "Instrument a Lambda function",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate Distributed Tracing into a non-trivial serverless application in our Distributed Tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 307.4405,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Instrument</em> a <em>Lambda</em> <em>function</em>",
        "sections": "<em>Instrument</em> a <em>Lambda</em> <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "New Relic provides working minimal examples as a starting point for instrumenting your own <em>serverless</em> functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own <em>instrumentation</em>. While there are many ways to manage"
      },
      "id": "605aa85628ccbcc6d13ae663"
    },
    {
      "sections": [
        "Legacy manual instrumentation",
        "Go",
        "Zip and upload recommendations",
        "Java",
        "Tip",
        ".NET Core",
        "Async handler function",
        "Inheriting from APIGatewayProxyFunction",
        "Important",
        "Using the SQS Wrapper",
        "Using the SNS Wrapper",
        "Node.js",
        "Python"
      ],
      "title": "Legacy manual instrumentation",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "694e22b2ce401a96d200ab2e12a08850532b3e5a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy/",
      "published_at": "2021-05-22T11:11:39Z",
      "updated_at": "2021-05-06T02:46:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On this page, you will learn how to manually instrument your lambda function. It is organized by runtime language. Go To instrument your Go-language Lambda: Download our Go agent package and place it in the same directory as your function. Install the agent: go get -u github.com/newrelic/go-agent. In your Lambda code, import our components, create an application, and update how you start your Lambda. See our GitHub repo for an example of an instrumented Lambda. Optional: Add custom events that will be associated with your Lambda invocation by using the RecordCustomEvent API. For example: func handler(ctx context.Context) { if txn := newrelic.FromContext(ctx); nil != txn { txn.Application().RecordCustomEvent(\"MyEvent\", map[string]interface{}{ \"zip\": \"zap\", }) } fmt.Println(\"hello world!\") } Copy Build and zip your Lambda function and upload it to AWS. Zip and upload recommendations Here are suggestions for zipping and uploading the Lambda: Build the binary for execution on Linux. This produces a binary file called main. You can use: $ GOOS=linux go build -o main Copy Zip the binary into a deployment package using: $ zip deployment.zip main Copy Upload the zip file to AWS using either the AWS Lambda console or the AWS CLI. Name the handler main (to match the name given during the binary build). The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this is the account ID for the root/parent account. Optional: To configure logging, see Go agent logging. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Java Monitoring for AWS Lambda in Java doesn't use our APM Java agent. Instead, it uses these two OpenTracing dependencies: AWS Lambda OpenTracing Java SDK: OpenTracing instrumentation for AWS Lambda RequestHandler and RequestStreamHandler. Our AWS Lambda OpenTracing Tracer: An OpenTracing Tracer implementation designed to monitor AWS Lambda. It generates spans, error events, transaction events, error traces, and provides distributed tracing support. Tip Supported OpenTracing Versions OpenTracing 0.31.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:1.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:1.0.0 OpenTracing 0.32.0, 0.33.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:2.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:2.1.0 To instrument your Java Lambda: In your project’s build.gradle file, include our OpenTracing AWS Lambda Tracer and the AWS Lambda OpenTracing SDK dependencies: dependencies { compile(\"com.newrelic.opentracing:java-aws-lambda:2.1.0\") compile(\"com.newrelic.opentracing:newrelic-java-lambda:2.1.1\") compile(\"io.opentracing:opentracing-util:0.33.0\") } Copy Implement the AWS Lambda RequestHandler interface as shown in the Java Lambda example and override the doHandleRequest method. In the doHandleRequest method, call the LambdaTracing.instrument(...) API to create a root span to trace the lambda function's execution. This is also where you will define your business logic for the lambda function. Register a LambdaTracer.INSTANCE as the OpenTracing Global tracer, as shown in the Java Lambda example. Create a ZIP deployment package and upload it to AWS Lambda. Or deploy it via other means. In the AWS Lambda console, set the handler. For the example Java Lambda, the handler would be com.handler.example.MyLambdaHandler::handleRequest. Because handleRequest is assumed, you could also use com.handler.example.MyLambdaHandler. The following AWS console environment variables are required if you want your Lambda function to be included in distributed tracing. This is recommended. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_PRIMARY_APPLICATION_ID. This is also your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this must be the account ID for the root/parent account. Optional: In the Lambda console, enable debug logging by adding this environment variable: NEW_RELIC_DEBUG is true. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Please see the AWS Lambda distributed tracing example for a complete project that illustrates common use cases such as: Distributed tracing between Lambda functions Manual span creation (aka custom instrumentation) Tracing external calls Adding custom attributes (aka Tags) to spans .NET Core Our monitoring of .NET Core-based AWS Lambda functions doesn't use our standard .NET Core APM agent. Instead, it uses a NuGet package. To instrument your .NET Core Lambda: In your Lambda Functions project, install the NewRelic.OpenTracing.AmazonLambda.Tracer NuGet package. Note: NewRelic.OpenTracing.AmazonLambda.Tracer depends on version 1.2.0+ of Amazon.Lambda.APIGatewayEvent NuGet package. If the environment already uses a lower version of Amazon.Lambda.APIGatewayEvent, the New Relic package may produce errors such as System.MissingMethodException . Import the NuGet package and OpenTracing utils: using OpenTracing.Util; using NewRelic.OpenTracing.AmazonLambda; Copy Instrument your function, as shown in this example: public class Function { static Function() { // Register The NewRelic Lambda Tracer Instance GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public object FunctionWrapper(ILambdaContext context) { // Instantiate NewRelic TracingWrapper and pass your FunctionHandler as // an argument return new TracingRequestHandler().LambdaWrapper(FunctionHandler, context); } /// <summary> /// A simple function that takes a string and does a ToUpper /// </summary> /// <param name=\"input\"></param> /// <param name=\"context\"></param> /// <returns></returns> public object FunctionHandler(ILambdaContext context) { ... } } Copy Tip The arguments passed to FunctionWrapper must match the signature of FunctionHandler. If your handler function returns a Task, the Lambda wrapper will block on the return task until it completes, so that it can measure the duration and capture exceptions, if any are present. In addition, you may also inherit from the APIGatewayProxyFunction. For an example, see below: Async handler function public override Task<int> FunctionHandlerAsync(ILambdaContext lambdaContext) { // This call will block by calling task.Result Task<int> task = new TracingRequestHandler().LambdaWrapper( ActualFunctionHandlerAsync, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(ILambdaContext lambdaContext) { // Function can make other async operations here ... } Copy Inheriting from APIGatewayProxyFunction public class LambdaFunction : APIGatewayProxyFunction { static LambdaFunction() { // Register The NewRelic Lambda Tracer Instance OpenTracing.Util.GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public override Task<APIGatewayProxyResponse> FunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { Task<APIGatewayProxyResponse> task = new TracingRequestHandler().LambdaWrapper(ActualFunctionHandlerAsync, request, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { return base.FunctionHandlerAsync(request, lambdaContext); } } Copy Optional for SQS and SNS: Starting in version 1.0 of our .NET Lambda Tracer, distributed tracing support has been added for SQS and SNS. To enable distributed tracing for SQS or SNS you will need to complete the items in this step as well as setup the environment variables in the step that follows this one. Important Enabling distributed tracing support for SQS and SNS will disable automatic instrumentation for both of SQS and SNS and require the use of these wrappers to instrument them. Set the NEW_RELIC_USE_DT_WRAPPER environment variable to true. To instrument SQS and SNS calls you will need to use the provided wrappers. Using the SQS Wrapper The SQS wrapper supports wrapping the following methods: Amazon.SQS.AmazonSQSClient.SendMessageAsync(...) Amazon.SQS.AmazonSQSClient.SendMessageBatchAsync(...) Examples // SQS Client AmazonSQSClient client = new AmazonSQSClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // SendMessageRequest SendMessageRequest sendRequest = new SendMessageRequest(\"QUEUE_URI_STRING\", \"An SQS Message\"); Task<SendMessageResponse> responseOne = SQSWrapper.WrapRequest(client.SendMessageAsync, sendRequest); // String-based Task<SendMessageResponse> responseTwo = SQSWrapper.WrapRequest(client.SendMessageAsync, \"QUEUE_URI_STRING\", \"Another SQS Message\"); // SendMessageBatchRequest List<SendMessageBatchRequestEntry> batchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id1\", \"First SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id2\", \"Second SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id3\", \"Third SQS Message\")); SendMessageBatchRequest sendBatchRequest = new SendMessageBatchRequest(QUEUE_URI, batchEntries); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, sendBatchRequest); // SendMessageBatchRequestEntry List List<SendMessageBatchRequestEntry> moreBatchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id4\", \"Fourth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id5\", \"Fifth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id6\", \"Sixth SQS Message\")); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, moreBatchEntries); Copy Using the SNS Wrapper The SNS wrapper supports wrapping the following methods: Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient.PublishAsync(...) Examples // SNS Client AmazonSimpleNotificationServiceClient client = new Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // PublishRequest - Phone Number PublishRequest phonePublishRequest = new PublishRequest(); phonePublishRequest.PhoneNumber = +1XXX5555100; phonePublishRequest.Message = \"An SNS Message for phones\"; Task<PublishResponse> phoneResponse = SNSWrapper.WrapRequest(client.PublishAsync, phonePublishRequest); // PublishRequest - ARN PublishRequest publishRequest = new PublishRequest(\"TOPIC_ARN\", \"An SNS Message\"); Task<PublishResponse> publishResponse = SNSWrapper.WrapRequest(client.PublishAsync, publishRequest); // String-based without subject Task<PublishResponse> ResponseOne = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Another SNS Message\"); // String-based with subject Task<PublishResponse> ResponseTwo = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Yet Another SNS Message\", \"A Subject\"); Copy The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS Lambda console: NEW_RELIC_ACCOUNT_ID: The account ID the Lambda is reporting to. NEW_RELIC_TRUSTED_ACCOUNT_KEY: This is also the account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Ensure that the wrapper function (FunctionWrapper in above example) is set up as the function handler. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Node.js To instrument your Node.js Lambda: Download our Node.js agent package and place it in the same directory as your function, ensuring the agent is installed as a dependency in the node_modules directory. Use the Node Package Manager: npm install newrelic --save Copy Install our AWS SDK module alongside the Node.js agent: npm install @newrelic/aws-sdk --save Copy In your Lambda code, require the agent module and the AWS SDK at the top of the file, and wrap the handler function. For example: const newrelic = require('newrelic'); require('@newrelic/aws-sdk'); // Other module loads go under the two require statements above module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { // This is your handler function code console.log('Lambda executed'); callback(); }); Copy Optional: You can also add custom events to your Lambda using the recordCustomEvent API. For example: module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { newrelic.recordCustomEvent(‘MyEventType’, {foo: ‘bar’}); console.log('Lambda executed'); callback(); }); Copy Zip your Lambda function and the Node.js agent folder together. Requirements and recommendations: The New Relic files outside the New Relic agent folder don't need to be included. If your Lambda function file name is, for example, lambda_function.node, we recommend naming your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set these environment variables: NEW_RELIC_NO_CONFIG_FILE. Set to true if not using a configuration file. NEW_RELIC_APP_NAME: Your application name. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Optional: To run the agent in serverless mode outside of AWS in a local environment, set the environment variable NEW_RELIC_SERVERLESS_MODE_ENABLED to true. (When executing this in an AWS Lambda environment, the agent will automatically run in serverless mode. Do not use this variable if you're running in AWS.) Optional: To enable logging in serverless mode, set these environment variables: Set NEW_RELIC_LOG_ENABLED to true. Set NEW_RELIC_LOG to stdout for output to CloudWatch, or set to any writeable file location. The log level is set to info by default. See other log levels. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Python To instrument your Python Lambda: Download our Python agent package and place it in the same directory as your function. To do this, use pip: pip install -t . newrelic Copy Important If you use Homebrew, you may get this error: DistutilsOptionError: must supply either home or prefix/exec-prefix -- not both. For details, see the Homebrew GitHub post. In your Lambda code, import the Python agent module and decorate the handler function using the New Relic decorator. The New Relic package must be imported first in your code. Here's an example: import newrelic.agent newrelic.agent.initialize() @newrelic.agent.lambda_handler() def handler(event, context): ... Copy Optional: You can also add custom events to your Lambda using the record_custom_event API. Here's an example: @newrelic.agent.lambda_handler() def handler(event, context): newrelic.agent.record_custom_event('CustomEvent', {'foo': 'bar'}) … Copy Zip your lambda_function.py and newrelic/ folder together using these guidelines: The New Relic files outside the newrelic/ folder don't need to be included. If your Lambda function file name is, for example, lambda_function.py, name your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set this environment variable: NEW_RELIC_SERVERLESS_MODE_ENABLED. Set to true The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED. Set to true. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Optional: To configure logging, use the NEW_RELIC_LOG and NEW_RELIC_LOG_LEVEL environment variables in the AWS Console. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. The New Relic decorator gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, configure CloudWatch to send those logs to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.6834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Legacy manual <em>instrumentation</em>",
        "sections": "Legacy manual <em>instrumentation</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ". In the <em>AWS</em> console, set this environment variable: NEW_RELIC_<em>SERVERLESS</em>_MODE_ENABLED. Set to true The following environment variables are not required for <em>Lambda</em> <em>monitoring</em> to <em>function</em> but they are required if you want your <em>Lambda</em> functions to be included in distributed traces. To <em>enable</em> distributed"
      },
      "id": "603ebbcb64441f800a4e8850"
    },
    {
      "sections": [
        "Update serverless monitoring for AWS Lambda",
        "Important",
        "Update our Lambda integration via CLI",
        "Update layers via CLI",
        "Update a manual Serverless application repository install",
        "Enabling log management",
        "Caution"
      ],
      "title": "Update serverless monitoring for AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "7075499bcc9b1ff1e346a705ab414adcca54fd09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/update-serverless-monitoring-aws-lambda/",
      "published_at": "2021-05-22T05:30:55Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After enabling our monitoring for AWS Lambda, you should occasionally update our Lambda function that's used to report AWS log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our Lambda monitoring using our CLI tool. Update via AWS Serverless Application Repository: Use this if you enabled using the manual procedure. Important These update procedures apply to our serverless monitoring for AWS Lambda, and not to our infrastructure monitoring for AWS Lambda integration. Update our Lambda integration via CLI This section describes how to update if your Lambda monitoring was enabled using our recommended CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region identifier (for example, us-west-2). newrelic-lambda integrations update \\ --aws-region YOUR_REGION Copy If you do not have our logs enabled, you'll also need to update your Amazon CloudWatch log subscription filters with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --aws-region YOUR_REGION Copy Update layers via CLI This section describes how to update your function's Layer if you installed it with our CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy Pass the --upgrade flag to the install command: newrelic-lambda layers install \\ --function installed \\ --nr-account-id NR_ACCOUNT_ID \\ --upgrade Copy Update a manual Serverless application repository install If you manually installed the ingest function from the AWS Serverless Application Repository (and didn't use the CLI), update using this procedure: Run the following, replacing YOUR_REGION with your region (for example, us-west-2). aws serverlessrepo create-cloud-formation-change-set \\ --application-id arn:aws:serverlessrepo:us-east-1:463657938898:applications/NewRelic-log-ingestion \\ --stack-name NewRelic-log-ingestion \\ --capabilities CAPABILITY_RESOURCE_POLICY \\ --region YOUR_REGION Copy This command outputs several fields, one of which is the ChangeSetId: an ARN for the change set that you just created. Copy that ARN. Use the ARN in this command, which executes the change set: aws cloudformation execute-change-set --change-set-name YOUR_CHANGE_SET_ARN Copy Enabling log management If you currently don't have New Relic's log management enabled, but would like to: Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region (for example, us-west-2). newrelic-lambda integrations update \\ --enable-logs \\ --aws-region YOUR_REGION Copy Then do either of the following: Update your Amazon CloudWatch log subscription filters for each region with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --filter-pattern \"\" \\ --aws-region YOUR_REGION Copy Or, you can send function logs to New Relic directly, bypassing CloudWatch and the newrelic-log-ingestion Lambda. To do this, set the environment variable NEW_RELIC_EXTENSION_SEND_FUNCTION_LOGS=true in your Lambda function configuration. After that, be sure to remove any existing New Relic log subscriptions for that function using this command: newrelic-lambda subscriptions uninstall \\ --function FUNCTION_NAME \\ --aws-region YOUR_REGION Copy If the log subscription is present while the extension is sending logs, logs will be sent twice, resulting in duplicate log records in New Relic. Optionally, if you'd like to avoid Amazon's charges for CloudWatch Log ingestion, you can also modify your function's execution role so that it doesn't grant the CloudWatch Log permissions. This will prevent your function from logging to CloudWatch. Caution CloudWatch Logs ingest fees can be considerable, but this step should be taken with caution. Make sure your New Relic log ingestion integration is working well and meeting your needs before disabling CloudWatch logs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.06674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "sections": "Update <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "After enabling our <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, you should occasionally update our <em>Lambda</em> <em>function</em> that&#x27;s used to report <em>AWS</em> log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our <em>Lambda</em> <em>monitoring</em> using our CLI tool. Update via <em>AWS</em> <em>Serverless</em>"
      },
      "id": "6045248c28ccbc98a82c606b"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/update-serverless-monitoring-aws-lambda": [
    {
      "sections": [
        "Instrument your own functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "title": "Instrument your own functions",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-09T22:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.66248,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument your own <em>functions</em>",
        "sections": "Instrument your own <em>functions</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ": AWSTemplateFormatVersion: &#x27;2010-09-09&#x27; Transform: <em>AWS</em>::<em>Serverless</em>-2016-10-31 Description: And example of a simple instrumented NodeJS <em>Lambda</em> Resources: NewRelicExample: Type: <em>AWS</em>::<em>Serverless</em>::<em>Function</em> Properties: # In this example, we&#x27;re using the SAM CLI to package and deploy our <em>lambda</em>. SAM"
      },
      "id": "605aa8a064441f453b868bb9"
    },
    {
      "sections": [
        "Instrument a Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "title": "Instrument a Lambda function",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate Distributed Tracing into a non-trivial serverless application in our Distributed Tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.11911,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument a <em>Lambda</em> <em>function</em>",
        "sections": "Instrument a <em>Lambda</em> <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " and deploy <em>Lambda</em> functions, <em>AWS</em> CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates"
      },
      "id": "605aa85628ccbcc6d13ae663"
    },
    {
      "sections": [
        "Legacy manual instrumentation",
        "Go",
        "Zip and upload recommendations",
        "Java",
        "Tip",
        ".NET Core",
        "Async handler function",
        "Inheriting from APIGatewayProxyFunction",
        "Important",
        "Using the SQS Wrapper",
        "Using the SNS Wrapper",
        "Node.js",
        "Python"
      ],
      "title": "Legacy manual instrumentation",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "694e22b2ce401a96d200ab2e12a08850532b3e5a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy/",
      "published_at": "2021-05-22T11:11:39Z",
      "updated_at": "2021-05-06T02:46:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On this page, you will learn how to manually instrument your lambda function. It is organized by runtime language. Go To instrument your Go-language Lambda: Download our Go agent package and place it in the same directory as your function. Install the agent: go get -u github.com/newrelic/go-agent. In your Lambda code, import our components, create an application, and update how you start your Lambda. See our GitHub repo for an example of an instrumented Lambda. Optional: Add custom events that will be associated with your Lambda invocation by using the RecordCustomEvent API. For example: func handler(ctx context.Context) { if txn := newrelic.FromContext(ctx); nil != txn { txn.Application().RecordCustomEvent(\"MyEvent\", map[string]interface{}{ \"zip\": \"zap\", }) } fmt.Println(\"hello world!\") } Copy Build and zip your Lambda function and upload it to AWS. Zip and upload recommendations Here are suggestions for zipping and uploading the Lambda: Build the binary for execution on Linux. This produces a binary file called main. You can use: $ GOOS=linux go build -o main Copy Zip the binary into a deployment package using: $ zip deployment.zip main Copy Upload the zip file to AWS using either the AWS Lambda console or the AWS CLI. Name the handler main (to match the name given during the binary build). The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this is the account ID for the root/parent account. Optional: To configure logging, see Go agent logging. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Java Monitoring for AWS Lambda in Java doesn't use our APM Java agent. Instead, it uses these two OpenTracing dependencies: AWS Lambda OpenTracing Java SDK: OpenTracing instrumentation for AWS Lambda RequestHandler and RequestStreamHandler. Our AWS Lambda OpenTracing Tracer: An OpenTracing Tracer implementation designed to monitor AWS Lambda. It generates spans, error events, transaction events, error traces, and provides distributed tracing support. Tip Supported OpenTracing Versions OpenTracing 0.31.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:1.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:1.0.0 OpenTracing 0.32.0, 0.33.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:2.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:2.1.0 To instrument your Java Lambda: In your project’s build.gradle file, include our OpenTracing AWS Lambda Tracer and the AWS Lambda OpenTracing SDK dependencies: dependencies { compile(\"com.newrelic.opentracing:java-aws-lambda:2.1.0\") compile(\"com.newrelic.opentracing:newrelic-java-lambda:2.1.1\") compile(\"io.opentracing:opentracing-util:0.33.0\") } Copy Implement the AWS Lambda RequestHandler interface as shown in the Java Lambda example and override the doHandleRequest method. In the doHandleRequest method, call the LambdaTracing.instrument(...) API to create a root span to trace the lambda function's execution. This is also where you will define your business logic for the lambda function. Register a LambdaTracer.INSTANCE as the OpenTracing Global tracer, as shown in the Java Lambda example. Create a ZIP deployment package and upload it to AWS Lambda. Or deploy it via other means. In the AWS Lambda console, set the handler. For the example Java Lambda, the handler would be com.handler.example.MyLambdaHandler::handleRequest. Because handleRequest is assumed, you could also use com.handler.example.MyLambdaHandler. The following AWS console environment variables are required if you want your Lambda function to be included in distributed tracing. This is recommended. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_PRIMARY_APPLICATION_ID. This is also your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this must be the account ID for the root/parent account. Optional: In the Lambda console, enable debug logging by adding this environment variable: NEW_RELIC_DEBUG is true. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Please see the AWS Lambda distributed tracing example for a complete project that illustrates common use cases such as: Distributed tracing between Lambda functions Manual span creation (aka custom instrumentation) Tracing external calls Adding custom attributes (aka Tags) to spans .NET Core Our monitoring of .NET Core-based AWS Lambda functions doesn't use our standard .NET Core APM agent. Instead, it uses a NuGet package. To instrument your .NET Core Lambda: In your Lambda Functions project, install the NewRelic.OpenTracing.AmazonLambda.Tracer NuGet package. Note: NewRelic.OpenTracing.AmazonLambda.Tracer depends on version 1.2.0+ of Amazon.Lambda.APIGatewayEvent NuGet package. If the environment already uses a lower version of Amazon.Lambda.APIGatewayEvent, the New Relic package may produce errors such as System.MissingMethodException . Import the NuGet package and OpenTracing utils: using OpenTracing.Util; using NewRelic.OpenTracing.AmazonLambda; Copy Instrument your function, as shown in this example: public class Function { static Function() { // Register The NewRelic Lambda Tracer Instance GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public object FunctionWrapper(ILambdaContext context) { // Instantiate NewRelic TracingWrapper and pass your FunctionHandler as // an argument return new TracingRequestHandler().LambdaWrapper(FunctionHandler, context); } /// <summary> /// A simple function that takes a string and does a ToUpper /// </summary> /// <param name=\"input\"></param> /// <param name=\"context\"></param> /// <returns></returns> public object FunctionHandler(ILambdaContext context) { ... } } Copy Tip The arguments passed to FunctionWrapper must match the signature of FunctionHandler. If your handler function returns a Task, the Lambda wrapper will block on the return task until it completes, so that it can measure the duration and capture exceptions, if any are present. In addition, you may also inherit from the APIGatewayProxyFunction. For an example, see below: Async handler function public override Task<int> FunctionHandlerAsync(ILambdaContext lambdaContext) { // This call will block by calling task.Result Task<int> task = new TracingRequestHandler().LambdaWrapper( ActualFunctionHandlerAsync, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(ILambdaContext lambdaContext) { // Function can make other async operations here ... } Copy Inheriting from APIGatewayProxyFunction public class LambdaFunction : APIGatewayProxyFunction { static LambdaFunction() { // Register The NewRelic Lambda Tracer Instance OpenTracing.Util.GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public override Task<APIGatewayProxyResponse> FunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { Task<APIGatewayProxyResponse> task = new TracingRequestHandler().LambdaWrapper(ActualFunctionHandlerAsync, request, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { return base.FunctionHandlerAsync(request, lambdaContext); } } Copy Optional for SQS and SNS: Starting in version 1.0 of our .NET Lambda Tracer, distributed tracing support has been added for SQS and SNS. To enable distributed tracing for SQS or SNS you will need to complete the items in this step as well as setup the environment variables in the step that follows this one. Important Enabling distributed tracing support for SQS and SNS will disable automatic instrumentation for both of SQS and SNS and require the use of these wrappers to instrument them. Set the NEW_RELIC_USE_DT_WRAPPER environment variable to true. To instrument SQS and SNS calls you will need to use the provided wrappers. Using the SQS Wrapper The SQS wrapper supports wrapping the following methods: Amazon.SQS.AmazonSQSClient.SendMessageAsync(...) Amazon.SQS.AmazonSQSClient.SendMessageBatchAsync(...) Examples // SQS Client AmazonSQSClient client = new AmazonSQSClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // SendMessageRequest SendMessageRequest sendRequest = new SendMessageRequest(\"QUEUE_URI_STRING\", \"An SQS Message\"); Task<SendMessageResponse> responseOne = SQSWrapper.WrapRequest(client.SendMessageAsync, sendRequest); // String-based Task<SendMessageResponse> responseTwo = SQSWrapper.WrapRequest(client.SendMessageAsync, \"QUEUE_URI_STRING\", \"Another SQS Message\"); // SendMessageBatchRequest List<SendMessageBatchRequestEntry> batchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id1\", \"First SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id2\", \"Second SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id3\", \"Third SQS Message\")); SendMessageBatchRequest sendBatchRequest = new SendMessageBatchRequest(QUEUE_URI, batchEntries); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, sendBatchRequest); // SendMessageBatchRequestEntry List List<SendMessageBatchRequestEntry> moreBatchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id4\", \"Fourth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id5\", \"Fifth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id6\", \"Sixth SQS Message\")); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, moreBatchEntries); Copy Using the SNS Wrapper The SNS wrapper supports wrapping the following methods: Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient.PublishAsync(...) Examples // SNS Client AmazonSimpleNotificationServiceClient client = new Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // PublishRequest - Phone Number PublishRequest phonePublishRequest = new PublishRequest(); phonePublishRequest.PhoneNumber = +1XXX5555100; phonePublishRequest.Message = \"An SNS Message for phones\"; Task<PublishResponse> phoneResponse = SNSWrapper.WrapRequest(client.PublishAsync, phonePublishRequest); // PublishRequest - ARN PublishRequest publishRequest = new PublishRequest(\"TOPIC_ARN\", \"An SNS Message\"); Task<PublishResponse> publishResponse = SNSWrapper.WrapRequest(client.PublishAsync, publishRequest); // String-based without subject Task<PublishResponse> ResponseOne = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Another SNS Message\"); // String-based with subject Task<PublishResponse> ResponseTwo = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Yet Another SNS Message\", \"A Subject\"); Copy The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS Lambda console: NEW_RELIC_ACCOUNT_ID: The account ID the Lambda is reporting to. NEW_RELIC_TRUSTED_ACCOUNT_KEY: This is also the account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Ensure that the wrapper function (FunctionWrapper in above example) is set up as the function handler. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Node.js To instrument your Node.js Lambda: Download our Node.js agent package and place it in the same directory as your function, ensuring the agent is installed as a dependency in the node_modules directory. Use the Node Package Manager: npm install newrelic --save Copy Install our AWS SDK module alongside the Node.js agent: npm install @newrelic/aws-sdk --save Copy In your Lambda code, require the agent module and the AWS SDK at the top of the file, and wrap the handler function. For example: const newrelic = require('newrelic'); require('@newrelic/aws-sdk'); // Other module loads go under the two require statements above module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { // This is your handler function code console.log('Lambda executed'); callback(); }); Copy Optional: You can also add custom events to your Lambda using the recordCustomEvent API. For example: module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { newrelic.recordCustomEvent(‘MyEventType’, {foo: ‘bar’}); console.log('Lambda executed'); callback(); }); Copy Zip your Lambda function and the Node.js agent folder together. Requirements and recommendations: The New Relic files outside the New Relic agent folder don't need to be included. If your Lambda function file name is, for example, lambda_function.node, we recommend naming your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set these environment variables: NEW_RELIC_NO_CONFIG_FILE. Set to true if not using a configuration file. NEW_RELIC_APP_NAME: Your application name. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Optional: To run the agent in serverless mode outside of AWS in a local environment, set the environment variable NEW_RELIC_SERVERLESS_MODE_ENABLED to true. (When executing this in an AWS Lambda environment, the agent will automatically run in serverless mode. Do not use this variable if you're running in AWS.) Optional: To enable logging in serverless mode, set these environment variables: Set NEW_RELIC_LOG_ENABLED to true. Set NEW_RELIC_LOG to stdout for output to CloudWatch, or set to any writeable file location. The log level is set to info by default. See other log levels. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Python To instrument your Python Lambda: Download our Python agent package and place it in the same directory as your function. To do this, use pip: pip install -t . newrelic Copy Important If you use Homebrew, you may get this error: DistutilsOptionError: must supply either home or prefix/exec-prefix -- not both. For details, see the Homebrew GitHub post. In your Lambda code, import the Python agent module and decorate the handler function using the New Relic decorator. The New Relic package must be imported first in your code. Here's an example: import newrelic.agent newrelic.agent.initialize() @newrelic.agent.lambda_handler() def handler(event, context): ... Copy Optional: You can also add custom events to your Lambda using the record_custom_event API. Here's an example: @newrelic.agent.lambda_handler() def handler(event, context): newrelic.agent.record_custom_event('CustomEvent', {'foo': 'bar'}) … Copy Zip your lambda_function.py and newrelic/ folder together using these guidelines: The New Relic files outside the newrelic/ folder don't need to be included. If your Lambda function file name is, for example, lambda_function.py, name your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set this environment variable: NEW_RELIC_SERVERLESS_MODE_ENABLED. Set to true The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED. Set to true. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a sub-account, this needs to be the account ID for the root/parent account. Optional: To configure logging, use the NEW_RELIC_LOG and NEW_RELIC_LOG_LEVEL environment variables in the AWS Console. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. The New Relic decorator gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, configure CloudWatch to send those logs to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.04218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Async handler <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ". In the <em>AWS</em> console, set this environment variable: NEW_RELIC_<em>SERVERLESS</em>_MODE_ENABLED. Set to true The following environment variables are not required for <em>Lambda</em> <em>monitoring</em> to <em>function</em> but they are required if you want your <em>Lambda</em> functions to be included in distributed traces. To <em>enable</em> distributed"
      },
      "id": "603ebbcb64441f800a4e8850"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/architecture": [
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-05-22T05:30:54Z",
      "updated_at": "2021-05-09T22:54:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs10.x, nodejs12.x, nodejs14.x Python: python3.7, python3.8 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.16632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Before enabling <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, make sure you meet the requirements and learn about <em>AWS</em> charges resulting from its use. Recommended <em>AWS</em> <em>Lambda</em> language runtimes NodeJS: nodejs10.x, nodejs12.x, nodejs14.x Python: python3.7, python3.8 Go: provided, provided.al2 Java: java8.al2"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "sections": [
        "Instrument your own functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "title": "Instrument your own functions",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-09T22:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.69177,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument your own <em>functions</em>",
        "sections": "Instrument your own <em>functions</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ": AWSTemplateFormatVersion: &#x27;2010-09-09&#x27; Transform: <em>AWS</em>::<em>Serverless</em>-2016-10-31 Description: And example of a simple instrumented NodeJS <em>Lambda</em> Resources: NewRelicExample: Type: <em>AWS</em>::<em>Serverless</em>::<em>Function</em> Properties: # In this example, we&#x27;re using the SAM CLI to package and deploy our <em>lambda</em>. SAM"
      },
      "id": "605aa8a064441f453b868bb9"
    },
    {
      "sections": [
        "Instrument a Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "title": "Instrument a Lambda function",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate Distributed Tracing into a non-trivial serverless application in our Distributed Tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.76987,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument a <em>Lambda</em> <em>function</em>",
        "sections": "Instrument a <em>Lambda</em> <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " and deploy <em>Lambda</em> functions, <em>AWS</em> CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates"
      },
      "id": "605aa85628ccbcc6d13ae663"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring": [
    {
      "sections": [
        "Monitoring AWS Lambda with Serverless monitoring",
        "Tip",
        "Why it matters",
        "Access and requirements",
        "Next steps: Enable and use Lambda monitoring"
      ],
      "title": "Monitoring AWS Lambda with Serverless monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "5d1d86ec786398b3190ed1a6e152373e0547dc57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring/",
      "published_at": "2021-05-22T04:09:17Z",
      "updated_at": "2021-03-30T19:33:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer in-depth performance monitoring for your serverless AWS Lambda functions. Read on to learn about the feature, how it works, and its requirements. This Lambda monitoring feature is not the same as the Lambda monitoring integration, which only uses CloudWatch data. Serverless Lambda monitoring is more extensive and uses both CloudWatch data and code-level instrumentation to deliver more in-depth monitoring. Tip To use serverless monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters Do you need to rapidly instrument monitoring and observability to your serverless functions without resorting to code changes? Our Lambda layer provides unified visibility into the most detailed behaviors of your Lambda functions so you can understand what's going on in your serverless applications. Use all this information to troubleshoot your systems and optimize your functions so they can function faster and deliver with confidence on serverless architectures. Spend less time instrumenting, and more time building. Lambda monitoring gives you: Every invocation of your Lambda functions, including performance data like detailed duration, cold starts, exceptions, and tracebacks. AWS Lambda event source information, which provides context and attributes about events that triggered each AWS Lambda invocation, such as API Gateway, ALB SNS, SQS, DynamoDB, and more. Visibility into your entire ecosystem with distributed tracing: see the path of requests that led to your Lambda, and see Lambda spans in your other distributed traces. Logs in context, which provides full invocation and function level logs right along side the metrics, attributes, and trace data. Inventoried tags and metadata. We retrieve information from your AWS entities, giving you the ability to filter and facet down to the team, or specific metadata attributes on the function configuration or invocation itself. Easy ability to query your data with an automatic facet builder, which instantly facets your dashboards and charts by attribute or function to explore custom data, without having to write queries. Lambda data is displayed in its own dedicated UI in New Relic One. Access and requirements See Compatibility and requirements of AWS Lambda monitoring. Next steps: Enable and use Lambda monitoring To get started using our Lambda monitoring, see the installation and enablement instructions. You can also set up alerts or add your own custom events or attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.47906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "sections": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "We offer in-depth performance <em>monitoring</em> for your <em>serverless</em> <em>AWS</em> <em>Lambda</em> functions. Read on to learn about the feature, how it works, and its requirements. This <em>Lambda</em> <em>monitoring</em> feature is not the same as the <em>Lambda</em> <em>monitoring</em> integration, which only uses CloudWatch data. <em>Serverless</em> <em>Lambda</em>"
      },
      "id": "603eb08b28ccbc8b90eba75c"
    },
    {
      "sections": [
        "Instrument your own functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "title": "Instrument your own functions",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-09T22:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.7229,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument your own <em>functions</em>",
        "sections": "Instrument your own <em>functions</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ": AWSTemplateFormatVersion: &#x27;2010-09-09&#x27; Transform: <em>AWS</em>::<em>Serverless</em>-2016-10-31 Description: And example of a simple instrumented NodeJS <em>Lambda</em> Resources: NewRelicExample: Type: <em>AWS</em>::<em>Serverless</em>::<em>Function</em> Properties: # In this example, we&#x27;re using the SAM CLI to package and deploy our <em>lambda</em>. SAM"
      },
      "id": "605aa8a064441f453b868bb9"
    },
    {
      "sections": [
        "Instrument a Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "title": "Instrument a Lambda function",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate Distributed Tracing into a non-trivial serverless application in our Distributed Tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.18301,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument a <em>Lambda</em> <em>function</em>",
        "sections": "Instrument a <em>Lambda</em> <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " and deploy <em>Lambda</em> functions, <em>AWS</em> CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates"
      },
      "id": "605aa85628ccbcc6d13ae663"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring": [
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-05-22T05:30:54Z",
      "updated_at": "2021-05-09T22:54:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs10.x, nodejs12.x, nodejs14.x Python: python3.7, python3.8 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.08975,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Before enabling <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, make sure you meet the requirements and learn about <em>AWS</em> charges resulting from its use. Recommended <em>AWS</em> <em>Lambda</em> language runtimes NodeJS: nodejs10.x, nodejs12.x, nodejs14.x Python: python3.7, python3.8 Go: provided, provided.al2 Java: java8.al2"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "sections": [
        "Instrument your own functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "title": "Instrument your own functions",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-09T22:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.7229,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument your own <em>functions</em>",
        "sections": "Instrument your own <em>functions</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ": AWSTemplateFormatVersion: &#x27;2010-09-09&#x27; Transform: <em>AWS</em>::<em>Serverless</em>-2016-10-31 Description: And example of a simple instrumented NodeJS <em>Lambda</em> Resources: NewRelicExample: Type: <em>AWS</em>::<em>Serverless</em>::<em>Function</em> Properties: # In this example, we&#x27;re using the SAM CLI to package and deploy our <em>lambda</em>. SAM"
      },
      "id": "605aa8a064441f453b868bb9"
    },
    {
      "sections": [
        "Instrument a Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "title": "Instrument a Lambda function",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-06T03:23:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate Distributed Tracing into a non-trivial serverless application in our Distributed Tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.18301,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument a <em>Lambda</em> <em>function</em>",
        "sections": "Instrument a <em>Lambda</em> <em>function</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " and deploy <em>Lambda</em> functions, <em>AWS</em> CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates"
      },
      "id": "605aa85628ccbcc6d13ae663"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/troubleshooting/troubleshoot-enabling-serverless-monitoring-aws-lambda": [
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-05-22T05:30:54Z",
      "updated_at": "2021-05-09T22:54:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs10.x, nodejs12.x, nodejs14.x Python: python3.7, python3.8 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.16624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Before enabling <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, make sure you meet the requirements and learn about <em>AWS</em> charges resulting from its use. Recommended <em>AWS</em> <em>Lambda</em> language runtimes NodeJS: nodejs10.x, nodejs12.x, nodejs14.x Python: python3.7, python3.8 Go: provided, provided.al2 Java: java8.al2"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "sections": [
        "Instrument your own functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "title": "Instrument your own functions",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-09T22:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.93811,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument your own <em>functions</em>",
        "sections": "Instrument your own <em>functions</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ": AWSTemplateFormatVersion: &#x27;2010-09-09&#x27; Transform: <em>AWS</em>::<em>Serverless</em>-2016-10-31 Description: And example of a simple instrumented NodeJS <em>Lambda</em> Resources: NewRelicExample: Type: <em>AWS</em>::<em>Serverless</em>::<em>Function</em> Properties: # In this example, we&#x27;re using the SAM CLI to package and deploy our <em>lambda</em>. SAM"
      },
      "id": "605aa8a064441f453b868bb9"
    },
    {
      "sections": [
        "Link your AWS and New Relic accounts",
        "AWS permissions details",
        "Recommended method: The newrelic-lambda CLI",
        "Requirements",
        "CLI user AWS permissions details",
        "Integrate with CLI",
        "AWS regions and profiles",
        "Tip",
        "Alternative method",
        "Linking accounts manually",
        "The Infrastructure UI",
        "Manually Configuring the License Key Secret",
        "Troubleshooting",
        "Cannot Use AWS secrets manager",
        "Multiple AWS regions and accounts",
        "Failure to retrieve license key AccessDeniedException"
      ],
      "title": "Link your AWS and New Relic accounts",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Account Linking"
      ],
      "external_id": "8fdeff9ad6419bbcfbb1d35aeb8985cd6b43200c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/account-linking/",
      "published_at": "2021-05-22T13:59:21Z",
      "updated_at": "2021-05-06T02:45:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you link your AWS account to New Relic, you're granting permission to New Relic to create an inventory of your AWS account, and gather CloudWatch metrics for your Lambda functions. Resources in your AWS account then show up as entities in the entity explorer, decorated with config information. AWS permissions details To create this inventory, we need an IAM role that grants these IAM permissions, at a minimum: Resource: \"*\" Action: \"cloudwatch:GetMetricStatistics\" \"cloudwatch:ListMetrics\" \"cloudwatch:GetMetricData\" \"lambda:GetAccountSettings\" \"lambda:ListFunctions\" \"lambda:ListAliases\" \"lambda:ListTags\" \"lambda:ListEventSourceMappings\" Copy By default, we use the AWS Managed Policy ReadOnlyAccess. This allows the Infrastructure integration to see all the resources in your account, rather than just your Lambda functions and CloudWatch metrics. New Relic recommends this default, but we understand that some organizations have a very conservative security posture for third party integrations. A role with the permissions above is sufficient to allow Lambda telemetry collection, though traces that interact with other services may not work well. In this integration step, we'll also store your New Relic License Key in the AWS Secrets Manager service, so that we can send your telemetry to your New Relic account. Recommended method: The newrelic-lambda CLI Requirements To enable serverless monitoring using our Lambda layer, you need the following: AWS CLI v2 installed and configured using aws configure. Python version 3.3 or higher installed. newrelic-lambda CLI, which you can install by running pip3 install newrelic-lambda-cli. A New Relic account. You must be an admin, or have the Infrastructure manager add-on role. A user key. An AWS account with permissions for creating IAM resources, managed secrets, and Lambdas. You also need permissions for creating CloudFormation stacks and S3 buckets. CLI user AWS permissions details The CLI uses the AWS SDK to interact with AWS. The SDK will act using the same default profile as the AWS CLI. This profile needs, at a minimum, the following AWS permissions to run the CLI. Resource: * Actions: \"cloudformation:CreateChangeSet\", \"cloudformation:CreateStack\", \"cloudformation:DescribeStacks\", \"cloudformation:ExecuteChangeSets\", \"iam:AttachRolePolicy\", \"iam:CreateRole\", \"iam:GetRole\", \"iam:PassRole\", \"lambda:AddPermission\", \"lambda:CreateFunction\", \"lambda:GetFunction\", \"logs:DeleteSubscriptionFilter\", \"logs:DescribeSubscriptionFilters\", \"logs:PutSubscriptionFilter\" \"s3:GetObject\" \"serverlessrepo:CreateCloudFormationChangeSet\" \"secretsmanager:CreateSecret\" Resource: \"arn:aws:serverlessrepo:us-east-1:463657938898:applications/NewRelic-log-ingestion\" Actions: \"serverlessrepo:CreateCloudFormationTemplate\" \"serverlessrepo:GetCloudFormationTemplate\" Copy Integrate with CLI When all the requirements are in place, link your AWS account with your New Relic account by running the following command using your user key (replace all the highlighted values): AWS regions and profiles Setting the region To configure your region, use this environment variable to override the default region: export AWS_DEFAULT_REGION=MY_REGION # us-west-2, for example Copy The CLI tool also allows passing this per-command using --aws-region. Setting profiles If you have multiple AWS profiles and don't want to use the default, use AWS_PROFILE environment variable to set another profile name. Ensure the profile is properly configured (including the default region). Example: export AWS_PROFILE=MY_PROFILE Copy newrelic-lambda integrations install --nr-account-id YOUR_NR_ACCOUNT_ID \\ --nr-api-key YOUR_NEW_RELIC_USER_KEY Copy The newrelic-lambda CLI adds your New Relic license key as a secret in [AWS Secret Manager] (https://aws.amazon. com/secrets-manager/) for greater security. Tip Storing the New Relic license key in the AWS Secrets Manager Your New Relic license key identifies and authenticates you to New Relic, allowing us to associate your telemetry with your New Relic account. Each function that sends telemetry needs access to this value, and it needs to be managed securely. The AWS Secrets Manager solves these problems. If your organization prevents you from using AWS Secrets Manager or if you need to store more than one secret per region, see below for an alternative method to set your license key. Alternative method Linking accounts manually The Infrastructure UI The CLI is the least complicated way to link your accounts. Current CLI behavior limits the setup of one managed secret per region. If you need more control or need to integrate more than one New Relic account per region, you can go through the linking process manually. Be sure to enable Lambda when selecting services to be monitored. Don't forget to configure the License Key Secret manually, as described next. Manually Configuring the License Key Secret In addition to linking your accounts, you'll need to configure the license key secret. Download this CloudFormation Template: license-key-secret.yaml Using the AWS CLI, or the AWS CloudFormation Console, install the template, supplying the LicenseKey parameter. You can find your New Relic License Key here. It will be labeled \"INGEST - LICENSE\". Be sure to use the license key for the account you configured with the Infrastructure UI above. AWS CLI example: Be sure to replace YOUR_LICENSE_KEY with the license key you found above. aws cloudformation create-stack --stack-name NewRelicLicenseKeySecret \\ --template-body file://license-key-secret.yaml \\ --parameters 'ParameterKey=LicenseKey,ParameterValue=YOUR_LICENSE_KEY' Copy Troubleshooting Cannot Use AWS secrets manager If your organization does not allow the use of AWS Secrets Manager, the New Relic Lambda Extension will accept a NEW_RELIC_LICENSE_KEY environment variable. Add the --disable-license-key-secret flag from the newrelic-lambda integrations install command. Then set this environment variable to your New Relic license key in your Lambda function configuration. Multiple AWS regions and accounts The newrelic-lambda CLI should be run once per region, with the --aws-region parameter. Use the same linked account name, and the tool will detect that the account link has been created already. The license key secret needs to be created in each region. Similarly, several AWS accounts can be linked to a New Relic account. Give each account a different linked account name. The --aws-profile argument to the CLI tool will select the named profile. The tool uses the same configuration as the AWS CLI. Failure to retrieve license key AccessDeniedException Your lambda code requires the execution role which has permission to read AWS Secrets Manager. If you find a log like the following, add the appropriate permission to the policy of the execution role. In our examples, check out the template.yaml file to see an easy way to grant this permission. Failed to retrieve license key AccessDeniedException: User: <ARN> is not authorized to perform: secretsmanager:GetSecretValue on resource: <ARN> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.62437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Link your <em>AWS</em> and New Relic accounts",
        "sections": "Link your <em>AWS</em> and New Relic accounts",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " store your New Relic License Key in the <em>AWS</em> Secrets Manager service, so that we can send your telemetry to your New Relic account. Recommended method: The newrelic-<em>lambda</em> CLI Requirements To enable <em>serverless</em> <em>monitoring</em> using our <em>Lambda</em> layer, you need the following: <em>AWS</em> CLI v2 installed"
      },
      "id": "605aa856e7b9d2454d76f227"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/ui-data/understand-lambda-data-structure": [
    {
      "sections": [
        "Understand the Lambda monitoring UI",
        "View your data",
        "Important",
        "UI pages",
        "Understand chart data",
        "For more help"
      ],
      "title": "Understand the Lambda monitoring UI",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "UI and data"
      ],
      "external_id": "45a6a881de05bcb4814f7f25f2bfa1632257a7f1",
      "image": "https://docs.newrelic.com/static/17e88e0171bc6b4358292daf4ddf7cf4/c1b63/new-relic-lambda-entities-screenshot_0.png",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/ui-data/understand-lambda-monitoring-ui/",
      "published_at": "2021-05-22T04:39:53Z",
      "updated_at": "2021-03-30T19:47:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Serverless monitoring for AWS Lambda offers in-depth performance monitoring for your Lambda functions. This document explains how to: Find your Lambda data in the UI Understand the UI components Understand your chart data How to create custom charts View your data one.newrelic.com> Explorer > Amazon Web Services > Lambda functions: Click Lambda functions to see charts and details. To view your Lambda data in New Relic: Go to one.newrelic.com, click Explorer. In the left nav under Amazon Web Services, click Lambda functions. For more about our UI, see Intro to New Relic One. Important If you can't find your Lambda data: Ensure you've followed the instructions for enabling Lambda monitoring. Note that this feature is different from our infrastructure monitoring Lambda integration. UI pages Here are descriptions of the UI pages available for our Lambda monitoring: UI page Functionality Summary The Summary page displays charts that give you a quick view into the most important performance data. If available, this will feature data gathered from APM agent instrumentation. CloudWatch metrics The CloudWatch metrics page displays Lambda data that comes from AWS CloudWatch. Charts include: invocation counts, duration, throttles, and error counts. Distributed tracing The Distributed tracing page shows distributed traces that include the monitored Lambda function. For details about this feature, see Distributed tracing. Errors The Errors page displays errors (AwsLambdaInvocationError events). You can filter by error rate, error percentage, or error class. You can drill down into errors and see attributes and, if available, stack traces. Invocations The Invocations page lets you filter your invocations by attribute, and view duration, throughput, external calls, and invocation breakdowns. About invocation breakdowns: Some invocations will generate a breakdown if distributed tracing is enabled during instrumentation. Breakdowns are sampled; approximately 10% of invocations generate a breakdown. This sampling rate may be higher, depending on upstream sampling decisions. Logs The Logs page displays recent log messages from your Lambda function. For details about this feature, see Logs. Understand chart data Lambda data charts are generated by running NRQL queries of Lambda-related event data. Reasons to view a chart's NRQL query include: To better understand what a chart is displaying To get ideas on how to create a custom NRQL query and chart Related documentation: Learn how to view a chart's query. Learn about Lambda data storage and structure. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.61522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand the <em>Lambda</em> <em>monitoring</em> <em>UI</em>",
        "sections": "Understand the <em>Lambda</em> <em>monitoring</em> <em>UI</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "<em>Serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> offers in-depth performance <em>monitoring</em> for your <em>Lambda</em> functions. This document explains how to: Find your <em>Lambda</em> <em>data</em> in the <em>UI</em> Understand the <em>UI</em> components Understand your chart <em>data</em> How to create custom charts View your <em>data</em> one.newrelic.com&gt; Explorer"
      },
      "id": "603eb10f196a67c65da83da2"
    },
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-05-22T05:30:54Z",
      "updated_at": "2021-05-09T22:54:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs10.x, nodejs12.x, nodejs14.x Python: python3.7, python3.8 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.16624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility <em>and</em> requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility <em>and</em> requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ". If an <em>AWS</em> SDK is not used, <em>Lambda</em> <em>data</em> will appear as external service calls in the <em>UI</em>, with minimal detail. In other words, we rely on the <em>AWS</em> SDK to facilitate instrumentation of your <em>function</em>. For the following services, only the &quot;target&quot; (<em>Lambda</em> <em>function</em> name, SNS topic ARN, DynamoDB table name, etc"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "sections": [
        "Instrument your own functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "title": "Instrument your own functions",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-09T22:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.69171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument your own <em>functions</em>",
        "sections": "<em>Lambda</em> console <em>UI</em> configuration",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ": AWSTemplateFormatVersion: &#x27;2010-09-09&#x27; Transform: <em>AWS</em>::<em>Serverless</em>-2016-10-31 Description: And example of a simple instrumented NodeJS <em>Lambda</em> Resources: NewRelicExample: Type: <em>AWS</em>::<em>Serverless</em>::<em>Function</em> Properties: # In this example, we&#x27;re using the SAM CLI to package and deploy our <em>lambda</em>. SAM"
      },
      "id": "605aa8a064441f453b868bb9"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/ui-data/understand-lambda-monitoring-ui": [
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-05-22T05:30:54Z",
      "updated_at": "2021-05-09T22:54:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs10.x, nodejs12.x, nodejs14.x Python: python3.7, python3.8 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.16624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility <em>and</em> requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility <em>and</em> requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ". If an <em>AWS</em> SDK is not used, <em>Lambda</em> <em>data</em> will appear as external service calls in the <em>UI</em>, with minimal detail. In other words, we rely on the <em>AWS</em> SDK to facilitate instrumentation of your <em>function</em>. For the following services, only the &quot;target&quot; (<em>Lambda</em> <em>function</em> name, SNS topic ARN, DynamoDB table name, etc"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "sections": [
        "Understand the Lambda data structure",
        "Sources of Lambda data",
        "Event definitions and attributes"
      ],
      "title": "Understand the Lambda data structure",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "UI and data"
      ],
      "external_id": "07406ff52f251eb6195f76d730e30615828cb734",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/ui-data/understand-lambda-data-structure/",
      "published_at": "2021-05-22T04:11:30Z",
      "updated_at": "2021-03-16T18:11:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our serverless monitoring for AWS Lambda offers in-depth performance monitoring for your Lambda functions. This document will explain the source, structure, and storage of your Lambda data. Sources of Lambda data Our Lambda monitoring data comes from these two sources: Our APM agent instrumentation (or similar customer-created instrumentation) AWS CloudWatch metrics For details on how this data is configured and how it flows to New Relic, see the enablement procedures. The data displayed in the UI is a combination of these data sources. For example, the Overview page displays data reported by instrumentation, while the Metrics page displays CloudWatch data. Event definitions and attributes Lambda data is stored in our database (NRDB) as events (data objects with associated attributes). Lambda data is attached to the following event types. Select an event name to see its attributes. AwsLambdaInvocation event: Captures overall timing and associated metadata. A Lambda invocation generates a single AwsLambdaInvocation event. AwsLambdaInvocationError event: If an error occurs during a Lambda, this event will be generated. Span: This includes detail about a segment of a Lambda function. Spans are used for distributed tracing. Distributed tracing relies on data sampling; 10% of invocations are sampled to generate spans. Custom event types: With some agent APIs, custom events can be created and associated with a particular Lambda invocation, and then queried with NRQL. For more about limits on event storage, see Access and requirements.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.01237,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand the <em>Lambda</em> <em>data</em> structure",
        "sections": "Understand the <em>Lambda</em> <em>data</em> structure",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Our <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> offers in-depth performance <em>monitoring</em> for your <em>Lambda</em> functions. This document will explain the source, structure, and storage of your <em>Lambda</em> <em>data</em>. Sources of <em>Lambda</em> <em>data</em> Our <em>Lambda</em> <em>monitoring</em> <em>data</em> comes from these two sources: Our APM agent instrumentation"
      },
      "id": "603eb0c8e7b9d24b202a0820"
    },
    {
      "sections": [
        "Instrument your own functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "title": "Instrument your own functions",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring",
        "Instrumentation"
      ],
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "published_at": "2021-05-22T05:30:02Z",
      "updated_at": "2021-05-09T22:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.69171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrument your own <em>functions</em>",
        "sections": "<em>Lambda</em> console <em>UI</em> configuration",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": ": AWSTemplateFormatVersion: &#x27;2010-09-09&#x27; Transform: <em>AWS</em>::<em>Serverless</em>-2016-10-31 Description: And example of a simple instrumented NodeJS <em>Lambda</em> Resources: NewRelicExample: Type: <em>AWS</em>::<em>Serverless</em>::<em>Function</em> Properties: # In this example, we&#x27;re using the SAM CLI to package and deploy our <em>lambda</em>. SAM"
      },
      "id": "605aa8a064441f453b868bb9"
    }
  ],
  "/docs/serverless-function-monitoring/index": [
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-05-22T05:30:54Z",
      "updated_at": "2021-05-09T22:54:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs10.x, nodejs12.x, nodejs14.x Python: python3.7, python3.8 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 516.9472,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements of AWS Lambda <em>monitoring</em>",
        "sections": "Compatibility and requirements of AWS Lambda <em>monitoring</em>",
        "tags": "<em>Serverless</em> function <em>monitoring</em>",
        "body": "Before enabling <em>serverless</em> <em>monitoring</em> for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs10.x, nodejs12.x, nodejs14.x Python: python3.7, python3.8 Go: provided, provided.al2 Java: java8.al2"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "sections": [
        "Configure serverless monitoring for AWS Lambda",
        "Set up alerts",
        "Add custom events"
      ],
      "title": "Configure serverless monitoring for AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Enable Lambda monitoring"
      ],
      "external_id": "7ccc0cbc8f96ad38d90cfa4e6c12b53f8ebfcbb4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/configure-serverless-monitoring-aws-lambda/",
      "published_at": "2021-05-22T14:00:20Z",
      "updated_at": "2021-03-16T18:10:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up serverless monitoring for AWS Lambda, you can add additional configuration to fine-tune your data. Set up alerts Our alerts let you get notifications on anything you can monitor with New Relic, including APM metrics, key transactions, NRQL queries, and more. For details about setting up alerts on Lambda functions, see monitoring for AWS Lambda: Configuring alerts Add custom events Besides the data we provide by default, you can also set up your own events or attributes. For details about these language-specific settings, see Configuring custom attributes and events in AWS Lambda.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.99954,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>serverless</em> <em>monitoring</em> for AWS Lambda",
        "sections": "Configure <em>serverless</em> <em>monitoring</em> for AWS Lambda",
        "tags": "<em>Serverless</em> function <em>monitoring</em>",
        "body": "After you set up <em>serverless</em> <em>monitoring</em> for AWS Lambda, you can add additional configuration to fine-tune your data. Set up alerts Our alerts let you get notifications on anything you can <em>monitor</em> with New Relic, including APM metrics, key transactions, NRQL queries, and more. For details about"
      },
      "id": "603e94df196a676d7ea83ddc"
    },
    {
      "sections": [
        "Monitoring AWS Lambda with Serverless monitoring",
        "Tip",
        "Why it matters",
        "Access and requirements",
        "Next steps: Enable and use Lambda monitoring"
      ],
      "title": "Monitoring AWS Lambda with Serverless monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "5d1d86ec786398b3190ed1a6e152373e0547dc57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring/",
      "published_at": "2021-05-22T04:09:17Z",
      "updated_at": "2021-03-30T19:33:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer in-depth performance monitoring for your serverless AWS Lambda functions. Read on to learn about the feature, how it works, and its requirements. This Lambda monitoring feature is not the same as the Lambda monitoring integration, which only uses CloudWatch data. Serverless Lambda monitoring is more extensive and uses both CloudWatch data and code-level instrumentation to deliver more in-depth monitoring. Tip To use serverless monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters Do you need to rapidly instrument monitoring and observability to your serverless functions without resorting to code changes? Our Lambda layer provides unified visibility into the most detailed behaviors of your Lambda functions so you can understand what's going on in your serverless applications. Use all this information to troubleshoot your systems and optimize your functions so they can function faster and deliver with confidence on serverless architectures. Spend less time instrumenting, and more time building. Lambda monitoring gives you: Every invocation of your Lambda functions, including performance data like detailed duration, cold starts, exceptions, and tracebacks. AWS Lambda event source information, which provides context and attributes about events that triggered each AWS Lambda invocation, such as API Gateway, ALB SNS, SQS, DynamoDB, and more. Visibility into your entire ecosystem with distributed tracing: see the path of requests that led to your Lambda, and see Lambda spans in your other distributed traces. Logs in context, which provides full invocation and function level logs right along side the metrics, attributes, and trace data. Inventoried tags and metadata. We retrieve information from your AWS entities, giving you the ability to filter and facet down to the team, or specific metadata attributes on the function configuration or invocation itself. Easy ability to query your data with an automatic facet builder, which instantly facets your dashboards and charts by attribute or function to explore custom data, without having to write queries. Lambda data is displayed in its own dedicated UI in New Relic One. Access and requirements See Compatibility and requirements of AWS Lambda monitoring. Next steps: Enable and use Lambda monitoring To get started using our Lambda monitoring, see the installation and enablement instructions. You can also set up alerts or add your own custom events or attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 384.82397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitoring</em> AWS Lambda with <em>Serverless</em> <em>monitoring</em>",
        "sections": "<em>Monitoring</em> AWS Lambda with <em>Serverless</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> function <em>monitoring</em>",
        "body": "We offer in-depth performance <em>monitoring</em> for your <em>serverless</em> AWS Lambda functions. Read on to learn about the feature, how it works, and its requirements. This Lambda <em>monitoring</em> feature is not the same as the Lambda <em>monitoring</em> integration, which only uses CloudWatch data. <em>Serverless</em> Lambda"
      },
      "id": "603eb08b28ccbc8b90eba75c"
    }
  ],
  "/docs/style-guide/article-templates/agent-api-guide-template": [
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "ba7c99eb79d6fa7ad574db5768a742a4d2084a41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-05-21T16:34:37Z",
      "updated_at": "2021-05-10T03:34:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.0473,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting docs <em>guide</em>",
        "sections": "Troubleshooting docs <em>guide</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ", this is the how of the troubleshooting doc. Provide an ordered list of steps to <em>guide</em> users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader"
      },
      "id": "6043f591196a675446960f74"
    },
    {
      "sections": [
        "Add to data dictionary",
        "Data dictionary structure",
        "Add a new data type",
        "Add attributes",
        "Attribute style guidelines",
        "Using units of measurement"
      ],
      "title": "Add to data dictionary",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "32b8cab502883cc3443e54c86a0bd4021cc5a10f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/data-dictionary-style-guidelines/",
      "published_at": "2021-05-21T16:33:39Z",
      "updated_at": "2021-04-28T03:20:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use the data dictionary to provide information about data types (for example, Transaction, Metric, Log) and attached attributes. This is exposed in the New Relic query experience, on hovering over the data types and attributes. And we also expose the dictionary to the public. This doc contains info on how to add data to the dictionary. Note that currently we don't have infrastructure integration data in the dictionary. We also have very few attributes for the Metric data type, just a few basic default ones, despite there being many potential attributes attached to that data type depending on what the data source is. Data dictionary structure The data in the data dictionary is structured like this: Data types: sometimes called \"events\" for historical reasons, these are the NRDB data objects, like Transaction, Metric, Log, Span, etc. Attributes: these are key:value pairs attached to data types. One attribute can have multiple data types listed for it. For example, appName is on multiple data types. Data source: The New Relic product from which the data originates. With the current implementation, a data type must have a single data source assigned. This isn't ideal, as theoretically a data type can come from multiple sources. Add a new data type To add a new data type: Make a new folder in this directory, alongside the other directories: /docs-website/tree/develop/src/data-dictionary/events Copy Duplicate a data type file (for example, this Metric data type), place it in the new folder, and fill it out with the new info. For how to add attributes on a new data type, keep reading. Add attributes To add attributes: Our goal is to avoid adding redundant attributes entries, so you should first check to see if there's an existing attribute that has the same name and same general definition as the one you're trying to add. If it exists, edit that file to include the new data type (under events:). If an existing attribute is fairly close in definition but not exact, try to edit the definition so it works for all associated data types. If there is no existing attribute, create a new one. The easiest way is to copy an existing attribute file, edit all relevant fields to be accurate, and place it in the folder of the data type it's attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see Style. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute style guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes on this: Feel free to use sentence fragments. Feel free to edit definitions submitted from internal teams as sometimes their definitions will be overly long or have unneeded links. Some attributes are only present in some situations (for example, when a specific APM agent is used, or when a specific config option is true). If it's easy to include that detail in the short description, do so, but it's not required. Write so it reads well as plain text. Details on this: Note that the docs site data dictionary has our usual docs styles available, but the query UI definitions have no styling available. This means that you should write definitions so that they are understandable without any styling, as plain text. You can often avoid any need for styling (for example, data types like Transaction are easy to understand as plain text, as are most phrasings that use attribute names or values. When plain text makes something too ambiguous and you need some styling, use single quotes to indicate attributes or values (for example, a definition like: Reported when 'category' is 'http'). We should avoid links because those aren't visible in the query UI; the query UI only displays plain text. However, every attribute entry in the query UI does display a link 'See attribute in docs' that links to the docs site entry. This means that we can use links provided that they will display in an easy to understand way in the query UI. For example, here's an example of an attribute that would read clearly in plain text despite not having a link. We should avoid using a link format like \"For more information, see Create an alert condition\", because it wouldn't read well in plain text, and would choose something like \"For more information, see our alert condition docs.\" Using units of measurement Attribute entries have an optional unit of measurement field in the front matter. For example, here the front matter for an attribute with a percent unit of measurement: --- name: cpuPercent type: attribute units: percentage (%) events: - ProcessSample --- Copy What unit of measurement to select for an attribute is sometimes obvious, like if the attribute value is measured in milliseconds (units: milliseconds (ms)) or seconds (units: seconds (s)) or a percentage (units: percentage (%)). We also have several units of measurement that are not obvious, like count, enum, rate, and ID. (Technically, these aren't actually \"units of measurement\" and are more just conceptual data types but we're doing it this way as a workaround so you can ignore the fact that units of measurement isn't actually accurate.) The main reason we want to specify this information is that this will control what kinds of queries or charts can be created or auto-suggested by New Relic. For example, the New Relic UI wouldn't want to auto-suggest a chart graphing the average of ID values because that wouldn't make any sense. So attributes with accurate units, such as data types, will help product provide more practical help/suggestions to customers in future. Here are some tips for the non-obvious unit types: count: This is a count of something, though not a count of time-based units. For a number to be a count, it must (a) only be capable of increasing during a given time/sampling period, and (b) have a theoretically uncapped range. This wouldn't be used for a count of time units; if it was a count of seconds, for example, you would just use 'seconds' as the unit of measurement. A couple of examples of a count: databaseCallCount threadConcurrency enum: enum is short for enumerated list. In other words, it is a specific range of numbers that represent other non-numeric elements. For example, an attribute that had HTTP error codes (404, 505, etc.) as possible values would be an enum. A range of numbers that represent color codes would be another example of an enum. (Theoretically, an enum can represent lists without numeric values but we have no need to categorize strings so we only care about numeric-value lists.) Example: httpResponsecode. rate: Use this for any rate (for example, count per second). These are typically for averaged rates over small units of time, like second or millisecond. We previously have used the unit of time for these attributes (for example, using seconds as the unit of measurement for a count per second rate), but now we want to use rate for these. This is necessary because the types of displays used for rates would be different than the types of displays used for a simpler duration/count measurement. Example: MySQL integration attribute db.innodb.dataReadBytesPerSecond, which has the definition \"Rate at which data is read from InnoDB tables in bytes per second.\" id: Use ID for any identification number attribute. Example: appId.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 278.75137,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Attribute <em>style</em> <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ". For more on that, see <em>Style</em>. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute <em>style</em> guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes"
      },
      "id": "6050b4da64441f84f1532199"
    },
    {
      "sections": [
        "Basic doc template",
        "Section example",
        "Code example",
        "List example",
        "Table example"
      ],
      "title": "Basic doc template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "8949f5c550b7fcab6ec76ca68fa8dd5ec2ed188f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/basic-doc-template/",
      "published_at": "2021-05-21T16:32:47Z",
      "updated_at": "2021-04-05T08:04:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the formatting tips in this template to organize the docs you create on the Docs site. Then replace the template information with your own text, lists, and tables as needed. Before you create sections, start your doc with a brief introduction, usually no more than a paragraph, that helps readers understand what your doc will cover. Your introduction (and the structure of your doc) should help readers understand within ten seconds whether they are in the right place. Section example Begin each section with a meaningful H2 title. The Docs site uses these to generate the contents, which appears automatically in the left navigation. If you want to include a screenshot with the section, provide a permalink for the Docs team to create the image for you. Due to security requirements, the Docs team manages all images on the Docs site. Code example def article_url(category, article, options={}) url_for(options.reverse_merge( :controller => 'articles';, :action => 'show', :category => category, :article => article )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add require('newrelic'); as the first line of your app's main module. Use the command npm install newrelic --save for each application you want to monitor. For unordered lists, use bullets (ul in HTML or * in Markdown). For example: Black White For complex lists, consider using collapsers. Table example Tables help organize detailed lists so the information is easier to skim. Tables are easier to manage in HTML. For exammple: <table> <thead> <tr> <th width={200}> **Item** </th> <th> **Requirements** </th> </tr> </thead> <tbody> <tr> <td> Some thing </td> <td> More detailed information about it </td> </tr> <tr> <td> Another thing </td> <td> More detailed information about another thing </td> </tr> </tbody> </table> Copy Tables created in Markdown use three or more hyphens --- to create each column’s header, and pipes | to separate each column. For example: | Item | Requirements ------------ | ------------ | Some thing | More detailed information about it | Another thing | More detailed information about another thing Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.52467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Basic doc <em>template</em>",
        "sections": "Basic doc <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " <em>article</em>_url(category, <em>article</em>, options={}) url_for(options.reverse_merge( :controller =&gt; &#x27;articles&#x27;;, :action =&gt; &#x27;show&#x27;, :category =&gt; category, :<em>article</em> =&gt; <em>article</em> )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add"
      },
      "id": "6042212b64441f49134e886d"
    }
  ],
  "/docs/style-guide/article-templates/agent-release-notes-template-123": [
    {
      "sections": [
        "Guide to using the Java agent API",
        "Important",
        "Use the API",
        "Transactions",
        "Instrument asynchronous work",
        "Distributed tracing API usage",
        "Caution",
        "Cross application tracing (CAT) API usage",
        "Obtain references to New Relic API classes",
        "Additional API functionality",
        "Additional API usage examples"
      ],
      "title": "Guide to using the Java agent API ",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "API guides"
      ],
      "external_id": "d2e891456fe10b28930afad273f760ef9f06a85a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/java-agent/api-guides/guide-using-java-agent-api/",
      "published_at": "2021-05-21T16:52:51Z",
      "updated_at": "2021-05-21T16:52:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Java agent API lets you control, customize, and extend the functionality of the APM Java agent. This API consists of: Static methods on the com.newrelic.api.agent.NewRelic class A @Trace annotation for implementing custom instrumentation A hierarchy of API objects providing additional functionality Use this API to set up custom instrumentation of your Java app and collect more in-depth data. For detailed information about this API, see the complete Javadoc on GitHub. Another way to set up custom instrumentation is to use XML instrumentation. The XML option is simpler and does not require modification of your app code, but it lacks the complete functionality of the Java agent API. Important For best results when using the API, ensure that you have the latest Java agent release. Several APIs used in the examples require Java agent 6.4.0 or higher. For all available New Relic APIs, see Intro to APIs. Use the API To access the API class, add newrelic-api.jar to your application class path. The jar is in the New Relic Java agent's installation zip file. You can call the API when the Java agent is not running. The API methods are just stubs; the implementation is added when the Java agent loads the class. Transactions To instrument Transactions in your application, use the following APIs. If you want to... Use this Create a Transaction when New Relic does not create one automatically @Trace(dispatcher = true) on the method that encompasses the work to be reported. When this annotation is used on a method within the context of an existing transaction, this will not start a new transaction, but rather include the method in the existing transaction. Capture the duration of a method that New Relic does not automatically trace @Trace() on the method you want to time. Set the name of the current Transaction NewRelic.setTransactionName(...) Start the timer for the response time of the current Transaction and to cause a Transaction you create to be reported as a Web transaction, rather than as an Other transaction NewRelic.setRequestAndReponse(...) Add custom attributes to Transactions and TransactionEvents NewRelic.addCustomParameter(...) Prevent a Transaction from being reported to New Relic NewRelic.ignoreTransaction() Exclude a Transaction when calculating your app's Apdex score NewRelic.ignoreApdex() Instrument asynchronous work For detailed information, see Java agent API for asynchronous applications. If you want to... Use this Trace an asynchronous method if it is linked to an existing Transaction... @Trace(async = true) Link the Transaction associated with the Token on the current thread... Token.link() or Token.linkAndExpire() Expire a Token associated with the current Transaction... Token.expire() Stop timing a Segment and have it report as part of its parent Transaction Segment.end() Stop timing a Segment and not have it report as part of its parent Transaction Segment.ignore() Distributed tracing API usage These APIs require distributed tracing to be enabled. See Java agent configuration for all distributed tracing config options. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. To see these APIs in action, see Using Java agent distributing tracing API with Kafka. Important With agent version 6.4.0, the following distributed tracing APIs were introduced, with the exception of addCustomAttribute(), which was introduced in 6.1.0. We highly recommended using these APIs instead of the deprecated ones. If you want to... Use this Create and insert distributed tracing headers into a Headers data structure. This API will insert both newrelic and W3C Trace Context headers (traceparent & tracestate), unless the agent is explicitly configured to exclude newrelic headers. Transaction.insertDistributedTraceHeaders(Headers) Copy For more on obtaining references to the current transaction and other API classes, see Obtain references. Accept the distributed tracing headers sent from the calling service and link these services together in a distributed trace. Transaction.acceptDistributedTraceHeaders(TransportType, Headers) Copy For more on obtaining references to the current transaction and other API classes, see Obtain references. The type-specific headers of an inbound or outbound message. For a provided implementation of Headers use ConcurrentHashMapHeaders. Headers Copy A utility class that provides enum constants for defining the transport type when accepting distributed tracing headers. TransportType Copy Add custom attributes to SpanEvents in distributed traces NewRelic.getAgent().getTracedMethod().addCustomAttribute(...) Caution With agent version 6.4.0, the following distributed tracing APIs have been deprecated and replaced by the APIs in the above table. It's highly recommended to upgrade the agent and use the new APIs instead of these deprecated ones. If you want to... Use this Create a payload to be sent to a called service. Transaction.createDistributedTracePayload() Copy For more on obtaining references to the current transaction and other API classes, see Obtain references. Caution API deprecated as of agent 6.4.0 Accept a payload sent from the first service; this will link these services together in a trace. Transaction.acceptDistributedTracePayload(...) Copy For more on obtaining references to the current transaction and other API classes, see Obtain references. Caution API deprecated as of agent 6.4.0 Payload used to connect services. The text() call returns a JSON string representation of the payload. DistributedTracePayload.text() Caution API deprecated as of agent 6.4.0 Payload used to connect services. The httpSafe() call returns a base64 encoded JSON string representation of the payload. DistributedTracePayload.httpSafe() Caution API deprecated as of agent 6.4.0 Cross application tracing (CAT) API usage To track external calls and add cross application tracing, use the following APIs: If you want to... Use this Trace across a custom transport channel that New Relic does not support by default, such as a proprietary RPC transport Transaction.getRequestMetadata(), .processRequestMetadata(...), .getResponseMetadata(), .processResponseMetadata(...) Copy Also refer to the information in this document about using Transaction to obtain references to New Relic API classes. View or change the metric name or a rollup metric name of a TracedMethod (A rollup metric name, such as OtherTransaction/all, is not scoped to a specific transaction. It represents all background transactions.) TracedMethod.getMetricName(), .setMetricName(...), .setRollupMetricName(...) Copy Also refer to the information in this document about using TracedMethod to obtain references to New Relic API classes. Report a call to an external HTTP service, database server, message queue, or other external resource that is being traced using the Java agent API's @Trace annotation TracedMethod.reportAsExternal(...) passing arguments constructed using ExternalParameters builder. Also refer to the information in this document about using TracedMethod to obtain references to New Relic API classes. Enable and add cross application tracing when communicating with an external HTTP or JMS service that is instrumented by New Relic TracedMethod.addOutboundRequestHeaders(...) along with TracedMethod.reportAsExternal(...) Also refer to the information in this document about using TracedMethod to obtain references to New Relic API classes. Add timing for an application server or dispatcher that is not supported automatically Transaction.setRequest(...), Transaction.setResponse(...), or NewRelic.setRequestAndResponse(...), and Transaction.markResponseSent() Also refer to the information in this document about using Transaction to obtain references to New Relic API classes. Obtain references to New Relic API classes Other tasks require the New Relic Agent object. The Agent object exposes multiple objects that give you the following functionality: If you want to... Use this Get a reference to the current Transaction NewRelic.getAgent().getTransaction() Get a Token to link asynchronous work NewRelic.getAgent().getTransaction().getToken() Copy Start and get a reference to a Segment NewRelic.getAgent().getTransaction().startSegment() Copy Get a reference to the method currently being traced NewRelic.getAgent().getTracedMethod() Get a reference to the Agent logger NewRelic.getAgent().getLogger() Get a reference to the Agent configuration NewRelic.getAgent().getConfig() Get a reference to an aggregator for custom metrics NewRelic.getAgent().getAggregator() Get a reference to Insights in order to record custom events NewRelic.getAgent().getInsights() Additional API functionality The following APIs provide additional functionality, such as setting app server info, reporting errors, adding page load timing information, recording custom metrics, and sending custom events to Insights. If you want to... Use this Explicitly set port, name, and version information for an application server or dispatcher and the instance name for a JVM NewRelic.setAppServerPort(...), .setServerInfo(...), and .setInstanceName(...) Copy Report an error that New Relic does not report automatically NewRelic.noticeError(...) When inside a transaction, the last call to noticeError wins. Only 1 error will be reported per transaction. Add browser page load timing for Transactions that New Relic does not add to the header automatically NewRelic.getBrowserTimingHeader(), .getBrowserTimingFooter(), .setUserName(String name), .setAccountName(String name), and .setProductName(String name) Copy Create and accumulate custom metrics NewRelic.recordMetric(...), .recordResponseTimeMetric(...), or .incrementCounter(...) Record custom events Insights.recordCustomEvent(...) Or, use NewRelic.addCustomParameter(...) to add custom attributes to the New Relic-defined TransactionEvent type. Also refer to the information in this document about using Insights to obtain references to New Relic API classes. Additional API usage examples For detailed code examples about using the APIs, see New Relic's documentation about custom instrumentation for: External calls, cross application traces, messaging, datastores, and web frameworks Cross application tracing and external datastore calls Apps using custom instrumentation with annotation Custom framework instrumentation API Preventing unwanted instrumentation Inserting custom attributes Inserting custom events Collecting custom metrics",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2.1407132,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "id": "6043c7f8e7b9d2dd935799df",
      "highlight": {}
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-05-21T16:41:03Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2.1397452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "id": "604220b2e7b9d2f2402a07fa",
      "highlight": {}
    },
    {
      "sections": [
        "Insights Dashboard API",
        "Important",
        "Requirements",
        "Overview",
        "Example use cases",
        "Account and data security",
        "Use the API Explorer",
        "View Dashboard API video",
        "Use API endpoints",
        "Dashboard API schema",
        "Caution",
        "Example dashboard schema",
        "Dashboard data definitions",
        "Widget data definitions",
        "Supported visualizations"
      ],
      "title": "Insights Dashboard API",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Insights API"
      ],
      "external_id": "71a0104d88a3a8859513802e853850d8b0456606",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/insights-apis/insights-dashboard-api/",
      "published_at": "2021-05-21T16:20:56Z",
      "updated_at": "2021-05-21T16:20:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Insights Dashboard API allows you to create and manage dashboards. Important Note that this API is deprecated. We have a migration guide to help you transition to using the new API. For instructions on using the UI, see Dashboards. Requirements If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Overview The Insights Dashboard API allows you to list, create, read, update, and delete new or existing dashboards. New Relic's API Explorer includes the cURL request format, available parameters, response status codes, and JSON response structure for available API calls. Example use cases The Insights Dashboard API is a flexible solution for many different use cases. Here are a few examples of how you can leverage the Dashboard API to solve problems: Automatically create dashboards for new teams or services pre-populated with standard organization metrics and charts. Use the API to view dashboard schemas, and save them in a central repository for source control and backups. Create widget and dashboard templates to allow teams to self-service. For detailed examples and use cases, see this New Relic blog post. Account and data security The Dashboard API includes safeguards to help ensure account and data security. Requirements Comments User key and permissions Required: This API requires a user key. You cannot use your account-level REST API key to manage dashboards. Cross-account widgets You can view cross-account widgets on a dashboard by using the Insights or New Relic One dashboards UI. However, the ability to view cross-account widgets when using the Dashboard API has these restrictions: To view the list of widgets on a specific dashboard with the Dashboard API, you must use the SHOW endpoint. To view a widget in the API payload, the widget's account ID must be the same as the account ID for the payload. If the account ID is not the same, the widget's details will not be listed. Instead, the widget's payload will show: \"visualization\": \"inaccessible\" Copy Use the API Explorer To view the Dashboard API options in the API Explorer: Log in to your New Relic account. Go to rpm.newrelic.com/api/explore. From the API Explorer's Select an account and key dropdown, select a user key. Select Dashboards, then select the API function. To use API functions with existing dashboards, include the dashboard id. To find the dashboard id, select the LIST endpoint, and apply filtering options. View Dashboard API video Follow along with this step-by-step tutorial to learn how to find your API keys, create new dashboards, view and update existing dashboards via the REST API. For a step-by-step guide to using the New Relic API Explorer to manage Insights dashboards, watch this video (approximately 6 minutes). Or, go directly to the full online course about New Relic APIs. Use API endpoints The API supports the following functions for Insights dashboards only. The API does not support these functions for data apps (collections of linked dashboards). API endpoints Comments CREATE POST /v2/dashboards Create a new dashboard. The API permits a maximum of 300 widgets when creating or updating a dashboard. Attempting to POST more than 300 widgets will produce an error. To add more widgets to the dashboard, use the Insights UI. UPDATE PUT /v2/dashboards/:id: Update an existing dashboard for the dashboard id. The API permits a maximum of 300 widgets when creating or updating a dashboard. Attempting to PUT more than 300 widgets will produce an error. To add more or edit existing widgets on the dashboard, use the Insights UI. SHOW GET /v2/dashboards/:id: View an existing dashboard and all accessible widgets for the dashboard id. To help ensure data security, the SHOW function returns only the dashboard widgets that the user has permission to view. If a dashboard includes widgets that the user is not authorized to view, the API will provide a placeholder with the visualization field set to inaccessible. LIST GET /v2/dashboards?page=:page:&per_page=:count: View a paginated list of dashboards. The list shows filterable dashboard metadata only; no widgets will appear in the list. Search options include: filter[title] as substring search filter[category] (all / favorites / mine} filter[created_after] as ISO date filter[created_before] as ISO date filter[updated_after] as ISO date filter[updated_before] as ISO date Sort options include: name recently_viewed last_edited If no sort option is provided, results will be ordered by id. Pagination options include the page and per_page fields. The per_page field controls the number of results per page with a default and maximum of 100 results. The response will include a pagination Link header, which provides next page and last page links. DELETE DELETE /v2/dashboards/:id: Delete an existing dashboard indicated by the dashboard id. Dashboard API schema JSON is the only supported format. When using API functions, be sure to add .json to the end of the request URL, as shown in the API Explorer. Important Widgets have a size limit of 3x3 (height and width may not exceed 3). Caution The Dashboard API 3-column restriction also applies to the dashboards you upload to New Relic One dashboards. If you update a dashboard with a different layout using the API, the uploaded dashboard will revert to the 3-column configuration. Example dashboard schema { \"dashboard\": { \"metadata\": { \"version\": 1 }, \"title\": \"API Widget Sample\", \"icon\":\"none|archive|bar-chart|line-chart|bullseye|user|usd|money|thumbs-up|thumbs-down|cloud|bell|bullhorn|comments-o|envelope|globe|shopping-cart|sitemap|clock-o|crosshairs|rocket|users|mobile|tablet|adjust|dashboard|flag|flask|road|bolt|cog|leaf|magic|puzzle-piece|bug|fire|legal|trophy|pie-chart|sliders|paper-plane|life-ring|heart\", \"grid_column_count\": 3|12, \"visibility\": \"owner|all\", \"editable\": \"read_only|editable_by_owner|editable_by_all\", \"filter\": { \"event_types\": [ \"Transaction\" ], \"attributes\": [ \"appName\" ] }, \"widgets\": [ { \"visualization\": \"billboard|gauge|billboard_comparison\", \"account_id\": 12345, \"data\": [ { \"nrql\": \"SELECT count(*) from Transaction since 5 minutes ago\" } ], \"presentation\": { \"title\": \"Threshold Event Chart\", \"notes\": null, \"threshold\": { \"red\": 18000000, \"yellow\": 8000000 } }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 1, \"column\": 1 } }, { \"visualization\": \"facet_bar_chart|faceted_line_chart|facet_pie_chart|facet_table|faceted_area_chart|heatmap\", \"account_id\": 12345, \"data\": [ { \"nrql\": \"SELECT count(*) from Transaction since 5 minutes ago facet appName\" } ], \"presentation\": { \"title\": \"Facet Chart\", \"notes\": null, \"drilldown_dashboard_id\": 64 }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 1, \"column\": 2 } }, { \"visualization\": \"attribute_sheet|single_event|histogram|funnel|raw_json|event_feed|event_table|uniques_list|line_chart|comparison_line_chart\", \"account_id\": 12345, \"data\": [ { \"nrql\": \"SELECT latest(appName), latest(duration) from Transaction since 5 minutes ago\" } ], \"presentation\": { \"title\": \"Simple Event Chart\", \"notes\": null }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 1, \"column\": 3 } }, { \"visualization\": \"markdown\", \"account_id\": 12345, \"data\": [ { \"source\": \"# Dashboard Note\\n\\n[link goes here](https://www.newrelic.com)\" } ], \"presentation\": { \"title\": \"\", \"notes\": null }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 2, \"column\": 1 } }, { \"visualization\": \"metric_line_chart\", \"account_id\": 12345, \"data\": [ { \"duration\": 1800000, \"end_time\": null, \"entity_ids\": [ 238575 ], \"metrics\": [ { \"name\": \"Apdex\", \"units\": null, \"scope\": \"\", \"values\": [ \"score\" ] } ], \"order_by\": \"score\", \"limit\": 10 } ], \"presentation\": { \"title\": \"Metric Line Chart\", \"notes\": null }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 2, \"column\": 2 } }, ] } } Copy Dashboard data definitions For examples of these data elements being used in a JSON call, see the Dashboard API schema. Dashboard data element Description metadata Object Specifies the version of the dashboard schema. The version must be 1. icon String Name of an icon from the Insights icon library. grid_column_count Integer Specifies the number of columns in the grid layout. title String User-supplied title of the dashboard. filter Object Specifies configuration of the smart filter on the dashboard. visibility String Specifies who can view the dashboard in the Insights UI and the API. editable String Specifies who can edit the dashboard in the Insights UI and the API. widgets Array Array of widget data element objects. Widget data definitions For examples of these data elements being used in a JSON call, see the Dashboard API schema. Widget data element Description visualization String What sort of visualization to place in the widget; for example, billboard, line_chart, area chart, etc. data Array Array of objects with chart-specific information needed to query necessary data. Currently only one data object is supported. account_id Long Source account to fetch data from, if not the current account. presentation Object Object with chart title and notes, plus chart-specific customization. layout Object Object with column, row, width, and height to determine chart layout in the dashboard. Supported visualizations The Dashboard API supports: event_table line_chart facet_table facet_bar_chart facet_pie_chart billboard faceted_area_chart faceted_line_chart event_table comparison_line_chart heatmap histogram billboard_comparison attribute_sheet funnel gauge json list Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2.1380959,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "id": "609f9c8664441fc63fd2a1f9",
      "highlight": {}
    }
  ],
  "/docs/style-guide/article-templates/api-tutorial-template": [
    {
      "sections": [
        "apiStyleGuidelines (Example agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Tip",
        "Parameters",
        "Return values",
        "Examples",
        "URL guidelines",
        "Title guidelines",
        "Short title guidelines",
        "Syntax guidelines",
        "Important"
      ],
      "title": "apiStyleGuidelines (Example agent API)",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "API writing guidelines"
      ],
      "external_id": "41eee9dfacd933b49935d7bd4d32cb76476c29ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/apistyleguidelines-example-agent-api/",
      "published_at": "2021-05-21T16:32:47Z",
      "updated_at": "2021-03-10T23:41:36Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.apiStyleGuidelines(data type $parameter_name[, integer $optional_param]) newrelic.apiStyleGuidelines(data type $parameter_name, array $different_param, string $third_param) Copy Briefly describe the call. Ideally, one line or less on the \"View all methods\" page. Requirements Agent version 1.2.3.4 or higher. Additional requirements on their own line (do not use bullets). Do not use any callouts. If there are no special requirements, write: Compatible with all agent versions. Description Describe the behavior of the call with as much detail as possible. Do not describe what individual parameters do except in broad strokes; details of parameters and call variants belong under the Parameters heading. Similarly, do not describe return values. When cross-referencing another API call, format its name with code blocks, and include parentheses () like this: anotherCoolMethod(). Tip You can include callouts, but use discretion. These pages are already visually busy. Parameters If there are no parameters, leave this section blank. If there is only one call variant, do not include a syntax block in this section. Parameter Description newrelic.apiStyleGuidelines(data type $parameter_name[, integer $optional_param]) Copy $parameter_name data type Required. Brief description of parameter. $optional_param integer Optional. Brief description of parameter. newrelic.apiStyleGuidelines(data type $parameter_name, array $different_param) Copy $parameter_name data type Required. Brief description of parameter. $different_param array Required. Brief description of parameter. $third_param string Required. Brief description of parameter. Return values What does this call return, and in what circumstances? Are there any things we expect customers to do with that return value? If the call does not return anything, leave this section blank. Examples This section documents rules for oddballs that aren't self-documenting. The rest of the examples are embedded within the page itself. In general, this page is intended for style reference. For examples of how to write good API method pages, check out our existing API docs, such as the PHP API. URL guidelines For the doc's URL: Manually edit the URL slug to remove the agent name. Where the API call does not already include separators (as in newrelic_awesome_call), separate the bits with hyphens -. For example: https://docs.newrelic.com/docs/new-relic-only/advanced-style-guide/writing-guidelines/api-style-guidelines Copy Title guidelines For the doc's title: Include the method name and the agent name in parentheses. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do not include parentheses () in the call itself. For example: apiStyleGuidelines (Example agent API) Copy Short title guidelines For the doc's short title: Include only the method name. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do not include parentheses (). Adjust if necessary to fit on a single line in the category's sidebar. For example: apiStyleGuidelines Copy Syntax guidelines Important The Python and iOS agents use their own guidelines. For those guidelines, see the existing methods in those languages. Document each variant of a call on its own line. Do not use any formatting except italicizing the data type. Wrap optional parameters (including the comma separator) in square brackets []. Indicate the variable portion by prefacing it with a dollar sign $. If the call must be prefixed with newrelic. or similar, include that in the syntax. Optional: Include the return value, if that seems important for your particular agent. If you do, follow language conventions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.00217,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>apiStyleGuidelines</em> (Example agent <em>API</em>)",
        "sections": "URL <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ":&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;new-relic-only&#x2F;advanced-<em>style</em>-<em>guide</em>&#x2F;<em>writing</em>-<em>guidelines</em>&#x2F;<em>api</em>-<em>style</em>-<em>guidelines</em> Copy Title <em>guidelines</em> For the doc&#x27;s title: Include the method name and the agent name in parentheses. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do"
      },
      "id": "60441b8d28ccbc0ab22c60b3"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-05-21T16:38:52Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.13492,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " documentation. For more information, see <em>apiStyleGuidelines</em> (for <em>style</em> <em>guidelines</em>) and Work with the <em>API</em> doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "ba7c99eb79d6fa7ad574db5768a742a4d2084a41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-05-21T16:34:37Z",
      "updated_at": "2021-05-10T03:34:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.88376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting docs <em>guide</em>",
        "sections": "Troubleshooting docs <em>guide</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ", this is the how of the troubleshooting doc. Provide an ordered list of steps to <em>guide</em> users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader"
      },
      "id": "6043f591196a675446960f74"
    }
  ],
  "/docs/style-guide/article-templates/apistyleguidelines-example-agent-api": [
    {
      "sections": [
        "API tutorial template",
        "Introduction (this heading will not be visible)",
        "Optional: Provide an overview for complex processes",
        "Provide a procedure to accomplish the task",
        "Tip",
        "Step 1. Do something...",
        "If needed: Step 2. Do something else...",
        "If needed: Step 3. Do something else...",
        "Last step. Verify that the task was completed...",
        "Optional: Do something else with the API",
        "Optional: Large example code block",
        "Code block example",
        "Optional: Troubleshooting"
      ],
      "title": "API tutorial template  ",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "API writing guidelines"
      ],
      "external_id": "a3fb036bc32f2dbc39c252acc9306e5ae0d5b7bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/api-tutorial-template/",
      "published_at": "2021-05-21T16:31:53Z",
      "updated_at": "2021-03-10T23:40:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is a template for an API tutorial document: Please skim the entire template first to understand the expected structure for this type of doc. Then, clone this doc using the Clone content link in the Page tools box. Delete all content up to Introduction (this heading won't be visible). For the doc title (the field at top of page): Doc should be named in a practical, use-case-focused way. Example: Add custom attributes to transactions Introduction (this heading will not be visible) Provide a brief explanation of what this document will teach customers, and why it is valuable for customers to know how to do that. Focus on the value the API provides to the customers and mention specific, common use cases. Any relevant notes about support/compatability should go here, too. Here's an example from the Java API asynchronous tutorial doc: New Relic for Java includes an API to instrument asynchronous activity. For supported frameworks, the Java agent usually instruments async work automatically. However, the async API can be useful for adding more detail to your data. This document provides examples of using tokens and segments to instrument your app. Optional: Provide an overview for complex processes This is an optional section for complicated tutorials that involve either using several methods in one procedure or that have different alternate steps you can take to achieve similar results. This section can link to lower-down sections to allow users to skip around as needed. For simple tutorials, this section isn't necessary. For an example, see this section of the Java async tutorial. Provide a procedure to accomplish the task Tell the user how to accomplish the task, and link to the methods necessary to accomplish that task. As much as possible, we're looking to describe tasks in \"procedures\" (procedure is tech writer jargon for a series of numbered steps). This may be tough to do for fairly open-ended/variable tasks, but it will usually be possible to chunk the content at a fairly high-level to make it into a procedure. Along the way, explain what the importance of the procedure step is, and how one might verify that the step was done correctly. For code samples, avoid using large chunks of code. Instead, use smaller pieces of code and give context for how they are being used. (If you think a large app code example would be helpful, place that later in the doc in the Example section.) Tip For an example of an open-ended task segmented into procedural chunks, see the Asynchronous doc section Connecting async threads. For another example, see this TomCat GAE Flex procedure. Base your procedure on the simple structure below. Tech writers will edit your content to match our style and formatting requirements: Step 1. Do something... Methods and example code to implement the first step. For each step, if applicable, indicate the significance of that step (why it's important) and how the user might verify that the step was done correctly (for example, something showing up in UI, or running a verification test of some sort). If needed: Step 2. Do something else... Methods and example code to implement step 2. If needed: Step 3. Do something else... Methods and example code to implement step 3. Last step. Verify that the task was completed... Explain how a user would know they'd completed the task correctly. In particular, how would the user find the new change or data in the New Relic UI. What NR products and pages would the change be noticed on? If new data shows up in Insights, what event types can it be found under? Optional: Do something else with the API Same as above. Make as many headings and separate procedures as needed. Optional: Large example code block If you think a large app code example would be useful, place here. Within any code block, explain all New Relic functions/methods, not just the main methods. Instead of in-line comments, consider using highlighted sections underneath the code block to give additional context. Here's an example: Code block example The following code example shows a segment starting in the storeItem method to measure how long the Lambda statement is waiting in the thread pool. To stop timing the segment, you must call either .end() or .ignore(). If you don't want to report the segment as part of its parent transaction, call .ignore(). Otherwise, to report the segment as part of its parent transaction, call .end(). private void storeItem(long id) { Segment segment = NewRelic.getAgent().getTransaction(). startSegment(\"storeItem\") ; segment. reportAsExternal (DatastoreParameters .product(\"H2\") .collection(null) .operation(\"insert\") .instance(\"localhost\", 8080) .databaseName(\"test\") .build()); // fire and forget DB_POOL.submit(() -> { segment.end(); insertData(id); }); } Copy The agent API calls in this sample are: startSegment(...): Begins the segment that will time the code. For more on this method, see the Javadoc. reportAsExternal(DatastoreParameters()): Associates the time with a datastore external call This will show up in New Relic APM with datastore data. For more information, see reportAsExternal API. segment.end(): Stops timing this segment. For more on this method, see the Javadoc. Optional: Troubleshooting Optional area for any common errors or troubleshooting tips.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.00177,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>API</em> tutorial template  ",
        "sections": "<em>API</em> tutorial template",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " to describe tasks in &quot;procedures&quot; (procedure is <em>tech</em> <em>writer</em> jargon for a series of numbered steps). This may be tough to do for fairly open-ended&#x2F;variable tasks, but it will usually be possible to chunk the content at a fairly high-level to make it into a procedure. Along the way, explain what"
      },
      "id": "60441b4a64441f7766378f09"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-05-21T16:38:52Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.13489,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " documentation. For more information, see <em>apiStyleGuidelines</em> (for <em>style</em> <em>guidelines</em>) and Work with the <em>API</em> doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "ba7c99eb79d6fa7ad574db5768a742a4d2084a41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-05-21T16:34:37Z",
      "updated_at": "2021-05-10T03:34:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.88373,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting docs <em>guide</em>",
        "sections": "Troubleshooting docs <em>guide</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ", this is the how of the troubleshooting doc. Provide an ordered list of steps to <em>guide</em> users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader"
      },
      "id": "6043f591196a675446960f74"
    }
  ],
  "/docs/style-guide/article-templates/basic-doc-template": [
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "ba7c99eb79d6fa7ad574db5768a742a4d2084a41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-05-21T16:34:37Z",
      "updated_at": "2021-05-10T03:34:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.04718,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting docs <em>guide</em>",
        "sections": "Troubleshooting docs <em>guide</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ", this is the how of the troubleshooting doc. Provide an ordered list of steps to <em>guide</em> users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader"
      },
      "id": "6043f591196a675446960f74"
    },
    {
      "sections": [
        "Add to data dictionary",
        "Data dictionary structure",
        "Add a new data type",
        "Add attributes",
        "Attribute style guidelines",
        "Using units of measurement"
      ],
      "title": "Add to data dictionary",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "32b8cab502883cc3443e54c86a0bd4021cc5a10f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/data-dictionary-style-guidelines/",
      "published_at": "2021-05-21T16:33:39Z",
      "updated_at": "2021-04-28T03:20:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use the data dictionary to provide information about data types (for example, Transaction, Metric, Log) and attached attributes. This is exposed in the New Relic query experience, on hovering over the data types and attributes. And we also expose the dictionary to the public. This doc contains info on how to add data to the dictionary. Note that currently we don't have infrastructure integration data in the dictionary. We also have very few attributes for the Metric data type, just a few basic default ones, despite there being many potential attributes attached to that data type depending on what the data source is. Data dictionary structure The data in the data dictionary is structured like this: Data types: sometimes called \"events\" for historical reasons, these are the NRDB data objects, like Transaction, Metric, Log, Span, etc. Attributes: these are key:value pairs attached to data types. One attribute can have multiple data types listed for it. For example, appName is on multiple data types. Data source: The New Relic product from which the data originates. With the current implementation, a data type must have a single data source assigned. This isn't ideal, as theoretically a data type can come from multiple sources. Add a new data type To add a new data type: Make a new folder in this directory, alongside the other directories: /docs-website/tree/develop/src/data-dictionary/events Copy Duplicate a data type file (for example, this Metric data type), place it in the new folder, and fill it out with the new info. For how to add attributes on a new data type, keep reading. Add attributes To add attributes: Our goal is to avoid adding redundant attributes entries, so you should first check to see if there's an existing attribute that has the same name and same general definition as the one you're trying to add. If it exists, edit that file to include the new data type (under events:). If an existing attribute is fairly close in definition but not exact, try to edit the definition so it works for all associated data types. If there is no existing attribute, create a new one. The easiest way is to copy an existing attribute file, edit all relevant fields to be accurate, and place it in the folder of the data type it's attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see Style. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute style guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes on this: Feel free to use sentence fragments. Feel free to edit definitions submitted from internal teams as sometimes their definitions will be overly long or have unneeded links. Some attributes are only present in some situations (for example, when a specific APM agent is used, or when a specific config option is true). If it's easy to include that detail in the short description, do so, but it's not required. Write so it reads well as plain text. Details on this: Note that the docs site data dictionary has our usual docs styles available, but the query UI definitions have no styling available. This means that you should write definitions so that they are understandable without any styling, as plain text. You can often avoid any need for styling (for example, data types like Transaction are easy to understand as plain text, as are most phrasings that use attribute names or values. When plain text makes something too ambiguous and you need some styling, use single quotes to indicate attributes or values (for example, a definition like: Reported when 'category' is 'http'). We should avoid links because those aren't visible in the query UI; the query UI only displays plain text. However, every attribute entry in the query UI does display a link 'See attribute in docs' that links to the docs site entry. This means that we can use links provided that they will display in an easy to understand way in the query UI. For example, here's an example of an attribute that would read clearly in plain text despite not having a link. We should avoid using a link format like \"For more information, see Create an alert condition\", because it wouldn't read well in plain text, and would choose something like \"For more information, see our alert condition docs.\" Using units of measurement Attribute entries have an optional unit of measurement field in the front matter. For example, here the front matter for an attribute with a percent unit of measurement: --- name: cpuPercent type: attribute units: percentage (%) events: - ProcessSample --- Copy What unit of measurement to select for an attribute is sometimes obvious, like if the attribute value is measured in milliseconds (units: milliseconds (ms)) or seconds (units: seconds (s)) or a percentage (units: percentage (%)). We also have several units of measurement that are not obvious, like count, enum, rate, and ID. (Technically, these aren't actually \"units of measurement\" and are more just conceptual data types but we're doing it this way as a workaround so you can ignore the fact that units of measurement isn't actually accurate.) The main reason we want to specify this information is that this will control what kinds of queries or charts can be created or auto-suggested by New Relic. For example, the New Relic UI wouldn't want to auto-suggest a chart graphing the average of ID values because that wouldn't make any sense. So attributes with accurate units, such as data types, will help product provide more practical help/suggestions to customers in future. Here are some tips for the non-obvious unit types: count: This is a count of something, though not a count of time-based units. For a number to be a count, it must (a) only be capable of increasing during a given time/sampling period, and (b) have a theoretically uncapped range. This wouldn't be used for a count of time units; if it was a count of seconds, for example, you would just use 'seconds' as the unit of measurement. A couple of examples of a count: databaseCallCount threadConcurrency enum: enum is short for enumerated list. In other words, it is a specific range of numbers that represent other non-numeric elements. For example, an attribute that had HTTP error codes (404, 505, etc.) as possible values would be an enum. A range of numbers that represent color codes would be another example of an enum. (Theoretically, an enum can represent lists without numeric values but we have no need to categorize strings so we only care about numeric-value lists.) Example: httpResponsecode. rate: Use this for any rate (for example, count per second). These are typically for averaged rates over small units of time, like second or millisecond. We previously have used the unit of time for these attributes (for example, using seconds as the unit of measurement for a count per second rate), but now we want to use rate for these. This is necessary because the types of displays used for rates would be different than the types of displays used for a simpler duration/count measurement. Example: MySQL integration attribute db.innodb.dataReadBytesPerSecond, which has the definition \"Rate at which data is read from InnoDB tables in bytes per second.\" id: Use ID for any identification number attribute. Example: appId.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 278.75134,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Attribute <em>style</em> <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ". For more on that, see <em>Style</em>. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute <em>style</em> guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes"
      },
      "id": "6050b4da64441f84f1532199"
    },
    {
      "sections": [
        "GraphQL API tutorial template",
        "Example query #1 with GraphQL",
        "Example query #2 with GraphQL",
        "Example query #3 with GraphQL"
      ],
      "title": "GraphQL API tutorial template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "9a7f90194f75eb7e347f54e7cc090d177cd39875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/graphql-api-tutorial-template/",
      "published_at": "2021-05-21T16:33:39Z",
      "updated_at": "2021-03-16T13:08:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the text in this template to create your own GraphQL API tutorial, then fill in details that will help users learn how to use GraphQL in practical ways. Ideally the final version of your GraphQL doc will include: An introduction paragraph describing what problem or use case the users want to solve, or why the API can help them query to get this data Three to five query examples that show interesting data they can get from GraphQL Sample intro paragraph: You can use the New Relic GraphQL API to [ add key use cases here]. To construct these queries and see responses, you can use the New Relic GraphQL Explorer. This document explains some of the available functions to query [ data to be queried]. Example query #1 with GraphQL Add a description here for your example query. Tell users why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #2 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #3 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.79471,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GraphQL API tutorial <em>template</em>",
        "sections": "GraphQL API tutorial <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "6042212b196a67f5d6a83dbf"
    }
  ],
  "/docs/style-guide/article-templates/create-release-notes": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/get-started/introduction-style-guide/",
      "sections": [
        "Introduction to the style guide",
        "Organize your doc to make it easier to read",
        "Use action-oriented titles",
        "Start the document with an introductory paragraph",
        "Keep documents short",
        "Use the New Relic voice",
        "Change doc titles and anchors",
        "Create and edit categories",
        "Start writing and editing docs"
      ],
      "published_at": "2021-05-21T16:34:36Z",
      "title": "Introduction to the style guide",
      "updated_at": "2021-04-12T11:26:22Z",
      "type": "docs",
      "external_id": "b0bfbe0b3791c4feb00fe86a41e49312cd9e82cd",
      "document_type": "page",
      "popularity": 1,
      "body": "We've written these guidelines to make it easier for you to contribute to our docs, as well as to give you some insight into how we think about good technical writing. We, the Tech Docs team, rely on your expertise to keep New Relic's documentation updated and useful. Thank you for your willingness to share your knowledge! Our style guide focuses on style and usage that's particular to our site. Our site follows American English conventions. For topics that aren't covered, please refer to the Microsoft Writing Style Guide (for guidelines on technical terminology) or the Chicago Manual of Style (for general writing and editing guidelines). Organize your doc to make it easier to read Consider these organization guidelines when thinking about the order of information in a doc. By following these guidelines, you'll make it easier for readers to skim and find what they need. How to organize information Comments Separate what and why from how. Define any necessary prerequisites, policies, or background information (the what and the why) before you step through the how (step-by-step procedures). Examples: Explain what the feature is and why it matters before telling readers how to use it. Describe any limitations with user permissions or subscription levels that would prevent them from using the feature. If the feature is available for any user or subscription level, don't bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting a procedure that they have everything they need. Front-load directions with context. Make sure readers know where they need to be, before telling them what to do. In general, use (select an app) to describe what users select from the product index. Examples: Go to one.newrelic.com > Explorer > (select an app or service). Select (account dropdown) > User preferences. On the command line, type gitk. Also, structure steps by front-loading context from the user's point of view. For example, instead of \"Go to x to do y,\" structure the step as \"To do y, go to x.\" Separate requirements from options. Example: Type the Email you use to sign in and to receive information from New Relic. Optional: Type additional user emails, separated by commas. Follow the \"five to nine\" guideline. Depending on the topic, organize the information so there is a maximum of five to nine chunks of information. For example, readers may start to get lost or overwhelmed after about five h2 sections or seven steps into a procedure. If you have more than nine h2 sections or steps, you might need to create an additional doc or procedure. Other organization tools to consider: Levels of headings Lists Collapsers Callouts Tables Code examples For more help section Use action-oriented titles Wherever possible, give your document or h2 heading a task- or action-oriented title. Focus on what users are trying to accomplish or the problem they're trying to solve. Use present-tense verbs, rather than \"-ing\" verbs. Quality Title example Bad The query history Okay View query history Good Query history: Create and edit NRQL queries Start the document with an introductory paragraph Unless the document is less than a single screen in length, begin with a brief paragraph that introduces the topic or summarizes the important points. Not sure where to start? Try writing all the content for your document first, and then add the introduction to the top to summarize your key points. Or use the introduction to expand on the text in your metaDescription in the metadata. Keep documents short The amount of content needed can help you decide whether you need one or more documents for the topic. If all of the document's contents apply directly to the title, then everything belongs in the same document. If several related sections could be logically split into individual documents, and the overall length of your document is more than about two screenfuls, split those sections into other documents. Be sure to include links to the related contents. If a large document needs to be broken into multiple smaller documents, consider whether they might be best grouped together in their own sub-category. Use the New Relic voice We strive for a voice that's approachable, expert, and visionary. Check out our voice guidelines for how to write content with these qualities. And keep in mind these essential writing tips that apply to any type of documentation. Guidelines Comments Be clear and direct. Remember to: Use present tense. Use active voice; avoid passive voice. Tell users what to do, not what they \"should\" do. If absolutely necessary, tell users what not to do in situations where unexpected results may occur. Whenever possible, provide an alternative suggestion when telling users what not to do. Example: Using active voice with an alternative suggestion for what not to do Do not use your config file to change this setting, because this could affect other processes. Instead, go to one.newrelic.com > APM > (select an app or service) > Settings > Application. Write to aid localization and translation. Do not use euphemisms, idioms, jargon, or slang. Use the same terms and wording consistently. If you need to include an abbreviation or acronym, spell it out the first time it appears in the document. Always take a moment to ask yourself whether people will really understand the terms you are using in the way you're using them. Change doc titles and anchors Because changes to doc titles, anchors, and redirects can break links to other docs, please create an issue to request these types of changes and we'll help you out with that. Create and edit categories Because changes to categories can affect large groups of docs at once, please create an issue to request these types of changes and we'll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see Create and edit content. To learn how to create and publish release notes, see Create release notes. To make it even easier to start a new doc, use templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 414.36206,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Create</em> and edit categories",
        "body": " large groups of docs at once, please <em>create</em> an issue to request these types of changes and we&#x27;ll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see <em>Create</em> and edit content. To learn how to <em>create</em> and publish <em>release</em> <em>notes</em>, see <em>Create</em> <em>release</em> <em>notes</em>. To make it even easier to start a new doc, use templates."
      },
      "id": "60415293e7b9d262f32a07d7"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2021-05-22T00:20:23Z",
      "updated_at": "2021-05-16T01:08:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's Docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The Docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic Docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.23235,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Agent <em>release</em> <em>notes</em>",
        "body": ": Go Java .NET Node.js PHP Python Ruby Agent <em>release</em> <em>notes</em> Here are links to New Relic <em>release</em> <em>notes</em> organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic."
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-05-22T11:51:20Z",
      "updated_at": "2021-05-10T05:10:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 82.79093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related <em>release</em> <em>notes</em> Rating NR21-02, 4&#x2F;26&#x2F;2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8&#x2F;20&#x2F;2020"
      },
      "id": "6045248b196a67f158960f1b"
    }
  ],
  "/docs/style-guide/article-templates/data-dictionary-style-guidelines": [
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "ba7c99eb79d6fa7ad574db5768a742a4d2084a41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-05-21T16:34:37Z",
      "updated_at": "2021-05-10T03:34:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.04712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting docs <em>guide</em>",
        "sections": "Troubleshooting docs <em>guide</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ", this is the how of the troubleshooting doc. Provide an ordered list of steps to <em>guide</em> users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader"
      },
      "id": "6043f591196a675446960f74"
    },
    {
      "sections": [
        "Basic doc template",
        "Section example",
        "Code example",
        "List example",
        "Table example"
      ],
      "title": "Basic doc template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "8949f5c550b7fcab6ec76ca68fa8dd5ec2ed188f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/basic-doc-template/",
      "published_at": "2021-05-21T16:32:47Z",
      "updated_at": "2021-04-05T08:04:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the formatting tips in this template to organize the docs you create on the Docs site. Then replace the template information with your own text, lists, and tables as needed. Before you create sections, start your doc with a brief introduction, usually no more than a paragraph, that helps readers understand what your doc will cover. Your introduction (and the structure of your doc) should help readers understand within ten seconds whether they are in the right place. Section example Begin each section with a meaningful H2 title. The Docs site uses these to generate the contents, which appears automatically in the left navigation. If you want to include a screenshot with the section, provide a permalink for the Docs team to create the image for you. Due to security requirements, the Docs team manages all images on the Docs site. Code example def article_url(category, article, options={}) url_for(options.reverse_merge( :controller => 'articles';, :action => 'show', :category => category, :article => article )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add require('newrelic'); as the first line of your app's main module. Use the command npm install newrelic --save for each application you want to monitor. For unordered lists, use bullets (ul in HTML or * in Markdown). For example: Black White For complex lists, consider using collapsers. Table example Tables help organize detailed lists so the information is easier to skim. Tables are easier to manage in HTML. For exammple: <table> <thead> <tr> <th width={200}> **Item** </th> <th> **Requirements** </th> </tr> </thead> <tbody> <tr> <td> Some thing </td> <td> More detailed information about it </td> </tr> <tr> <td> Another thing </td> <td> More detailed information about another thing </td> </tr> </tbody> </table> Copy Tables created in Markdown use three or more hyphens --- to create each column’s header, and pipes | to separate each column. For example: | Item | Requirements ------------ | ------------ | Some thing | More detailed information about it | Another thing | More detailed information about another thing Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.52464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Basic doc <em>template</em>",
        "sections": "Basic doc <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " <em>article</em>_url(category, <em>article</em>, options={}) url_for(options.reverse_merge( :controller =&gt; &#x27;articles&#x27;;, :action =&gt; &#x27;show&#x27;, :category =&gt; category, :<em>article</em> =&gt; <em>article</em> )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add"
      },
      "id": "6042212b64441f49134e886d"
    },
    {
      "sections": [
        "GraphQL API tutorial template",
        "Example query #1 with GraphQL",
        "Example query #2 with GraphQL",
        "Example query #3 with GraphQL"
      ],
      "title": "GraphQL API tutorial template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "9a7f90194f75eb7e347f54e7cc090d177cd39875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/graphql-api-tutorial-template/",
      "published_at": "2021-05-21T16:33:39Z",
      "updated_at": "2021-03-16T13:08:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the text in this template to create your own GraphQL API tutorial, then fill in details that will help users learn how to use GraphQL in practical ways. Ideally the final version of your GraphQL doc will include: An introduction paragraph describing what problem or use case the users want to solve, or why the API can help them query to get this data Three to five query examples that show interesting data they can get from GraphQL Sample intro paragraph: You can use the New Relic GraphQL API to [ add key use cases here]. To construct these queries and see responses, you can use the New Relic GraphQL Explorer. This document explains some of the available functions to query [ data to be queried]. Example query #1 with GraphQL Add a description here for your example query. Tell users why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #2 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #3 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.7947,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GraphQL API tutorial <em>template</em>",
        "sections": "GraphQL API tutorial <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "6042212b196a67f5d6a83dbf"
    }
  ],
  "/docs/style-guide/article-templates/graphql-api-tutorial-template": [
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "ba7c99eb79d6fa7ad574db5768a742a4d2084a41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-05-21T16:34:37Z",
      "updated_at": "2021-05-10T03:34:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.04706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting docs <em>guide</em>",
        "sections": "Troubleshooting docs <em>guide</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ", this is the how of the troubleshooting doc. Provide an ordered list of steps to <em>guide</em> users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader"
      },
      "id": "6043f591196a675446960f74"
    },
    {
      "sections": [
        "Add to data dictionary",
        "Data dictionary structure",
        "Add a new data type",
        "Add attributes",
        "Attribute style guidelines",
        "Using units of measurement"
      ],
      "title": "Add to data dictionary",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "32b8cab502883cc3443e54c86a0bd4021cc5a10f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/data-dictionary-style-guidelines/",
      "published_at": "2021-05-21T16:33:39Z",
      "updated_at": "2021-04-28T03:20:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use the data dictionary to provide information about data types (for example, Transaction, Metric, Log) and attached attributes. This is exposed in the New Relic query experience, on hovering over the data types and attributes. And we also expose the dictionary to the public. This doc contains info on how to add data to the dictionary. Note that currently we don't have infrastructure integration data in the dictionary. We also have very few attributes for the Metric data type, just a few basic default ones, despite there being many potential attributes attached to that data type depending on what the data source is. Data dictionary structure The data in the data dictionary is structured like this: Data types: sometimes called \"events\" for historical reasons, these are the NRDB data objects, like Transaction, Metric, Log, Span, etc. Attributes: these are key:value pairs attached to data types. One attribute can have multiple data types listed for it. For example, appName is on multiple data types. Data source: The New Relic product from which the data originates. With the current implementation, a data type must have a single data source assigned. This isn't ideal, as theoretically a data type can come from multiple sources. Add a new data type To add a new data type: Make a new folder in this directory, alongside the other directories: /docs-website/tree/develop/src/data-dictionary/events Copy Duplicate a data type file (for example, this Metric data type), place it in the new folder, and fill it out with the new info. For how to add attributes on a new data type, keep reading. Add attributes To add attributes: Our goal is to avoid adding redundant attributes entries, so you should first check to see if there's an existing attribute that has the same name and same general definition as the one you're trying to add. If it exists, edit that file to include the new data type (under events:). If an existing attribute is fairly close in definition but not exact, try to edit the definition so it works for all associated data types. If there is no existing attribute, create a new one. The easiest way is to copy an existing attribute file, edit all relevant fields to be accurate, and place it in the folder of the data type it's attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see Style. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute style guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes on this: Feel free to use sentence fragments. Feel free to edit definitions submitted from internal teams as sometimes their definitions will be overly long or have unneeded links. Some attributes are only present in some situations (for example, when a specific APM agent is used, or when a specific config option is true). If it's easy to include that detail in the short description, do so, but it's not required. Write so it reads well as plain text. Details on this: Note that the docs site data dictionary has our usual docs styles available, but the query UI definitions have no styling available. This means that you should write definitions so that they are understandable without any styling, as plain text. You can often avoid any need for styling (for example, data types like Transaction are easy to understand as plain text, as are most phrasings that use attribute names or values. When plain text makes something too ambiguous and you need some styling, use single quotes to indicate attributes or values (for example, a definition like: Reported when 'category' is 'http'). We should avoid links because those aren't visible in the query UI; the query UI only displays plain text. However, every attribute entry in the query UI does display a link 'See attribute in docs' that links to the docs site entry. This means that we can use links provided that they will display in an easy to understand way in the query UI. For example, here's an example of an attribute that would read clearly in plain text despite not having a link. We should avoid using a link format like \"For more information, see Create an alert condition\", because it wouldn't read well in plain text, and would choose something like \"For more information, see our alert condition docs.\" Using units of measurement Attribute entries have an optional unit of measurement field in the front matter. For example, here the front matter for an attribute with a percent unit of measurement: --- name: cpuPercent type: attribute units: percentage (%) events: - ProcessSample --- Copy What unit of measurement to select for an attribute is sometimes obvious, like if the attribute value is measured in milliseconds (units: milliseconds (ms)) or seconds (units: seconds (s)) or a percentage (units: percentage (%)). We also have several units of measurement that are not obvious, like count, enum, rate, and ID. (Technically, these aren't actually \"units of measurement\" and are more just conceptual data types but we're doing it this way as a workaround so you can ignore the fact that units of measurement isn't actually accurate.) The main reason we want to specify this information is that this will control what kinds of queries or charts can be created or auto-suggested by New Relic. For example, the New Relic UI wouldn't want to auto-suggest a chart graphing the average of ID values because that wouldn't make any sense. So attributes with accurate units, such as data types, will help product provide more practical help/suggestions to customers in future. Here are some tips for the non-obvious unit types: count: This is a count of something, though not a count of time-based units. For a number to be a count, it must (a) only be capable of increasing during a given time/sampling period, and (b) have a theoretically uncapped range. This wouldn't be used for a count of time units; if it was a count of seconds, for example, you would just use 'seconds' as the unit of measurement. A couple of examples of a count: databaseCallCount threadConcurrency enum: enum is short for enumerated list. In other words, it is a specific range of numbers that represent other non-numeric elements. For example, an attribute that had HTTP error codes (404, 505, etc.) as possible values would be an enum. A range of numbers that represent color codes would be another example of an enum. (Theoretically, an enum can represent lists without numeric values but we have no need to categorize strings so we only care about numeric-value lists.) Example: httpResponsecode. rate: Use this for any rate (for example, count per second). These are typically for averaged rates over small units of time, like second or millisecond. We previously have used the unit of time for these attributes (for example, using seconds as the unit of measurement for a count per second rate), but now we want to use rate for these. This is necessary because the types of displays used for rates would be different than the types of displays used for a simpler duration/count measurement. Example: MySQL integration attribute db.innodb.dataReadBytesPerSecond, which has the definition \"Rate at which data is read from InnoDB tables in bytes per second.\" id: Use ID for any identification number attribute. Example: appId.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 278.75128,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Attribute <em>style</em> <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ". For more on that, see <em>Style</em>. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute <em>style</em> guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes"
      },
      "id": "6050b4da64441f84f1532199"
    },
    {
      "sections": [
        "Basic doc template",
        "Section example",
        "Code example",
        "List example",
        "Table example"
      ],
      "title": "Basic doc template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "8949f5c550b7fcab6ec76ca68fa8dd5ec2ed188f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/basic-doc-template/",
      "published_at": "2021-05-21T16:32:47Z",
      "updated_at": "2021-04-05T08:04:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the formatting tips in this template to organize the docs you create on the Docs site. Then replace the template information with your own text, lists, and tables as needed. Before you create sections, start your doc with a brief introduction, usually no more than a paragraph, that helps readers understand what your doc will cover. Your introduction (and the structure of your doc) should help readers understand within ten seconds whether they are in the right place. Section example Begin each section with a meaningful H2 title. The Docs site uses these to generate the contents, which appears automatically in the left navigation. If you want to include a screenshot with the section, provide a permalink for the Docs team to create the image for you. Due to security requirements, the Docs team manages all images on the Docs site. Code example def article_url(category, article, options={}) url_for(options.reverse_merge( :controller => 'articles';, :action => 'show', :category => category, :article => article )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add require('newrelic'); as the first line of your app's main module. Use the command npm install newrelic --save for each application you want to monitor. For unordered lists, use bullets (ul in HTML or * in Markdown). For example: Black White For complex lists, consider using collapsers. Table example Tables help organize detailed lists so the information is easier to skim. Tables are easier to manage in HTML. For exammple: <table> <thead> <tr> <th width={200}> **Item** </th> <th> **Requirements** </th> </tr> </thead> <tbody> <tr> <td> Some thing </td> <td> More detailed information about it </td> </tr> <tr> <td> Another thing </td> <td> More detailed information about another thing </td> </tr> </tbody> </table> Copy Tables created in Markdown use three or more hyphens --- to create each column’s header, and pipes | to separate each column. For example: | Item | Requirements ------------ | ------------ | Some thing | More detailed information about it | Another thing | More detailed information about another thing Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.52464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Basic doc <em>template</em>",
        "sections": "Basic doc <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " <em>article</em>_url(category, <em>article</em>, options={}) url_for(options.reverse_merge( :controller =&gt; &#x27;articles&#x27;;, :action =&gt; &#x27;show&#x27;, :category =&gt; category, :<em>article</em> =&gt; <em>article</em> )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add"
      },
      "id": "6042212b64441f49134e886d"
    }
  ],
  "/docs/style-guide/article-templates/landing-page-template": [
    {
      "sections": [
        "Update the home page",
        "Update a link's URL",
        "Add a new tile to the home page",
        "Add a new section to the home page"
      ],
      "title": "Update the home page",
      "type": "docs",
      "tags": [
        "home page",
        "landing pages"
      ],
      "external_id": "d637697a72493d8dbe0c9538e5b35f13f62d7474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/edit-homepage/",
      "published_at": "2021-05-21T16:36:25Z",
      "updated_at": "2021-04-11T08:27:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can't just hit the edit button docs.newrelic.com to make edits to the home page. The page that opens is index.js, the file that manages the parts of the home page, but not the content. It's rare that you'll need to make changes to this file. Most home page changes will be to add a new tile or section to the page, or update links. These types of changes are handled in two files: src/data/homepage.yml - contains home page section titles, section descriptions, and the URLs for tiles. src/i18n/translations/en/translation.json - contains tile info, including the title and short description of tiles. Update a link's URL Change or add new links using homepage.yml. In homepage.yml, search for the link you want to change. Edit the URL, save, commit, and PR the change. Add a new tile to the home page You'll make changes to both homepage.yml and translations.json On the translations.json doc, find the spot where you want to add the new tile (which section, and in what order you want it to appear), and add a new entry with this format: \"t#\": { \"title\": \"tile name\", \"description\": \"Short description.\" }, Copy Make sure you update the number on the tile. If you want to insert it in the middle of a group, update all the subsequent tile numbers as well. Save the file. Open homepage.yml, find the spot where the new tile will be, and add a new line with the relative link for the new tile. For example, - /docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster Save and check that your new tile builds properly on a local build. Commit, push, PR when you're ready. Add a new section to the home page On the translations.json page, add a new section modeled in the spot where you want the new section to appear. Include at least one title. For example, here's the TDP entry, with one tile: \"tdp\": { \"title\": \"Telemetry Data Platform\", \"description\": \"Ingest, visualize, and alert on all your telemetry data in one place.\", \"t1\": { \"title\": \"Introduction to Telemetry Data Platform\", \"description\": \"How to manage all your monitoring in one place.\" }, Copy When you're done creating the info, save the file. In the homepage.yml page, find the corresponding location for the new section, and add the short name you provided in the translation.json file, title, description, and tile URLs. For example, here's the corresponding TDP section on homepage.yml. tdp: title: Telemetry Data Platform description: Ingest, visualize, and alert on all your telemetry data in one place. tiles: - /docs/data-ingest-apis/get-data-new-relic/getting-started/get-started-telemetry-data-platform Copy Save, build locally, commit, PR.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.87563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update the home <em>page</em>",
        "sections": "Update the home <em>page</em>",
        "tags": "<em>landing</em> <em>pages</em>",
        "body": "You can&#x27;t just hit the edit button docs.newrelic.com to make edits to the home <em>page</em>. The <em>page</em> that opens is index.js, the file that manages the parts of the home <em>page</em>, but not the content. It&#x27;s rare that you&#x27;ll need to make changes to this file. Most home <em>page</em> changes will be to add a new tile"
      },
      "id": "6072b300e7b9d231b2a5c663"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-05-21T16:38:52Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.33005,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Page</em> <em>templates</em>",
        "body": "Our Docs site is made up of different content types and templates. Most of the time, the default <em>page</em> content type and the basic <em>template</em> will have everything you&#x27;ll need. Read on for more information about our <em>page</em> types. Docs meta content (frontmatter) Thr top of every doc begins with a set"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Map page views by region in a custom app",
        "Before you begin",
        "New Relic terminology",
        "Build a custom app with a table chart",
        "Query your browser data",
        "Create and serve a new Nerdpack",
        "Review your app files and view your app locally",
        "Hard code your account ID",
        "Import the TableChart component",
        "Add a table with a single row",
        "Customize the look of your table (optional)",
        "Get your data into that table",
        "Make your app interactive with a text field",
        "Import the TextField component",
        "Add a row for your text field",
        "Build the text field object",
        "Get your data on a map",
        "Install Leaflet",
        "Add a webpack config file for Leaflet",
        "Import modules from Leaflet",
        "Import additional modules from New Relic One",
        "Get data for the map",
        "Customize the map marker colors",
        "Set your map's default center point",
        "Add a row for your map",
        "Replace \"Hello\" with the Leaflet code"
      ],
      "title": "Map page views by region in a custom app",
      "type": "developer",
      "tags": [
        "custom app",
        "map",
        "page views",
        "region",
        "nerdpack"
      ],
      "external_id": "6ff5d696556512bb8d8b33fb31732f22bab455cb",
      "image": "https://developer.newrelic.com/static/d87a72e8ee14c52fdfcb91895567d268/0086b/pageview.png",
      "url": "https://developer.newrelic.com/build-apps/map-pageviews-by-region/",
      "published_at": "2021-05-23T01:40:55Z",
      "updated_at": "2021-05-21T01:39:15Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Build a New Relic app showing page view data on a world map.",
      "body": "New Relic has powerful and flexible tools for building custom apps and populating them with data. This guide shows you how to build a custom app and populate it with page view data using New Relic's Query Language (NRQL - pronounced 'nurkle'). Then you make your data interactive. And last, if you have a little more time and want to install a third-party React library, you can display the page view data you collect on a map of the world. In this guide, you build an app to display page view data in two ways: In a table On a map Please review the Before you begin section to make sure you have everything you need and don't get stuck halfway through. Before you begin In order to get the most out of this guide, you must have: A New Relic developer account, API key, and the command-line tool. If you don't have these yet, see the steps in Setting up your development environment New Relic Browser page view data to populate the app. Without this data, you won't be able to complete this guide. To add your data to a world map in the second half of the guide: npm, which you'll use during this section of the guide to install Leaflet, a third-party JavaScript React library used to build interactive maps. If you're new to React and npm, you can go here to install Node.js and npm. New Relic terminology The following are some terms used in this guide: New Relic application: The finished product where data is rendered in New Relic One. This might look like a series of interactive charts or a map of the world. Nerdpack: New Relic's standard collection of JavaScript, JSON, CSS, and other files that control the functionality and look of your application. For more information, see Nerdpack file structure. Launcher: The button on New Relic One that launches your application. Nerdlets: New Relic React components used to build your application. The three default files are index.js, nr1.json, and styles.scss, but you can customize and add your own. Build a custom app with a table chart Step 1 of 8 Query your browser data Use Query builder to write a NRQL query to see your page view data, as follows. On New Relic One, select Query your data (in the top right corner). That puts you in NRQL mode. You'll use NRQL to test your query before dropping the data into your table. Copy and paste this query into a clear query field, and then select Run. FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' FACET countryCode, regionCode SINCE 1 week ago LIMIT 1000 Copy If you have PageView data, this query shows a week of average page views broken down by country and limited to a thousand items. The table will be full width and use the \"chart\" class defined in the CSS. If you don't have any results at this point, ensure your query doesn't have any errors. If your query is correct, you might not have the Browser agent installed. Step 2 of 8 Create and serve a new Nerdpack To get started, create a new Nerdpack, and serve it up to New Relic from your local development environment: Update nr1 and create a new Nerdpack for this app: bash Copy $ nr1 update $ nr1 create --type nerdpack --name pageviews-app ✔ Component created successfully! nerdpack pageviews-app is available at \"./pageviews-app\" Serve the project up to New Relic: bash Copy $ cd pageviews-app && nr1 nerdpack:serve Found and loaded 2 nr1.json files on PageviewsApp (00e0f043-1fc3-42cd-a8ca-7eef5fc9cd45) Nerdpack. Nerdpack: ✔ PageviewsApp (00e0f043-1fc3-42cd-a8ca-7eef5fc9cd45) nr1.json Launchers: ✔ pageviews-app-launcher launchers/pageviews-app-launcher/nr1.json Nerdlets: ✔ pageviews-app-nerdlet nerdlets/pageviews-app-nerdlet/nr1.json 🛠 Built artifact files for: ⁎ 00e0f043-1fc3-42cd-a8ca-7eef5fc9cd45--pageviews-app-nerdlet built ✔ ✔ Nerdpack built successfully! ★ Starting as orchestrator... ✔ Server ready! Test it at: https://staging-one.newrelic.com/?nerdpacks=local ↩ Server will reload automatically if you modify any file! 🛠 Built artifact files for: ⁎ 00e0f043-1fc3-42cd-a8ca-7eef5fc9cd45--pageviews-app-nerdlet built ✔ ✔ Nerdpack built successfully! Step 3 of 8 Review your app files and view your app locally Navigate to your pageviews-app to see how it's structured. It contains a launcher folder, where you can customize the description and icon that will be displayed on the app's launcher in New Relic One. It also contains nerdlets, which each contain three default files: index.js, nr1.json, and styles.scss. You'll edit some of these files as part of this guide. For more information, see Nerdpack file structure. Now in your browser, open https://one.newrelic.com/?nerdpacks=local, and then click Apps to see the pageview-apps Nerdpack that you served up. When you select the launcher, you see a Hello message. Step 4 of 8 Hard code your account ID For the purposes of this exercise and for your convenience, hard code your account ID. In the pageview-app-nerdlet directory, in the index.js file, add this code between the import and export lines. (Read about finding your account ID here). index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 3 const accountId = 0; // Replace with your account ID 4 5 export default class PageViewApp extends React.Component { 6 render() { 7 return <h1>Hello, pageview-app-nerdlet Nerdlet!</h1>; 8 } 9 } pageview-app-nerdlet/index.js Copy 1 pageview-app-nerdlet/styles.scss Copy 1 .extended-webpackrc.js Copy Step 5 of 8 Import the TableChart component To show your data in a table chart, import the TableChart component from New Relic One. To do so, in index.js, add this code under import React. index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { TableChart } from 'nr1'; 3 4 const accountId = 0; // Replace with your account ID 5 6 export default class PageViewApp extends React.Component { 7 render() { 8 return <h1>Hello, pageview-app-nerdlet Nerdlet!</h1>; 9 } 10 } pageview-app-nerdlet/index.js Copy 1 pageview-app-nerdlet/styles.scss Copy 1 .extended-webpackrc.js Copy Step 6 of 8 Add a table with a single row To add a table with a single row, in the index.js file, replace this line with this export code: index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { TableChart } from 'nr1'; 3 4 const accountId = 0; // Replace with your account ID 5 6 export default class PageViewApp extends React.Component { 7 render() { 8 return ( 9 <div className=\"container\"> 10 <div className=\"row\"></div> 11 </div> 12 ); 13 } 14 } pageview-app-nerdlet/index.js Copy 1 pageview-app-nerdlet/styles.scss Copy 1 .extended-webpackrc.js Copy Step 7 of 8 Customize the look of your table (optional) You can use standard CSS to customize the look of your components. In the styles.scss file, add this CSS. Feel free to customize this CSS to your taste. index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { TableChart } from 'nr1'; 3 4 const accountId = 0; // Replace with your account ID 5 6 export default class PageViewApp extends React.Component { 7 render() { 8 return ( 9 <div className=\"container\"> 10 <div className=\"row\"></div> 11 </div> 12 ); 13 } 14 } pageview-app-nerdlet/index.js Copy 1 .container { 2 width: 100%; 3 height: 99vh; 4 display: flex; 5 flex-direction: column; 6 .row { 7 margin: 10px; 8 display: flex; 9 flex-direction: row; 10 } 11 .chart { 12 height: 250px; 13 } 14 } pageview-app-nerdlet/styles.scss Copy 1 .extended-webpackrc.js Copy Step 8 of 8 Get your data into that table Now that you've got a table, you can drop a TableChart populated with data from the NRQL query you wrote at the very beginning of this guide. Put this code into the row div. index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { TableChart } from 'nr1'; 3 4 const accountId = 0; // Replace with your account ID 5 6 export default class PageViewApp extends React.Component { 7 render() { 8 return ( 9 <div className=\"container\"> 10 <div className=\"row\"> 11 <TableChart 12 accountId={accountId} 13 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' SINCE 1 week ago LIMIT 1000`} 14 fullWidth 15 className=\"chart\" 16 /> 17 </div> 18 </div> 19 ); 20 } 21 } pageview-app-nerdlet/index.js Copy 1 .container { 2 width: 100%; 3 height: 99vh; 4 display: flex; 5 flex-direction: column; 6 .row { 7 margin: 10px; 8 display: flex; 9 flex-direction: row; 10 } 11 .chart { 12 height: 250px; 13 } 14 } pageview-app-nerdlet/styles.scss Copy 1 .extended-webpackrc.js Copy Go to New Relic One and click your app to see your data in the table. (You might need to serve your app to New Relic again.) Congratulations! You made your app! Continue on to make it interactive and show your data on a map. Make your app interactive with a text field Once you confirm that data is getting to New Relic from your app, you can start customizing it and making it interactive. To do this, you add a text field to filter your data. Later, you use a third-party library called Leaflet to show that data on a world map. Step 1 of 3 Import the TextField component Like you did with the TableChart component, you need to import a TextField component from New Relic One. index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { TableChart, TextField } from 'nr1'; 3 4 const accountId = 0; // Replace with your account ID 5 6 export default class PageViewApp extends React.Component { 7 render() { 8 return ( 9 <div className=\"container\"> 10 <div className=\"row\"> 11 <TableChart 12 accountId={accountId} 13 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' SINCE 1 week ago LIMIT 1000`} 14 fullWidth 15 className=\"chart\" 16 /> 17 </div> 18 </div> 19 ); 20 } 21 } pageview-app-nerdlet/index.js Copy 1 .container { 2 width: 100%; 3 height: 99vh; 4 display: flex; 5 flex-direction: column; 6 .row { 7 margin: 10px; 8 display: flex; 9 flex-direction: row; 10 } 11 .chart { 12 height: 250px; 13 } 14 } pageview-app-nerdlet/styles.scss Copy 1 .extended-webpackrc.js Copy Step 2 of 3 Add a row for your text field To add a text field filter above the table, put this code above the TableChart div. The text field will have a default value of \"US\". index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { TableChart, TextField } from 'nr1'; 3 4 const accountId = 0; // Replace with your account ID 5 6 export default class PageViewApp extends React.Component { 7 render() { 8 return ( 9 <div className=\"container\"> 10 <div className=\"row\"> 11 <div className=\"row\"> 12 <TextField 13 placeholder=\"US\" 14 onChange={(event) => { 15 this.setState({ countryCode: event.target.value }); 16 }} 17 /> 18 </div> 19 <TableChart 20 accountId={accountId} 21 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' SINCE 1 week ago LIMIT 1000`} 22 fullWidth 23 className=\"chart\" 24 /> 25 </div> 26 </div> 27 ); 28 } 29 } pageview-app-nerdlet/index.js Copy 1 .container { 2 width: 100%; 3 height: 99vh; 4 display: flex; 5 flex-direction: column; 6 .row { 7 margin: 10px; 8 display: flex; 9 flex-direction: row; 10 } 11 .chart { 12 height: 250px; 13 } 14 } pageview-app-nerdlet/styles.scss Copy 1 .extended-webpackrc.js Copy Step 3 of 3 Build the text field object Above the render() function, add a constructor to build the text field object. index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { TableChart, TextField } from 'nr1'; 3 4 const accountId = 0; // Replace with your account ID 5 6 export default class PageViewApp extends React.Component { 7 constructor(props) { 8 super(props); 9 this.state = { 10 countryCode: null, 11 }; 12 } 13 14 render() { 15 return ( 16 <div className=\"container\"> 17 <div className=\"row\"> 18 <div className=\"row\"> 19 <TextField 20 placeholder=\"US\" 21 onChange={(event) => { 22 this.setState({ countryCode: event.target.value }); 23 }} 24 /> 25 </div> 26 <TableChart 27 accountId={accountId} 28 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' SINCE 1 week ago LIMIT 1000`} 29 fullWidth 30 className=\"chart\" 31 /> 32 </div> 33 </div> 34 ); 35 } 36 } pageview-app-nerdlet/index.js Copy 1 .container { 2 width: 100%; 3 height: 99vh; 4 display: flex; 5 flex-direction: column; 6 .row { 7 margin: 10px; 8 display: flex; 9 flex-direction: row; 10 } 11 .chart { 12 height: 250px; 13 } 14 } pageview-app-nerdlet/styles.scss Copy 1 .extended-webpackrc.js Copy Above return, add: index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { TableChart, TextField } from 'nr1'; 3 4 const accountId = 0; // Replace with your account ID 5 6 export default class PageViewApp extends React.Component { 7 constructor(props) { 8 super(props); 9 this.state = { 10 countryCode: null, 11 }; 12 } 13 14 render() { 15 const { countryCode } = this.state; 16 17 return ( 18 <div className=\"container\"> 19 <div className=\"row\"> 20 <div className=\"row\"> 21 <TextField 22 placeholder=\"US\" 23 onChange={(event) => { 24 this.setState({ countryCode: event.target.value }); 25 }} 26 /> 27 </div> 28 <TableChart 29 accountId={accountId} 30 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' SINCE 1 week ago LIMIT 1000`} 31 fullWidth 32 className=\"chart\" 33 /> 34 </div> 35 </div> 36 ); 37 } 38 } pageview-app-nerdlet/index.js Copy 1 .container { 2 width: 100%; 3 height: 99vh; 4 display: flex; 5 flex-direction: column; 6 .row { 7 margin: 10px; 8 display: flex; 9 flex-direction: row; 10 } 11 .chart { 12 height: 250px; 13 } 14 } pageview-app-nerdlet/styles.scss Copy 1 .extended-webpackrc.js Copy Now add countryCode to your table chart query. index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { TableChart, TextField } from 'nr1'; 3 4 const accountId = 0; // Replace with your account ID 5 6 export default class PageViewApp extends React.Component { 7 constructor(props) { 8 super(props); 9 this.state = { 10 countryCode: null, 11 }; 12 } 13 14 render() { 15 const { countryCode } = this.state; 16 17 return ( 18 <div className=\"container\"> 19 <div className=\"row\"> 20 <div className=\"row\"> 21 <TextField 22 placeholder=\"US\" 23 onChange={(event) => { 24 this.setState({ countryCode: event.target.value }); 25 }} 26 /> 27 </div> 28 <TableChart 29 accountId={accountId} 30 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' ${ 31 countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' 32 } FACET countryCode, regionCode SINCE 1 week ago LIMIT 1000`} 33 fullWidth 34 className=\"chart\" 35 /> 36 </div> 37 </div> 38 ); 39 } 40 } pageview-app-nerdlet/index.js Copy 1 .container { 2 width: 100%; 3 height: 99vh; 4 display: flex; 5 flex-direction: column; 6 .row { 7 margin: 10px; 8 display: flex; 9 flex-direction: row; 10 } 11 .chart { 12 height: 250px; 13 } 14 } pageview-app-nerdlet/styles.scss Copy 1 .extended-webpackrc.js Copy Reload your app to try out the text field. Get your data on a map To create the map, you use npm to install Leaflet. Step 1 of 9 Install Leaflet In your terminal, type: bash Copy $ npm install --save leaflet react-leaflet In your nerdlets styles.scss file, import the Leaflet CSS: index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { TableChart, TextField } from 'nr1'; 3 4 const accountId = 0; // Replace with your account ID 5 6 export default class PageViewApp extends React.Component { 7 constructor(props) { 8 super(props); 9 this.state = { 10 countryCode: null, 11 }; 12 } 13 14 render() { 15 const { countryCode } = this.state; 16 17 return ( 18 <div className=\"container\"> 19 <div className=\"row\"> 20 <div className=\"row\"> 21 <TextField 22 placeholder=\"US\" 23 onChange={(event) => { 24 this.setState({ countryCode: event.target.value }); 25 }} 26 /> 27 </div> 28 <TableChart 29 accountId={accountId} 30 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' ${ 31 countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' 32 } FACET countryCode, regionCode SINCE 1 week ago LIMIT 1000`} 33 fullWidth 34 className=\"chart\" 35 /> 36 </div> 37 </div> 38 ); 39 } 40 } pageview-app-nerdlet/index.js Copy 1 @import `~leaflet/dist/leaflet.css`; 2 3 .container { 4 width: 100%; 5 height: 99vh; 6 display: flex; 7 flex-direction: column; 8 .row { 9 margin: 10px; 10 display: flex; 11 flex-direction: row; 12 } 13 .chart { 14 height: 250px; 15 } 16 } pageview-app-nerdlet/styles.scss Copy 1 .extended-webpackrc.js Copy While you're in styles.scss, fix the width and height of your map: index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { TableChart, TextField } from 'nr1'; 3 4 const accountId = 0; // Replace with your account ID 5 6 export default class PageViewApp extends React.Component { 7 constructor(props) { 8 super(props); 9 this.state = { 10 countryCode: null, 11 }; 12 } 13 14 render() { 15 const { countryCode } = this.state; 16 17 return ( 18 <div className=\"container\"> 19 <div className=\"row\"> 20 <div className=\"row\"> 21 <TextField 22 placeholder=\"US\" 23 onChange={(event) => { 24 this.setState({ countryCode: event.target.value }); 25 }} 26 /> 27 </div> 28 <TableChart 29 accountId={accountId} 30 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' ${ 31 countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' 32 } FACET countryCode, regionCode SINCE 1 week ago LIMIT 1000`} 33 fullWidth 34 className=\"chart\" 35 /> 36 </div> 37 </div> 38 ); 39 } 40 } pageview-app-nerdlet/index.js Copy 1 @import `~leaflet/dist/leaflet.css`; 2 3 .container { 4 width: 100%; 5 height: 99vh; 6 display: flex; 7 flex-direction: column; 8 .row { 9 margin: 10px; 10 display: flex; 11 flex-direction: row; 12 } 13 .chart { 14 height: 250px; 15 } 16 } 17 18 .containerMap { 19 width: 100%; 20 z-index: 0; 21 height: 70vh; 22 } pageview-app-nerdlet/styles.scss Copy 1 .extended-webpackrc.js Copy Step 2 of 9 Add a webpack config file for Leaflet Add a webpack configuration file .extended-webpackrc.js to the top-level folder in your nerdpack. This supports your use of map tiling information data from Leaflet. index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { TableChart, TextField } from 'nr1'; 3 4 const accountId = 0; // Replace with your account ID 5 6 export default class PageViewApp extends React.Component { 7 constructor(props) { 8 super(props); 9 this.state = { 10 countryCode: null, 11 }; 12 } 13 14 render() { 15 const { countryCode } = this.state; 16 17 return ( 18 <div className=\"container\"> 19 <div className=\"row\"> 20 <div className=\"row\"> 21 <TextField 22 placeholder=\"US\" 23 onChange={(event) => { 24 this.setState({ countryCode: event.target.value }); 25 }} 26 /> 27 </div> 28 <TableChart 29 accountId={accountId} 30 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' ${ 31 countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' 32 } FACET countryCode, regionCode SINCE 1 week ago LIMIT 1000`} 33 fullWidth 34 className=\"chart\" 35 /> 36 </div> 37 </div> 38 ); 39 } 40 } pageview-app-nerdlet/index.js Copy 1 @import `~leaflet/dist/leaflet.css`; 2 3 .container { 4 width: 100%; 5 height: 99vh; 6 display: flex; 7 flex-direction: column; 8 .row { 9 margin: 10px; 10 display: flex; 11 flex-direction: row; 12 } 13 .chart { 14 height: 250px; 15 } 16 } 17 18 .containerMap { 19 width: 100%; 20 z-index: 0; 21 height: 70vh; 22 } pageview-app-nerdlet/styles.scss Copy 1 module.exports = { 2 module: { 3 rules: [ 4 { 5 test: /\\.(png|jpe?g|gif)$/, 6 use: [ 7 { 8 loader: 'file-loader', 9 options: {}, 10 }, 11 { 12 loader: 'url-loader', 13 options: { limit: 25000 }, 14 }, 15 ], 16 }, 17 ], 18 }, 19 }; .extended-webpackrc.js Copy Step 3 of 9 Import modules from Leaflet In index.js, import modules from Leaflet. index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { TableChart, TextField } from 'nr1'; 3 import { Map, CircleMarker, TileLayer } from 'react-leaflet'; 4 5 const accountId = 0; // Replace with your account ID 6 7 export default class PageViewApp extends React.Component { 8 constructor(props) { 9 super(props); 10 this.state = { 11 countryCode: null, 12 }; 13 } 14 15 render() { 16 const { countryCode } = this.state; 17 18 return ( 19 <div className=\"container\"> 20 <div className=\"row\"> 21 <div className=\"row\"> 22 <TextField 23 placeholder=\"US\" 24 onChange={(event) => { 25 this.setState({ countryCode: event.target.value }); 26 }} 27 /> 28 </div> 29 <TableChart 30 accountId={accountId} 31 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' ${ 32 countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' 33 } FACET countryCode, regionCode SINCE 1 week ago LIMIT 1000`} 34 fullWidth 35 className=\"chart\" 36 /> 37 </div> 38 </div> 39 ); 40 } 41 } pageview-app-nerdlet/index.js Copy 1 @import `~leaflet/dist/leaflet.css`; 2 3 .container { 4 width: 100%; 5 height: 99vh; 6 display: flex; 7 flex-direction: column; 8 .row { 9 margin: 10px; 10 display: flex; 11 flex-direction: row; 12 } 13 .chart { 14 height: 250px; 15 } 16 } 17 18 .containerMap { 19 width: 100%; 20 z-index: 0; 21 height: 70vh; 22 } pageview-app-nerdlet/styles.scss Copy 1 module.exports = { 2 module: { 3 rules: [ 4 { 5 test: /\\.(png|jpe?g|gif)$/, 6 use: [ 7 { 8 loader: 'file-loader', 9 options: {}, 10 }, 11 { 12 loader: 'url-loader', 13 options: { limit: 25000 }, 14 }, 15 ], 16 }, 17 ], 18 }, 19 }; .extended-webpackrc.js Copy Step 4 of 9 Import additional modules from New Relic One You need several more modules from New Relic One to make the Leaflet map work well. Import them with this code: index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { 3 TableChart, 4 TextField, 5 NerdGraphQuery, 6 Spinner, 7 Button, 8 BlockText, 9 } from 'nr1'; 10 import { Map, CircleMarker, TileLayer } from 'react-leaflet'; 11 12 const accountId = 0; // Replace with your account ID 13 14 export default class PageViewApp extends React.Component { 15 constructor(props) { 16 super(props); 17 this.state = { 18 countryCode: null, 19 }; 20 } 21 22 render() { 23 const { countryCode } = this.state; 24 25 return ( 26 <div className=\"container\"> 27 <div className=\"row\"> 28 <div className=\"row\"> 29 <TextField 30 placeholder=\"US\" 31 onChange={(event) => { 32 this.setState({ countryCode: event.target.value }); 33 }} 34 /> 35 </div> 36 <TableChart 37 accountId={accountId} 38 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' ${ 39 countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' 40 } FACET countryCode, regionCode SINCE 1 week ago LIMIT 1000`} 41 fullWidth 42 className=\"chart\" 43 /> 44 </div> 45 </div> 46 ); 47 } 48 } pageview-app-nerdlet/index.js Copy 1 @import `~leaflet/dist/leaflet.css`; 2 3 .container { 4 width: 100%; 5 height: 99vh; 6 display: flex; 7 flex-direction: column; 8 .row { 9 margin: 10px; 10 display: flex; 11 flex-direction: row; 12 } 13 .chart { 14 height: 250px; 15 } 16 } 17 18 .containerMap { 19 width: 100%; 20 z-index: 0; 21 height: 70vh; 22 } pageview-app-nerdlet/styles.scss Copy 1 module.exports = { 2 module: { 3 rules: [ 4 { 5 test: /\\.(png|jpe?g|gif)$/, 6 use: [ 7 { 8 loader: 'file-loader', 9 options: {}, 10 }, 11 { 12 loader: 'url-loader', 13 options: { limit: 25000 }, 14 }, 15 ], 16 }, 17 ], 18 }, 19 }; .extended-webpackrc.js Copy NerdGraphQuery lets you make multiple NRQL queries at once and is what will populate the map with data. Spinner adds a loading spinner. Button gives you button components. BlockText give you block text components. Step 5 of 9 Get data for the map Using latitude and longitude with country codes, you can put New Relic data on a map. index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { 3 TableChart, 4 TextField, 5 NerdGraphQuery, 6 Spinner, 7 Button, 8 BlockText, 9 } from 'nr1'; 10 import { Map, CircleMarker, TileLayer } from 'react-leaflet'; 11 12 const accountId = 0; // Replace with your account ID 13 14 export default class PageViewApp extends React.Component { 15 constructor(props) { 16 super(props); 17 this.state = { 18 countryCode: null, 19 }; 20 } 21 22 mapData() { 23 const { countryCode } = this.state; 24 const query = `{ 25 actor { 26 account(id: 1606862) { 27 mapData: nrql(query: \"SELECT count(*) as x, average(duration) as y, sum(asnLatitude)/count(*) as lat, sum(asnLongitude)/count(*) as lng FROM PageView FACET regionCode, countryCode WHERE appName = 'WebPortal' ${ 28 countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' 29 } LIMIT 1000 \") { 30 results 31 nrql 32 } 33 } 34 } 35 }`; 36 37 return query; 38 } 39 40 render() { 41 const { countryCode } = this.state; 42 43 return ( 44 <div className=\"container\"> 45 <div className=\"row\"> 46 <div className=\"row\"> 47 <TextField 48 placeholder=\"US\" 49 onChange={(event) => { 50 this.setState({ countryCode: event.target.value }); 51 }} 52 /> 53 </div> 54 <TableChart 55 accountId={accountId} 56 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' ${ 57 countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' 58 } FACET countryCode, regionCode SINCE 1 week ago LIMIT 1000`} 59 fullWidth 60 className=\"chart\" 61 /> 62 </div> 63 </div> 64 ); 65 } 66 } pageview-app-nerdlet/index.js Copy 1 @import `~leaflet/dist/leaflet.css`; 2 3 .container { 4 width: 100%; 5 height: 99vh; 6 display: flex; 7 flex-direction: column; 8 .row { 9 margin: 10px; 10 display: flex; 11 flex-direction: row; 12 } 13 .chart { 14 height: 250px; 15 } 16 } 17 18 .containerMap { 19 width: 100%; 20 z-index: 0; 21 height: 70vh; 22 } pageview-app-nerdlet/styles.scss Copy 1 module.exports = { 2 module: { 3 rules: [ 4 { 5 test: /\\.(png|jpe?g|gif)$/, 6 use: [ 7 { 8 loader: 'file-loader', 9 options: {}, 10 }, 11 { 12 loader: 'url-loader', 13 options: { limit: 25000 }, 14 }, 15 ], 16 }, 17 ], 18 }, 19 }; .extended-webpackrc.js Copy Step 6 of 9 Customize the map marker colors Above the mapData function, add this code to customize the map marker colors. index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { 3 TableChart, 4 TextField, 5 NerdGraphQuery, 6 Spinner, 7 Button, 8 BlockText, 9 } from 'nr1'; 10 import { Map, CircleMarker, TileLayer } from 'react-leaflet'; 11 12 const accountId = 0; // Replace with your account ID 13 14 export default class PageViewApp extends React.Component { 15 constructor(props) { 16 super(props); 17 this.state = { 18 countryCode: null, 19 }; 20 } 21 22 getMarkerColor(measure, apdexTarget = 1.7) { 23 if (measure <= apdexTarget) { 24 return '#11A600'; 25 } else if (measure >= apdexTarget && measure <= apdexTarget * 4) { 26 return '#FFD966'; 27 } else { 28 return '#BF0016'; 29 } 30 } 31 32 mapData() { 33 const { countryCode } = this.state; 34 const query = `{ 35 actor { 36 account(id: 1606862) { 37 mapData: nrql(query: \"SELECT count(*) as x, average(duration) as y, sum(asnLatitude)/count(*) as lat, sum(asnLongitude)/count(*) as lng FROM PageView FACET regionCode, countryCode WHERE appName = 'WebPortal' ${ 38 countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' 39 } LIMIT 1000 \") { 40 results 41 nrql 42 } 43 } 44 } 45 }`; 46 47 return query; 48 } 49 50 render() { 51 const { countryCode } = this.state; 52 53 return ( 54 <div className=\"container\"> 55 <div className=\"row\"> 56 <div className=\"row\"> 57 <TextField 58 placeholder=\"US\" 59 onChange={(event) => { 60 this.setState({ countryCode: event.target.value }); 61 }} 62 /> 63 </div> 64 <TableChart 65 accountId={accountId} 66 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' ${ 67 countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' 68 } FACET countryCode, regionCode SINCE 1 week ago LIMIT 1000`} 69 fullWidth 70 className=\"chart\" 71 /> 72 </div> 73 </div> 74 ); 75 } 76 } pageview-app-nerdlet/index.js Copy 1 @import `~leaflet/dist/leaflet.css`; 2 3 .container { 4 width: 100%; 5 height: 99vh; 6 display: flex; 7 flex-direction: column; 8 .row { 9 margin: 10px; 10 display: flex; 11 flex-direction: row; 12 } 13 .chart { 14 height: 250px; 15 } 16 } 17 18 .containerMap { 19 width: 100%; 20 z-index: 0; 21 height: 70vh; 22 } pageview-app-nerdlet/styles.scss Copy 1 module.exports = { 2 module: { 3 rules: [ 4 { 5 test: /\\.(png|jpe?g|gif)$/, 6 use: [ 7 { 8 loader: 'file-loader', 9 options: {}, 10 }, 11 { 12 loader: 'url-loader', 13 options: { limit: 25000 }, 14 }, 15 ], 16 }, 17 ], 18 }, 19 }; .extended-webpackrc.js Copy Feel free to change the HTML color code values to your taste. In this example, #11A600 is green, #FFD966 is sort of yellow, and #BF0016 is red. Step 7 of 9 Set your map's default center point Set a default center point for your map using latitude and longitude. index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { 3 TableChart, 4 TextField, 5 NerdGraphQuery, 6 Spinner, 7 Button, 8 BlockText, 9 } from 'nr1'; 10 import { Map, CircleMarker, TileLayer } from 'react-leaflet'; 11 12 const accountId = 0; // Replace with your account ID 13 14 export default class PageViewApp extends React.Component { 15 constructor(props) { 16 super(props); 17 this.state = { 18 countryCode: null, 19 }; 20 } 21 22 getMarkerColor(measure, apdexTarget = 1.7) { 23 if (measure <= apdexTarget) { 24 return '#11A600'; 25 } else if (measure >= apdexTarget && measure <= apdexTarget * 4) { 26 return '#FFD966'; 27 } else { 28 return '#BF0016'; 29 } 30 } 31 32 mapData() { 33 const { countryCode } = this.state; 34 const query = `{ 35 actor { 36 account(id: 1606862) { 37 mapData: nrql(query: \"SELECT count(*) as x, average(duration) as y, sum(asnLatitude)/count(*) as lat, sum(asnLongitude)/count(*) as lng FROM PageView FACET regionCode, countryCode WHERE appName = 'WebPortal' ${ 38 countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' 39 } LIMIT 1000 \") { 40 results 41 nrql 42 } 43 } 44 } 45 }`; 46 47 return query; 48 } 49 50 render() { 51 const { countryCode } = this.state; 52 const defaultMapCenter = [10.5731, -7.5898]; 53 54 return ( 55 <div className=\"container\"> 56 <div className=\"row\"> 57 <div className=\"row\"> 58 <TextField 59 placeholder=\"US\" 60 onChange={(event) => { 61 this.setState({ countryCode: event.target.value }); 62 }} 63 /> 64 </div> 65 <TableChart 66 accountId={accountId} 67 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' ${ 68 countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' 69 } FACET countryCode, regionCode SINCE 1 week ago LIMIT 1000`} 70 fullWidth 71 className=\"chart\" 72 /> 73 </div> 74 </div> 75 ); 76 } 77 } pageview-app-nerdlet/index.js Copy 1 @import `~leaflet/dist/leaflet.css`; 2 3 .container { 4 width: 100%; 5 height: 99vh; 6 display: flex; 7 flex-direction: column; 8 .row { 9 margin: 10px; 10 display: flex; 11 flex-direction: row; 12 } 13 .chart { 14 height: 250px; 15 } 16 } 17 18 .containerMap { 19 width: 100%; 20 z-index: 0; 21 height: 70vh; 22 } pageview-app-nerdlet/styles.scss Copy 1 module.exports = { 2 module: { 3 rules: [ 4 { 5 test: /\\.(png|jpe?g|gif)$/, 6 use: [ 7 { 8 loader: 'file-loader', 9 options: {}, 10 }, 11 { 12 loader: 'url-loader', 13 options: { limit: 25000 }, 14 }, 15 ], 16 }, 17 ], 18 }, 19 }; .extended-webpackrc.js Copy Step 8 of 9 Add a row for your map Between the text field row and the table chart row, insert a new row for the map content using NerdGraphQuery. index.js styles.scss .extended-webpackrc.js 1 import React from 'react'; 2 import { 3 TableChart, 4 TextField, 5 NerdGraphQuery, 6 Spinner, 7 Button, 8 BlockText, 9 } from 'nr1'; 10 import { Map, CircleMarker, TileLayer } from 'react-leaflet'; 11 12 const accountId = 0; // Replace with your account ID 13 14 export default class PageViewApp extends React.Component { 15 constructor(props) { 16 super(props); 17 this.state = { 18 countryCode: null, 19 }; 20 } 21 22 getMarkerColor(measure, apdexTarget = 1.7) { 23 if (measure <= apdexTarget) { 24 return '#11A600'; 25 } else if (measure >= apdexTarget && measure <= apdexTarget * 4) { 26 return '#FFD966'; 27 } else { 28 return '#BF0016'; 29 } 30 } 31 32 mapData() { 33 const { countryCode } = this.state; 34 const query = `{ 35 actor { 36 account(id: 1606862) { 37 mapData: nrql(query: \"SELECT count(*) as x, average(duration) as y, sum(asnLatitude)/count(*) as lat, sum(asnLongitude)/count(*) as lng FROM PageView FACET regionCode, countryCode WHERE appName = 'WebPortal' ${ 38 countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' 39 } LIMIT 1000 \") { 40 results 41 nrql 42 } 43 } 44 } 45 }`; 46 47 return query; 48 } 49 50 render() { 51 const { countryCode } = this.state; 52 const defaultMapCenter = [10.5731, -7.5898]; 53 54 return ( 55 <div className=\"container\"> 56 <div className=\"row\"> 57 <div className=\"row\"> 58 <TextField 59 placeholder=\"US\" 60 onChange={(event) => { 61 this.setState({ countryCode: event.target.value }); 62 }} 63 /> 64 </div> 65 <div className=\"row\"> 66 <NerdGraphQuery query={this.mapData()}> 67 {({ loading, error, data }) => { 68 if (loading) { 69 return <Spinner fillContainer />; 70 } 71 if (error) { 72 return 'Error'; 73 } 74 const { results } = data.actor.account.mapData; 75 console.debug(results); 76 return 'Hello'; 77 }} 78 </NerdGraphQuery> 79 </div> 80 <TableChart 81 accountId={accountId} 82 query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' ${ 83 countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' 84 } FACET countryCode, regionCode SINCE 1 week ago LIMIT 1000`} 85 fullWidth 86 className=\"chart\" 87 /> 88 </div> 89 </div> 90 ); 91 } 92 } pageview-app-nerdlet/index.js Copy 1 @import `~leaflet/dist/leaflet.css`; 2 3 .container { 4 width: 100%; 5 height: 99vh; 6 display: flex; 7 flex-direction: column; 8 .row { 9 margin: 10px; 10 display: flex; 11 flex-direction: row; 12 } 13 .chart { 14 height: 250px; 15 } 16 } 17 18 .containerMap { 19 width: 100%; 20 z-index: 0; 21 height: 70vh; 22 } pageview-app-nerdlet/styles.scss Copy 1 module.exports = { 2 module: { 3 rules: [ 4 { 5 test: /\\.(png|jpe?g|gif)$/, 6 use: [ 7 { 8 loader: 'file-loader', 9 options: {}, 10 }, 11 { 12 loader: 'url-loader', 13 options: { limit: 25000 }, 14 }, 15 ], 16 }, 17 ], 18 }, 19 }; .extended-webpackrc.js Copy Reload your application in New Relic One to test that it works. Step 9 of 9 Replace \"Hello\" with the Leaflet code Replace return \"Hello\"; with: index.js styles.scss .extended-webpackrc.js import React from 'react'; import { TableChart, TextField, NerdGraphQuery, Spinner, Button, BlockText, } from 'nr1'; import { Map, CircleMarker, TileLayer } from 'react-leaflet'; const accountId = 0; // Replace with your account ID export default class PageViewApp extends React.Component { constructor(props) { super(props); this.state = { countryCode: null, }; } getMarkerColor(measure, apdexTarget = 1.7) { if (measure <= apdexTarget) { return '#11A600'; } else if (measure >= apdexTarget && measure <= apdexTarget * 4) { return '#FFD966'; } else { return '#BF0016'; } } mapData() { const { countryCode } = this.state; const query = `{ actor { account(id: 1606862) { mapData: nrql(query: \"SELECT count(*) as x, average(duration) as y, sum(asnLatitude)/count(*) as lat, sum(asnLongitude)/count(*) as lng FROM PageView FACET regionCode, countryCode WHERE appName = 'WebPortal' ${ countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' } LIMIT 1000 \") { results nrql } } } }`; return query; } render() { const { countryCode } = this.state; const defaultMapCenter = [10.5731, -7.5898]; return ( <div className=\"container\"> <div className=\"row\"> <div className=\"row\"> <TextField placeholder=\"US\" onChange={(event) => { this.setState({ countryCode: event.target.value }); }} /> </div> <div className=\"row\"> <NerdGraphQuery query={this.mapData()}> {({ loading, error, data }) => { if (loading) { return <Spinner fillContainer />; } if (error) { return 'Error'; } const { results } = data.actor.account.mapData; console.debug(results); return ( <Map className=\"containerMap\" center={defaultMapCenter} zoom={2} zoomControl > <TileLayer attribution='&copy OpenStreetMap contributors' url=\"https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\" /> {results.map((pt, i) => { const center = [pt.lat, pt.lng]; return ( <CircleMarker key={`circle-${i}`} center={center} color={this.getMarkerColor(pt.y)} radius={Math.log(pt.x) * 3} onClick={() => { alert(JSON.stringify(pt)); }} /> ); })} </Map> ); }} </NerdGraphQuery> </div> <TableChart accountId={accountId} query={`FROM PageView SELECT count(*), average(duration) WHERE appName = 'WebPortal' ${ countryCode ? ` WHERE countryCode like '%${countryCode}%' ` : '' } FACET countryCode, regionCode SINCE 1 week ago LIMIT 1000`} fullWidth className=\"chart\" /> </div> </div> ); } } pageview-app-nerdlet/index.js Copy 1 @import `~leaflet/dist/leaflet.css`; 2 3 .container { 4 width: 100%; 5 height: 99vh; 6 display: flex; 7 flex-direction: column; 8 .row { 9 margin: 10px; 10 display: flex; 11 flex-direction: row; 12 } 13 .chart { 14 height: 250px; 15 } 16 } 17 18 .containerMap { 19 width: 100%; 20 z-index: 0; 21 height: 70vh; 22 } pageview-app-nerdlet/styles.scss Copy 1 module.exports = { 2 module: { 3 rules: [ 4 { 5 test: /\\.(png|jpe?g|gif)$/, 6 use: [ 7 { 8 loader: 'file-loader', 9 options: {}, 10 }, 11 { 12 loader: 'url-loader', 13 options: { limit: 25000 }, 14 }, 15 ], 16 }, 17 ], 18 }, 19 }; .extended-webpackrc.js Copy This code creates a world map centered on the latitude and longitude you chose using OpenStreetMap data and your marker colors. Reload your app to see the pageview data on the map!",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 91.115234,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> views by region in a custom app",
        "sections": "Map <em>page</em> views by region in a custom app",
        "info": "Build a New Relic app showing <em>page</em> view data on a world map.",
        "tags": "<em>page</em> views",
        "body": "New Relic has powerful and flexible tools for building custom apps and populating them with data. This guide shows you how to build a custom app and populate it with <em>page</em> view data using New Relic&#x27;s Query Language (NRQL - pronounced &#x27;nurkle&#x27;). Then you make your data interactive. And last, if you"
      },
      "id": "6091fa3b196a67ac08d52a1a"
    }
  ],
  "/docs/style-guide/article-templates/troubleshooting-docs-guide": [
    {
      "sections": [
        "Add to data dictionary",
        "Data dictionary structure",
        "Add a new data type",
        "Add attributes",
        "Attribute style guidelines",
        "Using units of measurement"
      ],
      "title": "Add to data dictionary",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "32b8cab502883cc3443e54c86a0bd4021cc5a10f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/data-dictionary-style-guidelines/",
      "published_at": "2021-05-21T16:33:39Z",
      "updated_at": "2021-04-28T03:20:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use the data dictionary to provide information about data types (for example, Transaction, Metric, Log) and attached attributes. This is exposed in the New Relic query experience, on hovering over the data types and attributes. And we also expose the dictionary to the public. This doc contains info on how to add data to the dictionary. Note that currently we don't have infrastructure integration data in the dictionary. We also have very few attributes for the Metric data type, just a few basic default ones, despite there being many potential attributes attached to that data type depending on what the data source is. Data dictionary structure The data in the data dictionary is structured like this: Data types: sometimes called \"events\" for historical reasons, these are the NRDB data objects, like Transaction, Metric, Log, Span, etc. Attributes: these are key:value pairs attached to data types. One attribute can have multiple data types listed for it. For example, appName is on multiple data types. Data source: The New Relic product from which the data originates. With the current implementation, a data type must have a single data source assigned. This isn't ideal, as theoretically a data type can come from multiple sources. Add a new data type To add a new data type: Make a new folder in this directory, alongside the other directories: /docs-website/tree/develop/src/data-dictionary/events Copy Duplicate a data type file (for example, this Metric data type), place it in the new folder, and fill it out with the new info. For how to add attributes on a new data type, keep reading. Add attributes To add attributes: Our goal is to avoid adding redundant attributes entries, so you should first check to see if there's an existing attribute that has the same name and same general definition as the one you're trying to add. If it exists, edit that file to include the new data type (under events:). If an existing attribute is fairly close in definition but not exact, try to edit the definition so it works for all associated data types. If there is no existing attribute, create a new one. The easiest way is to copy an existing attribute file, edit all relevant fields to be accurate, and place it in the folder of the data type it's attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see Style. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute style guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes on this: Feel free to use sentence fragments. Feel free to edit definitions submitted from internal teams as sometimes their definitions will be overly long or have unneeded links. Some attributes are only present in some situations (for example, when a specific APM agent is used, or when a specific config option is true). If it's easy to include that detail in the short description, do so, but it's not required. Write so it reads well as plain text. Details on this: Note that the docs site data dictionary has our usual docs styles available, but the query UI definitions have no styling available. This means that you should write definitions so that they are understandable without any styling, as plain text. You can often avoid any need for styling (for example, data types like Transaction are easy to understand as plain text, as are most phrasings that use attribute names or values. When plain text makes something too ambiguous and you need some styling, use single quotes to indicate attributes or values (for example, a definition like: Reported when 'category' is 'http'). We should avoid links because those aren't visible in the query UI; the query UI only displays plain text. However, every attribute entry in the query UI does display a link 'See attribute in docs' that links to the docs site entry. This means that we can use links provided that they will display in an easy to understand way in the query UI. For example, here's an example of an attribute that would read clearly in plain text despite not having a link. We should avoid using a link format like \"For more information, see Create an alert condition\", because it wouldn't read well in plain text, and would choose something like \"For more information, see our alert condition docs.\" Using units of measurement Attribute entries have an optional unit of measurement field in the front matter. For example, here the front matter for an attribute with a percent unit of measurement: --- name: cpuPercent type: attribute units: percentage (%) events: - ProcessSample --- Copy What unit of measurement to select for an attribute is sometimes obvious, like if the attribute value is measured in milliseconds (units: milliseconds (ms)) or seconds (units: seconds (s)) or a percentage (units: percentage (%)). We also have several units of measurement that are not obvious, like count, enum, rate, and ID. (Technically, these aren't actually \"units of measurement\" and are more just conceptual data types but we're doing it this way as a workaround so you can ignore the fact that units of measurement isn't actually accurate.) The main reason we want to specify this information is that this will control what kinds of queries or charts can be created or auto-suggested by New Relic. For example, the New Relic UI wouldn't want to auto-suggest a chart graphing the average of ID values because that wouldn't make any sense. So attributes with accurate units, such as data types, will help product provide more practical help/suggestions to customers in future. Here are some tips for the non-obvious unit types: count: This is a count of something, though not a count of time-based units. For a number to be a count, it must (a) only be capable of increasing during a given time/sampling period, and (b) have a theoretically uncapped range. This wouldn't be used for a count of time units; if it was a count of seconds, for example, you would just use 'seconds' as the unit of measurement. A couple of examples of a count: databaseCallCount threadConcurrency enum: enum is short for enumerated list. In other words, it is a specific range of numbers that represent other non-numeric elements. For example, an attribute that had HTTP error codes (404, 505, etc.) as possible values would be an enum. A range of numbers that represent color codes would be another example of an enum. (Theoretically, an enum can represent lists without numeric values but we have no need to categorize strings so we only care about numeric-value lists.) Example: httpResponsecode. rate: Use this for any rate (for example, count per second). These are typically for averaged rates over small units of time, like second or millisecond. We previously have used the unit of time for these attributes (for example, using seconds as the unit of measurement for a count per second rate), but now we want to use rate for these. This is necessary because the types of displays used for rates would be different than the types of displays used for a simpler duration/count measurement. Example: MySQL integration attribute db.innodb.dataReadBytesPerSecond, which has the definition \"Rate at which data is read from InnoDB tables in bytes per second.\" id: Use ID for any identification number attribute. Example: appId.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 278.75125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Attribute <em>style</em> <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ". For more on that, see <em>Style</em>. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute <em>style</em> guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes"
      },
      "id": "6050b4da64441f84f1532199"
    },
    {
      "sections": [
        "Basic doc template",
        "Section example",
        "Code example",
        "List example",
        "Table example"
      ],
      "title": "Basic doc template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "8949f5c550b7fcab6ec76ca68fa8dd5ec2ed188f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/basic-doc-template/",
      "published_at": "2021-05-21T16:32:47Z",
      "updated_at": "2021-04-05T08:04:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the formatting tips in this template to organize the docs you create on the Docs site. Then replace the template information with your own text, lists, and tables as needed. Before you create sections, start your doc with a brief introduction, usually no more than a paragraph, that helps readers understand what your doc will cover. Your introduction (and the structure of your doc) should help readers understand within ten seconds whether they are in the right place. Section example Begin each section with a meaningful H2 title. The Docs site uses these to generate the contents, which appears automatically in the left navigation. If you want to include a screenshot with the section, provide a permalink for the Docs team to create the image for you. Due to security requirements, the Docs team manages all images on the Docs site. Code example def article_url(category, article, options={}) url_for(options.reverse_merge( :controller => 'articles';, :action => 'show', :category => category, :article => article )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add require('newrelic'); as the first line of your app's main module. Use the command npm install newrelic --save for each application you want to monitor. For unordered lists, use bullets (ul in HTML or * in Markdown). For example: Black White For complex lists, consider using collapsers. Table example Tables help organize detailed lists so the information is easier to skim. Tables are easier to manage in HTML. For exammple: <table> <thead> <tr> <th width={200}> **Item** </th> <th> **Requirements** </th> </tr> </thead> <tbody> <tr> <td> Some thing </td> <td> More detailed information about it </td> </tr> <tr> <td> Another thing </td> <td> More detailed information about another thing </td> </tr> </tbody> </table> Copy Tables created in Markdown use three or more hyphens --- to create each column’s header, and pipes | to separate each column. For example: | Item | Requirements ------------ | ------------ | Some thing | More detailed information about it | Another thing | More detailed information about another thing Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.52463,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Basic doc <em>template</em>",
        "sections": "Basic doc <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " <em>article</em>_url(category, <em>article</em>, options={}) url_for(options.reverse_merge( :controller =&gt; &#x27;articles&#x27;;, :action =&gt; &#x27;show&#x27;, :category =&gt; category, :<em>article</em> =&gt; <em>article</em> )) end Copy List example For multi-step, actionable procedures, use ordered lists (ol in HTML or numbers in Markdown). For example: Add"
      },
      "id": "6042212b64441f49134e886d"
    },
    {
      "sections": [
        "GraphQL API tutorial template",
        "Example query #1 with GraphQL",
        "Example query #2 with GraphQL",
        "Example query #3 with GraphQL"
      ],
      "title": "GraphQL API tutorial template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "9a7f90194f75eb7e347f54e7cc090d177cd39875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/graphql-api-tutorial-template/",
      "published_at": "2021-05-21T16:33:39Z",
      "updated_at": "2021-03-16T13:08:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a template. Feel free to copy the text in this template to create your own GraphQL API tutorial, then fill in details that will help users learn how to use GraphQL in practical ways. Ideally the final version of your GraphQL doc will include: An introduction paragraph describing what problem or use case the users want to solve, or why the API can help them query to get this data Three to five query examples that show interesting data they can get from GraphQL Sample intro paragraph: You can use the New Relic GraphQL API to [ add key use cases here]. To construct these queries and see responses, you can use the New Relic GraphQL Explorer. This document explains some of the available functions to query [ data to be queried]. Example query #1 with GraphQL Add a description here for your example query. Tell users why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #2 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries. Example query #3 with GraphQL Add a description here for your example query. Tell the customer why they want to query this kind of data. Fill out the first block with your code, and the second with the data returned by the query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This query returns the following: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your data. Use the New Relic GraphQL Explorer to experiment with queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.7947,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "GraphQL API tutorial <em>template</em>",
        "sections": "GraphQL API tutorial <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "6042212b196a67f5d6a83dbf"
    }
  ],
  "/docs/style-guide/get-started/introduction-style-guide": [
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-05-21T16:41:03Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.13454,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "Basic <em>style</em> <em>guide</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    },
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-05-21T14:30:16Z",
      "updated_at": "2021-05-06T04:01:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right-click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also mouse over. collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account The primary account in a New Relic account with sub-accounts. Refer to a master's subordinate accounts as sub-accounts, not children or slaves. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account Don't use. See master account. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of Browser docs. Often abbreviated as RUM, this is a generic industry term for Browser monitoring. New Relic refers to this as page load timing (in Browser docs) or New Relic Browser (in non-Browser docs). Within Browser docs, use this term only for SEO or clarification, never to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures. However, avoid using generic “you” or “your” when permissions are involved, because we can't assume what permissions the user has. For example, we can't just say “you can add and remove users from your account settings” when that is actually an Owner or Admin level capability. When permissions are relevant, use a permissions callout.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.27817,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>introduction</em>",
        "tags": "Basic <em>style</em> <em>guide</em>",
        "body": "You can use this dictionary to <em>guide</em> your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft <em>Style</em> <em>Guide</em>, but we&#x27;ll use Chicago Manual of <em>Style</em> in a pinch. We also follow American English"
      },
      "id": "60421ec1196a676986a83d87"
    },
    {
      "sections": [
        "Introduction to the query builder",
        "Important",
        "Why it matters",
        "Get started",
        "Use the query builder: basic and advanced modes",
        "Tip",
        "Basic mode",
        "Advanced (NRQL) mode",
        "Advanced (PromQL-style) mode",
        "Use your charts"
      ],
      "title": "Introduction to the query builder",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "5d862557e0e3f4ef89dbd7da6ffdbe0d358790d2",
      "image": "https://docs.newrelic.com/static/30b623e8356b28b9361bedb0813db4c6/8c557/querybuilder04.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/introduction-query-builder/",
      "published_at": "2021-05-22T05:32:51Z",
      "updated_at": "2021-05-15T22:25:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the query builder, you can run queries of your data to create custom charts and other visualizations. You can also build custom dashboards containing multiple charts. Important Are you a New Relic Insights user? See our transition guide. Why it matters Modern business systems are a complex maze of data-generating elements. You need an easy, solid way to fetch, analyze, and visualize the never-ending stream of data flowing from your daily working activities. Use the query builder to: Quickly access your data and build customized charts to learn and understand the health of your infrastructure, applications, and other services. Add charts to your dashboards to obtain a complete real-time view of the state of your system. Share your charts with colleagues or users in just two clicks. Get acquainted with querying by using basic mode, then switch to advanced mode to refine your charts using NRQL. Get started Before querying, you may want to read Introduction to querying and how to explore your data. To find the query builder, go to one.newrelic.com and click Query your data. Use the query builder: basic and advanced modes The query builder has several modes: Basic mode Advanced (NRQL) mode Advanced (PromQL-style) mode Tip You can also switch to the Data explorer tab at any time to browse your data and create charts visually, without performing queries. Basic mode Basic mode doesn't require a query language, and so it's useful if you aren't familiar with NRQL or SQL. It's also a quick way to answer one-off questions, such as how many cities outside of the United States are accessing the shopping site for your company. one.newrelic.com > Query your data > Query builder > Basic mode Use basic mode to guide you through the process to specify data for a chart. With basic mode you can: Choose your data source. In basic mode, you start by selecting an event and then picking the attribute that corresponds to the information to show in your chart. Specify (filter) the data for your chart. You can narrow the results and choose an attribute to facet by. Select the time range to present in the chart. You can select a time range from the menu or use the custom option to create your own time range. See Use basic mode for more information about this feature. Advanced (NRQL) mode With the advanced (NRQL) mode you can create your own queries using the NRQL query language. NRQL queries may be simple or complex, depending on what data you want to use and how to display it in your chart. This example of the advanced mode shows the NRQL query with the same data as used in basic mode. one.newrelic.com > Query your data > Query builder > Advanced (NRQL). Use advanced (NRQL) mode to write a query that specifies data for a chart. Tip With APM's real time streaming, you can query and visualize your data for transactions, errors, and custom events in dashboards. See Use advanced (NRQL) mode for more information about using this feature. Advanced (PromQL-style) mode With the advanced (PromQL-style) mode you can run basic PromQL-style queries. You can switch between basic and advanced modes while defining your query in order to: customize some of the values. learn how NRQL queries are structured using the data you specified in basic mode. Important If you build your query in basic mode and update it using advanced mode, you cannot return to basic mode to edit that query. You must make any additional changes in advanced (NRQL) mode. Once you specify the data you want, your chart is ready to view. Your query automatically runs in basic mode as you make changes to the inputs. If using advanced (NRQL or PromQL-style) mode, run your query. Use your charts Once you have built your chart you can: Change the type of chart. Based on the data you specified, the query builder selects the chart type that displays your results most effectively. However, you can choose from other available chart types to present your data in the visual format that you want to use. Share your chart. Add your chart to a dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.51472,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> <em>to</em> <em>the</em> query builder",
        "sections": "<em>Introduction</em> <em>to</em> <em>the</em> query builder",
        "body": "With the query builder, you can run queries of your data to create custom charts and other visualizations. You can also build custom dashboards containing multiple charts. Important Are you a New Relic Insights user? See our transition <em>guide</em>. Why it matters Modern business systems are a complex"
      },
      "id": "603ec08f196a67f7b7a83dd2"
    }
  ],
  "/docs/style-guide/processes-procedures/delete-document": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-05-21T16:38:52Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.43533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and <em>style</em> of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-05-21T16:36:25Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.75305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures you would use the docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures&#x2F;images directory. If the images directory does"
      },
      "id": "604220ec196a67105da83dc2"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-05-21T16:35:31Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.40042,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or Docs site contributor"
      },
      "id": "604220b2196a6775f5a83dc0"
    }
  ],
  "/docs/style-guide/processes-procedures/docs-site-edit-checklist": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-05-21T16:38:52Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.43533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and <em>style</em> of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-05-21T16:36:25Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.75305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures you would use the docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures&#x2F;images directory. If the images directory does"
      },
      "id": "604220ec196a67105da83dc2"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-05-21T16:37:17Z",
      "updated_at": "2021-03-16T14:19:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based on its filename and filepath in the GitHub repository. For example, this is the filename and path for Rename or redirect a document: /docs/style-guide/processes-procedures/rename-or-redirect-document.mdx Copy The URL is: https://docs.newrelic.com/style-guide/processes-procedures/rename-or-redirect-document Copy If you rename a document's filename or change its path by moving it to a new directory, make sure to add a redirect to its old filepath. To change the document's location in the left navigation, update the navigation configuration file. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update the title in the left navigation, edit the yml file for the section that you're in. For example, the Style guide docs use /src/nav/style-guide.yml. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.12503,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " a document: &#x2F;docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-<em>procedures</em>&#x2F;rename-or-redirect-document.mdx Copy The URL is: https:&#x2F;&#x2F;docs.newrelic.com&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-<em>procedures</em>&#x2F;rename-or-redirect-document Copy If you rename a document&#x27;s filename or change its path by moving it to a new directory, make sure to add"
      },
      "id": "604220ec196a670d0ba83dd4"
    }
  ],
  "/docs/style-guide/processes-procedures/edit-homepage": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-05-21T16:38:52Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.04082,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Page</em> templates",
        "body": " service. For more information, see Work with attribute definition content type. <em>Landing</em> <em>pages</em> This format is for a more user-friendly and readable <em>landing</em> <em>page</em>, which replaces the standard taxonomy list views. For more information, see Working with <em>landing</em> <em>pages</em>. Release notes This format includes"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/landing-page-template/",
      "sections": [
        "Landing page template",
        "Important",
        "Front matter",
        "Tip",
        "Introduction section",
        "Tiles",
        "Button for viewing all docs in the category",
        "Code sample"
      ],
      "published_at": "2021-05-21T16:34:36Z",
      "title": "Landing page template",
      "updated_at": "2021-04-12T11:25:05Z",
      "type": "docs",
      "external_id": "c40093f49b3daaa82483e1f82228c53a3b12ad6c",
      "document_type": "page",
      "popularity": 1,
      "body": "Landing pages are a specialized type of page that serve as the starting pages for various New Relic products. For example, you'll see landing pages for Application monitoring (APM) and Browser monitoring. Important This landing page information does not apply to the docs home page. If you need to create a new landing page, you can either copy an existing landing page, or you can modify the sample landing page shown at the bottom. The next sections look at what you need to include for each landing page. Front matter When you insert the front matter, be sure to designate the type as landingPage. Here's an example: --- title: New Relic APM type: landingPage --- Copy Tip In the front matter, the following are optional: tags, translate, and redirects. So, you can leave them out if they don't have any values. Introduction section Following the front matter, the first content section is a two-column introduction (also called the hero section). This includes the following: A <LandingPageHero> component wrapping all the introductory content. A <HeroContent> component wrapping the text portion of the introduction (the content in the left column). An image or video (appears in the right column). A caption (optional), which is wrapped by the <figcaption> component. Here's an example of the hero section that shows you where to insert your content: <LandingPageHero> <HeroContent> INSERT_PARAGRAPHS_FOR_YOUR_INTRODUCTION </HeroContent> ![INSERT_ALT-TEXT_HERE](./images/INSERT_IMAGE_FILE_NAME.png \"INSERT_THE_IMAGE_TITLE_HERE\") <figcaption> INSERT_OPTIONAL_CAPTION_USING_SAME_INDENTATION_AS_IMAGE </figcaption> </LandingPageHero> Copy Tiles Tiles are a series of boxes after the introduction. They contain the main subject areas for your product. You should just list these in order you want them to appear, and the cascading style sheet will render them across the page. Here's an example of a tile: <LandingPageTileGrid> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE.\" href=\"/docs/INSERT_THE_DIRECTORY_PATH_TO_THE_TARGET_LANDING_PAGE_INDEX.HTML\" icon=\"fe-INSERT_THE_ICON_NAME\" > INSERT_TILE_CONTENT_HERE... </LandingPageTile> ... Copy For each tile, do the following: Insert a value for title that explains the purpose of the category. Insert a value for href that links to the target landing page. If the target landing page is index.html, you can just include the directory path with no filename since index.html is the default (it doesn't cause any problems if you include index.html). Insert a value for icon by prefixing the icon name with fe- (Feather icons), logo- (third-party logos), or nr- (New Relic logos). For example, here is the format for a feather icon: fe-alert-triangle). Tip For more details about icons, see Embed images. Between the LandingPageTile tags, insert text, such as a bullet list with links to product documentation. Button for viewing all docs in the category After your tiles, you should have a single button that offers to take users to all the documentation for that category. The table of contents page that gets linked here is always at the same path as the landing page, but with /table-of-contents appended to it. These table of contents pages get built automatically for every landing page. For example, if this landing page was located at /docs/apm, this link should be /docs/apm/table-of-contents. Here's an example: <ButtonLink role=\"button\" to=\"INSERT_LINK_TO_DIRECTORY_WITH_ALL_THESE_DOCS/table-of-contents\" variant=\"normal\" > View all INSERT_YOUR_CATEGORY_HERE docs </ButtonLink> Copy Code sample Here's a sample landing page you could modify to suit your needs: --- title: INSERT_YOUR_TITLE_HERE type: landingPage --- <LandingPageHero> <HeroContent> INSERT_PARAGRAPHS_FOR_YOUR_INTRODUCTION </HeroContent> ![INSERT_ALT-TEXT_HERE](./images/INSERT_IMAGE_FILE_NAME.png \"INSERT_THE_IMAGE_TITLE_HERE\") <figcaption> INSERT_OPTIONAL_CAPTION_USING_SAME_INDENTATION_AS_IMAGE </figcaption> </LandingPageHero> <LandingPageTileGrid> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * [INSERT_LINK_NAME](INSERT_LINK_URL) Aliquam auctor mattis nisl ut iaculis. * [INSERT_LINK_NAME](INSERT_LINK_URL) Suspendisse pharetra elit sit amet risus euismod, a consectetur tortor vulputate. </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) to lectus diam, ornare vitae dui suscipit, laoreet ultrices lacus. * Mauris tempor massa ac augue mattis, nec pharetra quam mollis [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) rhoncus tortor vitae libero laoreet feugiat. * Donec dui elit, fermentum vel faucibus sed, rhoncus in felis [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) uspendisse pharetra elit sit amet risus euismod. * Pellentesque finibus magna vitae hendrerit gravida [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) Etiam imperdiet felis eu ipsum consequat tristique. * Etiam imperdiet felis eu ipsum consequat tristique [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) Quisque hendrerit, dolor sed sodales aliquet. * Vestibulum varius lectus ac velit euismod [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> </LandingPageTileGrid> <ButtonLink role=\"button\" to=\"INSERT_LINK_TO_DIRECTORY_WITH_ALL_THESE_DOCS/table-of-contents\" variant=\"normal\" > View all INSERT_YOUR_CATEGORY_HERE docs </ButtonLink> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 68.41161,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Landing</em> <em>page</em> template",
        "sections": "<em>Landing</em> <em>page</em> template",
        "body": "<em>Landing</em> <em>pages</em> are a specialized type of <em>page</em> that serve as the starting <em>pages</em> for various New Relic products. For example, you&#x27;ll see <em>landing</em> <em>pages</em> for Application monitoring (APM) and Browser monitoring. Important This <em>landing</em> <em>page</em> information does not apply to the docs <em>home</em> <em>page</em>. If you need"
      },
      "id": "6042212a28ccbc283feba79d"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/whats-new/2020/12/alerts-applied-intelligence-new-landing-page/",
      "sections": [
        "Alerts and Applied Intelligence new landing page"
      ],
      "published_at": "2021-05-22T14:30:32Z",
      "title": "Alerts and Applied Intelligence new landing page",
      "updated_at": "2021-03-11T00:23:50Z",
      "type": "docs",
      "external_id": "e638c09fec3d43f739db17f5f9d73466bde0ea40",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "Alerts and Applied Intelligence have a new landing page that surfaces and highlights insights and analytics about how your alert configuration is performing. If you're using Incident Intelligence, you'll find the Issue and Incident feeds on the tabs in the Overview page. The new landing page includes three tabs: Summary - An overview highlighting analytics about how your alert configuration is performing. Issues - Groups of incidents that describe the underlying problem. When a new incident is created, Applied Intelligence opens an issue and evaluates other open issues for potential correlation. By default, the feed is filtered to show only the active issues with the most recently updated at the top. Clicking on an issue opens a page with additional details specific to that issue. Incidents - Groups of events that describe the symptoms of your system over time. These symptoms are detected by monitoring tools that evaluate your data streams and events. The incident feed includes all of your environment’s issues including those from New Relic, PagerDuty, and all other supported sources. By default most recent incidents are displayed on top and clicking on an incident opens a page with additional relevant details.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 18.524614,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alerts and Applied Intelligence new <em>landing</em> <em>page</em>",
        "sections": "Alerts and Applied Intelligence new <em>landing</em> <em>page</em>",
        "body": "Alerts and Applied Intelligence have a new <em>landing</em> <em>page</em> that surfaces and highlights insights and analytics about how your alert configuration is performing. If you&#x27;re using Incident Intelligence, you&#x27;ll find the Issue and Incident feeds on the tabs in the Overview <em>page</em>. The new <em>landing</em> <em>page</em>"
      },
      "id": "60446b4228ccbc98752c60c6"
    }
  ],
  "/docs/style-guide/processes-procedures/embed-images": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-05-21T16:38:52Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.43527,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and <em>style</em> of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-05-21T16:35:31Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.4004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or Docs site contributor"
      },
      "id": "604220b2196a6775f5a83dc0"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-05-21T16:37:17Z",
      "updated_at": "2021-03-16T14:19:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based on its filename and filepath in the GitHub repository. For example, this is the filename and path for Rename or redirect a document: /docs/style-guide/processes-procedures/rename-or-redirect-document.mdx Copy The URL is: https://docs.newrelic.com/style-guide/processes-procedures/rename-or-redirect-document Copy If you rename a document's filename or change its path by moving it to a new directory, make sure to add a redirect to its old filepath. To change the document's location in the left navigation, update the navigation configuration file. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update the title in the left navigation, edit the yml file for the section that you're in. For example, the Style guide docs use /src/nav/style-guide.yml. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.12503,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " a document: &#x2F;docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-<em>procedures</em>&#x2F;rename-or-redirect-document.mdx Copy The URL is: https:&#x2F;&#x2F;docs.newrelic.com&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-<em>procedures</em>&#x2F;rename-or-redirect-document Copy If you rename a document&#x27;s filename or change its path by moving it to a new directory, make sure to add"
      },
      "id": "604220ec196a670d0ba83dd4"
    }
  ],
  "/docs/style-guide/processes-procedures/embed-videos": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-05-21T16:38:52Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.43527,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and <em>style</em> of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-05-21T16:36:25Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.75305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures you would use the docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures&#x2F;images directory. If the images directory does"
      },
      "id": "604220ec196a67105da83dc2"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-05-21T16:35:31Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.4004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or Docs site contributor"
      },
      "id": "604220b2196a6775f5a83dc0"
    }
  ],
  "/docs/style-guide/processes-procedures/include-a-doc-in-multiple-menus": [
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "ba7c99eb79d6fa7ad574db5768a742a4d2084a41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-05-21T16:34:37Z",
      "updated_at": "2021-05-10T03:34:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.2586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting <em>docs</em> guide",
        "sections": "Troubleshooting <em>docs</em> guide",
        "tags": "<em>Article</em> templates",
        "body": " the user is trying to solve. <em>Include</em> steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this <em>doc</em> via Google. If the problem text is very short, you can <em>include</em> the cause text here. Solution Generally"
      },
      "id": "6043f591196a675446960f74"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/levels-headings/",
      "sections": [
        "Levels of headings",
        "Use parallel construction",
        "Keep it short, avoid -ing words",
        "Do not use h1 headings",
        "Use level two headings to identify chunks of information",
        "Important",
        "Avoid using level three headings"
      ],
      "published_at": "2021-05-21T14:31:50Z",
      "title": "Levels of headings",
      "updated_at": "2021-05-21T14:31:50Z",
      "type": "docs",
      "external_id": "981282f676b2697e24f69ad23bce7e3412bb1d22",
      "document_type": "page",
      "popularity": 1,
      "body": "Taking some time to consider your headings and document titles will be time well spent. Titles and headings are not only important for search results, but they can make your docs easier to skim. For all headings and document titles, use sentence case. Use parallel construction Use parallel construction when naming headers. For example, use all nouns (\"Organization,\" \"Tone\"), all verbs (\"Create,\" \"Delete\"), etc. Keep it short, avoid -ing words For all headers, keep the title as short as possible. In particular, avoid headers that are more than a line long. As with all our writing, you should feel free to address the reader directly: Install the agent, for example, rather than Agent installation. You should also avoid -ing words, which add to character count without contributing clarity. Do not use h1 headings After you publish your doc, the Docs site will automatically use what you added to the Title field as the doc's level one heading (h1). To ensure that your doc is properly indexed for search, do not manually create additional h1 headings. If your doc's title is long and you would like a shorter title to appear in the sidebar menu, create a GitHub issue and we'll help you with that change. Use level two headings to identify chunks of information Organize chunks of information into sections with level two headings (##). For example: ## Create a new user [#create-new-user] Copy Important If you don't specify an ID manually, the site will use your header text as that header's ID (also known as anchor link). Create a manual ID to preserve links to that header if you change the header text. If you have too many level sections, consider splitting the document into multiple pages. Avoid using level three headings Avoid using ### headings unless it makes sense for the content or if the content is lengthy. Collapsers, tables, and other structural elements are often a better choice. Be particularly careful about level three headings that make a level two section longer than a single screen height. Here are two examples of good scenarios for using level three headings: Example #1: Events-to-metrics API doc Example #2: Infrastructure integration doc",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.89239,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Keep it short, <em>avoid</em> -<em>ing</em> words",
        "body": " feel free to address the reader directly: Install the agent, for example, rather than Agent installation. You should also avoid -ing words, which add to character count without contributing clarity. Do not use h1 headings After you publish your <em>doc</em>, the Docs site will automatically use what you added"
      },
      "id": "604221d3196a677e3aa83db4"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/five-questions-help-write-docs/",
      "sections": [
        "Five questions to help write docs",
        "There's really only 1Q",
        "5Qs and sub-questions",
        "1. Did you use or observe the thing you are writing about?",
        "2. Is this the best place to put this information?",
        "3. Can readers tell in ten seconds if they are in the right place?",
        "4. Is the information in the best possible format?",
        "5. Is the language approachable, expert, and visionary?"
      ],
      "published_at": "2021-05-21T14:31:06Z",
      "title": "Five questions to help write docs",
      "updated_at": "2021-05-16T15:37:41Z",
      "type": "docs",
      "external_id": "14fd5c4efd0e8aa26e04d97ae61da33eef9489ee",
      "document_type": "page",
      "popularity": 1,
      "body": "Our five questions form the core of how our Tech Docs team thinks about writing excellent technical documentation. Informally, we call these our 5Qs. Anyone can contribute to our Docs site. We want you to feel confident and proud that your contributions provide valuable content and quality. We also want our readers to trust and easily use the information in our docs. To help you plan, write, and edit excellent docs, ask yourself these five questions. There's really only 1Q Read on for our five questions, but before you do: Know that these questions all exist to help answer one question. Whenever you write a doc, ask yourself: What problem are we trying to solve? It's critical you know what you're trying to do and why that goal matters to your readers. Asking the five questions (and the sub-questions!) will help you ensure you're building the right thing. 5Qs and sub-questions Each of the five questions includes sub-questions to help guide your thinking. 1. Did you use or observe the thing you are writing about? Think about who your audience is and the level of complexity they need. End users' point of view Ask yourself: Audience Do you know who is reading your document (dev/ops teams, support personnel, non-technical staff, etc.)? Can you articulate what this thing is (feature, procedure) and why it matters to our customers? For conceptual info, did you interview multiple stakeholders? Testing Put yourself in the user's shoes. For example: Did you use the thing on your own? Did you watch a subject matter expert use the thing? If you can't do it on your own or observe, did you send the draft to at least three SMEs? Before publishing Did you compare the final version of your text against the thing you're writing about? 2. Is this the best place to put this information? Think about where this information belongs. Where does this information belong? Ask yourself: What problem are you trying to solve? Is text always the best answer? Does this doc need to exist at all? For example: Are we duplicating content from somewhere else in the Docs site? Are we duplicating content already in the UI? Could customers have a better experience if we modified the UI design or copy instead of creating a doc? Would another web property be a better home for this information? For example: The Explorers Hub? NRU course? NRU video embedded into the doc? The public New Relic blog? The public New Relic website? 3. Can readers tell in ten seconds if they are in the right place? Think about what the content is and what you can do to make the information easy to skim to find information. Can users skim to find information? Ask yourself: Title and headings Does the title accurately represent what's in the doc? Do the headings accurately represent what's in the doc? Do the title and headings use words the way your readers do? Do the title and headings avoid New Relic jargon? Structure Does the overall structure of the doc help readers find what they're looking for? Is the doc trying to address too many topics? When you glance at the doc, do you see short paragraphs, short sentences, and other visual aids? Or do you see a dense wall of text? Introduction Does the intro give a concise synopsis of what's in the doc? Does the intro give readers an alternate path if they're in the wrong place? 4. Is the information in the best possible format? Think about how to present the information visually. Presentation of information Ask yourself: Visual formats Did you use visual formats appropriately? Would a screenshot make any of the information easier to understand? Does your image caption clearly explain what matters so that the user does not necessarily even need to read the surrounding text? Would a diagram make any of the information easier to understand? Is there a video we could embed to make things clearer? Can step-by-step UI procedures be replaced with a \"show me\" video? Procedures Are your procedures well-structured? Do step-by-step UI procedures even need to be documented? Did you limit the procedural text to action steps and omit detailed explanatory text or edge cases? If detailed explanations need to enhance a procedure, have you organized the info in a way that expert users can skip the details? Text flow Read your draft more than once. Is the documentation direct and to the point? Did you use bullets, tables, or clamshells to improve flow? 5. Is the language approachable, expert, and visionary? Think about why the information matters and why readers will trust and use it. For more information, see the Marketing brand guidelines PDF (34.7M). (This is an internal New Relic link.) Effective language Ask yourself: Readers' point of view Did you tell users why as well as how? Can you articulate not only what this thing is (feature, procedure) and also why it matters to our customers? Did you include useful examples or use cases? Did you include information about relationships this feature has to other New Relic platform tools? Style guide resources Did you follow our style guide? Did you use our edit checklist? Did you use pronouns, contractions, and a conversational tone throughout? Did you review the usage dictionary and other resources in the style guide to make sure that terms are used correctly? Readability Is the text easy to read? Is the language clear? Do you have to reread any sentences or paragraphs to understand them? If so, can you simplify the wording and sentence structure? Does the doc score 40 or better on the Flesch-Kinkaid reading ease scale? If not, try taking another pass at the prose. But don't chase the Flesch-Kincaid score in itself: we're not out to frustrate ourselves, but to write docs that are a pleasure to read. Where to go from here Did you offer readers a clear \"next step\" in each section? If it is necessary to tell a user not to do something, did you also tell them what to do instead? Is the topic complete? Is the doc actionable?",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.16905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Five questions to help write <em>docs</em>",
        "sections": "3. Can readers tell <em>in</em> ten seconds if they <em>are</em> <em>in</em> the right place?",
        "body": ". Whenever you write a <em>doc</em>, ask yourself: What problem are we trying to solve? It&#x27;s critical you know what you&#x27;re trying to do and why that goal matters to your readers. Asking the five questions (and the sub-questions!) will help you ensure you&#x27;re building the right thing. 5Qs and sub-questions Each"
      },
      "id": "60421ef3196a676926a83d81"
    }
  ],
  "/docs/style-guide/processes-procedures/rename-or-redirect-document": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-05-21T16:38:52Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.4352,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and <em>style</em> of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-05-21T16:36:25Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.75305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures you would use the docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures&#x2F;images directory. If the images directory does"
      },
      "id": "604220ec196a67105da83dc2"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-05-21T16:35:31Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.4004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or Docs site contributor"
      },
      "id": "604220b2196a6775f5a83dc0"
    }
  ],
  "/docs/style-guide/processes-procedures/tech-writer-workflow": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-05-21T16:38:52Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.7568,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> style guide"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "ba7c99eb79d6fa7ad574db5768a742a4d2084a41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-05-21T16:34:37Z",
      "updated_at": "2021-05-10T03:34:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.78378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> style guide"
      },
      "id": "6043f591196a675446960f74"
    },
    {
      "sections": [
        "Add to data dictionary",
        "Data dictionary structure",
        "Add a new data type",
        "Add attributes",
        "Attribute style guidelines",
        "Using units of measurement"
      ],
      "title": "Add to data dictionary",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "32b8cab502883cc3443e54c86a0bd4021cc5a10f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/data-dictionary-style-guidelines/",
      "published_at": "2021-05-21T16:33:39Z",
      "updated_at": "2021-04-28T03:20:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use the data dictionary to provide information about data types (for example, Transaction, Metric, Log) and attached attributes. This is exposed in the New Relic query experience, on hovering over the data types and attributes. And we also expose the dictionary to the public. This doc contains info on how to add data to the dictionary. Note that currently we don't have infrastructure integration data in the dictionary. We also have very few attributes for the Metric data type, just a few basic default ones, despite there being many potential attributes attached to that data type depending on what the data source is. Data dictionary structure The data in the data dictionary is structured like this: Data types: sometimes called \"events\" for historical reasons, these are the NRDB data objects, like Transaction, Metric, Log, Span, etc. Attributes: these are key:value pairs attached to data types. One attribute can have multiple data types listed for it. For example, appName is on multiple data types. Data source: The New Relic product from which the data originates. With the current implementation, a data type must have a single data source assigned. This isn't ideal, as theoretically a data type can come from multiple sources. Add a new data type To add a new data type: Make a new folder in this directory, alongside the other directories: /docs-website/tree/develop/src/data-dictionary/events Copy Duplicate a data type file (for example, this Metric data type), place it in the new folder, and fill it out with the new info. For how to add attributes on a new data type, keep reading. Add attributes To add attributes: Our goal is to avoid adding redundant attributes entries, so you should first check to see if there's an existing attribute that has the same name and same general definition as the one you're trying to add. If it exists, edit that file to include the new data type (under events:). If an existing attribute is fairly close in definition but not exact, try to edit the definition so it works for all associated data types. If there is no existing attribute, create a new one. The easiest way is to copy an existing attribute file, edit all relevant fields to be accurate, and place it in the folder of the data type it's attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see Style. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute style guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes on this: Feel free to use sentence fragments. Feel free to edit definitions submitted from internal teams as sometimes their definitions will be overly long or have unneeded links. Some attributes are only present in some situations (for example, when a specific APM agent is used, or when a specific config option is true). If it's easy to include that detail in the short description, do so, but it's not required. Write so it reads well as plain text. Details on this: Note that the docs site data dictionary has our usual docs styles available, but the query UI definitions have no styling available. This means that you should write definitions so that they are understandable without any styling, as plain text. You can often avoid any need for styling (for example, data types like Transaction are easy to understand as plain text, as are most phrasings that use attribute names or values. When plain text makes something too ambiguous and you need some styling, use single quotes to indicate attributes or values (for example, a definition like: Reported when 'category' is 'http'). We should avoid links because those aren't visible in the query UI; the query UI only displays plain text. However, every attribute entry in the query UI does display a link 'See attribute in docs' that links to the docs site entry. This means that we can use links provided that they will display in an easy to understand way in the query UI. For example, here's an example of an attribute that would read clearly in plain text despite not having a link. We should avoid using a link format like \"For more information, see Create an alert condition\", because it wouldn't read well in plain text, and would choose something like \"For more information, see our alert condition docs.\" Using units of measurement Attribute entries have an optional unit of measurement field in the front matter. For example, here the front matter for an attribute with a percent unit of measurement: --- name: cpuPercent type: attribute units: percentage (%) events: - ProcessSample --- Copy What unit of measurement to select for an attribute is sometimes obvious, like if the attribute value is measured in milliseconds (units: milliseconds (ms)) or seconds (units: seconds (s)) or a percentage (units: percentage (%)). We also have several units of measurement that are not obvious, like count, enum, rate, and ID. (Technically, these aren't actually \"units of measurement\" and are more just conceptual data types but we're doing it this way as a workaround so you can ignore the fact that units of measurement isn't actually accurate.) The main reason we want to specify this information is that this will control what kinds of queries or charts can be created or auto-suggested by New Relic. For example, the New Relic UI wouldn't want to auto-suggest a chart graphing the average of ID values because that wouldn't make any sense. So attributes with accurate units, such as data types, will help product provide more practical help/suggestions to customers in future. Here are some tips for the non-obvious unit types: count: This is a count of something, though not a count of time-based units. For a number to be a count, it must (a) only be capable of increasing during a given time/sampling period, and (b) have a theoretically uncapped range. This wouldn't be used for a count of time units; if it was a count of seconds, for example, you would just use 'seconds' as the unit of measurement. A couple of examples of a count: databaseCallCount threadConcurrency enum: enum is short for enumerated list. In other words, it is a specific range of numbers that represent other non-numeric elements. For example, an attribute that had HTTP error codes (404, 505, etc.) as possible values would be an enum. A range of numbers that represent color codes would be another example of an enum. (Theoretically, an enum can represent lists without numeric values but we have no need to categorize strings so we only care about numeric-value lists.) Example: httpResponsecode. rate: Use this for any rate (for example, count per second). These are typically for averaged rates over small units of time, like second or millisecond. We previously have used the unit of time for these attributes (for example, using seconds as the unit of measurement for a count per second rate), but now we want to use rate for these. This is necessary because the types of displays used for rates would be different than the types of displays used for a simpler duration/count measurement. Example: MySQL integration attribute db.innodb.dataReadBytesPerSecond, which has the definition \"Rate at which data is read from InnoDB tables in bytes per second.\" id: Use ID for any identification number attribute. Example: appId.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.28914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> style guide"
      },
      "id": "6050b4da64441f84f1532199"
    }
  ],
  "/docs/style-guide/processes-procedures/update-left-navigation-pane": [
    {
      "sections": [
        "APM metric alert conditions",
        "Identify the entity",
        "Tip",
        "Create the NRQL alert condition"
      ],
      "title": "APM metric alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "814a7cfd5d3e929b8fab22e744b444d3e8606a00",
      "image": "https://docs.newrelic.com/static/f7794c6f3a8b598c37f31dcdd6f183b7/c1b63/nrql_condition_builder_modal.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/apm-metric-alert-conditions/",
      "published_at": "2021-05-21T18:28:40Z",
      "updated_at": "2021-05-16T08:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "While there are various ways to create APM metric alert conditions, we recommend using NRQL because this provides additional controls, improved detection time, and consistency across all data types. In 2021, we made it easier to create NRQL alert conditions from charts and queries throughout New Relic One. See below an example of how to create an APM external service condition using NRQL. Setting up an APM metric condition is a two-part process: First, you need to identify the entity, then you create the NRQL condition. Identify the entity Here's how to get started: Go to one.newrelic.com, and click APM in the toolbar. Find the service you’d like to alert on. Click on the service. In the left navigation pane, click External services. Under Top 20 external services, find the service you want and click on it. On the right side of the page, where you see graphs for Response time and External calls per minute (throughput), decide which of these two options you would like to alert on. In the upper-right corner of the graph you choose, click the three dots, and select Create alert condition. Tip If you don’t see these three dots, ensure the Show new view option at the top of the page is enabled. This launches a modal with the NRQL alert condition builder, the query is pre-populated. If you choose response time, your query may look like this: If you choose external calls per minute, your query may look like this: With your query pre-populated in the condition builder, continue to the next section to create the NRQL alert condition. Create the NRQL alert condition In the modal, complete the following: Enter a condition name. In Define your signal, observe that any LIMIT, SINCE...AGO, and TIMESERIES clauses are removed so that the NRQL query syntax is valid. Tip If no results are returned, ensure you are in the correct account by looking at the current account in the upper-left of the modal. If it's not correct, you may need to close out of the modal and double-check that the correct account is selected in the account picker in the upper-left corner of the page. Fill out the remaining fields, select or create a policy near the bottom of the form, and save your condition. See our additional information about querying APM metric timeslice data with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.19699,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ", and click APM in the toolbar. Find the service you’d like to alert on. Click on the service. In the <em>left</em> <em>navigation</em> <em>pane</em>, click External services. Under Top 20 external services, find the service you want and click on it. On the right side of the page, where you see graphs for Response time"
      },
      "id": "603e9ca1196a67b538a83dc9"
    },
    {
      "sections": [
        "Azure AD SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Add SCIM/SSO application",
        "Step 2. Configure connection",
        "Step 3. Configure provisioning rules",
        "Tip",
        "Step 4. Assign users and groups",
        "What's next?"
      ],
      "title": "Azure AD SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "d6e7f7e95daa833451159a3db4e2c4257270b5e9",
      "image": "https://docs.newrelic.com/static/0a9a32fd5041e6e2ea37cc5f032b6910/8c557/Azure_AD_Provisioning_Attribute_Mapping_2_0.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/azure-ad-scimsso-application-configuration/",
      "published_at": "2021-05-21T16:48:35Z",
      "updated_at": "2021-05-15T16:22:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Azure AD-specific details on how to configure the New Relic Azure AD SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Step 1. Add SCIM/SSO application Azure AD provides an application gallery, which includes various integrations for Azure AD, including the ones that New Relic offers. Add the New Relic SCIM/SSO application to your list of applications. Go to the Azure Active Directory admin center, and sign in if necessary. aad.portal.azure.com/ Click on All services in the left hand menu. In the main pane, click on Enterprise applications. Click on +New Application. Find our SCIM/SSO application by entering New Relic in the name search box, and click on the application New Relic by Organization. Click on Add. Continue with the following section to connect the New Relic SCIM/SSO application to New Relic. Step 2. Configure connection Configure the New Relic SCIM/SSO application to automatically provision your users to New Relic. From the New Relic SCIM/SSO application page, click on the Provisioning link in the sidebar. In the main pane, click on Get started. In the Provisioning Mode pick-list, choose Automatic. In New Relic's authentication domain UI, set up a new domain with SCIM enabled. In Azure AD's New Relic SCIM/SSO app, in the Admin credentials section, fill out the Tenant URL and Secret token fields with the values provided in New Relic's authentication domain UI. To verify you can connect to New Relic, click Test Connection. When you see a message indicating verification success, click Save. The New Relic SCIM/SSO application can now connect with New Relic. Continue with the following section to configure the provisioning rules. Step 3. Configure provisioning rules Initially, nothing is configured to be sent to New Relic. You must configure Azure AD to send changes for user creation, updates, and deactivation. Go to the Provisioning page and complete the following: Expand the Mappings section. Click Provision Azure Active Directory Users. Verify the Target Object Actions Create Update and Delete checkboxes are all checked. Verify the Attribute Mappings look correct for your environment. Each of the New Relic attributes shown in the list must receive a value. Tip Ensure that the Azure Active Directory attributes shown in the list on the left are good sources for the information to send to New Relic. In particular, not all environments set the mail attribute. If your environment does not set the mail attribute, userPrincipalName could be a good alternative. Leave the switch for Enabled set to Off until you're done with the user and group configuration in the next section. Once all configuration is ready, return to this page and set the switch to On. Click Save. Here's an example of a filled-in attribute mapping page with the default values. Your values may be configured differently depending on your situation. After saving the provisioning rules, the New Relic SCIM/SSO application is ready to provision any changes made to users assigned to the application. Continue with the following section to assign users and groups to the New Relic SCIM/SSO application. Step 4. Assign users and groups After the New Relic SCIM/SSO application configuration and the New Relic side configuration is finished, you can assign users and groups to the application. From the New Relic SCIM/SSO application page, click on Users and groups in the sidebar. Click +Add user. From the Add Assignment page, click on Users and groups, and select the appropriate users or groups that you'd like to provision. Then click Select and Assign. The selected users and groups appear on the Users and groups page, indicating that they're candidates for provisioning. Repeat the steps to add users and groups until all desired entities have been assigned to the application. What's next? When you're done importing users, here are some potential next steps: Users created via your identity provider start out as full users. If your organization is on New Relic One pricing, these users are billable. To convert users to free basic users, use the User management UI. After adding users, you'll want to grant them access to specific New Relic accounts, specific groups, and specific roles. To learn how to do this, see Manage users.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.19833,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ", and sign in if necessary. aad.portal.azure.com&#x2F; Click on All services in the <em>left</em> hand menu. In the main <em>pane</em>, click on Enterprise applications. Click on +New Application. Find our SCIM&#x2F;SSO application by entering New Relic in the name search box, and click on the application New Relic by Organization"
      },
      "id": "6043f5c964441fcfb0378ef3"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/mobile-apps-release-notes/new-relic-ios-release-notes/new-relic-ios-3720/",
      "sections": [
        "Mobile app for iOS v3.72.0",
        "Notes",
        "New features",
        "Fixes"
      ],
      "published_at": "2021-05-22T13:09:06Z",
      "title": "Mobile app for iOS v3.72.0",
      "updated_at": "2021-05-15T09:05:08Z",
      "type": "docs",
      "external_id": "9fd71e8ad3d29c3dddff555d07486c4b3d564552",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "Notes Now featuring a global left navigation on iPad, with an explorer for all your entities. New features Added in an entity explorer page on iPad that supports Infrastructure integrations, along with a lot of other types of entities Added in a global left navigation bar on iPad, to allow you to quickly access Home, Explorer, Dashboards, Alerts, and Query from anywhere Renamed integration reported services to OpenTelemetry services Fixes Fixed an issue when opening dashboard universal links",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.23866,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "Notes Now featuring a global <em>left</em> <em>navigation</em> on iPad, with an explorer for all your entities. New features Added in an entity explorer page on iPad that supports Infrastructure integrations, along with a lot of other types of entities Added in a global <em>left</em> <em>navigation</em> bar on iPad, to allow you"
      },
      "id": "609f8ec4196a67396322b166"
    }
  ],
  "/docs/style-guide/processes-procedures/use-content-types-text-formats": [
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-05-21T16:36:25Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.75302,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures you would use the docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures&#x2F;images directory. If the images directory does"
      },
      "id": "604220ec196a67105da83dc2"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-05-21T16:35:31Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.4004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or Docs site contributor"
      },
      "id": "604220b2196a6775f5a83dc0"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-05-21T16:37:17Z",
      "updated_at": "2021-03-16T14:19:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based on its filename and filepath in the GitHub repository. For example, this is the filename and path for Rename or redirect a document: /docs/style-guide/processes-procedures/rename-or-redirect-document.mdx Copy The URL is: https://docs.newrelic.com/style-guide/processes-procedures/rename-or-redirect-document Copy If you rename a document's filename or change its path by moving it to a new directory, make sure to add a redirect to its old filepath. To change the document's location in the left navigation, update the navigation configuration file. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update the title in the left navigation, edit the yml file for the section that you're in. For example, the Style guide docs use /src/nav/style-guide.yml. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.12502,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " a document: &#x2F;docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-<em>procedures</em>&#x2F;rename-or-redirect-document.mdx Copy The URL is: https:&#x2F;&#x2F;docs.newrelic.com&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-<em>procedures</em>&#x2F;rename-or-redirect-document Copy If you rename a document&#x27;s filename or change its path by moving it to a new directory, make sure to add"
      },
      "id": "604220ec196a670d0ba83dd4"
    }
  ]
}