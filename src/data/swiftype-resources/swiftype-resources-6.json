{
  "/docs/agents/ruby-agent/background-jobs/delayedjob-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-07-02T12:16:29Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.10875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-07-02T12:17:39Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.11798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-07-02T12:17:39Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.10738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes": [
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-07-02T12:17:39Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.11798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-07-02T12:17:39Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.10738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    },
    {
      "sections": [
        "Rake instrumentation",
        "Enable Rake support",
        "Remove newrelic-rake when appropriate",
        "Caution",
        "Capture Rake job arguments"
      ],
      "title": "Rake instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "d9f92b20388116f3ad38161c58ea8238e6243c71",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/rake-instrumentation/",
      "published_at": "2021-07-02T12:17:39Z",
      "updated_at": "2021-03-16T07:58:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher Ruby agent version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app's Rake tasks, add the names of the target tasks to the rake.tasks element in your newrelic.yml file. The Ruby agent matches these names against your active tasks using string regex. Example: Instrumenting two Rake tasks For example, to instrument the Rake tasks deploy and deploy:all, add the following to your newrelic.yml file: rake: tasks: [\"deploy\", \"deploy:all\"] Copy Since task name matching is with regex, you can instrument all of your app's Rake tasks by using a wildcard regex like [\".+\"]. However, this will not include Rake tasks that are in your deny list by default from the autostart.blacklisted_rake_tasks configuration setting, such as db:migrate. To include any Rake tasks that are in your deny list by default, include them in your customized deny list. To ensure the tasks are instrumented before they run if you are using Rails but your Rake task does not require the Rails environment, add require 'tasks/newrelic' to the top of the Rake tasks. Remove newrelic-rake when appropriate The newrelic-rake third-party gem provides Rake instrumentation support as an add-on to the Ruby agent. If the agent detects newrelic-rake, it will not install the built-in Rake instrumentation, but it will record a log message like this at startup: INFO : Not installing New Relic supported Rake instrumentation because the third party newrelic-rake gem is present Copy Caution Removing the newrelic-rake gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. To switch to New Relic's built-in Rake instrumentation and change your transaction names: Remove the newrelic-rake gem. Specify the tasks you want to instrument in your config file. Capture Rake job arguments By default Rake job arguments are not captured. To capture Rake job arguments, use: attributes.include: job.rake.* Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.73535,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Capture Rake <em>job</em> arguments",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher <em>Ruby</em> <em>agent</em> version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app&#x27;s Rake tasks, add"
      },
      "id": "603e9fea64441f1e104e8841"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/rake-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-07-02T12:16:29Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.10875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-07-02T12:17:39Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.11798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-07-02T12:17:39Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.10738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/resque-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-07-02T12:16:29Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.10875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-07-02T12:17:39Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.11798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Rake instrumentation",
        "Enable Rake support",
        "Remove newrelic-rake when appropriate",
        "Caution",
        "Capture Rake job arguments"
      ],
      "title": "Rake instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "d9f92b20388116f3ad38161c58ea8238e6243c71",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/rake-instrumentation/",
      "published_at": "2021-07-02T12:17:39Z",
      "updated_at": "2021-03-16T07:58:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher Ruby agent version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app's Rake tasks, add the names of the target tasks to the rake.tasks element in your newrelic.yml file. The Ruby agent matches these names against your active tasks using string regex. Example: Instrumenting two Rake tasks For example, to instrument the Rake tasks deploy and deploy:all, add the following to your newrelic.yml file: rake: tasks: [\"deploy\", \"deploy:all\"] Copy Since task name matching is with regex, you can instrument all of your app's Rake tasks by using a wildcard regex like [\".+\"]. However, this will not include Rake tasks that are in your deny list by default from the autostart.blacklisted_rake_tasks configuration setting, such as db:migrate. To include any Rake tasks that are in your deny list by default, include them in your customized deny list. To ensure the tasks are instrumented before they run if you are using Rails but your Rake task does not require the Rails environment, add require 'tasks/newrelic' to the top of the Rake tasks. Remove newrelic-rake when appropriate The newrelic-rake third-party gem provides Rake instrumentation support as an add-on to the Ruby agent. If the agent detects newrelic-rake, it will not install the built-in Rake instrumentation, but it will record a log message like this at startup: INFO : Not installing New Relic supported Rake instrumentation because the third party newrelic-rake gem is present Copy Caution Removing the newrelic-rake gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. To switch to New Relic's built-in Rake instrumentation and change your transaction names: Remove the newrelic-rake gem. Specify the tasks you want to instrument in your config file. Capture Rake job arguments By default Rake job arguments are not captured. To capture Rake job arguments, use: attributes.include: job.rake.* Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.73535,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Capture Rake <em>job</em> arguments",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher <em>Ruby</em> <em>agent</em> version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app&#x27;s Rake tasks, add"
      },
      "id": "603e9fea64441f1e104e8841"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-07-02T12:16:29Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.10875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-07-02T12:17:39Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.10738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    },
    {
      "sections": [
        "Rake instrumentation",
        "Enable Rake support",
        "Remove newrelic-rake when appropriate",
        "Caution",
        "Capture Rake job arguments"
      ],
      "title": "Rake instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "d9f92b20388116f3ad38161c58ea8238e6243c71",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/rake-instrumentation/",
      "published_at": "2021-07-02T12:17:39Z",
      "updated_at": "2021-03-16T07:58:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher Ruby agent version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app's Rake tasks, add the names of the target tasks to the rake.tasks element in your newrelic.yml file. The Ruby agent matches these names against your active tasks using string regex. Example: Instrumenting two Rake tasks For example, to instrument the Rake tasks deploy and deploy:all, add the following to your newrelic.yml file: rake: tasks: [\"deploy\", \"deploy:all\"] Copy Since task name matching is with regex, you can instrument all of your app's Rake tasks by using a wildcard regex like [\".+\"]. However, this will not include Rake tasks that are in your deny list by default from the autostart.blacklisted_rake_tasks configuration setting, such as db:migrate. To include any Rake tasks that are in your deny list by default, include them in your customized deny list. To ensure the tasks are instrumented before they run if you are using Rails but your Rake task does not require the Rails environment, add require 'tasks/newrelic' to the top of the Rake tasks. Remove newrelic-rake when appropriate The newrelic-rake third-party gem provides Rake instrumentation support as an add-on to the Ruby agent. If the agent detects newrelic-rake, it will not install the built-in Rake instrumentation, but it will record a log message like this at startup: INFO : Not installing New Relic supported Rake instrumentation because the third party newrelic-rake gem is present Copy Caution Removing the newrelic-rake gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. To switch to New Relic's built-in Rake instrumentation and change your transaction names: Remove the newrelic-rake gem. Specify the tasks you want to instrument in your config file. Capture Rake job arguments By default Rake job arguments are not captured. To capture Rake job arguments, use: attributes.include: job.rake.* Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.73535,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Capture Rake <em>job</em> arguments",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher <em>Ruby</em> <em>agent</em> version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app&#x27;s Rake tasks, add"
      },
      "id": "603e9fea64441f1e104e8841"
    }
  ],
  "/docs/agents/ruby-agent/configuration/connect-hosts-your-account": [
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.42532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "You can configure the New Relic <em>Ruby</em> <em>agent</em> with settings in a <em>configuration</em> file, environment variables, or programmatically with server-side <em>configuration</em>. This document summarizes the <em>configuration</em> options available for the <em>Ruby</em> <em>agent</em>. If the default value for a <em>configuration</em> option is (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "High security mode",
        "Requirements",
        "Account level",
        "Enable high security mode (version 2)",
        "Caution",
        "Results of enabling high security mode (version 2)",
        "Results of enabling high security mode v1 (deprecated)",
        "Migrate from version 1 to version 2"
      ],
      "title": "High security mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Manage APM agents",
        "Configuration"
      ],
      "external_id": "128d0e140cf1d5cf849640c070f1f9b0b2beb84e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/manage-apm-agents/configuration/high-security-mode/",
      "published_at": "2021-07-01T17:19:02Z",
      "updated_at": "2021-07-01T17:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's default APM agent settings provide a high level of security. However, you may need to guarantee that even if the default APM agent settings are overridden to be more permissive, no sensitive data will ever be sent to New Relic. If this is the case, then you will want to turn on APM's high security mode (also known as enterprise security mode). For more information about our security measures, see our security and privacy documentation, or visit the New Relic security website. Requirements Customers on our New Relic One pricing plan require Enterprise edition. Customers on our original pricing plan have access depending on their subscription level. Account level If you choose to turn on high security, you must enable high security for all applications reporting to the account. High security must be set on each individual account. For organizations that have a parent/child account structure, child accounts don't automatically inherit the high security setting when enabled on the parent account. Currently there are two versions of high security mode. Version 1 is deprecated and is only available if you already have it. If you are enabling high security mode for the first time, the only option is version 2 (v2). Agent Version 2 support C SDK n/a Go All versions Java 3.7 or higher (enabled by default) .NET 3.3 or higher Node.js 1.7.0 or higher PHP 4.9 or higher Python 2.22.0.0 or higher Ruby 3.9.1 or higher Enable high security mode (version 2) To enable high security, you must update both the local configuration on your server and the remote configuration in the UI. Caution Once you enable high security for an account, high security cannot be turned off without assistance from New Relic Support. Setting location Description Set in UI To set high security in the UI: Go to one.newrelic.com, click the account dropdown and select Account settings. On that page, select High security mode. If you are on our original pricing plan, only the account owner can view this option. If the agent is configured for high security via the UI but not locally, then the agent connections will be rejected, and the agent will shut down. However, this won't shut down your application. Local, via agent Enable high security mode in your agent configuration file. High security mode is disabled by default, and the exact procedure to enable it varies by agent: C SDK: n/a Go Java .NET Node.js PHP Python Ruby If the agent is configured for high security locally but not via the UI, then the agent connections will be rejected, and the agent will shut down. This will not shut down your application. Results of enabling high security mode (version 2) Once enabled, high security mode (v2) ensures the following for your account: Feature Comments Requires agents to use a secure connection (HTTPS) High security mode requires a secure (HTTPS) connection. Non-secure connection attempts will be rejected. The latest version of all New Relic agents support HTTPS. If the configuration is not set appropriately, the agent will override the property to ensure all data in transit per the latest industry standards. Prevents HTTP param capture High security mode does not allow HTTP params, which may contain sensitive customer data, to be sent to the New Relic collector. If the agent is configured to send HTTP params locally or through server-side configuration, high security mode will override the configuration to never capture HTTP params. Prevents message queue param capture High security mode does not allow message queue params, which may contain sensitive customer data, to be sent to the New Relic collector. If the agent is configured to send message queue params locally or through server-side configuration, then high security mode will override the configuration to never capture message queue params. Prevents raw query statement capture High security mode does not allow raw database query statements, which may contain sensitive customer data, to be captured. If the agent is configured to capture raw queries locally or through server-side configuration, then high security mode will override the configuration to never capture raw queries. Prevents user attribute capture High security mode does not allow attributes set using each agent's API to be captured, as these may contain sensitive customer data. For example, in the Java agent, attributes passed in through the following NewRelic agent API calls will be blocked: NewRelic.addCustomParameter(String key, String value) Copy NewRelic.addCustomParameter(String key, Number value) Copy NewRelic.setUserName(String name) Copy NewRelic.setAccountName(String name) Copy NewRelic.setProductName(String name) Copy Prevents noticeError attribute capture High security mode does not allow attributes set using each agent's noticeError API call to be captured as these may contain sensitive customer data. For example, in the Java agent, attributes passed in through the following NewRelic agent API calls will be blocked: NewRelic.noticeError(String message, Map<String, String> params) Copy NewRelic.noticeError(Throwable throwable, Map<String, String> params) Copy Prevents custom events High security mode does not allow custom events to be created using the agent API, as these may contain sensitive customer data. For example, in the .NET agent, the API call RecordCustomEvent will be blocked. Prevents deploying Custom Instrumentation via CIE High security mode does not allow deploying custom instrumentation when using the Custom Instrumentation Editor. If you have high security mode enabled, you must export the instrumentation and manually import it to your app server. Results of enabling high security mode v1 (deprecated) High security mode version 1 is deprecated and only available if you enabled it prior to version 2 being available. High security mode version 1 ensures the following for your account: Feature Comments Requires agents to use a secure connection (HTTPS) High security mode requires an encrypted connection (HTTPS). Non-secure connection attempts will be rejected. The latest version of all New Relic agents support HTTPS. If the configuration is not set appropriately, the agent will override the property to ensure that all data in transit is encrypted as per the latest industry standards. Prevents HTTP param capture Agents configured to capture HTTP params, which may contain sensitive customer data, are not allowed to connect to New Relic. If the local configuration is set to capture request parameters, then New Relic's collector will reject the connection, and the agent will shut down. Prevents raw query statement capture Agents configured to capture raw database query statements, which may contain sensitive customer data, are not allowed to connect to New Relic. If the agent is configured to capture raw queries locally or through server-side configuration, New Relic's collector will reject the connection and the agent will shut down. Prevents deploying Custom Instrumentation via CIE High security mode does not allow deploying custom instrumentation when using the Custom Instrumentation Editor. If you have high security mode enabled, you must export the instrumentation and manually import it to your app server. Migrate from version 1 to version 2 These are the main differences between the two versions of high security: In order to make high security even more secure, high security must be enabled in the New Relic user interface and in the local New Relic configuration file. High security v1 only required high security to be set in the New Relic UI. User attributes, noticeError attributes, and message queue parameters are turned off with high security in version 2, but not in version 1. To update from v1 to v2, add high_security: true to your local agent configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.34719,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Agents</em>",
        "body": " an encrypted connection (HTTPS). Non-secure connection attempts will be rejected. The latest version of all New Relic <em>agents</em> support HTTPS. If the <em>configuration</em> is not set appropriately, the <em>agent</em> will override the property to ensure that all data in transit is encrypted as per the latest industry"
      },
      "id": "6043c83be7b9d290e1579a04"
    },
    {
      "sections": [
        "Collect custom attributes",
        "Requirements",
        "APM: Record custom attributes",
        "Important",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Browser monitoring: Record custom attributes",
        "Infrastructure monitoring: Record custom attributes",
        "Mobile monitoring: Record custom attributes",
        "For more help"
      ],
      "title": "Collect custom attributes",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "ad362b1a5cf3a5661eb416584fd9c79db064f539",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/data/customize-data/collect-custom-attributes/",
      "published_at": "2021-07-02T19:49:53Z",
      "updated_at": "2021-07-02T19:49:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For some New Relic solutions, one way to report custom data to New Relic is to use custom attributes. For example, for New Relic browser monitoring, you might create a custom attribute to track the user name associated with a slow or failing request. Requirements Custom attributes are available for these New Relic solutions: APM Browser monitoring Mobile monitoring Infrastructure monitoring For other custom data solutions, see Intro to custom data. APM: Record custom attributes Important Review the list of reserved terms used by NRQL. Using reserved terms can cause issues. To enable and use custom attributes for APM, follow the procedure for your APM agent: C SDK To add custom attributes to applications monitored by the C SDK, call one of the attribute functions; for example, newrelic_add_attribute_double(). The key name for your custom attribute depends on what you specify when you call the function. Go Custom attribute collection is enabled by default in the Go agent. However, you can disable custom attribute collection. Java Custom attribute collection is enabled by default in Java. You can collect custom attributes using XML and the Java agent APIs. These two methods can be used in conjunction with each other. Method How to do it Specify attributes in XML XML allows you to specify custom attributes without changing any of your source code. You can have multiple XML files for custom attributes that are grouped by some logical facet. To set custom attributes for your Java app via XML: Review the New Relic Java agent's documentation about XML file format, methods and classes, and examples. From your Extensions directory within the New Relic Java agent, create a single XML file. Define the methods you want New Relic to monitor by editing your XML file directly. Define an XML instrumentation file using the New Relic UI. This may require additional config in the common: block of your newrelic.yml. See Report custom attributes under Instrumentation options for more detail. Call the agent's API Example 1: Adding custom attributes to transactions To collect custom attributes using the agent's API, call the relevant methods: For each method you want to record an attribute for, call NewRelic.addCustomParameter(...). Optional: Include or exclude certain attributes with attributes.include and attributes.exclude. For example, to record a variable named userId, include this code in the parent method: NewRelic.addCustomParameter(\"userId\", userId); Copy Example 2: Adding custom attributes to spans in distributed traces To collect custom attributes using the agent's API, call the relevant methods: For each span (currently executing method) that you want to record an attribute for, call NewRelic.getAgent().getTracedMethod().addCustomAttribute(...). Optional: Include or exclude certain attributes with span_events.attributes.include and span_events.attributes.exclude. For example, to record a variable named userId on the current span, include this code in the associated method: NewRelic.getAgent().getTracedMethod().addCustomAttribute(\"userId\", userId); Copy Collect user attributes The Java agent also includes a built-in mechanism to enable user attributes and collect user information from HttpServletRequest.getUserPrincipal() as custom attributes. .NET Custom attribute collection is enabled by default in .NET. To collect custom attributes, call the relevant API methods: For each method for which you want to record an attribute, call AddCustomAttribute. Optional: Include or exclude attributes with the include and exclude configuration options. For example, to record attributes for a coupon code (string) and an item ID code (number), you could include this code in the parent method: IAgent agent = NewRelic.Api.Agent.NewRelic.GetAgent(); ITransaction transaction = agent.CurrentTransaction; transaction .AddCustomAttribute(\"Discount Code\", \"Summer Super Sale\") .AddCustomAttribute(\"Item Code\", 31456); Copy Node.js Custom attribute collection is enabled by default in Node.js. To collect custom attributes, call the relevant API method: For each attribute you want to record, call newrelic.addCustomAttribute. To record multiple attributes using a single call, use newrelic.addCustomAttributes. For example, to record attributes for a coupon code and an item ID code, you could include this in the parent method: newrelic.addCustomAttributes({ \"Discount Code\": \"Summer Super Sale\", \"Item Code\": 31456 }); Copy PHP Custom attribute collection is enabled by default in PHP. To collect custom attributes, call the relevant API method for each method that you want to record an attribute; newrelic_add_custom_parameter for transaction events and spans newrelic_add_custom_span_parameter for only spans For example, to record a variable named $userId, include this code in the parent method: newrelic_add_custom_parameter ('userID', $userId) Copy Python Custom attribute collection is enabled by default in Python. To collect custom attributes, call add_custom_parameter for each method that you want to record an attribute. For example, to record a variable named user_id, include this code in the parent method: newrelic.agent.add_custom_parameter('user_id', user_id) Copy Ruby Custom attribute collection is enabled by default in Ruby. To collect custom attributes, call the relevant API methods: For Ruby agent version 3.12.0 or higher, use the add_custom_attributes method. For example, to record a variable named @user_id, include this code in the parent method: ::NewRelic::Agent.add_custom_attributes({ user_id: @user.id }) Copy For Ruby agent version 3.11.2 or lower, use the add_custom_parameters method. For example, to record a variable named @user_id, include this code in the parent method: ::NewRelic::Agent.add_custom_parameters({ user_id: @user.id }) Copy Browser monitoring: Record custom attributes The browser agent provides an API to specify extra details associated with a page view or browser interaction, either by forwarding attributes from APM to browser monitoring or by specifying custom attributes through JavaScript. Values forwarded from the APM agent are encoded and injected into browser attributes by our browser agent. Infrastructure monitoring: Record custom attributes Our Infrastructure monitoring lets you create custom attributes that are used to annotate the data from the infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. Mobile monitoring: Record custom attributes Mobile agents include API calls to record custom attributes: For an overview of mobile monitoring custom data, see Insert custom events and attributes Android method: setAttribute iOS method: setAttribute For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.199425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Ruby</em>",
        "tags": "Install and <em>configure</em>",
        "body": " a variable named user_id, include this code in the parent method: newrelic.<em>agent</em>.add_custom_parameter(&#x27;user_id&#x27;, user_id) Copy <em>Ruby</em> Custom attribute collection is enabled by default in <em>Ruby</em>. To collect custom attributes, call the relevant API methods: For <em>Ruby</em> <em>agent</em> version 3.12.0 or higher, use"
      },
      "id": "603eb9a3196a67a990a83da5"
    }
  ],
  "/docs/agents/ruby-agent/configuration/custom-ssl-certificates-ruby": [
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.42532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "You can configure the New Relic <em>Ruby</em> <em>agent</em> with settings in a <em>configuration</em> file, environment variables, or programmatically with server-side <em>configuration</em>. This document summarizes the <em>configuration</em> options available for the <em>Ruby</em> <em>agent</em>. If the default value for a <em>configuration</em> option is (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "High security mode",
        "Requirements",
        "Account level",
        "Enable high security mode (version 2)",
        "Caution",
        "Results of enabling high security mode (version 2)",
        "Results of enabling high security mode v1 (deprecated)",
        "Migrate from version 1 to version 2"
      ],
      "title": "High security mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Manage APM agents",
        "Configuration"
      ],
      "external_id": "128d0e140cf1d5cf849640c070f1f9b0b2beb84e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/manage-apm-agents/configuration/high-security-mode/",
      "published_at": "2021-07-01T17:19:02Z",
      "updated_at": "2021-07-01T17:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's default APM agent settings provide a high level of security. However, you may need to guarantee that even if the default APM agent settings are overridden to be more permissive, no sensitive data will ever be sent to New Relic. If this is the case, then you will want to turn on APM's high security mode (also known as enterprise security mode). For more information about our security measures, see our security and privacy documentation, or visit the New Relic security website. Requirements Customers on our New Relic One pricing plan require Enterprise edition. Customers on our original pricing plan have access depending on their subscription level. Account level If you choose to turn on high security, you must enable high security for all applications reporting to the account. High security must be set on each individual account. For organizations that have a parent/child account structure, child accounts don't automatically inherit the high security setting when enabled on the parent account. Currently there are two versions of high security mode. Version 1 is deprecated and is only available if you already have it. If you are enabling high security mode for the first time, the only option is version 2 (v2). Agent Version 2 support C SDK n/a Go All versions Java 3.7 or higher (enabled by default) .NET 3.3 or higher Node.js 1.7.0 or higher PHP 4.9 or higher Python 2.22.0.0 or higher Ruby 3.9.1 or higher Enable high security mode (version 2) To enable high security, you must update both the local configuration on your server and the remote configuration in the UI. Caution Once you enable high security for an account, high security cannot be turned off without assistance from New Relic Support. Setting location Description Set in UI To set high security in the UI: Go to one.newrelic.com, click the account dropdown and select Account settings. On that page, select High security mode. If you are on our original pricing plan, only the account owner can view this option. If the agent is configured for high security via the UI but not locally, then the agent connections will be rejected, and the agent will shut down. However, this won't shut down your application. Local, via agent Enable high security mode in your agent configuration file. High security mode is disabled by default, and the exact procedure to enable it varies by agent: C SDK: n/a Go Java .NET Node.js PHP Python Ruby If the agent is configured for high security locally but not via the UI, then the agent connections will be rejected, and the agent will shut down. This will not shut down your application. Results of enabling high security mode (version 2) Once enabled, high security mode (v2) ensures the following for your account: Feature Comments Requires agents to use a secure connection (HTTPS) High security mode requires a secure (HTTPS) connection. Non-secure connection attempts will be rejected. The latest version of all New Relic agents support HTTPS. If the configuration is not set appropriately, the agent will override the property to ensure all data in transit per the latest industry standards. Prevents HTTP param capture High security mode does not allow HTTP params, which may contain sensitive customer data, to be sent to the New Relic collector. If the agent is configured to send HTTP params locally or through server-side configuration, high security mode will override the configuration to never capture HTTP params. Prevents message queue param capture High security mode does not allow message queue params, which may contain sensitive customer data, to be sent to the New Relic collector. If the agent is configured to send message queue params locally or through server-side configuration, then high security mode will override the configuration to never capture message queue params. Prevents raw query statement capture High security mode does not allow raw database query statements, which may contain sensitive customer data, to be captured. If the agent is configured to capture raw queries locally or through server-side configuration, then high security mode will override the configuration to never capture raw queries. Prevents user attribute capture High security mode does not allow attributes set using each agent's API to be captured, as these may contain sensitive customer data. For example, in the Java agent, attributes passed in through the following NewRelic agent API calls will be blocked: NewRelic.addCustomParameter(String key, String value) Copy NewRelic.addCustomParameter(String key, Number value) Copy NewRelic.setUserName(String name) Copy NewRelic.setAccountName(String name) Copy NewRelic.setProductName(String name) Copy Prevents noticeError attribute capture High security mode does not allow attributes set using each agent's noticeError API call to be captured as these may contain sensitive customer data. For example, in the Java agent, attributes passed in through the following NewRelic agent API calls will be blocked: NewRelic.noticeError(String message, Map<String, String> params) Copy NewRelic.noticeError(Throwable throwable, Map<String, String> params) Copy Prevents custom events High security mode does not allow custom events to be created using the agent API, as these may contain sensitive customer data. For example, in the .NET agent, the API call RecordCustomEvent will be blocked. Prevents deploying Custom Instrumentation via CIE High security mode does not allow deploying custom instrumentation when using the Custom Instrumentation Editor. If you have high security mode enabled, you must export the instrumentation and manually import it to your app server. Results of enabling high security mode v1 (deprecated) High security mode version 1 is deprecated and only available if you enabled it prior to version 2 being available. High security mode version 1 ensures the following for your account: Feature Comments Requires agents to use a secure connection (HTTPS) High security mode requires an encrypted connection (HTTPS). Non-secure connection attempts will be rejected. The latest version of all New Relic agents support HTTPS. If the configuration is not set appropriately, the agent will override the property to ensure that all data in transit is encrypted as per the latest industry standards. Prevents HTTP param capture Agents configured to capture HTTP params, which may contain sensitive customer data, are not allowed to connect to New Relic. If the local configuration is set to capture request parameters, then New Relic's collector will reject the connection, and the agent will shut down. Prevents raw query statement capture Agents configured to capture raw database query statements, which may contain sensitive customer data, are not allowed to connect to New Relic. If the agent is configured to capture raw queries locally or through server-side configuration, New Relic's collector will reject the connection and the agent will shut down. Prevents deploying Custom Instrumentation via CIE High security mode does not allow deploying custom instrumentation when using the Custom Instrumentation Editor. If you have high security mode enabled, you must export the instrumentation and manually import it to your app server. Migrate from version 1 to version 2 These are the main differences between the two versions of high security: In order to make high security even more secure, high security must be enabled in the New Relic user interface and in the local New Relic configuration file. High security v1 only required high security to be set in the New Relic UI. User attributes, noticeError attributes, and message queue parameters are turned off with high security in version 2, but not in version 1. To update from v1 to v2, add high_security: true to your local agent configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.34719,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Agents</em>",
        "body": " an encrypted connection (HTTPS). Non-secure connection attempts will be rejected. The latest version of all New Relic <em>agents</em> support HTTPS. If the <em>configuration</em> is not set appropriately, the <em>agent</em> will override the property to ensure that all data in transit is encrypted as per the latest industry"
      },
      "id": "6043c83be7b9d290e1579a04"
    },
    {
      "sections": [
        "Collect custom attributes",
        "Requirements",
        "APM: Record custom attributes",
        "Important",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Browser monitoring: Record custom attributes",
        "Infrastructure monitoring: Record custom attributes",
        "Mobile monitoring: Record custom attributes",
        "For more help"
      ],
      "title": "Collect custom attributes",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "ad362b1a5cf3a5661eb416584fd9c79db064f539",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/data/customize-data/collect-custom-attributes/",
      "published_at": "2021-07-02T19:49:53Z",
      "updated_at": "2021-07-02T19:49:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For some New Relic solutions, one way to report custom data to New Relic is to use custom attributes. For example, for New Relic browser monitoring, you might create a custom attribute to track the user name associated with a slow or failing request. Requirements Custom attributes are available for these New Relic solutions: APM Browser monitoring Mobile monitoring Infrastructure monitoring For other custom data solutions, see Intro to custom data. APM: Record custom attributes Important Review the list of reserved terms used by NRQL. Using reserved terms can cause issues. To enable and use custom attributes for APM, follow the procedure for your APM agent: C SDK To add custom attributes to applications monitored by the C SDK, call one of the attribute functions; for example, newrelic_add_attribute_double(). The key name for your custom attribute depends on what you specify when you call the function. Go Custom attribute collection is enabled by default in the Go agent. However, you can disable custom attribute collection. Java Custom attribute collection is enabled by default in Java. You can collect custom attributes using XML and the Java agent APIs. These two methods can be used in conjunction with each other. Method How to do it Specify attributes in XML XML allows you to specify custom attributes without changing any of your source code. You can have multiple XML files for custom attributes that are grouped by some logical facet. To set custom attributes for your Java app via XML: Review the New Relic Java agent's documentation about XML file format, methods and classes, and examples. From your Extensions directory within the New Relic Java agent, create a single XML file. Define the methods you want New Relic to monitor by editing your XML file directly. Define an XML instrumentation file using the New Relic UI. This may require additional config in the common: block of your newrelic.yml. See Report custom attributes under Instrumentation options for more detail. Call the agent's API Example 1: Adding custom attributes to transactions To collect custom attributes using the agent's API, call the relevant methods: For each method you want to record an attribute for, call NewRelic.addCustomParameter(...). Optional: Include or exclude certain attributes with attributes.include and attributes.exclude. For example, to record a variable named userId, include this code in the parent method: NewRelic.addCustomParameter(\"userId\", userId); Copy Example 2: Adding custom attributes to spans in distributed traces To collect custom attributes using the agent's API, call the relevant methods: For each span (currently executing method) that you want to record an attribute for, call NewRelic.getAgent().getTracedMethod().addCustomAttribute(...). Optional: Include or exclude certain attributes with span_events.attributes.include and span_events.attributes.exclude. For example, to record a variable named userId on the current span, include this code in the associated method: NewRelic.getAgent().getTracedMethod().addCustomAttribute(\"userId\", userId); Copy Collect user attributes The Java agent also includes a built-in mechanism to enable user attributes and collect user information from HttpServletRequest.getUserPrincipal() as custom attributes. .NET Custom attribute collection is enabled by default in .NET. To collect custom attributes, call the relevant API methods: For each method for which you want to record an attribute, call AddCustomAttribute. Optional: Include or exclude attributes with the include and exclude configuration options. For example, to record attributes for a coupon code (string) and an item ID code (number), you could include this code in the parent method: IAgent agent = NewRelic.Api.Agent.NewRelic.GetAgent(); ITransaction transaction = agent.CurrentTransaction; transaction .AddCustomAttribute(\"Discount Code\", \"Summer Super Sale\") .AddCustomAttribute(\"Item Code\", 31456); Copy Node.js Custom attribute collection is enabled by default in Node.js. To collect custom attributes, call the relevant API method: For each attribute you want to record, call newrelic.addCustomAttribute. To record multiple attributes using a single call, use newrelic.addCustomAttributes. For example, to record attributes for a coupon code and an item ID code, you could include this in the parent method: newrelic.addCustomAttributes({ \"Discount Code\": \"Summer Super Sale\", \"Item Code\": 31456 }); Copy PHP Custom attribute collection is enabled by default in PHP. To collect custom attributes, call the relevant API method for each method that you want to record an attribute; newrelic_add_custom_parameter for transaction events and spans newrelic_add_custom_span_parameter for only spans For example, to record a variable named $userId, include this code in the parent method: newrelic_add_custom_parameter ('userID', $userId) Copy Python Custom attribute collection is enabled by default in Python. To collect custom attributes, call add_custom_parameter for each method that you want to record an attribute. For example, to record a variable named user_id, include this code in the parent method: newrelic.agent.add_custom_parameter('user_id', user_id) Copy Ruby Custom attribute collection is enabled by default in Ruby. To collect custom attributes, call the relevant API methods: For Ruby agent version 3.12.0 or higher, use the add_custom_attributes method. For example, to record a variable named @user_id, include this code in the parent method: ::NewRelic::Agent.add_custom_attributes({ user_id: @user.id }) Copy For Ruby agent version 3.11.2 or lower, use the add_custom_parameters method. For example, to record a variable named @user_id, include this code in the parent method: ::NewRelic::Agent.add_custom_parameters({ user_id: @user.id }) Copy Browser monitoring: Record custom attributes The browser agent provides an API to specify extra details associated with a page view or browser interaction, either by forwarding attributes from APM to browser monitoring or by specifying custom attributes through JavaScript. Values forwarded from the APM agent are encoded and injected into browser attributes by our browser agent. Infrastructure monitoring: Record custom attributes Our Infrastructure monitoring lets you create custom attributes that are used to annotate the data from the infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. Mobile monitoring: Record custom attributes Mobile agents include API calls to record custom attributes: For an overview of mobile monitoring custom data, see Insert custom events and attributes Android method: setAttribute iOS method: setAttribute For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.199425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Ruby</em>",
        "tags": "Install and <em>configure</em>",
        "body": " a variable named user_id, include this code in the parent method: newrelic.<em>agent</em>.add_custom_parameter(&#x27;user_id&#x27;, user_id) Copy <em>Ruby</em> Custom attribute collection is enabled by default in <em>Ruby</em>. To collect custom attributes, call the relevant API methods: For <em>Ruby</em> <em>agent</em> version 3.12.0 or higher, use"
      },
      "id": "603eb9a3196a67a990a83da5"
    }
  ],
  "/docs/agents/ruby-agent/configuration/ruby-agent-configuration": [
    {
      "sections": [
        "High security mode",
        "Requirements",
        "Account level",
        "Enable high security mode (version 2)",
        "Caution",
        "Results of enabling high security mode (version 2)",
        "Results of enabling high security mode v1 (deprecated)",
        "Migrate from version 1 to version 2"
      ],
      "title": "High security mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Manage APM agents",
        "Configuration"
      ],
      "external_id": "128d0e140cf1d5cf849640c070f1f9b0b2beb84e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/manage-apm-agents/configuration/high-security-mode/",
      "published_at": "2021-07-01T17:19:02Z",
      "updated_at": "2021-07-01T17:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's default APM agent settings provide a high level of security. However, you may need to guarantee that even if the default APM agent settings are overridden to be more permissive, no sensitive data will ever be sent to New Relic. If this is the case, then you will want to turn on APM's high security mode (also known as enterprise security mode). For more information about our security measures, see our security and privacy documentation, or visit the New Relic security website. Requirements Customers on our New Relic One pricing plan require Enterprise edition. Customers on our original pricing plan have access depending on their subscription level. Account level If you choose to turn on high security, you must enable high security for all applications reporting to the account. High security must be set on each individual account. For organizations that have a parent/child account structure, child accounts don't automatically inherit the high security setting when enabled on the parent account. Currently there are two versions of high security mode. Version 1 is deprecated and is only available if you already have it. If you are enabling high security mode for the first time, the only option is version 2 (v2). Agent Version 2 support C SDK n/a Go All versions Java 3.7 or higher (enabled by default) .NET 3.3 or higher Node.js 1.7.0 or higher PHP 4.9 or higher Python 2.22.0.0 or higher Ruby 3.9.1 or higher Enable high security mode (version 2) To enable high security, you must update both the local configuration on your server and the remote configuration in the UI. Caution Once you enable high security for an account, high security cannot be turned off without assistance from New Relic Support. Setting location Description Set in UI To set high security in the UI: Go to one.newrelic.com, click the account dropdown and select Account settings. On that page, select High security mode. If you are on our original pricing plan, only the account owner can view this option. If the agent is configured for high security via the UI but not locally, then the agent connections will be rejected, and the agent will shut down. However, this won't shut down your application. Local, via agent Enable high security mode in your agent configuration file. High security mode is disabled by default, and the exact procedure to enable it varies by agent: C SDK: n/a Go Java .NET Node.js PHP Python Ruby If the agent is configured for high security locally but not via the UI, then the agent connections will be rejected, and the agent will shut down. This will not shut down your application. Results of enabling high security mode (version 2) Once enabled, high security mode (v2) ensures the following for your account: Feature Comments Requires agents to use a secure connection (HTTPS) High security mode requires a secure (HTTPS) connection. Non-secure connection attempts will be rejected. The latest version of all New Relic agents support HTTPS. If the configuration is not set appropriately, the agent will override the property to ensure all data in transit per the latest industry standards. Prevents HTTP param capture High security mode does not allow HTTP params, which may contain sensitive customer data, to be sent to the New Relic collector. If the agent is configured to send HTTP params locally or through server-side configuration, high security mode will override the configuration to never capture HTTP params. Prevents message queue param capture High security mode does not allow message queue params, which may contain sensitive customer data, to be sent to the New Relic collector. If the agent is configured to send message queue params locally or through server-side configuration, then high security mode will override the configuration to never capture message queue params. Prevents raw query statement capture High security mode does not allow raw database query statements, which may contain sensitive customer data, to be captured. If the agent is configured to capture raw queries locally or through server-side configuration, then high security mode will override the configuration to never capture raw queries. Prevents user attribute capture High security mode does not allow attributes set using each agent's API to be captured, as these may contain sensitive customer data. For example, in the Java agent, attributes passed in through the following NewRelic agent API calls will be blocked: NewRelic.addCustomParameter(String key, String value) Copy NewRelic.addCustomParameter(String key, Number value) Copy NewRelic.setUserName(String name) Copy NewRelic.setAccountName(String name) Copy NewRelic.setProductName(String name) Copy Prevents noticeError attribute capture High security mode does not allow attributes set using each agent's noticeError API call to be captured as these may contain sensitive customer data. For example, in the Java agent, attributes passed in through the following NewRelic agent API calls will be blocked: NewRelic.noticeError(String message, Map<String, String> params) Copy NewRelic.noticeError(Throwable throwable, Map<String, String> params) Copy Prevents custom events High security mode does not allow custom events to be created using the agent API, as these may contain sensitive customer data. For example, in the .NET agent, the API call RecordCustomEvent will be blocked. Prevents deploying Custom Instrumentation via CIE High security mode does not allow deploying custom instrumentation when using the Custom Instrumentation Editor. If you have high security mode enabled, you must export the instrumentation and manually import it to your app server. Results of enabling high security mode v1 (deprecated) High security mode version 1 is deprecated and only available if you enabled it prior to version 2 being available. High security mode version 1 ensures the following for your account: Feature Comments Requires agents to use a secure connection (HTTPS) High security mode requires an encrypted connection (HTTPS). Non-secure connection attempts will be rejected. The latest version of all New Relic agents support HTTPS. If the configuration is not set appropriately, the agent will override the property to ensure that all data in transit is encrypted as per the latest industry standards. Prevents HTTP param capture Agents configured to capture HTTP params, which may contain sensitive customer data, are not allowed to connect to New Relic. If the local configuration is set to capture request parameters, then New Relic's collector will reject the connection, and the agent will shut down. Prevents raw query statement capture Agents configured to capture raw database query statements, which may contain sensitive customer data, are not allowed to connect to New Relic. If the agent is configured to capture raw queries locally or through server-side configuration, New Relic's collector will reject the connection and the agent will shut down. Prevents deploying Custom Instrumentation via CIE High security mode does not allow deploying custom instrumentation when using the Custom Instrumentation Editor. If you have high security mode enabled, you must export the instrumentation and manually import it to your app server. Migrate from version 1 to version 2 These are the main differences between the two versions of high security: In order to make high security even more secure, high security must be enabled in the New Relic user interface and in the local New Relic configuration file. High security v1 only required high security to be set in the New Relic UI. User attributes, noticeError attributes, and message queue parameters are turned off with high security in version 2, but not in version 1. To update from v1 to v2, add high_security: true to your local agent configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.34714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Agents</em>",
        "body": " an encrypted connection (HTTPS). Non-secure connection attempts will be rejected. The latest version of all New Relic <em>agents</em> support HTTPS. If the <em>configuration</em> is not set appropriately, the <em>agent</em> will override the property to ensure that all data in transit is encrypted as per the latest industry"
      },
      "id": "6043c83be7b9d290e1579a04"
    },
    {
      "sections": [
        "Collect custom attributes",
        "Requirements",
        "APM: Record custom attributes",
        "Important",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Browser monitoring: Record custom attributes",
        "Infrastructure monitoring: Record custom attributes",
        "Mobile monitoring: Record custom attributes",
        "For more help"
      ],
      "title": "Collect custom attributes",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "ad362b1a5cf3a5661eb416584fd9c79db064f539",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/data/customize-data/collect-custom-attributes/",
      "published_at": "2021-07-02T19:49:53Z",
      "updated_at": "2021-07-02T19:49:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For some New Relic solutions, one way to report custom data to New Relic is to use custom attributes. For example, for New Relic browser monitoring, you might create a custom attribute to track the user name associated with a slow or failing request. Requirements Custom attributes are available for these New Relic solutions: APM Browser monitoring Mobile monitoring Infrastructure monitoring For other custom data solutions, see Intro to custom data. APM: Record custom attributes Important Review the list of reserved terms used by NRQL. Using reserved terms can cause issues. To enable and use custom attributes for APM, follow the procedure for your APM agent: C SDK To add custom attributes to applications monitored by the C SDK, call one of the attribute functions; for example, newrelic_add_attribute_double(). The key name for your custom attribute depends on what you specify when you call the function. Go Custom attribute collection is enabled by default in the Go agent. However, you can disable custom attribute collection. Java Custom attribute collection is enabled by default in Java. You can collect custom attributes using XML and the Java agent APIs. These two methods can be used in conjunction with each other. Method How to do it Specify attributes in XML XML allows you to specify custom attributes without changing any of your source code. You can have multiple XML files for custom attributes that are grouped by some logical facet. To set custom attributes for your Java app via XML: Review the New Relic Java agent's documentation about XML file format, methods and classes, and examples. From your Extensions directory within the New Relic Java agent, create a single XML file. Define the methods you want New Relic to monitor by editing your XML file directly. Define an XML instrumentation file using the New Relic UI. This may require additional config in the common: block of your newrelic.yml. See Report custom attributes under Instrumentation options for more detail. Call the agent's API Example 1: Adding custom attributes to transactions To collect custom attributes using the agent's API, call the relevant methods: For each method you want to record an attribute for, call NewRelic.addCustomParameter(...). Optional: Include or exclude certain attributes with attributes.include and attributes.exclude. For example, to record a variable named userId, include this code in the parent method: NewRelic.addCustomParameter(\"userId\", userId); Copy Example 2: Adding custom attributes to spans in distributed traces To collect custom attributes using the agent's API, call the relevant methods: For each span (currently executing method) that you want to record an attribute for, call NewRelic.getAgent().getTracedMethod().addCustomAttribute(...). Optional: Include or exclude certain attributes with span_events.attributes.include and span_events.attributes.exclude. For example, to record a variable named userId on the current span, include this code in the associated method: NewRelic.getAgent().getTracedMethod().addCustomAttribute(\"userId\", userId); Copy Collect user attributes The Java agent also includes a built-in mechanism to enable user attributes and collect user information from HttpServletRequest.getUserPrincipal() as custom attributes. .NET Custom attribute collection is enabled by default in .NET. To collect custom attributes, call the relevant API methods: For each method for which you want to record an attribute, call AddCustomAttribute. Optional: Include or exclude attributes with the include and exclude configuration options. For example, to record attributes for a coupon code (string) and an item ID code (number), you could include this code in the parent method: IAgent agent = NewRelic.Api.Agent.NewRelic.GetAgent(); ITransaction transaction = agent.CurrentTransaction; transaction .AddCustomAttribute(\"Discount Code\", \"Summer Super Sale\") .AddCustomAttribute(\"Item Code\", 31456); Copy Node.js Custom attribute collection is enabled by default in Node.js. To collect custom attributes, call the relevant API method: For each attribute you want to record, call newrelic.addCustomAttribute. To record multiple attributes using a single call, use newrelic.addCustomAttributes. For example, to record attributes for a coupon code and an item ID code, you could include this in the parent method: newrelic.addCustomAttributes({ \"Discount Code\": \"Summer Super Sale\", \"Item Code\": 31456 }); Copy PHP Custom attribute collection is enabled by default in PHP. To collect custom attributes, call the relevant API method for each method that you want to record an attribute; newrelic_add_custom_parameter for transaction events and spans newrelic_add_custom_span_parameter for only spans For example, to record a variable named $userId, include this code in the parent method: newrelic_add_custom_parameter ('userID', $userId) Copy Python Custom attribute collection is enabled by default in Python. To collect custom attributes, call add_custom_parameter for each method that you want to record an attribute. For example, to record a variable named user_id, include this code in the parent method: newrelic.agent.add_custom_parameter('user_id', user_id) Copy Ruby Custom attribute collection is enabled by default in Ruby. To collect custom attributes, call the relevant API methods: For Ruby agent version 3.12.0 or higher, use the add_custom_attributes method. For example, to record a variable named @user_id, include this code in the parent method: ::NewRelic::Agent.add_custom_attributes({ user_id: @user.id }) Copy For Ruby agent version 3.11.2 or lower, use the add_custom_parameters method. For example, to record a variable named @user_id, include this code in the parent method: ::NewRelic::Agent.add_custom_parameters({ user_id: @user.id }) Copy Browser monitoring: Record custom attributes The browser agent provides an API to specify extra details associated with a page view or browser interaction, either by forwarding attributes from APM to browser monitoring or by specifying custom attributes through JavaScript. Values forwarded from the APM agent are encoded and injected into browser attributes by our browser agent. Infrastructure monitoring: Record custom attributes Our Infrastructure monitoring lets you create custom attributes that are used to annotate the data from the infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. Mobile monitoring: Record custom attributes Mobile agents include API calls to record custom attributes: For an overview of mobile monitoring custom data, see Insert custom events and attributes Android method: setAttribute iOS method: setAttribute For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.199356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Ruby</em>",
        "tags": "Install and <em>configure</em>",
        "body": " a variable named user_id, include this code in the parent method: newrelic.<em>agent</em>.add_custom_parameter(&#x27;user_id&#x27;, user_id) Copy <em>Ruby</em> Custom attribute collection is enabled by default in <em>Ruby</em>. To collect custom attributes, call the relevant API methods: For <em>Ruby</em> <em>agent</em> version 3.12.0 or higher, use"
      },
      "id": "603eb9a3196a67a990a83da5"
    },
    {
      "sections": [
        "Custom SSL certificates (Ruby)",
        "Use a custom CA bundle",
        "Installing SSL Certificates"
      ],
      "title": "Custom SSL certificates (Ruby)",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "6827e03a9ae61ae344e1cd2c847d085eb75704e1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/custom-ssl-certificates-ruby/",
      "published_at": "2021-07-02T12:18:21Z",
      "updated_at": "2021-04-28T23:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic requires HTTPS for all traffic to APM and the New Relic REST API. The Ruby agent connects to New Relic collector servers over SSL by default, and uses a system/host installed set of SSL certificate to validate the identity of the collector servers when connecting. In most cases, this default set of certificates is sufficient. In certain configurations, you may need to use a custom CA bundle. For example, you may use an HTTP proxy to intercept and decrypt SSL traffic from the agent, which then establishes a separate SSL connection to New Relic. Custom CA bundles are available in versions 3.9.4 or higher of the Ruby agent. Use a custom CA bundle To configure the agent to use a custom CA bundle when validating the SSL certificate presented by a proxy, set the ca_bundle_path configuration setting in your newrelic.yml file or via the NEW_RELIC_CA_BUNDLE_PATH environment variable: common: &default_settings ca_bundle_path: certificates/mycert.pem # ... other settings ... Copy Specify a path to a .pem file containing each certificate you want the agent to use when validating the identity of the proxy or server. You can concatenate multiple certificates into a single .pem file. (For an example, see the default pem file.) Relative path: If you specify a relative path, the agent will assign a path relative to the working directory of your app server process at runtime. Absolute path: If your working directory is / rather than the root of your application, be sure to specify an absolute path. Installing SSL Certificates If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you need to ensure they're now installed for 7.0 or highter releases of the agent to make successful HTTPS connections to New Relic servers. These CA certificates may be installed in various ways, depending on your host. The following external links are helpful guidiance for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.41302,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Custom SSL certificates (<em>Ruby</em>)",
        "sections": "Custom SSL certificates (<em>Ruby</em>)",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " in versions 3.9.4 or higher of the <em>Ruby</em> <em>agent</em>. Use a custom CA bundle To configure the <em>agent</em> to use a custom CA bundle when validating the SSL certificate presented by a proxy, set the ca_bundle_path <em>configuration</em> setting in your newrelic.yml file or via the NEW_RELIC_CA_BUNDLE_PATH environment variable"
      },
      "id": "603ec4aa28ccbce02ceba785"
    }
  ],
  "/docs/agents/ruby-agent/features/cross-application-tracing-ruby": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.89347,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Garbage collection",
        "Important",
        "Enable garbage collection instrumentation",
        "View app-wide GC statistics",
        "View detailed GC metrics",
        "For more help"
      ],
      "title": "Garbage collection",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "9981cf22973c76aec7d8d0ac31c2793e04a42e48",
      "image": "https://docs.newrelic.com/static/e2fdc5c35adef00b9a2646a1ec6589c9/c1b63/garbage_collection_overview.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/garbage-collection/",
      "published_at": "2021-07-02T12:19:36Z",
      "updated_at": "2021-05-05T14:31:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Garbage collection (GC) finds unused data objects and reclaims that memory space for use by another process. The New Relic Ruby agent can collect information about how much time is spent in garbage collection for applications running on MRI 1.9.2 or higher or Ruby Enterprise Edition, but you must explicitly enable this feature in your application. Important Avoid using garbage collection in production for long periods of time, as it increases overhead. Enable garbage collection instrumentation To activate the feature, add the appropriate call in your application initialization. MRI 1.9.2 or higher: GC::Profiler.enable Ruby Enterprise Edition: GC.enable_stats For Rails applications, you can either add this call to an initializer in config/initializers, or add it directly to your config/application.rb file. View app-wide GC statistics To view overall garbage collection statistics: Log into New Relic, select a Ruby app, and go to Summary. From the APM Summary page, look for GC Execution statistics on the Web transactions time chart. one.newrelic.com > APM > (select a Ruby app) > Summary: On the Web transactions time chart, garbage collection statistics are labeled GC Execution. View detailed GC metrics To view garbage collection metrics on a per-transaction basis, go to one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction). You can then view the amount of time spent in GC, and the average number of times GC is called for each transaction. Hide other labels for a detailed view of garbage collection. one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction): Select an individual transaction to view detailed GC metrics, including average time and average number of calls. Detailed information includes: Garbage collection details Comments Trend of garbage collection time Garbage collection usually takes a small amount of time, and therefore the trend line may not be visible in your charts. To view the trend in garbage collection time, navigate to the overview chart or to detailed transaction metrics. Then, hide every chart label except GC Execution by selecting each label. Average number of calls To view the average number of garbage collection calls for each controller action: From your APM Summary page, select Transaction. Then select a controller action and view the App Server Breakdown. For more help Additional documentation resources include: \"Eating the 1.9 elephant\" blog post (what New Relic discovered when we used garbage collection to fine-tune our own website) APM Summary page (features and drill-down details when using the APM Summary page) Transactions page (features and drill-down details for transactions) Ruby agent configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.13187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Additional documentation resources include: &quot;Eating the 1.9 elephant&quot; blog post (what New Relic discovered when we used garbage collection to fine-tune our own website) APM Summary page (<em>features</em> and drill-down details when using the APM Summary page) Transactions page (<em>features</em> and drill-down details for transactions) <em>Ruby</em> <em>agent</em> configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)"
      },
      "id": "603eba3a28ccbcb144eba7aa"
    },
    {
      "sections": [
        "Message queues",
        "Requirements",
        "Performance improvements with background tasks",
        "Queue operations",
        "View in New Relic UI",
        "Transactions page",
        "Tip",
        "Transaction trace summary page",
        "Transaction trace details tab"
      ],
      "title": "Message queues",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "1c074612f5486198c2639542507e2008abb20187",
      "image": "https://docs.newrelic.com/static/1789ce28689c4575593e79b8305171fd/c1b63/transactions_page.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/message-queues/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-05-05T01:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe/consume messages) as Message background tasks. Message creation via RabbitMQ also appears in transaction traces. Requirements Requires New Relic Ruby agent version 4.3.0 or higher. Instrumentation is automatic for supported versions of Bunny AMQP, and requires no additional configuration. Performance improvements with background tasks One way to increase responsiveness of web applications is to delegate work to background processes. Message queues are commonly used for this inter-process communication. In the context of message queuing systems, applications typically interact with message brokers to send and receive messages. The RabbitMQ Bunny client library allows Ruby applications to interface with message brokers that implement the Advanced Message Queuing Protocol (AMQP). New Relic's Ruby agent shows messages sent and received using the RabbitMQ client library. With this visibility, you can see details including: Number of messages produced by your app Time your app spends publishing messages Time your app spends processing \"consumed\" messages APM conveniently groups and reports operations that interact with queues. By analyzing this information, you can more easily identify bottlenecks and areas for performance improvement in your message passing architecture. Queue operations Supported entry points for queue operations appear as Put (publish a message) or Take (receive a message) in APM's user interface. Queue operations Publish a message (Put in UI) Receive a message (Take in UI) RabbitMQ publish pop subscribe (with block) View in New Relic UI Message queue operations are visible in several places in the APM UI: Transactions page Queue operations appear on APM's Transactions page for the selected app. The Put and Take metrics appear in the Breakdown table and are categorized as MessageBroker metrics. Here is an example: Transaction traces also provide additional details for messages. Tip You can select transaction traces from the app's Summary or Transactions pages in APM. Transaction trace summary page The Transaction trace summary page may show Put and Take operations in the Slowest components section. For example: Transaction trace details tab The Transaction trace page includes a dedicated Details tab that shows more detailed information about the transaction. Here is an example:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.01539,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe&#x2F;consume messages) as Message background"
      },
      "id": "604427cb28ccbcc86f2c606a"
    }
  ],
  "/docs/agents/ruby-agent/features/developer-mode": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.89346,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Garbage collection",
        "Important",
        "Enable garbage collection instrumentation",
        "View app-wide GC statistics",
        "View detailed GC metrics",
        "For more help"
      ],
      "title": "Garbage collection",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "9981cf22973c76aec7d8d0ac31c2793e04a42e48",
      "image": "https://docs.newrelic.com/static/e2fdc5c35adef00b9a2646a1ec6589c9/c1b63/garbage_collection_overview.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/garbage-collection/",
      "published_at": "2021-07-02T12:19:36Z",
      "updated_at": "2021-05-05T14:31:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Garbage collection (GC) finds unused data objects and reclaims that memory space for use by another process. The New Relic Ruby agent can collect information about how much time is spent in garbage collection for applications running on MRI 1.9.2 or higher or Ruby Enterprise Edition, but you must explicitly enable this feature in your application. Important Avoid using garbage collection in production for long periods of time, as it increases overhead. Enable garbage collection instrumentation To activate the feature, add the appropriate call in your application initialization. MRI 1.9.2 or higher: GC::Profiler.enable Ruby Enterprise Edition: GC.enable_stats For Rails applications, you can either add this call to an initializer in config/initializers, or add it directly to your config/application.rb file. View app-wide GC statistics To view overall garbage collection statistics: Log into New Relic, select a Ruby app, and go to Summary. From the APM Summary page, look for GC Execution statistics on the Web transactions time chart. one.newrelic.com > APM > (select a Ruby app) > Summary: On the Web transactions time chart, garbage collection statistics are labeled GC Execution. View detailed GC metrics To view garbage collection metrics on a per-transaction basis, go to one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction). You can then view the amount of time spent in GC, and the average number of times GC is called for each transaction. Hide other labels for a detailed view of garbage collection. one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction): Select an individual transaction to view detailed GC metrics, including average time and average number of calls. Detailed information includes: Garbage collection details Comments Trend of garbage collection time Garbage collection usually takes a small amount of time, and therefore the trend line may not be visible in your charts. To view the trend in garbage collection time, navigate to the overview chart or to detailed transaction metrics. Then, hide every chart label except GC Execution by selecting each label. Average number of calls To view the average number of garbage collection calls for each controller action: From your APM Summary page, select Transaction. Then select a controller action and view the App Server Breakdown. For more help Additional documentation resources include: \"Eating the 1.9 elephant\" blog post (what New Relic discovered when we used garbage collection to fine-tune our own website) APM Summary page (features and drill-down details when using the APM Summary page) Transactions page (features and drill-down details for transactions) Ruby agent configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.13186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Additional documentation resources include: &quot;Eating the 1.9 elephant&quot; blog post (what New Relic discovered when we used garbage collection to fine-tune our own website) APM Summary page (<em>features</em> and drill-down details when using the APM Summary page) Transactions page (<em>features</em> and drill-down details for transactions) <em>Ruby</em> <em>agent</em> configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)"
      },
      "id": "603eba3a28ccbcb144eba7aa"
    },
    {
      "sections": [
        "Message queues",
        "Requirements",
        "Performance improvements with background tasks",
        "Queue operations",
        "View in New Relic UI",
        "Transactions page",
        "Tip",
        "Transaction trace summary page",
        "Transaction trace details tab"
      ],
      "title": "Message queues",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "1c074612f5486198c2639542507e2008abb20187",
      "image": "https://docs.newrelic.com/static/1789ce28689c4575593e79b8305171fd/c1b63/transactions_page.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/message-queues/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-05-05T01:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe/consume messages) as Message background tasks. Message creation via RabbitMQ also appears in transaction traces. Requirements Requires New Relic Ruby agent version 4.3.0 or higher. Instrumentation is automatic for supported versions of Bunny AMQP, and requires no additional configuration. Performance improvements with background tasks One way to increase responsiveness of web applications is to delegate work to background processes. Message queues are commonly used for this inter-process communication. In the context of message queuing systems, applications typically interact with message brokers to send and receive messages. The RabbitMQ Bunny client library allows Ruby applications to interface with message brokers that implement the Advanced Message Queuing Protocol (AMQP). New Relic's Ruby agent shows messages sent and received using the RabbitMQ client library. With this visibility, you can see details including: Number of messages produced by your app Time your app spends publishing messages Time your app spends processing \"consumed\" messages APM conveniently groups and reports operations that interact with queues. By analyzing this information, you can more easily identify bottlenecks and areas for performance improvement in your message passing architecture. Queue operations Supported entry points for queue operations appear as Put (publish a message) or Take (receive a message) in APM's user interface. Queue operations Publish a message (Put in UI) Receive a message (Take in UI) RabbitMQ publish pop subscribe (with block) View in New Relic UI Message queue operations are visible in several places in the APM UI: Transactions page Queue operations appear on APM's Transactions page for the selected app. The Put and Take metrics appear in the Breakdown table and are categorized as MessageBroker metrics. Here is an example: Transaction traces also provide additional details for messages. Tip You can select transaction traces from the app's Summary or Transactions pages in APM. Transaction trace summary page The Transaction trace summary page may show Put and Take operations in the Slowest components section. For example: Transaction trace details tab The Transaction trace page includes a dedicated Details tab that shows more detailed information about the transaction. Here is an example:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.01539,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe&#x2F;consume messages) as Message background"
      },
      "id": "604427cb28ccbcc86f2c606a"
    }
  ],
  "/docs/agents/ruby-agent/features/garbage-collection": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.89346,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Message queues",
        "Requirements",
        "Performance improvements with background tasks",
        "Queue operations",
        "View in New Relic UI",
        "Transactions page",
        "Tip",
        "Transaction trace summary page",
        "Transaction trace details tab"
      ],
      "title": "Message queues",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "1c074612f5486198c2639542507e2008abb20187",
      "image": "https://docs.newrelic.com/static/1789ce28689c4575593e79b8305171fd/c1b63/transactions_page.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/message-queues/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-05-05T01:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe/consume messages) as Message background tasks. Message creation via RabbitMQ also appears in transaction traces. Requirements Requires New Relic Ruby agent version 4.3.0 or higher. Instrumentation is automatic for supported versions of Bunny AMQP, and requires no additional configuration. Performance improvements with background tasks One way to increase responsiveness of web applications is to delegate work to background processes. Message queues are commonly used for this inter-process communication. In the context of message queuing systems, applications typically interact with message brokers to send and receive messages. The RabbitMQ Bunny client library allows Ruby applications to interface with message brokers that implement the Advanced Message Queuing Protocol (AMQP). New Relic's Ruby agent shows messages sent and received using the RabbitMQ client library. With this visibility, you can see details including: Number of messages produced by your app Time your app spends publishing messages Time your app spends processing \"consumed\" messages APM conveniently groups and reports operations that interact with queues. By analyzing this information, you can more easily identify bottlenecks and areas for performance improvement in your message passing architecture. Queue operations Supported entry points for queue operations appear as Put (publish a message) or Take (receive a message) in APM's user interface. Queue operations Publish a message (Put in UI) Receive a message (Take in UI) RabbitMQ publish pop subscribe (with block) View in New Relic UI Message queue operations are visible in several places in the APM UI: Transactions page Queue operations appear on APM's Transactions page for the selected app. The Put and Take metrics appear in the Breakdown table and are categorized as MessageBroker metrics. Here is an example: Transaction traces also provide additional details for messages. Tip You can select transaction traces from the app's Summary or Transactions pages in APM. Transaction trace summary page The Transaction trace summary page may show Put and Take operations in the Slowest components section. For example: Transaction trace details tab The Transaction trace page includes a dedicated Details tab that shows more detailed information about the transaction. Here is an example:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.01539,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe&#x2F;consume messages) as Message background"
      },
      "id": "604427cb28ccbcc86f2c606a"
    },
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-03-16T07:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.10.1 or higher. Excon instrumentation for Excon versions 0.19.0 and up relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus currently only have partial tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Hydra mechanism will also not get cross application tracing support. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism will also not get cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.97043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests"
      },
      "id": "603eb84a196a6755a9a83de9"
    }
  ],
  "/docs/agents/ruby-agent/features/http-client-tracing-ruby": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.89346,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Garbage collection",
        "Important",
        "Enable garbage collection instrumentation",
        "View app-wide GC statistics",
        "View detailed GC metrics",
        "For more help"
      ],
      "title": "Garbage collection",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "9981cf22973c76aec7d8d0ac31c2793e04a42e48",
      "image": "https://docs.newrelic.com/static/e2fdc5c35adef00b9a2646a1ec6589c9/c1b63/garbage_collection_overview.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/garbage-collection/",
      "published_at": "2021-07-02T12:19:36Z",
      "updated_at": "2021-05-05T14:31:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Garbage collection (GC) finds unused data objects and reclaims that memory space for use by another process. The New Relic Ruby agent can collect information about how much time is spent in garbage collection for applications running on MRI 1.9.2 or higher or Ruby Enterprise Edition, but you must explicitly enable this feature in your application. Important Avoid using garbage collection in production for long periods of time, as it increases overhead. Enable garbage collection instrumentation To activate the feature, add the appropriate call in your application initialization. MRI 1.9.2 or higher: GC::Profiler.enable Ruby Enterprise Edition: GC.enable_stats For Rails applications, you can either add this call to an initializer in config/initializers, or add it directly to your config/application.rb file. View app-wide GC statistics To view overall garbage collection statistics: Log into New Relic, select a Ruby app, and go to Summary. From the APM Summary page, look for GC Execution statistics on the Web transactions time chart. one.newrelic.com > APM > (select a Ruby app) > Summary: On the Web transactions time chart, garbage collection statistics are labeled GC Execution. View detailed GC metrics To view garbage collection metrics on a per-transaction basis, go to one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction). You can then view the amount of time spent in GC, and the average number of times GC is called for each transaction. Hide other labels for a detailed view of garbage collection. one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction): Select an individual transaction to view detailed GC metrics, including average time and average number of calls. Detailed information includes: Garbage collection details Comments Trend of garbage collection time Garbage collection usually takes a small amount of time, and therefore the trend line may not be visible in your charts. To view the trend in garbage collection time, navigate to the overview chart or to detailed transaction metrics. Then, hide every chart label except GC Execution by selecting each label. Average number of calls To view the average number of garbage collection calls for each controller action: From your APM Summary page, select Transaction. Then select a controller action and view the App Server Breakdown. For more help Additional documentation resources include: \"Eating the 1.9 elephant\" blog post (what New Relic discovered when we used garbage collection to fine-tune our own website) APM Summary page (features and drill-down details when using the APM Summary page) Transactions page (features and drill-down details for transactions) Ruby agent configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.13186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Additional documentation resources include: &quot;Eating the 1.9 elephant&quot; blog post (what New Relic discovered when we used garbage collection to fine-tune our own website) APM Summary page (<em>features</em> and drill-down details when using the APM Summary page) Transactions page (<em>features</em> and drill-down details for transactions) <em>Ruby</em> <em>agent</em> configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)"
      },
      "id": "603eba3a28ccbcb144eba7aa"
    },
    {
      "sections": [
        "Message queues",
        "Requirements",
        "Performance improvements with background tasks",
        "Queue operations",
        "View in New Relic UI",
        "Transactions page",
        "Tip",
        "Transaction trace summary page",
        "Transaction trace details tab"
      ],
      "title": "Message queues",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "1c074612f5486198c2639542507e2008abb20187",
      "image": "https://docs.newrelic.com/static/1789ce28689c4575593e79b8305171fd/c1b63/transactions_page.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/message-queues/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-05-05T01:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe/consume messages) as Message background tasks. Message creation via RabbitMQ also appears in transaction traces. Requirements Requires New Relic Ruby agent version 4.3.0 or higher. Instrumentation is automatic for supported versions of Bunny AMQP, and requires no additional configuration. Performance improvements with background tasks One way to increase responsiveness of web applications is to delegate work to background processes. Message queues are commonly used for this inter-process communication. In the context of message queuing systems, applications typically interact with message brokers to send and receive messages. The RabbitMQ Bunny client library allows Ruby applications to interface with message brokers that implement the Advanced Message Queuing Protocol (AMQP). New Relic's Ruby agent shows messages sent and received using the RabbitMQ client library. With this visibility, you can see details including: Number of messages produced by your app Time your app spends publishing messages Time your app spends processing \"consumed\" messages APM conveniently groups and reports operations that interact with queues. By analyzing this information, you can more easily identify bottlenecks and areas for performance improvement in your message passing architecture. Queue operations Supported entry points for queue operations appear as Put (publish a message) or Take (receive a message) in APM's user interface. Queue operations Publish a message (Put in UI) Receive a message (Take in UI) RabbitMQ publish pop subscribe (with block) View in New Relic UI Message queue operations are visible in several places in the APM UI: Transactions page Queue operations appear on APM's Transactions page for the selected app. The Put and Take metrics appear in the Breakdown table and are categorized as MessageBroker metrics. Here is an example: Transaction traces also provide additional details for messages. Tip You can select transaction traces from the app's Summary or Transactions pages in APM. Transaction trace summary page The Transaction trace summary page may show Put and Take operations in the Slowest components section. For example: Transaction trace details tab The Transaction trace page includes a dedicated Details tab that shows more detailed information about the transaction. Here is an example:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.01539,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe&#x2F;consume messages) as Message background"
      },
      "id": "604427cb28ccbcc86f2c606a"
    }
  ],
  "/docs/agents/ruby-agent/features/message-queues": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.89345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Garbage collection",
        "Important",
        "Enable garbage collection instrumentation",
        "View app-wide GC statistics",
        "View detailed GC metrics",
        "For more help"
      ],
      "title": "Garbage collection",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "9981cf22973c76aec7d8d0ac31c2793e04a42e48",
      "image": "https://docs.newrelic.com/static/e2fdc5c35adef00b9a2646a1ec6589c9/c1b63/garbage_collection_overview.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/garbage-collection/",
      "published_at": "2021-07-02T12:19:36Z",
      "updated_at": "2021-05-05T14:31:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Garbage collection (GC) finds unused data objects and reclaims that memory space for use by another process. The New Relic Ruby agent can collect information about how much time is spent in garbage collection for applications running on MRI 1.9.2 or higher or Ruby Enterprise Edition, but you must explicitly enable this feature in your application. Important Avoid using garbage collection in production for long periods of time, as it increases overhead. Enable garbage collection instrumentation To activate the feature, add the appropriate call in your application initialization. MRI 1.9.2 or higher: GC::Profiler.enable Ruby Enterprise Edition: GC.enable_stats For Rails applications, you can either add this call to an initializer in config/initializers, or add it directly to your config/application.rb file. View app-wide GC statistics To view overall garbage collection statistics: Log into New Relic, select a Ruby app, and go to Summary. From the APM Summary page, look for GC Execution statistics on the Web transactions time chart. one.newrelic.com > APM > (select a Ruby app) > Summary: On the Web transactions time chart, garbage collection statistics are labeled GC Execution. View detailed GC metrics To view garbage collection metrics on a per-transaction basis, go to one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction). You can then view the amount of time spent in GC, and the average number of times GC is called for each transaction. Hide other labels for a detailed view of garbage collection. one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction): Select an individual transaction to view detailed GC metrics, including average time and average number of calls. Detailed information includes: Garbage collection details Comments Trend of garbage collection time Garbage collection usually takes a small amount of time, and therefore the trend line may not be visible in your charts. To view the trend in garbage collection time, navigate to the overview chart or to detailed transaction metrics. Then, hide every chart label except GC Execution by selecting each label. Average number of calls To view the average number of garbage collection calls for each controller action: From your APM Summary page, select Transaction. Then select a controller action and view the App Server Breakdown. For more help Additional documentation resources include: \"Eating the 1.9 elephant\" blog post (what New Relic discovered when we used garbage collection to fine-tune our own website) APM Summary page (features and drill-down details when using the APM Summary page) Transactions page (features and drill-down details for transactions) Ruby agent configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.13186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Additional documentation resources include: &quot;Eating the 1.9 elephant&quot; blog post (what New Relic discovered when we used garbage collection to fine-tune our own website) APM Summary page (<em>features</em> and drill-down details when using the APM Summary page) Transactions page (<em>features</em> and drill-down details for transactions) <em>Ruby</em> <em>agent</em> configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)"
      },
      "id": "603eba3a28ccbcb144eba7aa"
    },
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-03-16T07:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.10.1 or higher. Excon instrumentation for Excon versions 0.19.0 and up relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus currently only have partial tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Hydra mechanism will also not get cross application tracing support. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism will also not get cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.97043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests"
      },
      "id": "603eb84a196a6755a9a83de9"
    }
  ],
  "/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent": [
    {
      "sections": [
        "Garbage collection",
        "Important",
        "Enable garbage collection instrumentation",
        "View app-wide GC statistics",
        "View detailed GC metrics",
        "For more help"
      ],
      "title": "Garbage collection",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "9981cf22973c76aec7d8d0ac31c2793e04a42e48",
      "image": "https://docs.newrelic.com/static/e2fdc5c35adef00b9a2646a1ec6589c9/c1b63/garbage_collection_overview.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/garbage-collection/",
      "published_at": "2021-07-02T12:19:36Z",
      "updated_at": "2021-05-05T14:31:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Garbage collection (GC) finds unused data objects and reclaims that memory space for use by another process. The New Relic Ruby agent can collect information about how much time is spent in garbage collection for applications running on MRI 1.9.2 or higher or Ruby Enterprise Edition, but you must explicitly enable this feature in your application. Important Avoid using garbage collection in production for long periods of time, as it increases overhead. Enable garbage collection instrumentation To activate the feature, add the appropriate call in your application initialization. MRI 1.9.2 or higher: GC::Profiler.enable Ruby Enterprise Edition: GC.enable_stats For Rails applications, you can either add this call to an initializer in config/initializers, or add it directly to your config/application.rb file. View app-wide GC statistics To view overall garbage collection statistics: Log into New Relic, select a Ruby app, and go to Summary. From the APM Summary page, look for GC Execution statistics on the Web transactions time chart. one.newrelic.com > APM > (select a Ruby app) > Summary: On the Web transactions time chart, garbage collection statistics are labeled GC Execution. View detailed GC metrics To view garbage collection metrics on a per-transaction basis, go to one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction). You can then view the amount of time spent in GC, and the average number of times GC is called for each transaction. Hide other labels for a detailed view of garbage collection. one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction): Select an individual transaction to view detailed GC metrics, including average time and average number of calls. Detailed information includes: Garbage collection details Comments Trend of garbage collection time Garbage collection usually takes a small amount of time, and therefore the trend line may not be visible in your charts. To view the trend in garbage collection time, navigate to the overview chart or to detailed transaction metrics. Then, hide every chart label except GC Execution by selecting each label. Average number of calls To view the average number of garbage collection calls for each controller action: From your APM Summary page, select Transaction. Then select a controller action and view the App Server Breakdown. For more help Additional documentation resources include: \"Eating the 1.9 elephant\" blog post (what New Relic discovered when we used garbage collection to fine-tune our own website) APM Summary page (features and drill-down details when using the APM Summary page) Transactions page (features and drill-down details for transactions) Ruby agent configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.13186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Additional documentation resources include: &quot;Eating the 1.9 elephant&quot; blog post (what New Relic discovered when we used garbage collection to fine-tune our own website) APM Summary page (<em>features</em> and drill-down details when using the APM Summary page) Transactions page (<em>features</em> and drill-down details for transactions) <em>Ruby</em> <em>agent</em> configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)"
      },
      "id": "603eba3a28ccbcb144eba7aa"
    },
    {
      "sections": [
        "Message queues",
        "Requirements",
        "Performance improvements with background tasks",
        "Queue operations",
        "View in New Relic UI",
        "Transactions page",
        "Tip",
        "Transaction trace summary page",
        "Transaction trace details tab"
      ],
      "title": "Message queues",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "1c074612f5486198c2639542507e2008abb20187",
      "image": "https://docs.newrelic.com/static/1789ce28689c4575593e79b8305171fd/c1b63/transactions_page.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/message-queues/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-05-05T01:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe/consume messages) as Message background tasks. Message creation via RabbitMQ also appears in transaction traces. Requirements Requires New Relic Ruby agent version 4.3.0 or higher. Instrumentation is automatic for supported versions of Bunny AMQP, and requires no additional configuration. Performance improvements with background tasks One way to increase responsiveness of web applications is to delegate work to background processes. Message queues are commonly used for this inter-process communication. In the context of message queuing systems, applications typically interact with message brokers to send and receive messages. The RabbitMQ Bunny client library allows Ruby applications to interface with message brokers that implement the Advanced Message Queuing Protocol (AMQP). New Relic's Ruby agent shows messages sent and received using the RabbitMQ client library. With this visibility, you can see details including: Number of messages produced by your app Time your app spends publishing messages Time your app spends processing \"consumed\" messages APM conveniently groups and reports operations that interact with queues. By analyzing this information, you can more easily identify bottlenecks and areas for performance improvement in your message passing architecture. Queue operations Supported entry points for queue operations appear as Put (publish a message) or Take (receive a message) in APM's user interface. Queue operations Publish a message (Put in UI) Receive a message (Take in UI) RabbitMQ publish pop subscribe (with block) View in New Relic UI Message queue operations are visible in several places in the APM UI: Transactions page Queue operations appear on APM's Transactions page for the selected app. The Put and Take metrics appear in the Breakdown table and are categorized as MessageBroker metrics. Here is an example: Transaction traces also provide additional details for messages. Tip You can select transaction traces from the app's Summary or Transactions pages in APM. Transaction trace summary page The Transaction trace summary page may show Put and Take operations in the Slowest components section. For example: Transaction trace details tab The Transaction trace page includes a dedicated Details tab that shows more detailed information about the transaction. Here is an example:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.01539,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe&#x2F;consume messages) as Message background"
      },
      "id": "604427cb28ccbcc86f2c606a"
    },
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-03-16T07:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.10.1 or higher. Excon instrumentation for Excon versions 0.19.0 and up relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus currently only have partial tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Hydra mechanism will also not get cross application tracing support. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism will also not get cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.97043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests"
      },
      "id": "603eb84a196a6755a9a83de9"
    }
  ],
  "/docs/agents/ruby-agent/features/record-deployments-ruby-agent": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.89344,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Garbage collection",
        "Important",
        "Enable garbage collection instrumentation",
        "View app-wide GC statistics",
        "View detailed GC metrics",
        "For more help"
      ],
      "title": "Garbage collection",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "9981cf22973c76aec7d8d0ac31c2793e04a42e48",
      "image": "https://docs.newrelic.com/static/e2fdc5c35adef00b9a2646a1ec6589c9/c1b63/garbage_collection_overview.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/garbage-collection/",
      "published_at": "2021-07-02T12:19:36Z",
      "updated_at": "2021-05-05T14:31:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Garbage collection (GC) finds unused data objects and reclaims that memory space for use by another process. The New Relic Ruby agent can collect information about how much time is spent in garbage collection for applications running on MRI 1.9.2 or higher or Ruby Enterprise Edition, but you must explicitly enable this feature in your application. Important Avoid using garbage collection in production for long periods of time, as it increases overhead. Enable garbage collection instrumentation To activate the feature, add the appropriate call in your application initialization. MRI 1.9.2 or higher: GC::Profiler.enable Ruby Enterprise Edition: GC.enable_stats For Rails applications, you can either add this call to an initializer in config/initializers, or add it directly to your config/application.rb file. View app-wide GC statistics To view overall garbage collection statistics: Log into New Relic, select a Ruby app, and go to Summary. From the APM Summary page, look for GC Execution statistics on the Web transactions time chart. one.newrelic.com > APM > (select a Ruby app) > Summary: On the Web transactions time chart, garbage collection statistics are labeled GC Execution. View detailed GC metrics To view garbage collection metrics on a per-transaction basis, go to one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction). You can then view the amount of time spent in GC, and the average number of times GC is called for each transaction. Hide other labels for a detailed view of garbage collection. one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction): Select an individual transaction to view detailed GC metrics, including average time and average number of calls. Detailed information includes: Garbage collection details Comments Trend of garbage collection time Garbage collection usually takes a small amount of time, and therefore the trend line may not be visible in your charts. To view the trend in garbage collection time, navigate to the overview chart or to detailed transaction metrics. Then, hide every chart label except GC Execution by selecting each label. Average number of calls To view the average number of garbage collection calls for each controller action: From your APM Summary page, select Transaction. Then select a controller action and view the App Server Breakdown. For more help Additional documentation resources include: \"Eating the 1.9 elephant\" blog post (what New Relic discovered when we used garbage collection to fine-tune our own website) APM Summary page (features and drill-down details when using the APM Summary page) Transactions page (features and drill-down details for transactions) Ruby agent configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.13185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Additional documentation resources include: &quot;Eating the 1.9 elephant&quot; blog post (what New Relic discovered when we used garbage collection to fine-tune our own website) APM Summary page (<em>features</em> and drill-down details when using the APM Summary page) Transactions page (<em>features</em> and drill-down details for transactions) <em>Ruby</em> <em>agent</em> configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)"
      },
      "id": "603eba3a28ccbcb144eba7aa"
    },
    {
      "sections": [
        "Message queues",
        "Requirements",
        "Performance improvements with background tasks",
        "Queue operations",
        "View in New Relic UI",
        "Transactions page",
        "Tip",
        "Transaction trace summary page",
        "Transaction trace details tab"
      ],
      "title": "Message queues",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "1c074612f5486198c2639542507e2008abb20187",
      "image": "https://docs.newrelic.com/static/1789ce28689c4575593e79b8305171fd/c1b63/transactions_page.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/message-queues/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-05-05T01:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe/consume messages) as Message background tasks. Message creation via RabbitMQ also appears in transaction traces. Requirements Requires New Relic Ruby agent version 4.3.0 or higher. Instrumentation is automatic for supported versions of Bunny AMQP, and requires no additional configuration. Performance improvements with background tasks One way to increase responsiveness of web applications is to delegate work to background processes. Message queues are commonly used for this inter-process communication. In the context of message queuing systems, applications typically interact with message brokers to send and receive messages. The RabbitMQ Bunny client library allows Ruby applications to interface with message brokers that implement the Advanced Message Queuing Protocol (AMQP). New Relic's Ruby agent shows messages sent and received using the RabbitMQ client library. With this visibility, you can see details including: Number of messages produced by your app Time your app spends publishing messages Time your app spends processing \"consumed\" messages APM conveniently groups and reports operations that interact with queues. By analyzing this information, you can more easily identify bottlenecks and areas for performance improvement in your message passing architecture. Queue operations Supported entry points for queue operations appear as Put (publish a message) or Take (receive a message) in APM's user interface. Queue operations Publish a message (Put in UI) Receive a message (Take in UI) RabbitMQ publish pop subscribe (with block) View in New Relic UI Message queue operations are visible in several places in the APM UI: Transactions page Queue operations appear on APM's Transactions page for the selected app. The Put and Take metrics appear in the Breakdown table and are categorized as MessageBroker metrics. Here is an example: Transaction traces also provide additional details for messages. Tip You can select transaction traces from the app's Summary or Transactions pages in APM. Transaction trace summary page The Transaction trace summary page may show Put and Take operations in the Slowest components section. For example: Transaction trace details tab The Transaction trace page includes a dedicated Details tab that shows more detailed information about the transaction. Here is an example:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.01538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe&#x2F;consume messages) as Message background"
      },
      "id": "604427cb28ccbcc86f2c606a"
    }
  ],
  "/docs/agents/ruby-agent/features/ruby-vm-measurements": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.89344,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Garbage collection",
        "Important",
        "Enable garbage collection instrumentation",
        "View app-wide GC statistics",
        "View detailed GC metrics",
        "For more help"
      ],
      "title": "Garbage collection",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "9981cf22973c76aec7d8d0ac31c2793e04a42e48",
      "image": "https://docs.newrelic.com/static/e2fdc5c35adef00b9a2646a1ec6589c9/c1b63/garbage_collection_overview.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/garbage-collection/",
      "published_at": "2021-07-02T12:19:36Z",
      "updated_at": "2021-05-05T14:31:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Garbage collection (GC) finds unused data objects and reclaims that memory space for use by another process. The New Relic Ruby agent can collect information about how much time is spent in garbage collection for applications running on MRI 1.9.2 or higher or Ruby Enterprise Edition, but you must explicitly enable this feature in your application. Important Avoid using garbage collection in production for long periods of time, as it increases overhead. Enable garbage collection instrumentation To activate the feature, add the appropriate call in your application initialization. MRI 1.9.2 or higher: GC::Profiler.enable Ruby Enterprise Edition: GC.enable_stats For Rails applications, you can either add this call to an initializer in config/initializers, or add it directly to your config/application.rb file. View app-wide GC statistics To view overall garbage collection statistics: Log into New Relic, select a Ruby app, and go to Summary. From the APM Summary page, look for GC Execution statistics on the Web transactions time chart. one.newrelic.com > APM > (select a Ruby app) > Summary: On the Web transactions time chart, garbage collection statistics are labeled GC Execution. View detailed GC metrics To view garbage collection metrics on a per-transaction basis, go to one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction). You can then view the amount of time spent in GC, and the average number of times GC is called for each transaction. Hide other labels for a detailed view of garbage collection. one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction): Select an individual transaction to view detailed GC metrics, including average time and average number of calls. Detailed information includes: Garbage collection details Comments Trend of garbage collection time Garbage collection usually takes a small amount of time, and therefore the trend line may not be visible in your charts. To view the trend in garbage collection time, navigate to the overview chart or to detailed transaction metrics. Then, hide every chart label except GC Execution by selecting each label. Average number of calls To view the average number of garbage collection calls for each controller action: From your APM Summary page, select Transaction. Then select a controller action and view the App Server Breakdown. For more help Additional documentation resources include: \"Eating the 1.9 elephant\" blog post (what New Relic discovered when we used garbage collection to fine-tune our own website) APM Summary page (features and drill-down details when using the APM Summary page) Transactions page (features and drill-down details for transactions) Ruby agent configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.13185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Additional documentation resources include: &quot;Eating the 1.9 elephant&quot; blog post (what New Relic discovered when we used garbage collection to fine-tune our own website) APM Summary page (<em>features</em> and drill-down details when using the APM Summary page) Transactions page (<em>features</em> and drill-down details for transactions) <em>Ruby</em> <em>agent</em> configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)"
      },
      "id": "603eba3a28ccbcb144eba7aa"
    },
    {
      "sections": [
        "Message queues",
        "Requirements",
        "Performance improvements with background tasks",
        "Queue operations",
        "View in New Relic UI",
        "Transactions page",
        "Tip",
        "Transaction trace summary page",
        "Transaction trace details tab"
      ],
      "title": "Message queues",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "1c074612f5486198c2639542507e2008abb20187",
      "image": "https://docs.newrelic.com/static/1789ce28689c4575593e79b8305171fd/c1b63/transactions_page.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/message-queues/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-05-05T01:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe/consume messages) as Message background tasks. Message creation via RabbitMQ also appears in transaction traces. Requirements Requires New Relic Ruby agent version 4.3.0 or higher. Instrumentation is automatic for supported versions of Bunny AMQP, and requires no additional configuration. Performance improvements with background tasks One way to increase responsiveness of web applications is to delegate work to background processes. Message queues are commonly used for this inter-process communication. In the context of message queuing systems, applications typically interact with message brokers to send and receive messages. The RabbitMQ Bunny client library allows Ruby applications to interface with message brokers that implement the Advanced Message Queuing Protocol (AMQP). New Relic's Ruby agent shows messages sent and received using the RabbitMQ client library. With this visibility, you can see details including: Number of messages produced by your app Time your app spends publishing messages Time your app spends processing \"consumed\" messages APM conveniently groups and reports operations that interact with queues. By analyzing this information, you can more easily identify bottlenecks and areas for performance improvement in your message passing architecture. Queue operations Supported entry points for queue operations appear as Put (publish a message) or Take (receive a message) in APM's user interface. Queue operations Publish a message (Put in UI) Receive a message (Take in UI) RabbitMQ publish pop subscribe (with block) View in New Relic UI Message queue operations are visible in several places in the APM UI: Transactions page Queue operations appear on APM's Transactions page for the selected app. The Put and Take metrics appear in the Breakdown table and are categorized as MessageBroker metrics. Here is an example: Transaction traces also provide additional details for messages. Tip You can select transaction traces from the app's Summary or Transactions pages in APM. Transaction trace summary page The Transaction trace summary page may show Put and Take operations in the Slowest components section. For example: Transaction trace details tab The Transaction trace page includes a dedicated Details tab that shows more detailed information about the transaction. Here is an example:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.01538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe&#x2F;consume messages) as Message background"
      },
      "id": "604427cb28ccbcc86f2c606a"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/metal-controller-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-05-05T14:33:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Cross application traces Auto-instrumentation for Browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's Cross Application Tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you have disabled middleware instrumentation as described above and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. For more information, see Cross application tracing in Ruby. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.13702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-07-02T12:23:04Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.55362,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)",
        "For more help"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-03-16T06:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work. For more help Additional documentation resources include Browser monitoring and the Ruby agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.43782,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/mongo-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-05-05T14:33:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Cross application traces Auto-instrumentation for Browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's Cross Application Tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you have disabled middleware instrumentation as described above and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. For more information, see Cross application tracing in Ruby. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.13702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)",
        "For more help"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-03-16T06:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work. For more help Additional documentation resources include Browser monitoring and the Ruby agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.43782,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Redis instrumentation",
        "Tip",
        "Interaction with newrelic-redis",
        "Important",
        "Capture Redis command arguments"
      ],
      "title": "Redis instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "9923fcd7dd89191c620a9490fb89cd8ca4bf31e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation/",
      "published_at": "2021-07-02T12:28:36Z",
      "updated_at": "2021-03-16T08:03:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent automatically instruments the Redis gem (gem version 3.0.0 or higher). After you install the agent and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart on the APM Summary page will show color-coded Redis information. Tip Redis instrumentation requires Ruby agent version 3.13.0 or higher. Interaction with newrelic-redis The third-party newrelic-redis gem provides Redis instrumentation support as an add-on to New Relic's Ruby agent. If the Ruby agent detects newrelic-redis, it will not install the built-in Redis instrumentation and will record a log message like this at startup: INFO : Not installing New Relic supported Redis instrumentation because the third party newrelic-redis gem is present Copy To use New Relic's built-in Redis instrumentation and view Redis information in the UI, remove the newrelic-redis gem. Important Removing the newrelic-redis gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. Capture Redis command arguments By default, the Ruby agent only captures Redis command names. To capture Redis command arguments, use this configuration: transaction_tracer: record_redis_arguments: true Copy The agent limits the number of characters and arguments collected from each transaction trace node. The agent truncates items that exceed these limits.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.40384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Redis <em>instrumentation</em>",
        "sections": "Redis <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> automatically instruments the Redis <em>gem</em> (<em>gem</em> version 3.0.0 or higher). After you install the <em>agent</em> and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart"
      },
      "id": "603ed7a628ccbca064eba784"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/rack-metal-support": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-05-05T14:33:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Cross application traces Auto-instrumentation for Browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's Cross Application Tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you have disabled middleware instrumentation as described above and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. For more information, see Cross application tracing in Ruby. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.13702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-07-02T12:23:04Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.55362,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)",
        "For more help"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-03-16T06:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work. For more help Additional documentation resources include Browser monitoring and the Ruby agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.43782,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/sequel-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-05-05T14:33:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Cross application traces Auto-instrumentation for Browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's Cross Application Tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you have disabled middleware instrumentation as described above and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. For more information, see Cross application tracing in Ruby. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.13702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-07-02T12:23:04Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.55362,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)",
        "For more help"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-03-16T06:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work. For more help Additional documentation resources include Browser monitoring and the Ruby agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.43782,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/apm-agent-security-ruby": [
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-07-02T12:24:20Z",
      "updated_at": "2021-04-28T01:27:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent include: Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the Browser JavaScript agent when you enable auto-instrumentation. After enabling Browser injection, you can view Browser data in the APM Summary page and quickly switch between the APM and Browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.215004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " not listed for your New Relic <em>agent</em>, <em>get</em> support at support.newrelic.com. Background jobs Background jobs supported by the New Relic <em>Ruby</em> <em>agent</em> include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3"
      },
      "id": "603ebad028ccbc6835eba79d"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Tip",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-07-02T12:23:04Z",
      "updated_at": "2021-03-16T08:00:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Tip To use Ruby or any other agent, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Integrate the Ruby agent with New Relic Browser to gain visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.55054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " frameworks and platforms. You can also use the <em>Ruby</em> <em>agent</em> in a Google App Engine (GAE) flexible environment. Before you install the <em>Ruby</em> <em>agent</em>, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app&#x27;s Apdex (user satisfaction). <em>Get</em>"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Compatibility and requirements for the Java agent",
        "Requirements to install the agent",
        "JVM",
        "Tip",
        "Security requirements",
        "Use of other monitoring software",
        "Built-in instrumentation",
        "App/Web servers",
        "Frameworks and libraries",
        "HTTP and messaging",
        "Datastores",
        "Instance-level database information",
        "Hosting services",
        "Asynchronous instrumentation",
        "Other instrumented features",
        "Connect the agent to other New Relic products"
      ],
      "title": "Compatibility and requirements for the Java agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "Getting started"
      ],
      "external_id": "4f74ff9a5d2402145001db0dd2c07e95166e2403",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/java-agent/getting-started/compatibility-requirements-java-agent/",
      "published_at": "2021-07-01T21:42:46Z",
      "updated_at": "2021-07-01T21:42:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Java agent includes built-in instrumentation of the most popular parts of the Java ecosystem, including app servers, frameworks, databases, and message queuing systems. For frameworks and libraries that are not instrumented out of the box, you can extend the agent with Java custom instrumentation. Requirements to install the agent Before you install the Java agent, ensure your system meets these requirements: JVM Tip The Java agent is compatible with any JVM-based language, including: Java, Scala, Kotlin, and Clojure. For instrumentation support for language-specific features, see the Automatically instrumented frameworks and libraries section below. Java version Compatible agent versions Java 5 Agent v1.3.0 to v2.21.7 Java 6 Agent v3.0.0 to v4.3.0 Java 7 Agent v3.0.0 to v6.5.0 Java 8 Agent v3.10.0 to current Java 9 Agent v3.43.0 to current Java 10 Agent v4.4.0 to current Java 11 Agent v4.7.0 to current Java 12 Agent v4.12.0 to current Java 13 Agent v5.7.0 to current Java 14 Agent v5.11.0 to current Java 15 Agent v6.1.0 to current Compatible: IBM JVM versions 7 and 8 for Linux Eclipse OpenJ9 versions 8 to 13 for Linux, Windows, and macOS OpenJDK and AdoptOpenJDK JVM versions 7 to 15 for Linux, Windows, and macOS Oracle Hotspot JVM versions 7 to 15 for Linux, Solaris, Windows, and macOS Azul Zing JVM versions 8 and 11 for Linux, Windows, and macOS Azul Zulu JVM versions 8 to 12 for Linux, Windows, and macOS Amazon Corretto JVM versions 8 and 11 for Linux, Windows, and macOS Alibaba Dragonwell JVM versions 8 and 11 for Linux, Windows, and macOS Compatible only with Java agent 4.3.x [ ZIP | 2.8 MB] legacy agent: Apple Hotspot JVM version 6 for macOS IBM JVM version 6 Oracle Hotspot JVM version 6.0 for Linux, Solaris, Windows, macOS Compatible only with Java agent 2.21.x [ ZIP | 2.8 MB] legacy agent: Oracle Hotspot JVM version 5.0 for Linux, Solaris, Windows, macOS (Java SE 5.0) Oracle JRockit up to and including 1.6.0_50 Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Use of other monitoring software If your application uses other application monitoring software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors while using other monitoring software. Built-in instrumentation After you install the Java agent, it automatically instruments many popular frameworks and libraries. With automatic instrumentation, the agent collects rich data out of the box, and data will show up in your New Relic dashboards within minutes of installation. Even if your library is not automatically instrumented, you can still collect data with custom instrumentation and the Java agent API. The agent automatically instruments these frameworks and libraries: App/Web servers The agent automatically instruments the following app/web servers. To install the Java agent on supported app/web servers, see Install the Java agent. ColdFusion 10 Glassfish 3.0 to 5.x JBoss 7.0 to latest JBoss EAP 6.0 to latest Jetty 7.0.0.M3 to 9.4.x Mule ESB 3.4 to 3.8.x Netty 3.3.0.Alpha1 to 5.0.0.Alpha1 Resin 3.1.9 to 4.0.x Spray-can 1.3.1 to latest Tomcat 7.0.0 to 9.0.x TomEE 1.5 to 8.0.x WebLogic 12.1.2.1 to 12.2.x WebSphere 8.5.x to 9.x WebSphere Liberty Profile 8.5 to latest WildFly 8.0.0.Final to latest Frameworks and libraries The agent automatically instruments the following frameworks. To install the Java agent on supported frameworks, see Install the Java agent. Akka 2.2.0-RC1 to latest AmazonS3 client 1.2.13 to latest AmazonSNS and AmazonSNSAsync clients 1.11.12 to latest AmazonSQS and AmazonSQSAsync clients 1.3.22 to latest S3Client 2.1.0 to latest SnsClient 2.1.0 to latest SqsClient 2.1.0 to latest CXF 2.1.3 to latest Grails 1.3.7 to 2.3.x Hibernate 3.3.0.CR1 to 6.0.0.Alpha2 Hystrix 1.3.15 to latest JAX-RS 1.0 to 2.0 JCache API 1.0.0 to latest Jersey 1.0.1 to 2.x JSF (Java Server Faces) Play 2.3.0 to latest Quartz Job Scheduler 1.8.3 to 2.2.x RESTEasy 2.2-RC-1 to latest Spray 1.3.1 to latest Spring 3.0.0.RELEASE to latest Spring webclient 5.0.0.RELEASE to latest Spring Web Services from 1.5.7 to latest Spring Boot 1.4.x to latest Struts 2 Thrift 0.8.0 to latest Vert.x 3.2.0 to 3.8.3 HTTP and messaging The agent automatically instruments the following HTTP clients and messaging services. For instructions, see Install the Java agent. Akka HTTP 2.4.5 to latest Akka Http Core from 0.4 to latest AsyncHttpClient 2.0.0-RC1 to latest gRPC 1.4.0 to latest HttpAsyncClient 4.1 to latest Apache Httpclient from 3.0 to latest java.net.HttpURLConnection JMS and Spring-JMS 1.1 to latest Kafka Clients 0.10.0.0 to latest (for metric and event data) Kafka Clients 0.11.0.0 to latest (for distributed tracing, metric, and event data) OkHttp 3.x to 4.3.x Ning AsyncHttpClient 1.x Play WS 2.6.0 to latest RabbitMQ 1.7.2 to latest (AMQP and JMS) Spray-client 1.3.1 to latest Spring webclient from 5.0.0.release to latest Datastores New Relic currently supports MySQL and PostgreSQL to capture explain plans for slow database queries. Amazon DynamoDB 1.11.106 to latest Anorm from 2.0 to 2.5 DataStax Cassandra 2.1.2 to 4.0.0 (If you use high security, see the configuration documentation for allow lists.) DB2 9.1 to latest Derby 10.2.1.6 to latest Generic JDBC (any JDBC compliant driver) H2 1.0.57 to latest HSQL 1.7.2.2 to latest INet Oracle Driver (Oranxo) 3.06, 3.14 INet MERLIA 7.0.3, 8.04.03, and 8.06 Jedis Redis driver 1.4.0 to 2.10.x, 3.0.0 to latest jTDS 1.2 to latest MariaDB 1.1.7 or higher Microsoft SQL Server 1.2 to latest MongoDB 2.12.0-rc0 to latest (synchronous clients only) MySQL mysql-connector-java 3.0.8 to latest Oracle ojdbc5, ojdbc6, ojdbc7, ojdbc8, ojdbc10, ojdbc14 Postgres 8.0-312.jdbc3 to latest Slick 3.0.0 to latest Solr 4.0 to latest Spymemcached 2.11 to latest Sybase (jConnect) JDBC 3 driver 6.0 to latest Instance-level database information New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Java agent versions 3.33.0 or higher support the following: Any compatible JDBC driver Amazon DynamoDB 1.11.106 or higher DataStax Cassandra driver 2.1.2 to 4.0.0 Jedis Redis driver 1.4 to 2.10.x, 3.0.0 to latest Mongo 2.12.0 to latest (synchronous clients only)/li> Spymemcached 2.11.0 to 2.12.x Exception: Instance-level information is not reported for calls to the getBulk() API method. The Java agent reports the database name and database server/identifier attributes on slow query traces and transaction traces for these database drivers. To request instance-level information from additional datastores, get support at support.newrelic.com. Hosting services You can install the Java agent on a variety of hosting services, including ones not listed below. Here are detailed installation guides for particular hosting services: Google App Engine (GAE) flexible environment Heroku Asynchronous instrumentation For supported frameworks, the Java agent usually instruments async work automatically. However, you can use the Java agent API to extend this instrumentation. Other instrumented features EJB Session Beans 3.0 or higher JMX JSP (Java Server Pages) 2.0 to 2.2 Scala 2.9.3 to 2.13.x Connect the agent to other New Relic products The Java agent integrates with other New Relic products to give you end-to-end visibility: Product Integration Browser monitoring The Java agent automatically injects the Browser JavaScript agent when you enable auto-instrumentation. After enabling Browser injection, you can view Browser data in the APM Summary page and quickly switch between the APM and Browser data for a particular app. For configuration options and manual instrumentation, see Browser monitoring and the Java agent. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in Infrastructure. New Relic One dashboards The Java agent sends default events and attributes to dashboards, or you can run NRQL queries in the query builder. You can also record custom events for advanced analysis. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.69803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for the Java <em>agent</em>",
        "sections": "Compatibility and requirements for the Java <em>agent</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Bulk() API method. The Java <em>agent</em> reports the database name and database server&#x2F;identifier attributes on slow query traces and transaction traces for these database drivers. To request instance-level information from additional datastores, <em>get</em> support at support.newrelic.com. Hosting services You can"
      },
      "id": "6043b8f6196a6771a9960f87"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby": [
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-07-02T12:24:20Z",
      "updated_at": "2021-04-28T01:27:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent include: Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the Browser JavaScript agent when you enable auto-instrumentation. After enabling Browser injection, you can view Browser data in the APM Summary page and quickly switch between the APM and Browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.215004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " not listed for your New Relic <em>agent</em>, <em>get</em> support at support.newrelic.com. Background jobs Background jobs supported by the New Relic <em>Ruby</em> <em>agent</em> include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3"
      },
      "id": "603ebad028ccbc6835eba79d"
    },
    {
      "sections": [
        "Compatibility and requirements for the Java agent",
        "Requirements to install the agent",
        "JVM",
        "Tip",
        "Security requirements",
        "Use of other monitoring software",
        "Built-in instrumentation",
        "App/Web servers",
        "Frameworks and libraries",
        "HTTP and messaging",
        "Datastores",
        "Instance-level database information",
        "Hosting services",
        "Asynchronous instrumentation",
        "Other instrumented features",
        "Connect the agent to other New Relic products"
      ],
      "title": "Compatibility and requirements for the Java agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "Getting started"
      ],
      "external_id": "4f74ff9a5d2402145001db0dd2c07e95166e2403",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/java-agent/getting-started/compatibility-requirements-java-agent/",
      "published_at": "2021-07-01T21:42:46Z",
      "updated_at": "2021-07-01T21:42:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Java agent includes built-in instrumentation of the most popular parts of the Java ecosystem, including app servers, frameworks, databases, and message queuing systems. For frameworks and libraries that are not instrumented out of the box, you can extend the agent with Java custom instrumentation. Requirements to install the agent Before you install the Java agent, ensure your system meets these requirements: JVM Tip The Java agent is compatible with any JVM-based language, including: Java, Scala, Kotlin, and Clojure. For instrumentation support for language-specific features, see the Automatically instrumented frameworks and libraries section below. Java version Compatible agent versions Java 5 Agent v1.3.0 to v2.21.7 Java 6 Agent v3.0.0 to v4.3.0 Java 7 Agent v3.0.0 to v6.5.0 Java 8 Agent v3.10.0 to current Java 9 Agent v3.43.0 to current Java 10 Agent v4.4.0 to current Java 11 Agent v4.7.0 to current Java 12 Agent v4.12.0 to current Java 13 Agent v5.7.0 to current Java 14 Agent v5.11.0 to current Java 15 Agent v6.1.0 to current Compatible: IBM JVM versions 7 and 8 for Linux Eclipse OpenJ9 versions 8 to 13 for Linux, Windows, and macOS OpenJDK and AdoptOpenJDK JVM versions 7 to 15 for Linux, Windows, and macOS Oracle Hotspot JVM versions 7 to 15 for Linux, Solaris, Windows, and macOS Azul Zing JVM versions 8 and 11 for Linux, Windows, and macOS Azul Zulu JVM versions 8 to 12 for Linux, Windows, and macOS Amazon Corretto JVM versions 8 and 11 for Linux, Windows, and macOS Alibaba Dragonwell JVM versions 8 and 11 for Linux, Windows, and macOS Compatible only with Java agent 4.3.x [ ZIP | 2.8 MB] legacy agent: Apple Hotspot JVM version 6 for macOS IBM JVM version 6 Oracle Hotspot JVM version 6.0 for Linux, Solaris, Windows, macOS Compatible only with Java agent 2.21.x [ ZIP | 2.8 MB] legacy agent: Oracle Hotspot JVM version 5.0 for Linux, Solaris, Windows, macOS (Java SE 5.0) Oracle JRockit up to and including 1.6.0_50 Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Use of other monitoring software If your application uses other application monitoring software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors while using other monitoring software. Built-in instrumentation After you install the Java agent, it automatically instruments many popular frameworks and libraries. With automatic instrumentation, the agent collects rich data out of the box, and data will show up in your New Relic dashboards within minutes of installation. Even if your library is not automatically instrumented, you can still collect data with custom instrumentation and the Java agent API. The agent automatically instruments these frameworks and libraries: App/Web servers The agent automatically instruments the following app/web servers. To install the Java agent on supported app/web servers, see Install the Java agent. ColdFusion 10 Glassfish 3.0 to 5.x JBoss 7.0 to latest JBoss EAP 6.0 to latest Jetty 7.0.0.M3 to 9.4.x Mule ESB 3.4 to 3.8.x Netty 3.3.0.Alpha1 to 5.0.0.Alpha1 Resin 3.1.9 to 4.0.x Spray-can 1.3.1 to latest Tomcat 7.0.0 to 9.0.x TomEE 1.5 to 8.0.x WebLogic 12.1.2.1 to 12.2.x WebSphere 8.5.x to 9.x WebSphere Liberty Profile 8.5 to latest WildFly 8.0.0.Final to latest Frameworks and libraries The agent automatically instruments the following frameworks. To install the Java agent on supported frameworks, see Install the Java agent. Akka 2.2.0-RC1 to latest AmazonS3 client 1.2.13 to latest AmazonSNS and AmazonSNSAsync clients 1.11.12 to latest AmazonSQS and AmazonSQSAsync clients 1.3.22 to latest S3Client 2.1.0 to latest SnsClient 2.1.0 to latest SqsClient 2.1.0 to latest CXF 2.1.3 to latest Grails 1.3.7 to 2.3.x Hibernate 3.3.0.CR1 to 6.0.0.Alpha2 Hystrix 1.3.15 to latest JAX-RS 1.0 to 2.0 JCache API 1.0.0 to latest Jersey 1.0.1 to 2.x JSF (Java Server Faces) Play 2.3.0 to latest Quartz Job Scheduler 1.8.3 to 2.2.x RESTEasy 2.2-RC-1 to latest Spray 1.3.1 to latest Spring 3.0.0.RELEASE to latest Spring webclient 5.0.0.RELEASE to latest Spring Web Services from 1.5.7 to latest Spring Boot 1.4.x to latest Struts 2 Thrift 0.8.0 to latest Vert.x 3.2.0 to 3.8.3 HTTP and messaging The agent automatically instruments the following HTTP clients and messaging services. For instructions, see Install the Java agent. Akka HTTP 2.4.5 to latest Akka Http Core from 0.4 to latest AsyncHttpClient 2.0.0-RC1 to latest gRPC 1.4.0 to latest HttpAsyncClient 4.1 to latest Apache Httpclient from 3.0 to latest java.net.HttpURLConnection JMS and Spring-JMS 1.1 to latest Kafka Clients 0.10.0.0 to latest (for metric and event data) Kafka Clients 0.11.0.0 to latest (for distributed tracing, metric, and event data) OkHttp 3.x to 4.3.x Ning AsyncHttpClient 1.x Play WS 2.6.0 to latest RabbitMQ 1.7.2 to latest (AMQP and JMS) Spray-client 1.3.1 to latest Spring webclient from 5.0.0.release to latest Datastores New Relic currently supports MySQL and PostgreSQL to capture explain plans for slow database queries. Amazon DynamoDB 1.11.106 to latest Anorm from 2.0 to 2.5 DataStax Cassandra 2.1.2 to 4.0.0 (If you use high security, see the configuration documentation for allow lists.) DB2 9.1 to latest Derby 10.2.1.6 to latest Generic JDBC (any JDBC compliant driver) H2 1.0.57 to latest HSQL 1.7.2.2 to latest INet Oracle Driver (Oranxo) 3.06, 3.14 INet MERLIA 7.0.3, 8.04.03, and 8.06 Jedis Redis driver 1.4.0 to 2.10.x, 3.0.0 to latest jTDS 1.2 to latest MariaDB 1.1.7 or higher Microsoft SQL Server 1.2 to latest MongoDB 2.12.0-rc0 to latest (synchronous clients only) MySQL mysql-connector-java 3.0.8 to latest Oracle ojdbc5, ojdbc6, ojdbc7, ojdbc8, ojdbc10, ojdbc14 Postgres 8.0-312.jdbc3 to latest Slick 3.0.0 to latest Solr 4.0 to latest Spymemcached 2.11 to latest Sybase (jConnect) JDBC 3 driver 6.0 to latest Instance-level database information New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Java agent versions 3.33.0 or higher support the following: Any compatible JDBC driver Amazon DynamoDB 1.11.106 or higher DataStax Cassandra driver 2.1.2 to 4.0.0 Jedis Redis driver 1.4 to 2.10.x, 3.0.0 to latest Mongo 2.12.0 to latest (synchronous clients only)/li> Spymemcached 2.11.0 to 2.12.x Exception: Instance-level information is not reported for calls to the getBulk() API method. The Java agent reports the database name and database server/identifier attributes on slow query traces and transaction traces for these database drivers. To request instance-level information from additional datastores, get support at support.newrelic.com. Hosting services You can install the Java agent on a variety of hosting services, including ones not listed below. Here are detailed installation guides for particular hosting services: Google App Engine (GAE) flexible environment Heroku Asynchronous instrumentation For supported frameworks, the Java agent usually instruments async work automatically. However, you can use the Java agent API to extend this instrumentation. Other instrumented features EJB Session Beans 3.0 or higher JMX JSP (Java Server Pages) 2.0 to 2.2 Scala 2.9.3 to 2.13.x Connect the agent to other New Relic products The Java agent integrates with other New Relic products to give you end-to-end visibility: Product Integration Browser monitoring The Java agent automatically injects the Browser JavaScript agent when you enable auto-instrumentation. After enabling Browser injection, you can view Browser data in the APM Summary page and quickly switch between the APM and Browser data for a particular app. For configuration options and manual instrumentation, see Browser monitoring and the Java agent. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in Infrastructure. New Relic One dashboards The Java agent sends default events and attributes to dashboards, or you can run NRQL queries in the query builder. You can also record custom events for advanced analysis. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.69797,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for the Java <em>agent</em>",
        "sections": "Compatibility and requirements for the Java <em>agent</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Bulk() API method. The Java <em>agent</em> reports the database name and database server&#x2F;identifier attributes on slow query traces and transaction traces for these database drivers. To request instance-level information from additional datastores, <em>get</em> support at support.newrelic.com. Hosting services You can"
      },
      "id": "6043b8f6196a6771a9960f87"
    },
    {
      "sections": [
        "New Relic's GitHub repository"
      ],
      "title": "New Relic's GitHub repository",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "98a98d3ab40ab9b58304065ccdb043af42d35bdd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/new-relics-github-repository/",
      "published_at": "2021-07-02T12:24:19Z",
      "updated_at": "2021-03-16T08:00:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic clones the Ruby repository on GitHub at newrelic-ruby-agent. GitHub also hosts limited rdoc-generated documentation: rdoc.info/github/newrelic/newrelic-ruby-agent. The head of main will generally have New Relic's latest release. However, we reserve the ability to push an edge to the master. If you download a release from GitHub, use the appropriate tag. We usually push beta versions of a release to a working branch before tagging them for General Availability. Fork away and feel free to send us pull requests (branches only please) for any ideas or bugfixes you come up with at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.63823,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "New Relic clones the <em>Ruby</em> repository on GitHub at newrelic-<em>ruby</em>-<em>agent</em>. GitHub also hosts limited rdoc-generated documentation: rdoc.info&#x2F;github&#x2F;newrelic&#x2F;newrelic-<em>ruby</em>-<em>agent</em>. The head of main will generally have New Relic&#x27;s latest release. However, we reserve the ability to push an edge"
      },
      "id": "603eb6b564441f50c84e8879"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/migration-7x-guide": [
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-07-02T12:24:20Z",
      "updated_at": "2021-04-28T01:27:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent include: Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the Browser JavaScript agent when you enable auto-instrumentation. After enabling Browser injection, you can view Browser data in the APM Summary page and quickly switch between the APM and Browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.215004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " not listed for your New Relic <em>agent</em>, <em>get</em> support at support.newrelic.com. Background jobs Background jobs supported by the New Relic <em>Ruby</em> <em>agent</em> include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3"
      },
      "id": "603ebad028ccbc6835eba79d"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Tip",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-07-02T12:23:04Z",
      "updated_at": "2021-03-16T08:00:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Tip To use Ruby or any other agent, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Integrate the Ruby agent with New Relic Browser to gain visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.55054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " frameworks and platforms. You can also use the <em>Ruby</em> <em>agent</em> in a Google App Engine (GAE) flexible environment. Before you install the <em>Ruby</em> <em>agent</em>, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app&#x27;s Apdex (user satisfaction). <em>Get</em>"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Compatibility and requirements for the Java agent",
        "Requirements to install the agent",
        "JVM",
        "Tip",
        "Security requirements",
        "Use of other monitoring software",
        "Built-in instrumentation",
        "App/Web servers",
        "Frameworks and libraries",
        "HTTP and messaging",
        "Datastores",
        "Instance-level database information",
        "Hosting services",
        "Asynchronous instrumentation",
        "Other instrumented features",
        "Connect the agent to other New Relic products"
      ],
      "title": "Compatibility and requirements for the Java agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "Getting started"
      ],
      "external_id": "4f74ff9a5d2402145001db0dd2c07e95166e2403",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/java-agent/getting-started/compatibility-requirements-java-agent/",
      "published_at": "2021-07-01T21:42:46Z",
      "updated_at": "2021-07-01T21:42:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Java agent includes built-in instrumentation of the most popular parts of the Java ecosystem, including app servers, frameworks, databases, and message queuing systems. For frameworks and libraries that are not instrumented out of the box, you can extend the agent with Java custom instrumentation. Requirements to install the agent Before you install the Java agent, ensure your system meets these requirements: JVM Tip The Java agent is compatible with any JVM-based language, including: Java, Scala, Kotlin, and Clojure. For instrumentation support for language-specific features, see the Automatically instrumented frameworks and libraries section below. Java version Compatible agent versions Java 5 Agent v1.3.0 to v2.21.7 Java 6 Agent v3.0.0 to v4.3.0 Java 7 Agent v3.0.0 to v6.5.0 Java 8 Agent v3.10.0 to current Java 9 Agent v3.43.0 to current Java 10 Agent v4.4.0 to current Java 11 Agent v4.7.0 to current Java 12 Agent v4.12.0 to current Java 13 Agent v5.7.0 to current Java 14 Agent v5.11.0 to current Java 15 Agent v6.1.0 to current Compatible: IBM JVM versions 7 and 8 for Linux Eclipse OpenJ9 versions 8 to 13 for Linux, Windows, and macOS OpenJDK and AdoptOpenJDK JVM versions 7 to 15 for Linux, Windows, and macOS Oracle Hotspot JVM versions 7 to 15 for Linux, Solaris, Windows, and macOS Azul Zing JVM versions 8 and 11 for Linux, Windows, and macOS Azul Zulu JVM versions 8 to 12 for Linux, Windows, and macOS Amazon Corretto JVM versions 8 and 11 for Linux, Windows, and macOS Alibaba Dragonwell JVM versions 8 and 11 for Linux, Windows, and macOS Compatible only with Java agent 4.3.x [ ZIP | 2.8 MB] legacy agent: Apple Hotspot JVM version 6 for macOS IBM JVM version 6 Oracle Hotspot JVM version 6.0 for Linux, Solaris, Windows, macOS Compatible only with Java agent 2.21.x [ ZIP | 2.8 MB] legacy agent: Oracle Hotspot JVM version 5.0 for Linux, Solaris, Windows, macOS (Java SE 5.0) Oracle JRockit up to and including 1.6.0_50 Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Use of other monitoring software If your application uses other application monitoring software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors while using other monitoring software. Built-in instrumentation After you install the Java agent, it automatically instruments many popular frameworks and libraries. With automatic instrumentation, the agent collects rich data out of the box, and data will show up in your New Relic dashboards within minutes of installation. Even if your library is not automatically instrumented, you can still collect data with custom instrumentation and the Java agent API. The agent automatically instruments these frameworks and libraries: App/Web servers The agent automatically instruments the following app/web servers. To install the Java agent on supported app/web servers, see Install the Java agent. ColdFusion 10 Glassfish 3.0 to 5.x JBoss 7.0 to latest JBoss EAP 6.0 to latest Jetty 7.0.0.M3 to 9.4.x Mule ESB 3.4 to 3.8.x Netty 3.3.0.Alpha1 to 5.0.0.Alpha1 Resin 3.1.9 to 4.0.x Spray-can 1.3.1 to latest Tomcat 7.0.0 to 9.0.x TomEE 1.5 to 8.0.x WebLogic 12.1.2.1 to 12.2.x WebSphere 8.5.x to 9.x WebSphere Liberty Profile 8.5 to latest WildFly 8.0.0.Final to latest Frameworks and libraries The agent automatically instruments the following frameworks. To install the Java agent on supported frameworks, see Install the Java agent. Akka 2.2.0-RC1 to latest AmazonS3 client 1.2.13 to latest AmazonSNS and AmazonSNSAsync clients 1.11.12 to latest AmazonSQS and AmazonSQSAsync clients 1.3.22 to latest S3Client 2.1.0 to latest SnsClient 2.1.0 to latest SqsClient 2.1.0 to latest CXF 2.1.3 to latest Grails 1.3.7 to 2.3.x Hibernate 3.3.0.CR1 to 6.0.0.Alpha2 Hystrix 1.3.15 to latest JAX-RS 1.0 to 2.0 JCache API 1.0.0 to latest Jersey 1.0.1 to 2.x JSF (Java Server Faces) Play 2.3.0 to latest Quartz Job Scheduler 1.8.3 to 2.2.x RESTEasy 2.2-RC-1 to latest Spray 1.3.1 to latest Spring 3.0.0.RELEASE to latest Spring webclient 5.0.0.RELEASE to latest Spring Web Services from 1.5.7 to latest Spring Boot 1.4.x to latest Struts 2 Thrift 0.8.0 to latest Vert.x 3.2.0 to 3.8.3 HTTP and messaging The agent automatically instruments the following HTTP clients and messaging services. For instructions, see Install the Java agent. Akka HTTP 2.4.5 to latest Akka Http Core from 0.4 to latest AsyncHttpClient 2.0.0-RC1 to latest gRPC 1.4.0 to latest HttpAsyncClient 4.1 to latest Apache Httpclient from 3.0 to latest java.net.HttpURLConnection JMS and Spring-JMS 1.1 to latest Kafka Clients 0.10.0.0 to latest (for metric and event data) Kafka Clients 0.11.0.0 to latest (for distributed tracing, metric, and event data) OkHttp 3.x to 4.3.x Ning AsyncHttpClient 1.x Play WS 2.6.0 to latest RabbitMQ 1.7.2 to latest (AMQP and JMS) Spray-client 1.3.1 to latest Spring webclient from 5.0.0.release to latest Datastores New Relic currently supports MySQL and PostgreSQL to capture explain plans for slow database queries. Amazon DynamoDB 1.11.106 to latest Anorm from 2.0 to 2.5 DataStax Cassandra 2.1.2 to 4.0.0 (If you use high security, see the configuration documentation for allow lists.) DB2 9.1 to latest Derby 10.2.1.6 to latest Generic JDBC (any JDBC compliant driver) H2 1.0.57 to latest HSQL 1.7.2.2 to latest INet Oracle Driver (Oranxo) 3.06, 3.14 INet MERLIA 7.0.3, 8.04.03, and 8.06 Jedis Redis driver 1.4.0 to 2.10.x, 3.0.0 to latest jTDS 1.2 to latest MariaDB 1.1.7 or higher Microsoft SQL Server 1.2 to latest MongoDB 2.12.0-rc0 to latest (synchronous clients only) MySQL mysql-connector-java 3.0.8 to latest Oracle ojdbc5, ojdbc6, ojdbc7, ojdbc8, ojdbc10, ojdbc14 Postgres 8.0-312.jdbc3 to latest Slick 3.0.0 to latest Solr 4.0 to latest Spymemcached 2.11 to latest Sybase (jConnect) JDBC 3 driver 6.0 to latest Instance-level database information New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Java agent versions 3.33.0 or higher support the following: Any compatible JDBC driver Amazon DynamoDB 1.11.106 or higher DataStax Cassandra driver 2.1.2 to 4.0.0 Jedis Redis driver 1.4 to 2.10.x, 3.0.0 to latest Mongo 2.12.0 to latest (synchronous clients only)/li> Spymemcached 2.11.0 to 2.12.x Exception: Instance-level information is not reported for calls to the getBulk() API method. The Java agent reports the database name and database server/identifier attributes on slow query traces and transaction traces for these database drivers. To request instance-level information from additional datastores, get support at support.newrelic.com. Hosting services You can install the Java agent on a variety of hosting services, including ones not listed below. Here are detailed installation guides for particular hosting services: Google App Engine (GAE) flexible environment Heroku Asynchronous instrumentation For supported frameworks, the Java agent usually instruments async work automatically. However, you can use the Java agent API to extend this instrumentation. Other instrumented features EJB Session Beans 3.0 or higher JMX JSP (Java Server Pages) 2.0 to 2.2 Scala 2.9.3 to 2.13.x Connect the agent to other New Relic products The Java agent integrates with other New Relic products to give you end-to-end visibility: Product Integration Browser monitoring The Java agent automatically injects the Browser JavaScript agent when you enable auto-instrumentation. After enabling Browser injection, you can view Browser data in the APM Summary page and quickly switch between the APM and Browser data for a particular app. For configuration options and manual instrumentation, see Browser monitoring and the Java agent. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in Infrastructure. New Relic One dashboards The Java agent sends default events and attributes to dashboards, or you can run NRQL queries in the query builder. You can also record custom events for advanced analysis. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.69797,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for the Java <em>agent</em>",
        "sections": "Compatibility and requirements for the Java <em>agent</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Bulk() API method. The Java <em>agent</em> reports the database name and database server&#x2F;identifier attributes on slow query traces and transaction traces for these database drivers. To request instance-level information from additional datastores, <em>get</em> support at support.newrelic.com. Hosting services You can"
      },
      "id": "6043b8f6196a6771a9960f87"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/new-relics-github-repository": [
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-07-02T12:24:20Z",
      "updated_at": "2021-04-28T01:27:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent include: Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the Browser JavaScript agent when you enable auto-instrumentation. After enabling Browser injection, you can view Browser data in the APM Summary page and quickly switch between the APM and Browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.215004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " not listed for your New Relic <em>agent</em>, <em>get</em> support at support.newrelic.com. Background jobs Background jobs supported by the New Relic <em>Ruby</em> <em>agent</em> include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3"
      },
      "id": "603ebad028ccbc6835eba79d"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Tip",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-07-02T12:23:04Z",
      "updated_at": "2021-03-16T08:00:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Tip To use Ruby or any other agent, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Integrate the Ruby agent with New Relic Browser to gain visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.55054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " frameworks and platforms. You can also use the <em>Ruby</em> <em>agent</em> in a Google App Engine (GAE) flexible environment. Before you install the <em>Ruby</em> <em>agent</em>, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app&#x27;s Apdex (user satisfaction). <em>Get</em>"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Compatibility and requirements for the Java agent",
        "Requirements to install the agent",
        "JVM",
        "Tip",
        "Security requirements",
        "Use of other monitoring software",
        "Built-in instrumentation",
        "App/Web servers",
        "Frameworks and libraries",
        "HTTP and messaging",
        "Datastores",
        "Instance-level database information",
        "Hosting services",
        "Asynchronous instrumentation",
        "Other instrumented features",
        "Connect the agent to other New Relic products"
      ],
      "title": "Compatibility and requirements for the Java agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "Getting started"
      ],
      "external_id": "4f74ff9a5d2402145001db0dd2c07e95166e2403",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/java-agent/getting-started/compatibility-requirements-java-agent/",
      "published_at": "2021-07-01T21:42:46Z",
      "updated_at": "2021-07-01T21:42:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Java agent includes built-in instrumentation of the most popular parts of the Java ecosystem, including app servers, frameworks, databases, and message queuing systems. For frameworks and libraries that are not instrumented out of the box, you can extend the agent with Java custom instrumentation. Requirements to install the agent Before you install the Java agent, ensure your system meets these requirements: JVM Tip The Java agent is compatible with any JVM-based language, including: Java, Scala, Kotlin, and Clojure. For instrumentation support for language-specific features, see the Automatically instrumented frameworks and libraries section below. Java version Compatible agent versions Java 5 Agent v1.3.0 to v2.21.7 Java 6 Agent v3.0.0 to v4.3.0 Java 7 Agent v3.0.0 to v6.5.0 Java 8 Agent v3.10.0 to current Java 9 Agent v3.43.0 to current Java 10 Agent v4.4.0 to current Java 11 Agent v4.7.0 to current Java 12 Agent v4.12.0 to current Java 13 Agent v5.7.0 to current Java 14 Agent v5.11.0 to current Java 15 Agent v6.1.0 to current Compatible: IBM JVM versions 7 and 8 for Linux Eclipse OpenJ9 versions 8 to 13 for Linux, Windows, and macOS OpenJDK and AdoptOpenJDK JVM versions 7 to 15 for Linux, Windows, and macOS Oracle Hotspot JVM versions 7 to 15 for Linux, Solaris, Windows, and macOS Azul Zing JVM versions 8 and 11 for Linux, Windows, and macOS Azul Zulu JVM versions 8 to 12 for Linux, Windows, and macOS Amazon Corretto JVM versions 8 and 11 for Linux, Windows, and macOS Alibaba Dragonwell JVM versions 8 and 11 for Linux, Windows, and macOS Compatible only with Java agent 4.3.x [ ZIP | 2.8 MB] legacy agent: Apple Hotspot JVM version 6 for macOS IBM JVM version 6 Oracle Hotspot JVM version 6.0 for Linux, Solaris, Windows, macOS Compatible only with Java agent 2.21.x [ ZIP | 2.8 MB] legacy agent: Oracle Hotspot JVM version 5.0 for Linux, Solaris, Windows, macOS (Java SE 5.0) Oracle JRockit up to and including 1.6.0_50 Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Use of other monitoring software If your application uses other application monitoring software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors while using other monitoring software. Built-in instrumentation After you install the Java agent, it automatically instruments many popular frameworks and libraries. With automatic instrumentation, the agent collects rich data out of the box, and data will show up in your New Relic dashboards within minutes of installation. Even if your library is not automatically instrumented, you can still collect data with custom instrumentation and the Java agent API. The agent automatically instruments these frameworks and libraries: App/Web servers The agent automatically instruments the following app/web servers. To install the Java agent on supported app/web servers, see Install the Java agent. ColdFusion 10 Glassfish 3.0 to 5.x JBoss 7.0 to latest JBoss EAP 6.0 to latest Jetty 7.0.0.M3 to 9.4.x Mule ESB 3.4 to 3.8.x Netty 3.3.0.Alpha1 to 5.0.0.Alpha1 Resin 3.1.9 to 4.0.x Spray-can 1.3.1 to latest Tomcat 7.0.0 to 9.0.x TomEE 1.5 to 8.0.x WebLogic 12.1.2.1 to 12.2.x WebSphere 8.5.x to 9.x WebSphere Liberty Profile 8.5 to latest WildFly 8.0.0.Final to latest Frameworks and libraries The agent automatically instruments the following frameworks. To install the Java agent on supported frameworks, see Install the Java agent. Akka 2.2.0-RC1 to latest AmazonS3 client 1.2.13 to latest AmazonSNS and AmazonSNSAsync clients 1.11.12 to latest AmazonSQS and AmazonSQSAsync clients 1.3.22 to latest S3Client 2.1.0 to latest SnsClient 2.1.0 to latest SqsClient 2.1.0 to latest CXF 2.1.3 to latest Grails 1.3.7 to 2.3.x Hibernate 3.3.0.CR1 to 6.0.0.Alpha2 Hystrix 1.3.15 to latest JAX-RS 1.0 to 2.0 JCache API 1.0.0 to latest Jersey 1.0.1 to 2.x JSF (Java Server Faces) Play 2.3.0 to latest Quartz Job Scheduler 1.8.3 to 2.2.x RESTEasy 2.2-RC-1 to latest Spray 1.3.1 to latest Spring 3.0.0.RELEASE to latest Spring webclient 5.0.0.RELEASE to latest Spring Web Services from 1.5.7 to latest Spring Boot 1.4.x to latest Struts 2 Thrift 0.8.0 to latest Vert.x 3.2.0 to 3.8.3 HTTP and messaging The agent automatically instruments the following HTTP clients and messaging services. For instructions, see Install the Java agent. Akka HTTP 2.4.5 to latest Akka Http Core from 0.4 to latest AsyncHttpClient 2.0.0-RC1 to latest gRPC 1.4.0 to latest HttpAsyncClient 4.1 to latest Apache Httpclient from 3.0 to latest java.net.HttpURLConnection JMS and Spring-JMS 1.1 to latest Kafka Clients 0.10.0.0 to latest (for metric and event data) Kafka Clients 0.11.0.0 to latest (for distributed tracing, metric, and event data) OkHttp 3.x to 4.3.x Ning AsyncHttpClient 1.x Play WS 2.6.0 to latest RabbitMQ 1.7.2 to latest (AMQP and JMS) Spray-client 1.3.1 to latest Spring webclient from 5.0.0.release to latest Datastores New Relic currently supports MySQL and PostgreSQL to capture explain plans for slow database queries. Amazon DynamoDB 1.11.106 to latest Anorm from 2.0 to 2.5 DataStax Cassandra 2.1.2 to 4.0.0 (If you use high security, see the configuration documentation for allow lists.) DB2 9.1 to latest Derby 10.2.1.6 to latest Generic JDBC (any JDBC compliant driver) H2 1.0.57 to latest HSQL 1.7.2.2 to latest INet Oracle Driver (Oranxo) 3.06, 3.14 INet MERLIA 7.0.3, 8.04.03, and 8.06 Jedis Redis driver 1.4.0 to 2.10.x, 3.0.0 to latest jTDS 1.2 to latest MariaDB 1.1.7 or higher Microsoft SQL Server 1.2 to latest MongoDB 2.12.0-rc0 to latest (synchronous clients only) MySQL mysql-connector-java 3.0.8 to latest Oracle ojdbc5, ojdbc6, ojdbc7, ojdbc8, ojdbc10, ojdbc14 Postgres 8.0-312.jdbc3 to latest Slick 3.0.0 to latest Solr 4.0 to latest Spymemcached 2.11 to latest Sybase (jConnect) JDBC 3 driver 6.0 to latest Instance-level database information New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Java agent versions 3.33.0 or higher support the following: Any compatible JDBC driver Amazon DynamoDB 1.11.106 or higher DataStax Cassandra driver 2.1.2 to 4.0.0 Jedis Redis driver 1.4 to 2.10.x, 3.0.0 to latest Mongo 2.12.0 to latest (synchronous clients only)/li> Spymemcached 2.11.0 to 2.12.x Exception: Instance-level information is not reported for calls to the getBulk() API method. The Java agent reports the database name and database server/identifier attributes on slow query traces and transaction traces for these database drivers. To request instance-level information from additional datastores, get support at support.newrelic.com. Hosting services You can install the Java agent on a variety of hosting services, including ones not listed below. Here are detailed installation guides for particular hosting services: Google App Engine (GAE) flexible environment Heroku Asynchronous instrumentation For supported frameworks, the Java agent usually instruments async work automatically. However, you can use the Java agent API to extend this instrumentation. Other instrumented features EJB Session Beans 3.0 or higher JMX JSP (Java Server Pages) 2.0 to 2.2 Scala 2.9.3 to 2.13.x Connect the agent to other New Relic products The Java agent integrates with other New Relic products to give you end-to-end visibility: Product Integration Browser monitoring The Java agent automatically injects the Browser JavaScript agent when you enable auto-instrumentation. After enabling Browser injection, you can view Browser data in the APM Summary page and quickly switch between the APM and Browser data for a particular app. For configuration options and manual instrumentation, see Browser monitoring and the Java agent. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in Infrastructure. New Relic One dashboards The Java agent sends default events and attributes to dashboards, or you can run NRQL queries in the query builder. You can also record custom events for advanced analysis. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.69791,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for the Java <em>agent</em>",
        "sections": "Compatibility and requirements for the Java <em>agent</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Bulk() API method. The Java <em>agent</em> reports the database name and database server&#x2F;identifier attributes on slow query traces and transaction traces for these database drivers. To request instance-level information from additional datastores, <em>get</em> support at support.newrelic.com. Hosting services You can"
      },
      "id": "6043b8f6196a6771a9960f87"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Tip",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-07-02T12:23:04Z",
      "updated_at": "2021-03-16T08:00:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Tip To use Ruby or any other agent, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Integrate the Ruby agent with New Relic Browser to gain visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.55054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " frameworks and platforms. You can also use the <em>Ruby</em> <em>agent</em> in a Google App Engine (GAE) flexible environment. Before you install the <em>Ruby</em> <em>agent</em>, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app&#x27;s Apdex (user satisfaction). <em>Get</em>"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Compatibility and requirements for the Java agent",
        "Requirements to install the agent",
        "JVM",
        "Tip",
        "Security requirements",
        "Use of other monitoring software",
        "Built-in instrumentation",
        "App/Web servers",
        "Frameworks and libraries",
        "HTTP and messaging",
        "Datastores",
        "Instance-level database information",
        "Hosting services",
        "Asynchronous instrumentation",
        "Other instrumented features",
        "Connect the agent to other New Relic products"
      ],
      "title": "Compatibility and requirements for the Java agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "Getting started"
      ],
      "external_id": "4f74ff9a5d2402145001db0dd2c07e95166e2403",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/java-agent/getting-started/compatibility-requirements-java-agent/",
      "published_at": "2021-07-01T21:42:46Z",
      "updated_at": "2021-07-01T21:42:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Java agent includes built-in instrumentation of the most popular parts of the Java ecosystem, including app servers, frameworks, databases, and message queuing systems. For frameworks and libraries that are not instrumented out of the box, you can extend the agent with Java custom instrumentation. Requirements to install the agent Before you install the Java agent, ensure your system meets these requirements: JVM Tip The Java agent is compatible with any JVM-based language, including: Java, Scala, Kotlin, and Clojure. For instrumentation support for language-specific features, see the Automatically instrumented frameworks and libraries section below. Java version Compatible agent versions Java 5 Agent v1.3.0 to v2.21.7 Java 6 Agent v3.0.0 to v4.3.0 Java 7 Agent v3.0.0 to v6.5.0 Java 8 Agent v3.10.0 to current Java 9 Agent v3.43.0 to current Java 10 Agent v4.4.0 to current Java 11 Agent v4.7.0 to current Java 12 Agent v4.12.0 to current Java 13 Agent v5.7.0 to current Java 14 Agent v5.11.0 to current Java 15 Agent v6.1.0 to current Compatible: IBM JVM versions 7 and 8 for Linux Eclipse OpenJ9 versions 8 to 13 for Linux, Windows, and macOS OpenJDK and AdoptOpenJDK JVM versions 7 to 15 for Linux, Windows, and macOS Oracle Hotspot JVM versions 7 to 15 for Linux, Solaris, Windows, and macOS Azul Zing JVM versions 8 and 11 for Linux, Windows, and macOS Azul Zulu JVM versions 8 to 12 for Linux, Windows, and macOS Amazon Corretto JVM versions 8 and 11 for Linux, Windows, and macOS Alibaba Dragonwell JVM versions 8 and 11 for Linux, Windows, and macOS Compatible only with Java agent 4.3.x [ ZIP | 2.8 MB] legacy agent: Apple Hotspot JVM version 6 for macOS IBM JVM version 6 Oracle Hotspot JVM version 6.0 for Linux, Solaris, Windows, macOS Compatible only with Java agent 2.21.x [ ZIP | 2.8 MB] legacy agent: Oracle Hotspot JVM version 5.0 for Linux, Solaris, Windows, macOS (Java SE 5.0) Oracle JRockit up to and including 1.6.0_50 Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Use of other monitoring software If your application uses other application monitoring software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors while using other monitoring software. Built-in instrumentation After you install the Java agent, it automatically instruments many popular frameworks and libraries. With automatic instrumentation, the agent collects rich data out of the box, and data will show up in your New Relic dashboards within minutes of installation. Even if your library is not automatically instrumented, you can still collect data with custom instrumentation and the Java agent API. The agent automatically instruments these frameworks and libraries: App/Web servers The agent automatically instruments the following app/web servers. To install the Java agent on supported app/web servers, see Install the Java agent. ColdFusion 10 Glassfish 3.0 to 5.x JBoss 7.0 to latest JBoss EAP 6.0 to latest Jetty 7.0.0.M3 to 9.4.x Mule ESB 3.4 to 3.8.x Netty 3.3.0.Alpha1 to 5.0.0.Alpha1 Resin 3.1.9 to 4.0.x Spray-can 1.3.1 to latest Tomcat 7.0.0 to 9.0.x TomEE 1.5 to 8.0.x WebLogic 12.1.2.1 to 12.2.x WebSphere 8.5.x to 9.x WebSphere Liberty Profile 8.5 to latest WildFly 8.0.0.Final to latest Frameworks and libraries The agent automatically instruments the following frameworks. To install the Java agent on supported frameworks, see Install the Java agent. Akka 2.2.0-RC1 to latest AmazonS3 client 1.2.13 to latest AmazonSNS and AmazonSNSAsync clients 1.11.12 to latest AmazonSQS and AmazonSQSAsync clients 1.3.22 to latest S3Client 2.1.0 to latest SnsClient 2.1.0 to latest SqsClient 2.1.0 to latest CXF 2.1.3 to latest Grails 1.3.7 to 2.3.x Hibernate 3.3.0.CR1 to 6.0.0.Alpha2 Hystrix 1.3.15 to latest JAX-RS 1.0 to 2.0 JCache API 1.0.0 to latest Jersey 1.0.1 to 2.x JSF (Java Server Faces) Play 2.3.0 to latest Quartz Job Scheduler 1.8.3 to 2.2.x RESTEasy 2.2-RC-1 to latest Spray 1.3.1 to latest Spring 3.0.0.RELEASE to latest Spring webclient 5.0.0.RELEASE to latest Spring Web Services from 1.5.7 to latest Spring Boot 1.4.x to latest Struts 2 Thrift 0.8.0 to latest Vert.x 3.2.0 to 3.8.3 HTTP and messaging The agent automatically instruments the following HTTP clients and messaging services. For instructions, see Install the Java agent. Akka HTTP 2.4.5 to latest Akka Http Core from 0.4 to latest AsyncHttpClient 2.0.0-RC1 to latest gRPC 1.4.0 to latest HttpAsyncClient 4.1 to latest Apache Httpclient from 3.0 to latest java.net.HttpURLConnection JMS and Spring-JMS 1.1 to latest Kafka Clients 0.10.0.0 to latest (for metric and event data) Kafka Clients 0.11.0.0 to latest (for distributed tracing, metric, and event data) OkHttp 3.x to 4.3.x Ning AsyncHttpClient 1.x Play WS 2.6.0 to latest RabbitMQ 1.7.2 to latest (AMQP and JMS) Spray-client 1.3.1 to latest Spring webclient from 5.0.0.release to latest Datastores New Relic currently supports MySQL and PostgreSQL to capture explain plans for slow database queries. Amazon DynamoDB 1.11.106 to latest Anorm from 2.0 to 2.5 DataStax Cassandra 2.1.2 to 4.0.0 (If you use high security, see the configuration documentation for allow lists.) DB2 9.1 to latest Derby 10.2.1.6 to latest Generic JDBC (any JDBC compliant driver) H2 1.0.57 to latest HSQL 1.7.2.2 to latest INet Oracle Driver (Oranxo) 3.06, 3.14 INet MERLIA 7.0.3, 8.04.03, and 8.06 Jedis Redis driver 1.4.0 to 2.10.x, 3.0.0 to latest jTDS 1.2 to latest MariaDB 1.1.7 or higher Microsoft SQL Server 1.2 to latest MongoDB 2.12.0-rc0 to latest (synchronous clients only) MySQL mysql-connector-java 3.0.8 to latest Oracle ojdbc5, ojdbc6, ojdbc7, ojdbc8, ojdbc10, ojdbc14 Postgres 8.0-312.jdbc3 to latest Slick 3.0.0 to latest Solr 4.0 to latest Spymemcached 2.11 to latest Sybase (jConnect) JDBC 3 driver 6.0 to latest Instance-level database information New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Java agent versions 3.33.0 or higher support the following: Any compatible JDBC driver Amazon DynamoDB 1.11.106 or higher DataStax Cassandra driver 2.1.2 to 4.0.0 Jedis Redis driver 1.4 to 2.10.x, 3.0.0 to latest Mongo 2.12.0 to latest (synchronous clients only)/li> Spymemcached 2.11.0 to 2.12.x Exception: Instance-level information is not reported for calls to the getBulk() API method. The Java agent reports the database name and database server/identifier attributes on slow query traces and transaction traces for these database drivers. To request instance-level information from additional datastores, get support at support.newrelic.com. Hosting services You can install the Java agent on a variety of hosting services, including ones not listed below. Here are detailed installation guides for particular hosting services: Google App Engine (GAE) flexible environment Heroku Asynchronous instrumentation For supported frameworks, the Java agent usually instruments async work automatically. However, you can use the Java agent API to extend this instrumentation. Other instrumented features EJB Session Beans 3.0 or higher JMX JSP (Java Server Pages) 2.0 to 2.2 Scala 2.9.3 to 2.13.x Connect the agent to other New Relic products The Java agent integrates with other New Relic products to give you end-to-end visibility: Product Integration Browser monitoring The Java agent automatically injects the Browser JavaScript agent when you enable auto-instrumentation. After enabling Browser injection, you can view Browser data in the APM Summary page and quickly switch between the APM and Browser data for a particular app. For configuration options and manual instrumentation, see Browser monitoring and the Java agent. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in Infrastructure. New Relic One dashboards The Java agent sends default events and attributes to dashboards, or you can run NRQL queries in the query builder. You can also record custom events for advanced analysis. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.69791,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for the Java <em>agent</em>",
        "sections": "Compatibility and requirements for the Java <em>agent</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Bulk() API method. The Java <em>agent</em> reports the database name and database server&#x2F;identifier attributes on slow query traces and transaction traces for these database drivers. To request instance-level information from additional datastores, <em>get</em> support at support.newrelic.com. Hosting services You can"
      },
      "id": "6043b8f6196a6771a9960f87"
    },
    {
      "sections": [
        "New Relic's GitHub repository"
      ],
      "title": "New Relic's GitHub repository",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "98a98d3ab40ab9b58304065ccdb043af42d35bdd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/new-relics-github-repository/",
      "published_at": "2021-07-02T12:24:19Z",
      "updated_at": "2021-03-16T08:00:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic clones the Ruby repository on GitHub at newrelic-ruby-agent. GitHub also hosts limited rdoc-generated documentation: rdoc.info/github/newrelic/newrelic-ruby-agent. The head of main will generally have New Relic's latest release. However, we reserve the ability to push an edge to the master. If you download a release from GitHub, use the appropriate tag. We usually push beta versions of a release to a working branch before tagging them for General Availability. Fork away and feel free to send us pull requests (branches only please) for any ideas or bugfixes you come up with at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.63823,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "New Relic clones the <em>Ruby</em> repository on GitHub at newrelic-<em>ruby</em>-<em>agent</em>. GitHub also hosts limited rdoc-generated documentation: rdoc.info&#x2F;github&#x2F;newrelic&#x2F;newrelic-<em>ruby</em>-<em>agent</em>. The head of main will generally have New Relic&#x27;s latest release. However, we reserve the ability to push an edge"
      },
      "id": "603eb6b564441f50c84e8879"
    }
  ],
  "/docs/agents/ruby-agent/index": [
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 82.81863,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "You can configure the New Relic <em>Ruby</em> <em>agent</em> with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the <em>Ruby</em> <em>agent</em>. If the default value for a configuration option is (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 79.76609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Ruby agent attributes",
        "httpResponseCode",
        "request.headers.referer",
        "request.parameters.*",
        "job.resque.args.*",
        "job.sidekiq.args.*",
        "Adding custom attributes",
        "Caution",
        "Upgrading the Ruby agent",
        "For more help"
      ],
      "title": "Ruby agent attributes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Attributes"
      ],
      "external_id": "76453699d829800b2dc9757c66c6f25f6c37f86a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/attributes/ruby-agent-attributes/",
      "published_at": "2021-07-02T12:16:28Z",
      "updated_at": "2021-06-02T22:15:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations. These attribute settings apply to version 3.12.0 or higher of the Ruby agent. Ruby agent attributes The following table lists the attributes that can be automatically captured by the Ruby agent: httpResponseCode The response status code for a web request. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Unavailable Note: The httpResponseCode attribute (string value) is deprecated as of agent version 6.12.0. http.statusCode (integer value) should be used instead. request.headers.referer The HTTP referrer header if present (minus the query string). Defaults: Transaction traces: Disabled Error collector (traced errors): Enabled Transaction events: Disabled Page views (browser monitoring): Unavailable request.parameters.* The HTTP request parameters, associated with the transaction. Available for Rails, Sinatra, and Grape applications only. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Disabled Note: The capture_params property is deprecated. However, if set to true, it will enable request parameters for transaction traces and traced errors. job.resque.args.* Job arguments passed to the Resque worker. Arguments passed to Resque workers are positional. These arguments are stored as keys of the form job.resque.args.<position> where position is the index of the argument to the perform method. For example, a Resque job that takes two arguments will have keys job.resque.args.0 and job.resque.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The resque.capture_params property is deprecated. However, if set to true, it will enable capture of Resque arguments for transaction traces, traced errors. job.sidekiq.args.* Job arguments passed to the Sidekiq worker. Arguments passed to Sidekiq workers are positional. These arguments are stored as keys of the form job.sidekiq.args.<position> where position is the index of the argument to the perform method. For example, a Sidekiq job that takes two arguments will have keys job.sidekiq.args.0 and job.sidekiq.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The sidekiq.capture_params property is deprecated. However, if set to true, it will enable capture of Sidekiq arguments for transaction traces and traced errors. Adding custom attributes To capture additional custom attributes from your application, use NewRelic::Agent.add_custom_attributes. For full reference see Collecting custom attributes. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Disabled Caution If you want to query your custom parameters or attributes, avoid using any of the reserved terms for naming them. Upgrading the Ruby agent When upgrading to Ruby agent 3.12.0 or higher, upgrade your newrelic.yml configuration. For more help Additional documentation resources include: Agent attributes (types, destinations, and limits for attributes used by New Relic agents) Enabling and disabling attributes (properties, rules, and backwards compatibility information for Ruby agent attributes) Attribute examples (scenarios and results of enabling and disabling different Ruby agent attributes)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 75.5564,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> attributes",
        "sections": "<em>Ruby</em> <em>agent</em> attributes",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " attributes (types, destinations, and limits for attributes used by New Relic <em>agents</em>) Enabling and disabling attributes (properties, rules, and backwards compatibility information for <em>Ruby</em> <em>agent</em> attributes) Attribute examples (scenarios and results of enabling and disabling different <em>Ruby</em> <em>agent</em> attributes)"
      },
      "id": "6044042028ccbc7da82c6083"
    }
  ],
  "/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent-gae-flexible-environment": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/include-a-doc-in-multiple-menus/",
      "sections": [
        "Include a doc in multiple menus"
      ],
      "published_at": "2021-07-01T16:03:42Z",
      "title": "Include a doc in multiple menus",
      "updated_at": "2021-06-02T17:05:51Z",
      "type": "docs",
      "external_id": "281e8e849c2b4fdd56046513c8ae2eecf24392f7",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have a document that should appear in multiple menus, you can include the same path in multiple taxonomy locations. For example, if you wanted to link to the APM landing page from another location of taxonomy (such as a differnt taxonomy level, a different category, etc.), you’d add a new entry in the navigation YAML file (for example, /src/nav/agents.yml). In this example, we add a link to the Ruby agent installation doc from the Distributed tracing category. You can now access this doc from either the Distributed tracing category or the Ruby agent category. - title: Distributed tracing path: /docs/distributed-tracing pages: - title: Concepts path: /docs/distributed-tracing/concepts pages: - title: Intro to distributed tracing path: /docs/distributed-tracing/concepts/introduction-distributed-tracing - title: Planning guide path: /docs/distributed-tracing/concepts/distributed-tracing-planning-guide - title: How distributed tracing works path: /docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works - title: This is a dummy doc path: /docs/agents/ruby-agent/installation/install-new-relic-ruby-agent Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.28305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " entry in the navigation YAML file (for example, &#x2F;src&#x2F;nav&#x2F;<em>agents</em>.yml). In this example, we add a link to the <em>Ruby</em> <em>agent</em> <em>installation</em> doc from the Distributed tracing category. You can now access this doc from either the Distributed tracing category or the <em>Ruby</em> <em>agent</em> category. - title: Distributed"
      },
      "id": "604220ec196a67358ea83da5"
    },
    {
      "sections": [
        "Update the Ruby agent",
        "Verify your Ruby agent versions",
        "Update the agent",
        "Instrument JRuby",
        "Ruby agent versions not supported",
        "Update unsupported agent versions",
        "Important"
      ],
      "title": "Update the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "3248580dc4c2039ed569a158783912ea23ef1fc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/update-ruby-agent/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-04-28T05:21:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To take full advantage of New Relic's latest features, enhancements, and important security patches, we recommend you update your Ruby agent to the latest version. For additional information about specific agent updates, refer to the Ruby agent release notes. Verify your Ruby agent versions To determine which Ruby agent versions your apps currently use: In New Relic, from the account dropdown, select Account settings > Connected agents. Optional: Sort by Oldest agent version. Update the agent To update the Ruby agent: Using Bundler: Run this command: bundle update newrelic_rpm Copy Not using Bundler: Run this command: gem update newrelic_rpm Copy Instrument JRuby For correct instrumentation: With JRuby versions 1.7 or higher, use New Relic Ruby agent version 3.6.8.164 to 3.18.1. With JRuby versions 9 or higher, use New Relic Ruby agent version 3.6.8.164 or higher. Otherwise, if your application has no transactions and you are using JRuby, you will not be able to see your CPU metrics. This was due to a bug in JRuby, where Process.times returned wall-clock time instead of elapsed CPU time. That bug was fixed as of New Relic’s Ruby agent 3.6.8.164 and JRuby 1.7.0. Ruby agent versions not supported End of life notification: As of January 26, 2015, New Relic will no longer accept data from Ruby agent versions earlier than 3.9.6. These agent versions use an out-of-date protocol when communicating with New Relic's data collection services. In addition, many of these versions contain a potential security issue where they may incorrectly send sensitive data to the New Relic collector. Update unsupported agent versions Important If you are updating from an older agent version, including major version jumps, review the following list for changes in functionality. Migration Comments From version 6 to 7 Release notes: Ruby agent 7.0.0 Please see our Ruby Agent 6.x to 7.x migration guide for helpful strategies and tips for migrating from earlier versions of the Ruby agent to 7.0.0. We cover new configuration settings, diagnosiing and installing SSL CA certificates and deprecated items and their replacements in this guide. Ruby 2.0 and 2.1 dropped Implemented prepend auto-instrumentation strategies for most Ruby gems/libraries Removed SSL cert bundle Removed various deprecated config options From version 5 to 6 Release notes: Ruby agent 6.0.0.351 With the addition of the Tracer API for flexible custom instrumentation, several APIs were deprecated. If used, they need to be updated. For more information, see Ruby custom instrumentation. From version 4 to 5 Release notes: Ruby agent 5.0.0.342 SSL connections to New Relic are now mandatory. From version 3 to 4 Release notes: Ruby agent 4.0.0.332 The agent no longer supports Ruby versions prior to 2.0, JRuby 1.7 and earlier, and all versions of Rubinius. Deprecated API calls For a list of deprecated API calls and their replacements, see Update deprecated API calls.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.34482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update the <em>Ruby</em> <em>agent</em>",
        "sections": "Update the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " To determine which <em>Ruby</em> <em>agent</em> versions your apps currently use: In New Relic, from the account dropdown, select Account settings &gt; Connected <em>agents</em>. Optional: Sort by Oldest <em>agent</em> version. Update the <em>agent</em> To update the <em>Ruby</em> <em>agent</em>: Using Bundler: Run this command: bundle update newrelic_rpm Copy Not using"
      },
      "id": "603eb7db64441f83f84e88b1"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file [#Updating_newrelic.yml]",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-16T08:01:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file [#Updating_newrelic.yml] Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.29018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " to version X.X.X&quot; Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    }
  ],
  "/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/include-a-doc-in-multiple-menus/",
      "sections": [
        "Include a doc in multiple menus"
      ],
      "published_at": "2021-07-01T16:03:42Z",
      "title": "Include a doc in multiple menus",
      "updated_at": "2021-06-02T17:05:51Z",
      "type": "docs",
      "external_id": "281e8e849c2b4fdd56046513c8ae2eecf24392f7",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have a document that should appear in multiple menus, you can include the same path in multiple taxonomy locations. For example, if you wanted to link to the APM landing page from another location of taxonomy (such as a differnt taxonomy level, a different category, etc.), you’d add a new entry in the navigation YAML file (for example, /src/nav/agents.yml). In this example, we add a link to the Ruby agent installation doc from the Distributed tracing category. You can now access this doc from either the Distributed tracing category or the Ruby agent category. - title: Distributed tracing path: /docs/distributed-tracing pages: - title: Concepts path: /docs/distributed-tracing/concepts pages: - title: Intro to distributed tracing path: /docs/distributed-tracing/concepts/introduction-distributed-tracing - title: Planning guide path: /docs/distributed-tracing/concepts/distributed-tracing-planning-guide - title: How distributed tracing works path: /docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works - title: This is a dummy doc path: /docs/agents/ruby-agent/installation/install-new-relic-ruby-agent Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.28304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " entry in the navigation YAML file (for example, &#x2F;src&#x2F;nav&#x2F;<em>agents</em>.yml). In this example, we add a link to the <em>Ruby</em> <em>agent</em> <em>installation</em> doc from the Distributed tracing category. You can now access this doc from either the Distributed tracing category or the <em>Ruby</em> <em>agent</em> category. - title: Distributed"
      },
      "id": "604220ec196a67358ea83da5"
    },
    {
      "sections": [
        "Update the Ruby agent",
        "Verify your Ruby agent versions",
        "Update the agent",
        "Instrument JRuby",
        "Ruby agent versions not supported",
        "Update unsupported agent versions",
        "Important"
      ],
      "title": "Update the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "3248580dc4c2039ed569a158783912ea23ef1fc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/update-ruby-agent/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-04-28T05:21:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To take full advantage of New Relic's latest features, enhancements, and important security patches, we recommend you update your Ruby agent to the latest version. For additional information about specific agent updates, refer to the Ruby agent release notes. Verify your Ruby agent versions To determine which Ruby agent versions your apps currently use: In New Relic, from the account dropdown, select Account settings > Connected agents. Optional: Sort by Oldest agent version. Update the agent To update the Ruby agent: Using Bundler: Run this command: bundle update newrelic_rpm Copy Not using Bundler: Run this command: gem update newrelic_rpm Copy Instrument JRuby For correct instrumentation: With JRuby versions 1.7 or higher, use New Relic Ruby agent version 3.6.8.164 to 3.18.1. With JRuby versions 9 or higher, use New Relic Ruby agent version 3.6.8.164 or higher. Otherwise, if your application has no transactions and you are using JRuby, you will not be able to see your CPU metrics. This was due to a bug in JRuby, where Process.times returned wall-clock time instead of elapsed CPU time. That bug was fixed as of New Relic’s Ruby agent 3.6.8.164 and JRuby 1.7.0. Ruby agent versions not supported End of life notification: As of January 26, 2015, New Relic will no longer accept data from Ruby agent versions earlier than 3.9.6. These agent versions use an out-of-date protocol when communicating with New Relic's data collection services. In addition, many of these versions contain a potential security issue where they may incorrectly send sensitive data to the New Relic collector. Update unsupported agent versions Important If you are updating from an older agent version, including major version jumps, review the following list for changes in functionality. Migration Comments From version 6 to 7 Release notes: Ruby agent 7.0.0 Please see our Ruby Agent 6.x to 7.x migration guide for helpful strategies and tips for migrating from earlier versions of the Ruby agent to 7.0.0. We cover new configuration settings, diagnosiing and installing SSL CA certificates and deprecated items and their replacements in this guide. Ruby 2.0 and 2.1 dropped Implemented prepend auto-instrumentation strategies for most Ruby gems/libraries Removed SSL cert bundle Removed various deprecated config options From version 5 to 6 Release notes: Ruby agent 6.0.0.351 With the addition of the Tracer API for flexible custom instrumentation, several APIs were deprecated. If used, they need to be updated. For more information, see Ruby custom instrumentation. From version 4 to 5 Release notes: Ruby agent 5.0.0.342 SSL connections to New Relic are now mandatory. From version 3 to 4 Release notes: Ruby agent 4.0.0.332 The agent no longer supports Ruby versions prior to 2.0, JRuby 1.7 and earlier, and all versions of Rubinius. Deprecated API calls For a list of deprecated API calls and their replacements, see Update deprecated API calls.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.34482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update the <em>Ruby</em> <em>agent</em>",
        "sections": "Update the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " To determine which <em>Ruby</em> <em>agent</em> versions your apps currently use: In New Relic, from the account dropdown, select Account settings &gt; Connected <em>agents</em>. Optional: Sort by Oldest <em>agent</em> version. Update the <em>agent</em> To update the <em>Ruby</em> <em>agent</em>: Using Bundler: Run this command: bundle update newrelic_rpm Copy Not using"
      },
      "id": "603eb7db64441f83f84e88b1"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file [#Updating_newrelic.yml]",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-16T08:01:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file [#Updating_newrelic.yml] Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.29018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " to version X.X.X&quot; Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    }
  ],
  "/docs/agents/ruby-agent/installation/ruby-agent-heroku": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/include-a-doc-in-multiple-menus/",
      "sections": [
        "Include a doc in multiple menus"
      ],
      "published_at": "2021-07-01T16:03:42Z",
      "title": "Include a doc in multiple menus",
      "updated_at": "2021-06-02T17:05:51Z",
      "type": "docs",
      "external_id": "281e8e849c2b4fdd56046513c8ae2eecf24392f7",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have a document that should appear in multiple menus, you can include the same path in multiple taxonomy locations. For example, if you wanted to link to the APM landing page from another location of taxonomy (such as a differnt taxonomy level, a different category, etc.), you’d add a new entry in the navigation YAML file (for example, /src/nav/agents.yml). In this example, we add a link to the Ruby agent installation doc from the Distributed tracing category. You can now access this doc from either the Distributed tracing category or the Ruby agent category. - title: Distributed tracing path: /docs/distributed-tracing pages: - title: Concepts path: /docs/distributed-tracing/concepts pages: - title: Intro to distributed tracing path: /docs/distributed-tracing/concepts/introduction-distributed-tracing - title: Planning guide path: /docs/distributed-tracing/concepts/distributed-tracing-planning-guide - title: How distributed tracing works path: /docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works - title: This is a dummy doc path: /docs/agents/ruby-agent/installation/install-new-relic-ruby-agent Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.28304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " entry in the navigation YAML file (for example, &#x2F;src&#x2F;nav&#x2F;<em>agents</em>.yml). In this example, we add a link to the <em>Ruby</em> <em>agent</em> <em>installation</em> doc from the Distributed tracing category. You can now access this doc from either the Distributed tracing category or the <em>Ruby</em> <em>agent</em> category. - title: Distributed"
      },
      "id": "604220ec196a67358ea83da5"
    },
    {
      "sections": [
        "Update the Ruby agent",
        "Verify your Ruby agent versions",
        "Update the agent",
        "Instrument JRuby",
        "Ruby agent versions not supported",
        "Update unsupported agent versions",
        "Important"
      ],
      "title": "Update the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "3248580dc4c2039ed569a158783912ea23ef1fc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/update-ruby-agent/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-04-28T05:21:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To take full advantage of New Relic's latest features, enhancements, and important security patches, we recommend you update your Ruby agent to the latest version. For additional information about specific agent updates, refer to the Ruby agent release notes. Verify your Ruby agent versions To determine which Ruby agent versions your apps currently use: In New Relic, from the account dropdown, select Account settings > Connected agents. Optional: Sort by Oldest agent version. Update the agent To update the Ruby agent: Using Bundler: Run this command: bundle update newrelic_rpm Copy Not using Bundler: Run this command: gem update newrelic_rpm Copy Instrument JRuby For correct instrumentation: With JRuby versions 1.7 or higher, use New Relic Ruby agent version 3.6.8.164 to 3.18.1. With JRuby versions 9 or higher, use New Relic Ruby agent version 3.6.8.164 or higher. Otherwise, if your application has no transactions and you are using JRuby, you will not be able to see your CPU metrics. This was due to a bug in JRuby, where Process.times returned wall-clock time instead of elapsed CPU time. That bug was fixed as of New Relic’s Ruby agent 3.6.8.164 and JRuby 1.7.0. Ruby agent versions not supported End of life notification: As of January 26, 2015, New Relic will no longer accept data from Ruby agent versions earlier than 3.9.6. These agent versions use an out-of-date protocol when communicating with New Relic's data collection services. In addition, many of these versions contain a potential security issue where they may incorrectly send sensitive data to the New Relic collector. Update unsupported agent versions Important If you are updating from an older agent version, including major version jumps, review the following list for changes in functionality. Migration Comments From version 6 to 7 Release notes: Ruby agent 7.0.0 Please see our Ruby Agent 6.x to 7.x migration guide for helpful strategies and tips for migrating from earlier versions of the Ruby agent to 7.0.0. We cover new configuration settings, diagnosiing and installing SSL CA certificates and deprecated items and their replacements in this guide. Ruby 2.0 and 2.1 dropped Implemented prepend auto-instrumentation strategies for most Ruby gems/libraries Removed SSL cert bundle Removed various deprecated config options From version 5 to 6 Release notes: Ruby agent 6.0.0.351 With the addition of the Tracer API for flexible custom instrumentation, several APIs were deprecated. If used, they need to be updated. For more information, see Ruby custom instrumentation. From version 4 to 5 Release notes: Ruby agent 5.0.0.342 SSL connections to New Relic are now mandatory. From version 3 to 4 Release notes: Ruby agent 4.0.0.332 The agent no longer supports Ruby versions prior to 2.0, JRuby 1.7 and earlier, and all versions of Rubinius. Deprecated API calls For a list of deprecated API calls and their replacements, see Update deprecated API calls.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.34482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update the <em>Ruby</em> <em>agent</em>",
        "sections": "Update the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " To determine which <em>Ruby</em> <em>agent</em> versions your apps currently use: In New Relic, from the account dropdown, select Account settings &gt; Connected <em>agents</em>. Optional: Sort by Oldest <em>agent</em> version. Update the <em>agent</em> To update the <em>Ruby</em> <em>agent</em>: Using Bundler: Run this command: bundle update newrelic_rpm Copy Not using"
      },
      "id": "603eb7db64441f83f84e88b1"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file [#Updating_newrelic.yml]",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-16T08:01:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file [#Updating_newrelic.yml] Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.29018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " to version X.X.X&quot; Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    }
  ],
  "/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/include-a-doc-in-multiple-menus/",
      "sections": [
        "Include a doc in multiple menus"
      ],
      "published_at": "2021-07-01T16:03:42Z",
      "title": "Include a doc in multiple menus",
      "updated_at": "2021-06-02T17:05:51Z",
      "type": "docs",
      "external_id": "281e8e849c2b4fdd56046513c8ae2eecf24392f7",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have a document that should appear in multiple menus, you can include the same path in multiple taxonomy locations. For example, if you wanted to link to the APM landing page from another location of taxonomy (such as a differnt taxonomy level, a different category, etc.), you’d add a new entry in the navigation YAML file (for example, /src/nav/agents.yml). In this example, we add a link to the Ruby agent installation doc from the Distributed tracing category. You can now access this doc from either the Distributed tracing category or the Ruby agent category. - title: Distributed tracing path: /docs/distributed-tracing pages: - title: Concepts path: /docs/distributed-tracing/concepts pages: - title: Intro to distributed tracing path: /docs/distributed-tracing/concepts/introduction-distributed-tracing - title: Planning guide path: /docs/distributed-tracing/concepts/distributed-tracing-planning-guide - title: How distributed tracing works path: /docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works - title: This is a dummy doc path: /docs/agents/ruby-agent/installation/install-new-relic-ruby-agent Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.28304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " entry in the navigation YAML file (for example, &#x2F;src&#x2F;nav&#x2F;<em>agents</em>.yml). In this example, we add a link to the <em>Ruby</em> <em>agent</em> <em>installation</em> doc from the Distributed tracing category. You can now access this doc from either the Distributed tracing category or the <em>Ruby</em> <em>agent</em> category. - title: Distributed"
      },
      "id": "604220ec196a67358ea83da5"
    },
    {
      "sections": [
        "Update the Ruby agent",
        "Verify your Ruby agent versions",
        "Update the agent",
        "Instrument JRuby",
        "Ruby agent versions not supported",
        "Update unsupported agent versions",
        "Important"
      ],
      "title": "Update the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "3248580dc4c2039ed569a158783912ea23ef1fc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/update-ruby-agent/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-04-28T05:21:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To take full advantage of New Relic's latest features, enhancements, and important security patches, we recommend you update your Ruby agent to the latest version. For additional information about specific agent updates, refer to the Ruby agent release notes. Verify your Ruby agent versions To determine which Ruby agent versions your apps currently use: In New Relic, from the account dropdown, select Account settings > Connected agents. Optional: Sort by Oldest agent version. Update the agent To update the Ruby agent: Using Bundler: Run this command: bundle update newrelic_rpm Copy Not using Bundler: Run this command: gem update newrelic_rpm Copy Instrument JRuby For correct instrumentation: With JRuby versions 1.7 or higher, use New Relic Ruby agent version 3.6.8.164 to 3.18.1. With JRuby versions 9 or higher, use New Relic Ruby agent version 3.6.8.164 or higher. Otherwise, if your application has no transactions and you are using JRuby, you will not be able to see your CPU metrics. This was due to a bug in JRuby, where Process.times returned wall-clock time instead of elapsed CPU time. That bug was fixed as of New Relic’s Ruby agent 3.6.8.164 and JRuby 1.7.0. Ruby agent versions not supported End of life notification: As of January 26, 2015, New Relic will no longer accept data from Ruby agent versions earlier than 3.9.6. These agent versions use an out-of-date protocol when communicating with New Relic's data collection services. In addition, many of these versions contain a potential security issue where they may incorrectly send sensitive data to the New Relic collector. Update unsupported agent versions Important If you are updating from an older agent version, including major version jumps, review the following list for changes in functionality. Migration Comments From version 6 to 7 Release notes: Ruby agent 7.0.0 Please see our Ruby Agent 6.x to 7.x migration guide for helpful strategies and tips for migrating from earlier versions of the Ruby agent to 7.0.0. We cover new configuration settings, diagnosiing and installing SSL CA certificates and deprecated items and their replacements in this guide. Ruby 2.0 and 2.1 dropped Implemented prepend auto-instrumentation strategies for most Ruby gems/libraries Removed SSL cert bundle Removed various deprecated config options From version 5 to 6 Release notes: Ruby agent 6.0.0.351 With the addition of the Tracer API for flexible custom instrumentation, several APIs were deprecated. If used, they need to be updated. For more information, see Ruby custom instrumentation. From version 4 to 5 Release notes: Ruby agent 5.0.0.342 SSL connections to New Relic are now mandatory. From version 3 to 4 Release notes: Ruby agent 4.0.0.332 The agent no longer supports Ruby versions prior to 2.0, JRuby 1.7 and earlier, and all versions of Rubinius. Deprecated API calls For a list of deprecated API calls and their replacements, see Update deprecated API calls.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.34482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update the <em>Ruby</em> <em>agent</em>",
        "sections": "Update the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " To determine which <em>Ruby</em> <em>agent</em> versions your apps currently use: In New Relic, from the account dropdown, select Account settings &gt; Connected <em>agents</em>. Optional: Sort by Oldest <em>agent</em> version. Update the <em>agent</em> To update the <em>Ruby</em> <em>agent</em>: Using Bundler: Run this command: bundle update newrelic_rpm Copy Not using"
      },
      "id": "603eb7db64441f83f84e88b1"
    },
    {
      "sections": [
        "Collect custom attributes",
        "Requirements",
        "APM: Record custom attributes",
        "Important",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Browser monitoring: Record custom attributes",
        "Infrastructure monitoring: Record custom attributes",
        "Mobile monitoring: Record custom attributes",
        "For more help"
      ],
      "title": "Collect custom attributes",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "ad362b1a5cf3a5661eb416584fd9c79db064f539",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/data/customize-data/collect-custom-attributes/",
      "published_at": "2021-07-02T19:49:53Z",
      "updated_at": "2021-07-02T19:49:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For some New Relic solutions, one way to report custom data to New Relic is to use custom attributes. For example, for New Relic browser monitoring, you might create a custom attribute to track the user name associated with a slow or failing request. Requirements Custom attributes are available for these New Relic solutions: APM Browser monitoring Mobile monitoring Infrastructure monitoring For other custom data solutions, see Intro to custom data. APM: Record custom attributes Important Review the list of reserved terms used by NRQL. Using reserved terms can cause issues. To enable and use custom attributes for APM, follow the procedure for your APM agent: C SDK To add custom attributes to applications monitored by the C SDK, call one of the attribute functions; for example, newrelic_add_attribute_double(). The key name for your custom attribute depends on what you specify when you call the function. Go Custom attribute collection is enabled by default in the Go agent. However, you can disable custom attribute collection. Java Custom attribute collection is enabled by default in Java. You can collect custom attributes using XML and the Java agent APIs. These two methods can be used in conjunction with each other. Method How to do it Specify attributes in XML XML allows you to specify custom attributes without changing any of your source code. You can have multiple XML files for custom attributes that are grouped by some logical facet. To set custom attributes for your Java app via XML: Review the New Relic Java agent's documentation about XML file format, methods and classes, and examples. From your Extensions directory within the New Relic Java agent, create a single XML file. Define the methods you want New Relic to monitor by editing your XML file directly. Define an XML instrumentation file using the New Relic UI. This may require additional config in the common: block of your newrelic.yml. See Report custom attributes under Instrumentation options for more detail. Call the agent's API Example 1: Adding custom attributes to transactions To collect custom attributes using the agent's API, call the relevant methods: For each method you want to record an attribute for, call NewRelic.addCustomParameter(...). Optional: Include or exclude certain attributes with attributes.include and attributes.exclude. For example, to record a variable named userId, include this code in the parent method: NewRelic.addCustomParameter(\"userId\", userId); Copy Example 2: Adding custom attributes to spans in distributed traces To collect custom attributes using the agent's API, call the relevant methods: For each span (currently executing method) that you want to record an attribute for, call NewRelic.getAgent().getTracedMethod().addCustomAttribute(...). Optional: Include or exclude certain attributes with span_events.attributes.include and span_events.attributes.exclude. For example, to record a variable named userId on the current span, include this code in the associated method: NewRelic.getAgent().getTracedMethod().addCustomAttribute(\"userId\", userId); Copy Collect user attributes The Java agent also includes a built-in mechanism to enable user attributes and collect user information from HttpServletRequest.getUserPrincipal() as custom attributes. .NET Custom attribute collection is enabled by default in .NET. To collect custom attributes, call the relevant API methods: For each method for which you want to record an attribute, call AddCustomAttribute. Optional: Include or exclude attributes with the include and exclude configuration options. For example, to record attributes for a coupon code (string) and an item ID code (number), you could include this code in the parent method: IAgent agent = NewRelic.Api.Agent.NewRelic.GetAgent(); ITransaction transaction = agent.CurrentTransaction; transaction .AddCustomAttribute(\"Discount Code\", \"Summer Super Sale\") .AddCustomAttribute(\"Item Code\", 31456); Copy Node.js Custom attribute collection is enabled by default in Node.js. To collect custom attributes, call the relevant API method: For each attribute you want to record, call newrelic.addCustomAttribute. To record multiple attributes using a single call, use newrelic.addCustomAttributes. For example, to record attributes for a coupon code and an item ID code, you could include this in the parent method: newrelic.addCustomAttributes({ \"Discount Code\": \"Summer Super Sale\", \"Item Code\": 31456 }); Copy PHP Custom attribute collection is enabled by default in PHP. To collect custom attributes, call the relevant API method for each method that you want to record an attribute; newrelic_add_custom_parameter for transaction events and spans newrelic_add_custom_span_parameter for only spans For example, to record a variable named $userId, include this code in the parent method: newrelic_add_custom_parameter ('userID', $userId) Copy Python Custom attribute collection is enabled by default in Python. To collect custom attributes, call add_custom_parameter for each method that you want to record an attribute. For example, to record a variable named user_id, include this code in the parent method: newrelic.agent.add_custom_parameter('user_id', user_id) Copy Ruby Custom attribute collection is enabled by default in Ruby. To collect custom attributes, call the relevant API methods: For Ruby agent version 3.12.0 or higher, use the add_custom_attributes method. For example, to record a variable named @user_id, include this code in the parent method: ::NewRelic::Agent.add_custom_attributes({ user_id: @user.id }) Copy For Ruby agent version 3.11.2 or lower, use the add_custom_parameters method. For example, to record a variable named @user_id, include this code in the parent method: ::NewRelic::Agent.add_custom_parameters({ user_id: @user.id }) Copy Browser monitoring: Record custom attributes The browser agent provides an API to specify extra details associated with a page view or browser interaction, either by forwarding attributes from APM to browser monitoring or by specifying custom attributes through JavaScript. Values forwarded from the APM agent are encoded and injected into browser attributes by our browser agent. Infrastructure monitoring: Record custom attributes Our Infrastructure monitoring lets you create custom attributes that are used to annotate the data from the infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. Mobile monitoring: Record custom attributes Mobile agents include API calls to record custom attributes: For an overview of mobile monitoring custom data, see Insert custom events and attributes Android method: setAttribute iOS method: setAttribute For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.15173,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Ruby</em>",
        "tags": "<em>Install</em> and configure",
        "body": " a variable named user_id, include this code in the parent method: newrelic.<em>agent</em>.add_custom_parameter(&#x27;user_id&#x27;, user_id) Copy <em>Ruby</em> Custom attribute collection is enabled by default in <em>Ruby</em>. To collect custom attributes, call the relevant API methods: For <em>Ruby</em> <em>agent</em> version 3.12.0 or higher, use"
      },
      "id": "603eb9a3196a67a990a83da5"
    }
  ],
  "/docs/agents/ruby-agent/installation/uninstall-ruby-agent": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/include-a-doc-in-multiple-menus/",
      "sections": [
        "Include a doc in multiple menus"
      ],
      "published_at": "2021-07-01T16:03:42Z",
      "title": "Include a doc in multiple menus",
      "updated_at": "2021-06-02T17:05:51Z",
      "type": "docs",
      "external_id": "281e8e849c2b4fdd56046513c8ae2eecf24392f7",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have a document that should appear in multiple menus, you can include the same path in multiple taxonomy locations. For example, if you wanted to link to the APM landing page from another location of taxonomy (such as a differnt taxonomy level, a different category, etc.), you’d add a new entry in the navigation YAML file (for example, /src/nav/agents.yml). In this example, we add a link to the Ruby agent installation doc from the Distributed tracing category. You can now access this doc from either the Distributed tracing category or the Ruby agent category. - title: Distributed tracing path: /docs/distributed-tracing pages: - title: Concepts path: /docs/distributed-tracing/concepts pages: - title: Intro to distributed tracing path: /docs/distributed-tracing/concepts/introduction-distributed-tracing - title: Planning guide path: /docs/distributed-tracing/concepts/distributed-tracing-planning-guide - title: How distributed tracing works path: /docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works - title: This is a dummy doc path: /docs/agents/ruby-agent/installation/install-new-relic-ruby-agent Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.283035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " entry in the navigation YAML file (for example, &#x2F;src&#x2F;nav&#x2F;<em>agents</em>.yml). In this example, we add a link to the <em>Ruby</em> <em>agent</em> <em>installation</em> doc from the Distributed tracing category. You can now access this doc from either the Distributed tracing category or the <em>Ruby</em> <em>agent</em> category. - title: Distributed"
      },
      "id": "604220ec196a67358ea83da5"
    },
    {
      "sections": [
        "Update the Ruby agent",
        "Verify your Ruby agent versions",
        "Update the agent",
        "Instrument JRuby",
        "Ruby agent versions not supported",
        "Update unsupported agent versions",
        "Important"
      ],
      "title": "Update the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "3248580dc4c2039ed569a158783912ea23ef1fc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/update-ruby-agent/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-04-28T05:21:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To take full advantage of New Relic's latest features, enhancements, and important security patches, we recommend you update your Ruby agent to the latest version. For additional information about specific agent updates, refer to the Ruby agent release notes. Verify your Ruby agent versions To determine which Ruby agent versions your apps currently use: In New Relic, from the account dropdown, select Account settings > Connected agents. Optional: Sort by Oldest agent version. Update the agent To update the Ruby agent: Using Bundler: Run this command: bundle update newrelic_rpm Copy Not using Bundler: Run this command: gem update newrelic_rpm Copy Instrument JRuby For correct instrumentation: With JRuby versions 1.7 or higher, use New Relic Ruby agent version 3.6.8.164 to 3.18.1. With JRuby versions 9 or higher, use New Relic Ruby agent version 3.6.8.164 or higher. Otherwise, if your application has no transactions and you are using JRuby, you will not be able to see your CPU metrics. This was due to a bug in JRuby, where Process.times returned wall-clock time instead of elapsed CPU time. That bug was fixed as of New Relic’s Ruby agent 3.6.8.164 and JRuby 1.7.0. Ruby agent versions not supported End of life notification: As of January 26, 2015, New Relic will no longer accept data from Ruby agent versions earlier than 3.9.6. These agent versions use an out-of-date protocol when communicating with New Relic's data collection services. In addition, many of these versions contain a potential security issue where they may incorrectly send sensitive data to the New Relic collector. Update unsupported agent versions Important If you are updating from an older agent version, including major version jumps, review the following list for changes in functionality. Migration Comments From version 6 to 7 Release notes: Ruby agent 7.0.0 Please see our Ruby Agent 6.x to 7.x migration guide for helpful strategies and tips for migrating from earlier versions of the Ruby agent to 7.0.0. We cover new configuration settings, diagnosiing and installing SSL CA certificates and deprecated items and their replacements in this guide. Ruby 2.0 and 2.1 dropped Implemented prepend auto-instrumentation strategies for most Ruby gems/libraries Removed SSL cert bundle Removed various deprecated config options From version 5 to 6 Release notes: Ruby agent 6.0.0.351 With the addition of the Tracer API for flexible custom instrumentation, several APIs were deprecated. If used, they need to be updated. For more information, see Ruby custom instrumentation. From version 4 to 5 Release notes: Ruby agent 5.0.0.342 SSL connections to New Relic are now mandatory. From version 3 to 4 Release notes: Ruby agent 4.0.0.332 The agent no longer supports Ruby versions prior to 2.0, JRuby 1.7 and earlier, and all versions of Rubinius. Deprecated API calls For a list of deprecated API calls and their replacements, see Update deprecated API calls.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.34482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update the <em>Ruby</em> <em>agent</em>",
        "sections": "Update the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " To determine which <em>Ruby</em> <em>agent</em> versions your apps currently use: In New Relic, from the account dropdown, select Account settings &gt; Connected <em>agents</em>. Optional: Sort by Oldest <em>agent</em> version. Update the <em>agent</em> To update the <em>Ruby</em> <em>agent</em>: Using Bundler: Run this command: bundle update newrelic_rpm Copy Not using"
      },
      "id": "603eb7db64441f83f84e88b1"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file [#Updating_newrelic.yml]",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-16T08:01:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file [#Updating_newrelic.yml] Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.29018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " to version X.X.X&quot; Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    }
  ],
  "/docs/agents/ruby-agent/installation/update-ruby-agent": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/include-a-doc-in-multiple-menus/",
      "sections": [
        "Include a doc in multiple menus"
      ],
      "published_at": "2021-07-01T16:03:42Z",
      "title": "Include a doc in multiple menus",
      "updated_at": "2021-06-02T17:05:51Z",
      "type": "docs",
      "external_id": "281e8e849c2b4fdd56046513c8ae2eecf24392f7",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have a document that should appear in multiple menus, you can include the same path in multiple taxonomy locations. For example, if you wanted to link to the APM landing page from another location of taxonomy (such as a differnt taxonomy level, a different category, etc.), you’d add a new entry in the navigation YAML file (for example, /src/nav/agents.yml). In this example, we add a link to the Ruby agent installation doc from the Distributed tracing category. You can now access this doc from either the Distributed tracing category or the Ruby agent category. - title: Distributed tracing path: /docs/distributed-tracing pages: - title: Concepts path: /docs/distributed-tracing/concepts pages: - title: Intro to distributed tracing path: /docs/distributed-tracing/concepts/introduction-distributed-tracing - title: Planning guide path: /docs/distributed-tracing/concepts/distributed-tracing-planning-guide - title: How distributed tracing works path: /docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works - title: This is a dummy doc path: /docs/agents/ruby-agent/installation/install-new-relic-ruby-agent Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.283035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " entry in the navigation YAML file (for example, &#x2F;src&#x2F;nav&#x2F;<em>agents</em>.yml). In this example, we add a link to the <em>Ruby</em> <em>agent</em> <em>installation</em> doc from the Distributed tracing category. You can now access this doc from either the Distributed tracing category or the <em>Ruby</em> <em>agent</em> category. - title: Distributed"
      },
      "id": "604220ec196a67358ea83da5"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file [#Updating_newrelic.yml]",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-16T08:01:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file [#Updating_newrelic.yml] Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.29018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " to version X.X.X&quot; Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Collect custom attributes",
        "Requirements",
        "APM: Record custom attributes",
        "Important",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Browser monitoring: Record custom attributes",
        "Infrastructure monitoring: Record custom attributes",
        "Mobile monitoring: Record custom attributes",
        "For more help"
      ],
      "title": "Collect custom attributes",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "ad362b1a5cf3a5661eb416584fd9c79db064f539",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/data/customize-data/collect-custom-attributes/",
      "published_at": "2021-07-02T19:49:53Z",
      "updated_at": "2021-07-02T19:49:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For some New Relic solutions, one way to report custom data to New Relic is to use custom attributes. For example, for New Relic browser monitoring, you might create a custom attribute to track the user name associated with a slow or failing request. Requirements Custom attributes are available for these New Relic solutions: APM Browser monitoring Mobile monitoring Infrastructure monitoring For other custom data solutions, see Intro to custom data. APM: Record custom attributes Important Review the list of reserved terms used by NRQL. Using reserved terms can cause issues. To enable and use custom attributes for APM, follow the procedure for your APM agent: C SDK To add custom attributes to applications monitored by the C SDK, call one of the attribute functions; for example, newrelic_add_attribute_double(). The key name for your custom attribute depends on what you specify when you call the function. Go Custom attribute collection is enabled by default in the Go agent. However, you can disable custom attribute collection. Java Custom attribute collection is enabled by default in Java. You can collect custom attributes using XML and the Java agent APIs. These two methods can be used in conjunction with each other. Method How to do it Specify attributes in XML XML allows you to specify custom attributes without changing any of your source code. You can have multiple XML files for custom attributes that are grouped by some logical facet. To set custom attributes for your Java app via XML: Review the New Relic Java agent's documentation about XML file format, methods and classes, and examples. From your Extensions directory within the New Relic Java agent, create a single XML file. Define the methods you want New Relic to monitor by editing your XML file directly. Define an XML instrumentation file using the New Relic UI. This may require additional config in the common: block of your newrelic.yml. See Report custom attributes under Instrumentation options for more detail. Call the agent's API Example 1: Adding custom attributes to transactions To collect custom attributes using the agent's API, call the relevant methods: For each method you want to record an attribute for, call NewRelic.addCustomParameter(...). Optional: Include or exclude certain attributes with attributes.include and attributes.exclude. For example, to record a variable named userId, include this code in the parent method: NewRelic.addCustomParameter(\"userId\", userId); Copy Example 2: Adding custom attributes to spans in distributed traces To collect custom attributes using the agent's API, call the relevant methods: For each span (currently executing method) that you want to record an attribute for, call NewRelic.getAgent().getTracedMethod().addCustomAttribute(...). Optional: Include or exclude certain attributes with span_events.attributes.include and span_events.attributes.exclude. For example, to record a variable named userId on the current span, include this code in the associated method: NewRelic.getAgent().getTracedMethod().addCustomAttribute(\"userId\", userId); Copy Collect user attributes The Java agent also includes a built-in mechanism to enable user attributes and collect user information from HttpServletRequest.getUserPrincipal() as custom attributes. .NET Custom attribute collection is enabled by default in .NET. To collect custom attributes, call the relevant API methods: For each method for which you want to record an attribute, call AddCustomAttribute. Optional: Include or exclude attributes with the include and exclude configuration options. For example, to record attributes for a coupon code (string) and an item ID code (number), you could include this code in the parent method: IAgent agent = NewRelic.Api.Agent.NewRelic.GetAgent(); ITransaction transaction = agent.CurrentTransaction; transaction .AddCustomAttribute(\"Discount Code\", \"Summer Super Sale\") .AddCustomAttribute(\"Item Code\", 31456); Copy Node.js Custom attribute collection is enabled by default in Node.js. To collect custom attributes, call the relevant API method: For each attribute you want to record, call newrelic.addCustomAttribute. To record multiple attributes using a single call, use newrelic.addCustomAttributes. For example, to record attributes for a coupon code and an item ID code, you could include this in the parent method: newrelic.addCustomAttributes({ \"Discount Code\": \"Summer Super Sale\", \"Item Code\": 31456 }); Copy PHP Custom attribute collection is enabled by default in PHP. To collect custom attributes, call the relevant API method for each method that you want to record an attribute; newrelic_add_custom_parameter for transaction events and spans newrelic_add_custom_span_parameter for only spans For example, to record a variable named $userId, include this code in the parent method: newrelic_add_custom_parameter ('userID', $userId) Copy Python Custom attribute collection is enabled by default in Python. To collect custom attributes, call add_custom_parameter for each method that you want to record an attribute. For example, to record a variable named user_id, include this code in the parent method: newrelic.agent.add_custom_parameter('user_id', user_id) Copy Ruby Custom attribute collection is enabled by default in Ruby. To collect custom attributes, call the relevant API methods: For Ruby agent version 3.12.0 or higher, use the add_custom_attributes method. For example, to record a variable named @user_id, include this code in the parent method: ::NewRelic::Agent.add_custom_attributes({ user_id: @user.id }) Copy For Ruby agent version 3.11.2 or lower, use the add_custom_parameters method. For example, to record a variable named @user_id, include this code in the parent method: ::NewRelic::Agent.add_custom_parameters({ user_id: @user.id }) Copy Browser monitoring: Record custom attributes The browser agent provides an API to specify extra details associated with a page view or browser interaction, either by forwarding attributes from APM to browser monitoring or by specifying custom attributes through JavaScript. Values forwarded from the APM agent are encoded and injected into browser attributes by our browser agent. Infrastructure monitoring: Record custom attributes Our Infrastructure monitoring lets you create custom attributes that are used to annotate the data from the infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. Mobile monitoring: Record custom attributes Mobile agents include API calls to record custom attributes: For an overview of mobile monitoring custom data, see Insert custom events and attributes Android method: setAttribute iOS method: setAttribute For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.15167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Ruby</em>",
        "tags": "<em>Install</em> and configure",
        "body": " a variable named user_id, include this code in the parent method: newrelic.<em>agent</em>.add_custom_parameter(&#x27;user_id&#x27;, user_id) Copy <em>Ruby</em> Custom attribute collection is enabled by default in <em>Ruby</em>. To collect custom attributes, call the relevant API methods: For <em>Ruby</em> <em>agent</em> version 3.12.0 or higher, use"
      },
      "id": "603eb9a3196a67a990a83da5"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/rack-middlewares": [
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-07-02T12:23:04Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.55362,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)",
        "For more help"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-03-16T06:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work. For more help Additional documentation resources include Browser monitoring and the Ruby agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.4378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Redis instrumentation",
        "Tip",
        "Interaction with newrelic-redis",
        "Important",
        "Capture Redis command arguments"
      ],
      "title": "Redis instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "9923fcd7dd89191c620a9490fb89cd8ca4bf31e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation/",
      "published_at": "2021-07-02T12:28:36Z",
      "updated_at": "2021-03-16T08:03:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent automatically instruments the Redis gem (gem version 3.0.0 or higher). After you install the agent and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart on the APM Summary page will show color-coded Redis information. Tip Redis instrumentation requires Ruby agent version 3.13.0 or higher. Interaction with newrelic-redis The third-party newrelic-redis gem provides Redis instrumentation support as an add-on to New Relic's Ruby agent. If the Ruby agent detects newrelic-redis, it will not install the built-in Redis instrumentation and will record a log message like this at startup: INFO : Not installing New Relic supported Redis instrumentation because the third party newrelic-redis gem is present Copy To use New Relic's built-in Redis instrumentation and view Redis information in the UI, remove the newrelic-redis gem. Important Removing the newrelic-redis gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. Capture Redis command arguments By default, the Ruby agent only captures Redis command names. To capture Redis command arguments, use this configuration: transaction_tracer: record_redis_arguments: true Copy The agent limits the number of characters and arguments collected from each transaction trace node. The agent truncates items that exceed these limits.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.40382,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Redis <em>instrumentation</em>",
        "sections": "Redis <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> automatically instruments the Redis <em>gem</em> (<em>gem</em> version 3.0.0 or higher). After you install the <em>agent</em> and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart"
      },
      "id": "603ed7a628ccbca064eba784"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-05-05T14:33:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Cross application traces Auto-instrumentation for Browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's Cross Application Tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you have disabled middleware instrumentation as described above and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. For more information, see Cross application tracing in Ruby. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.13701,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-07-02T12:23:04Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.55362,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)",
        "For more help"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-03-16T06:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work. For more help Additional documentation resources include Browser monitoring and the Ruby agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.4378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-07-02T12:27:49Z",
      "updated_at": "2021-05-05T14:33:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Cross application traces Auto-instrumentation for Browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's Cross Application Tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you have disabled middleware instrumentation as described above and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. For more information, see Cross application tracing in Ruby. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.137,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-07-02T12:23:04Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.5536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    },
    {
      "sections": [
        "Redis instrumentation",
        "Tip",
        "Interaction with newrelic-redis",
        "Important",
        "Capture Redis command arguments"
      ],
      "title": "Redis instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "9923fcd7dd89191c620a9490fb89cd8ca4bf31e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation/",
      "published_at": "2021-07-02T12:28:36Z",
      "updated_at": "2021-03-16T08:03:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent automatically instruments the Redis gem (gem version 3.0.0 or higher). After you install the agent and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart on the APM Summary page will show color-coded Redis information. Tip Redis instrumentation requires Ruby agent version 3.13.0 or higher. Interaction with newrelic-redis The third-party newrelic-redis gem provides Redis instrumentation support as an add-on to New Relic's Ruby agent. If the Ruby agent detects newrelic-redis, it will not install the built-in Redis instrumentation and will record a log message like this at startup: INFO : Not installing New Relic supported Redis instrumentation because the third party newrelic-redis gem is present Copy To use New Relic's built-in Redis instrumentation and view Redis information in the UI, remove the newrelic-redis gem. Important Removing the newrelic-redis gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. Capture Redis command arguments By default, the Ruby agent only captures Redis command names. To capture Redis command arguments, use this configuration: transaction_tracer: record_redis_arguments: true Copy The agent limits the number of characters and arguments collected from each transaction trace node. The agent truncates items that exceed these limits.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.40382,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Redis <em>instrumentation</em>",
        "sections": "Redis <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> automatically instruments the Redis <em>gem</em> (<em>gem</em> version 3.0.0 or higher). After you install the <em>agent</em> and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart"
      },
      "id": "603ed7a628ccbca064eba784"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/control-when-ruby-agent-starts": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.43819,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Uninstall the Ruby agent",
        "For more help"
      ],
      "title": "Uninstall the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "b92596a58ce64fd42a0349b0a3e0e07483122cb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/uninstall-ruby-agent/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-13T02:18:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how to uninstall the New Relic Ruby agent. For instructions on how to temporarily disable the agent, see Disable the agent. To uninstall the Ruby agent: Delete the line gem 'newrelic_rpm' from your Gemfile. Remove the newrelic.yml file from your RAILS_ROOT/config/ folder. Run bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for Ruby. For more help Additional documentation resources include: Troubleshooting the Ruby agent (a library of troubleshooting solutions for your Ruby application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.472755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "sections": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for <em>Ruby</em>. For more help Additional documentation resources include: <em>Troubleshooting</em> the <em>Ruby</em> <em>agent</em> (a library of <em>troubleshooting</em> solutions for your <em>Ruby</em> application)"
      },
      "id": "604404ec64441f7a8b378f3c"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.99401,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If true, the <em>agent</em> automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, installation, configuration, <em>troubleshooting</em>, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic&#x27;s Transaction Traces feature)"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/generating-logs-troubleshooting-ruby": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.43817,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Uninstall the Ruby agent",
        "For more help"
      ],
      "title": "Uninstall the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "b92596a58ce64fd42a0349b0a3e0e07483122cb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/uninstall-ruby-agent/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-13T02:18:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how to uninstall the New Relic Ruby agent. For instructions on how to temporarily disable the agent, see Disable the agent. To uninstall the Ruby agent: Delete the line gem 'newrelic_rpm' from your Gemfile. Remove the newrelic.yml file from your RAILS_ROOT/config/ folder. Run bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for Ruby. For more help Additional documentation resources include: Troubleshooting the Ruby agent (a library of troubleshooting solutions for your Ruby application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.472755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "sections": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for <em>Ruby</em>. For more help Additional documentation resources include: <em>Troubleshooting</em> the <em>Ruby</em> <em>agent</em> (a library of <em>troubleshooting</em> solutions for your <em>Ruby</em> application)"
      },
      "id": "604404ec64441f7a8b378f3c"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.99399,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If true, the <em>agent</em> automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, installation, configuration, <em>troubleshooting</em>, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic&#x27;s Transaction Traces feature)"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/incompatible-gems": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.43817,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Uninstall the Ruby agent",
        "For more help"
      ],
      "title": "Uninstall the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "b92596a58ce64fd42a0349b0a3e0e07483122cb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/uninstall-ruby-agent/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-13T02:18:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how to uninstall the New Relic Ruby agent. For instructions on how to temporarily disable the agent, see Disable the agent. To uninstall the Ruby agent: Delete the line gem 'newrelic_rpm' from your Gemfile. Remove the newrelic.yml file from your RAILS_ROOT/config/ folder. Run bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for Ruby. For more help Additional documentation resources include: Troubleshooting the Ruby agent (a library of troubleshooting solutions for your Ruby application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.472755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "sections": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for <em>Ruby</em>. For more help Additional documentation resources include: <em>Troubleshooting</em> the <em>Ruby</em> <em>agent</em> (a library of <em>troubleshooting</em> solutions for your <em>Ruby</em> application)"
      },
      "id": "604404ec64441f7a8b378f3c"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.99399,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If true, the <em>agent</em> automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, installation, configuration, <em>troubleshooting</em>, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic&#x27;s Transaction Traces feature)"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-data-appears-ruby": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.43816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Uninstall the Ruby agent",
        "For more help"
      ],
      "title": "Uninstall the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "b92596a58ce64fd42a0349b0a3e0e07483122cb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/uninstall-ruby-agent/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-13T02:18:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how to uninstall the New Relic Ruby agent. For instructions on how to temporarily disable the agent, see Disable the agent. To uninstall the Ruby agent: Delete the line gem 'newrelic_rpm' from your Gemfile. Remove the newrelic.yml file from your RAILS_ROOT/config/ folder. Run bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for Ruby. For more help Additional documentation resources include: Troubleshooting the Ruby agent (a library of troubleshooting solutions for your Ruby application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.472755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "sections": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for <em>Ruby</em>. For more help Additional documentation resources include: <em>Troubleshooting</em> the <em>Ruby</em> <em>agent</em> (a library of <em>troubleshooting</em> solutions for your <em>Ruby</em> application)"
      },
      "id": "604404ec64441f7a8b378f3c"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.99397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If true, the <em>agent</em> automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, installation, configuration, <em>troubleshooting</em>, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic&#x27;s Transaction Traces feature)"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-data-unicorn": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.43816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Uninstall the Ruby agent",
        "For more help"
      ],
      "title": "Uninstall the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "b92596a58ce64fd42a0349b0a3e0e07483122cb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/uninstall-ruby-agent/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-13T02:18:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how to uninstall the New Relic Ruby agent. For instructions on how to temporarily disable the agent, see Disable the agent. To uninstall the Ruby agent: Delete the line gem 'newrelic_rpm' from your Gemfile. Remove the newrelic.yml file from your RAILS_ROOT/config/ folder. Run bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for Ruby. For more help Additional documentation resources include: Troubleshooting the Ruby agent (a library of troubleshooting solutions for your Ruby application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.472755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "sections": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for <em>Ruby</em>. For more help Additional documentation resources include: <em>Troubleshooting</em> the <em>Ruby</em> <em>agent</em> (a library of <em>troubleshooting</em> solutions for your <em>Ruby</em> application)"
      },
      "id": "604404ec64441f7a8b378f3c"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.99397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If true, the <em>agent</em> automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, installation, configuration, <em>troubleshooting</em>, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic&#x27;s Transaction Traces feature)"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-log-file-ruby": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.438156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Uninstall the Ruby agent",
        "For more help"
      ],
      "title": "Uninstall the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "b92596a58ce64fd42a0349b0a3e0e07483122cb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/uninstall-ruby-agent/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-13T02:18:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how to uninstall the New Relic Ruby agent. For instructions on how to temporarily disable the agent, see Disable the agent. To uninstall the Ruby agent: Delete the line gem 'newrelic_rpm' from your Gemfile. Remove the newrelic.yml file from your RAILS_ROOT/config/ folder. Run bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for Ruby. For more help Additional documentation resources include: Troubleshooting the Ruby agent (a library of troubleshooting solutions for your Ruby application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.472755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "sections": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for <em>Ruby</em>. For more help Additional documentation resources include: <em>Troubleshooting</em> the <em>Ruby</em> <em>agent</em> (a library of <em>troubleshooting</em> solutions for your <em>Ruby</em> application)"
      },
      "id": "604404ec64441f7a8b378f3c"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.99396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If true, the <em>agent</em> automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, installation, configuration, <em>troubleshooting</em>, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic&#x27;s Transaction Traces feature)"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/not-installing-new-relic-supported-grape": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.438156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Uninstall the Ruby agent",
        "For more help"
      ],
      "title": "Uninstall the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "b92596a58ce64fd42a0349b0a3e0e07483122cb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/uninstall-ruby-agent/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-13T02:18:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how to uninstall the New Relic Ruby agent. For instructions on how to temporarily disable the agent, see Disable the agent. To uninstall the Ruby agent: Delete the line gem 'newrelic_rpm' from your Gemfile. Remove the newrelic.yml file from your RAILS_ROOT/config/ folder. Run bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for Ruby. For more help Additional documentation resources include: Troubleshooting the Ruby agent (a library of troubleshooting solutions for your Ruby application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.472755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "sections": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for <em>Ruby</em>. For more help Additional documentation resources include: <em>Troubleshooting</em> the <em>Ruby</em> <em>agent</em> (a library of <em>troubleshooting</em> solutions for your <em>Ruby</em> application)"
      },
      "id": "604404ec64441f7a8b378f3c"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.99396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If true, the <em>agent</em> automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, installation, configuration, <em>troubleshooting</em>, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic&#x27;s Transaction Traces feature)"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/passenger-troubleshooting": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.43815,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Uninstall the Ruby agent",
        "For more help"
      ],
      "title": "Uninstall the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "b92596a58ce64fd42a0349b0a3e0e07483122cb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/uninstall-ruby-agent/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-13T02:18:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how to uninstall the New Relic Ruby agent. For instructions on how to temporarily disable the agent, see Disable the agent. To uninstall the Ruby agent: Delete the line gem 'newrelic_rpm' from your Gemfile. Remove the newrelic.yml file from your RAILS_ROOT/config/ folder. Run bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for Ruby. For more help Additional documentation resources include: Troubleshooting the Ruby agent (a library of troubleshooting solutions for your Ruby application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.472755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "sections": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for <em>Ruby</em>. For more help Additional documentation resources include: <em>Troubleshooting</em> the <em>Ruby</em> <em>agent</em> (a library of <em>troubleshooting</em> solutions for your <em>Ruby</em> application)"
      },
      "id": "604404ec64441f7a8b378f3c"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.99394,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If true, the <em>agent</em> automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, installation, configuration, <em>troubleshooting</em>, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic&#x27;s Transaction Traces feature)"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/ruby-agent-audit-log": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.43815,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Uninstall the Ruby agent",
        "For more help"
      ],
      "title": "Uninstall the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "b92596a58ce64fd42a0349b0a3e0e07483122cb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/uninstall-ruby-agent/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-13T02:18:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how to uninstall the New Relic Ruby agent. For instructions on how to temporarily disable the agent, see Disable the agent. To uninstall the Ruby agent: Delete the line gem 'newrelic_rpm' from your Gemfile. Remove the newrelic.yml file from your RAILS_ROOT/config/ folder. Run bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for Ruby. For more help Additional documentation resources include: Troubleshooting the Ruby agent (a library of troubleshooting solutions for your Ruby application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.472755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "sections": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for <em>Ruby</em>. For more help Additional documentation resources include: <em>Troubleshooting</em> the <em>Ruby</em> <em>agent</em> (a library of <em>troubleshooting</em> solutions for your <em>Ruby</em> application)"
      },
      "id": "604404ec64441f7a8b378f3c"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.99394,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If true, the <em>agent</em> automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, installation, configuration, <em>troubleshooting</em>, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic&#x27;s Transaction Traces feature)"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/systemstackerror-stack-level-too-deep": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.43814,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Uninstall the Ruby agent",
        "For more help"
      ],
      "title": "Uninstall the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "b92596a58ce64fd42a0349b0a3e0e07483122cb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/uninstall-ruby-agent/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-13T02:18:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how to uninstall the New Relic Ruby agent. For instructions on how to temporarily disable the agent, see Disable the agent. To uninstall the Ruby agent: Delete the line gem 'newrelic_rpm' from your Gemfile. Remove the newrelic.yml file from your RAILS_ROOT/config/ folder. Run bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for Ruby. For more help Additional documentation resources include: Troubleshooting the Ruby agent (a library of troubleshooting solutions for your Ruby application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.47275,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "sections": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for <em>Ruby</em>. For more help Additional documentation resources include: <em>Troubleshooting</em> the <em>Ruby</em> <em>agent</em> (a library of <em>troubleshooting</em> solutions for your <em>Ruby</em> application)"
      },
      "id": "604404ec64441f7a8b378f3c"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.99393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If true, the <em>agent</em> automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, installation, configuration, <em>troubleshooting</em>, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic&#x27;s Transaction Traces feature)"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/update-deprecated-api-calls": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.43814,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Uninstall the Ruby agent",
        "For more help"
      ],
      "title": "Uninstall the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "b92596a58ce64fd42a0349b0a3e0e07483122cb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/uninstall-ruby-agent/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-13T02:18:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how to uninstall the New Relic Ruby agent. For instructions on how to temporarily disable the agent, see Disable the agent. To uninstall the Ruby agent: Delete the line gem 'newrelic_rpm' from your Gemfile. Remove the newrelic.yml file from your RAILS_ROOT/config/ folder. Run bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for Ruby. For more help Additional documentation resources include: Troubleshooting the Ruby agent (a library of troubleshooting solutions for your Ruby application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.47275,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "sections": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for <em>Ruby</em>. For more help Additional documentation resources include: <em>Troubleshooting</em> the <em>Ruby</em> <em>agent</em> (a library of <em>troubleshooting</em> solutions for your <em>Ruby</em> application)"
      },
      "id": "604404ec64441f7a8b378f3c"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.99393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If true, the <em>agent</em> automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, installation, configuration, <em>troubleshooting</em>, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic&#x27;s Transaction Traces feature)"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/update-private-api-calls-public-tracer-api": [
    {
      "sections": [
        "New Relic Browser and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "New Relic Browser and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-07-02T12:21:08Z",
      "updated_at": "2021-06-09T06:24:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements In order to use New Relic Browser with your Ruby agent, make sure you meet these requirements: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the Browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the Browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.43814,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "sections": "New Relic Browser and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add New Relic Browser instrumentation to your webpages either automatically or manually. To enable Browser in the user interface, follow the procedures to install the Browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Uninstall the Ruby agent",
        "For more help"
      ],
      "title": "Uninstall the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "b92596a58ce64fd42a0349b0a3e0e07483122cb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/uninstall-ruby-agent/",
      "published_at": "2021-07-02T12:26:33Z",
      "updated_at": "2021-03-13T02:18:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how to uninstall the New Relic Ruby agent. For instructions on how to temporarily disable the agent, see Disable the agent. To uninstall the Ruby agent: Delete the line gem 'newrelic_rpm' from your Gemfile. Remove the newrelic.yml file from your RAILS_ROOT/config/ folder. Run bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for Ruby. For more help Additional documentation resources include: Troubleshooting the Ruby agent (a library of troubleshooting solutions for your Ruby application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.47275,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "sections": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for <em>Ruby</em>. For more help Additional documentation resources include: <em>Troubleshooting</em> the <em>Ruby</em> <em>agent</em> (a library of <em>troubleshooting</em> solutions for your <em>Ruby</em> application)"
      },
      "id": "604404ec64441f7a8b378f3c"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "entity_guid",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "Caution",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes",
        "For more help"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-07-02T19:47:38Z",
      "updated_at": "2021-06-20T18:19:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. entity_guid Type String Default nil Environ variable NEW_RELIC_ENTITY_GUID The Entity GUID for the entity running this agent. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED Deprecated. For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The Browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT This is true by default, this enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Deprecated; use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default \"about,assets:clean,assets:clobber,assets:environment,assets:precompile,assets:precompile:all,db:create,db:drop,db:fixtures:load,db:migrate,db:migrate:status,db:rollback,db:schema:cache:clear,db:schema:cache:dump,db:schema:dump,db:schema:load,db:seed,db:setup,db:structure:dump,db:version,doc:app,log:clear,middleware,notes,notes:custom,rails:template,rails:update,routes,secret,spec,spec:features,spec:requests,spec:controllers,spec:helpers,spec:models,spec:views,spec:routing,spec:rcov,stats,test,test:all,test:all:db,test:recent,test:single,test:uncommitted,time:zones:all,tmp:clear,tmp:create,webpacker:compile\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED If true, enables cross-application tracing. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Deprecated; use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default false Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, installation, configuration, troubleshooting, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic's Transaction Traces feature)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.99393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If true, the <em>agent</em> automatically detects that it is running in Kubernetes. For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, installation, configuration, <em>troubleshooting</em>, known issues, advanced features and configuration, beta releases) Transaction traces and Configuring transaction traces (detailed information about New Relic&#x27;s Transaction Traces feature)"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/change-applied-intelligence-correlation-logic-decisions": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Tip",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Tip To use Incident Intelligence and Applied Intelligence, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Set up Incident Intelligence To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.90076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started <em>with</em> Incident <em>Intelligence</em>",
        "sections": "Get started <em>with</em> Incident <em>Intelligence</em>",
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": "As part of <em>Applied</em> <em>Intelligence</em>, Incident <em>Intelligence</em> helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Tip To use Incident <em>Intelligence</em> and <em>Applied</em> <em>Intelligence</em>, as well as the rest of our"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.90076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use Incident <em>Intelligence</em>",
        "sections": "Use Incident <em>Intelligence</em>",
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": " for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use <em>decisions</em> To further reduce noise or get improved incident <em>correlation</em>, you can <em>change</em> or customize your <em>decisions</em>. <em>Decisions</em> determine how Incident <em>Intelligence</em> groups incidents together. To get started, see <em>Decisions</em>."
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-07-02T09:43:25Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.3898,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Incident <em>Intelligence</em> destination examples",
        "sections": "Incident <em>Intelligence</em> destination examples",
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure Incident <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Tip",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Tip To use Incident Intelligence and Applied Intelligence, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Set up Incident Intelligence To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 391.91254,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " and correlations from what you&#x27;re monitoring. To get data from <em>alerts</em>: From one.newrelic.com, click <em>Alerts</em>. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click <em>Alerts</em>. Select the policies you want to connect to <em>Applied</em> <em>Intelligence</em>, and click Connect. You can add additional <em>alerts</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 391.91254,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-07-02T09:43:25Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.58905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence": [
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 391.9123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-07-02T09:43:25Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.589,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    },
    {
      "sections": [
        "EU/US datacenters and Incident Intelligence"
      ],
      "title": "EU/US datacenters and Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "7ff5005d6728922c357974438d731b8432cd3ffb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence/",
      "published_at": "2021-07-02T12:32:51Z",
      "updated_at": "2021-04-21T13:32:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Incident Intelligence service is performed solely in the United States. By using New Relic Incident Intelligence, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic's US region data center or in our EU region data center. If you elect to use the Suggested Responder feature and manage EU-based individuals, you may need to confirm that an appropriate data processing agreement is in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.97908,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "sections": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "New Relic&#x27;s <em>Incident</em> <em>Intelligence</em> service is performed solely in the United States. By using New Relic <em>Incident</em> <em>Intelligence</em>, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic&#x27;s US region data center"
      },
      "id": "60802950196a67858464a7cb"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Tip",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Tip To use Incident Intelligence and Applied Intelligence, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Set up Incident Intelligence To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 391.9123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " and correlations from what you&#x27;re monitoring. To get data from <em>alerts</em>: From one.newrelic.com, click <em>Alerts</em>. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click <em>Alerts</em>. Select the policies you want to connect to <em>Applied</em> <em>Intelligence</em>, and click Connect. You can add additional <em>alerts</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 391.9123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "EU/US datacenters and Incident Intelligence"
      ],
      "title": "EU/US datacenters and Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "7ff5005d6728922c357974438d731b8432cd3ffb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence/",
      "published_at": "2021-07-02T12:32:51Z",
      "updated_at": "2021-04-21T13:32:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Incident Intelligence service is performed solely in the United States. By using New Relic Incident Intelligence, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic's US region data center or in our EU region data center. If you elect to use the Suggested Responder feature and manage EU-based individuals, you may need to confirm that an appropriate data processing agreement is in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.97908,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "sections": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "New Relic&#x27;s <em>Incident</em> <em>Intelligence</em> service is performed solely in the United States. By using New Relic <em>Incident</em> <em>Intelligence</em>, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic&#x27;s US region data center"
      },
      "id": "60802950196a67858464a7cb"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/rest-api-applied-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Tip",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Tip To use Incident Intelligence and Applied Intelligence, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Set up Incident Intelligence To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 391.91205,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " and correlations from what you&#x27;re monitoring. To get data from <em>alerts</em>: From one.newrelic.com, click <em>Alerts</em>. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click <em>Alerts</em>. Select the policies you want to connect to <em>Applied</em> <em>Intelligence</em>, and click Connect. You can add additional <em>alerts</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 391.91205,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-07-02T09:43:25Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.5889,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Tip",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Tip To use Incident Intelligence and Applied Intelligence, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Set up Incident Intelligence To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 391.91205,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " and correlations from what you&#x27;re monitoring. To get data from <em>alerts</em>: From one.newrelic.com, click <em>Alerts</em>. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click <em>Alerts</em>. Select the policies you want to connect to <em>Applied</em> <em>Intelligence</em>, and click Connect. You can add additional <em>alerts</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-07-02T09:43:25Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.5889,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    },
    {
      "sections": [
        "EU/US datacenters and Incident Intelligence"
      ],
      "title": "EU/US datacenters and Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "7ff5005d6728922c357974438d731b8432cd3ffb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence/",
      "published_at": "2021-07-02T12:32:51Z",
      "updated_at": "2021-04-21T13:32:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Incident Intelligence service is performed solely in the United States. By using New Relic Incident Intelligence, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic's US region data center or in our EU region data center. If you elect to use the Suggested Responder feature and manage EU-based individuals, you may need to confirm that an appropriate data processing agreement is in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.97908,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "sections": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "New Relic&#x27;s <em>Incident</em> <em>Intelligence</em> service is performed solely in the United States. By using New Relic <em>Incident</em> <em>Intelligence</em>, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic&#x27;s US region data center"
      },
      "id": "60802950196a67858464a7cb"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Tip",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Tip To use Incident Intelligence and Applied Intelligence, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Set up Incident Intelligence To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.99133,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " and correlations from what you&#x27;re monitoring. To get data from <em>alerts</em>: From one.newrelic.com, click <em>Alerts</em>. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click <em>Alerts</em>. Select the policies you want to connect to <em>Applied</em> <em>Intelligence</em>, and click Connect. You can add additional <em>alerts</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.99133,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident workflows",
        "Tip",
        "Why it matters",
        "How it works",
        "When notifications are sent",
        "Create or edit a workflow",
        "Step 1. Add and name a workflow",
        "Step 2. Select your triggers",
        "Step 3. Optional: Add NRQL query data to enrich your notifications",
        "NRQL query enrichment examples",
        "Check overall Synthetic monitoring health",
        "Know when violation-related traffic for an application drops",
        "Add custom variables to your query",
        "Step 4. Create notification actions",
        "Configure the notifier",
        "Configure your notification message",
        "Optional: Test the notifier",
        "Notifier configuration examples",
        "Atlassian Jira notifier",
        "AWS EventBridge notifier",
        "ServiceNow notifier",
        "ServiceNow two-way integration",
        "Webhook notifier",
        "Slack",
        "Microsoft Teams",
        "Step 5. Optional: Test your workflow",
        "Step 6. Activate your workflow"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/3ed05f61b9dba60a21485541c108c1eb/c1b63/build-enricher-query.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-07-02T11:16:52Z",
      "updated_at": "2021-03-16T08:06:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Incident workflows (or \"workflows\") is a flexible notification system that works within Applied Intelligence to enhance and enrich alert notifications. Incident workflows use a friendly user interface to build rich notification message templates and customize how, when, and where they’re sent. Tip To use incident workflows and Applied Intelligence, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters Incident workflows sends alert events to many destinations in any format, enriched with additional context. The destinations include various notification platforms, like webhooks and Jira. Before being sent to a destination, a notification is enriched with extra information, including from the New Relic database (NRDB). Not only that, workflows creates a two-way connection between your notification platforms and New Relic. All of your alert policies can be grouped into a single incident workflow. Tip Incident workflows are currently in BETA. If you haven't signed up yet, go to one.newrelic.com > Alerts & AI and click Incident Workflows Request access. How it works Workflows are a collection of triggers and actions for alerts incidents. A workflow is a set of instructions that defines enriched notification templates, chooses triggers, and connects to multiple notification platforms: A notification template maps the workflows fields to your notification platform. Triggers are alerts policies that start workflow processes. Actions are operations that execute when workflows trigger. Actions include enriching a notification with extra information or configuring your notification platform to define the notification message format. Each workflow has a single account and uses that account’s conditions for its triggers. When notifications are sent Workflows use the same incidents you defined in your alert policies. In alert policies, incident preferences define how incidents and notifications are created when conditions in the policy are violated. Create or edit a workflow From one.newrelic.com, click Alerts & AI. In the left pane, click Incident workflows to open the workflows dashboard. Use the workflows dashboard to create, edit, enable, or disable your workflows. Here’s a basic overview: Add and name the workflow. Select triggers. Enrich your notifications with NRQL. Create notification actions. Test your workflow. Activate your workflow. Step 1. Add and name a workflow When you add a workflow, give it a unique, descriptive name that will help you remember its purpose later. Step 2. Select your triggers An alerts condition defines a violation. Violations are workflow triggers. These violations are either warning or critical thresholds defined in the Alert policy. Tip Each workflow must have at least one trigger. If you select more than one, only one of them needs to be true to trigger the actions that follow. Step 3. Optional: Add NRQL query data to enrich your notifications After you select triggers, enrich your notification data with NRQL queries. The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time. You can save any valid (error free) query into your workflow, even if they return an empty result. You can also query with violation-specific variables; for example {{entity.id}}. An example of a NRQL query you might use to enrich your workflow. NRQL query enrichment examples Here are some examples of how to set up enrichment queries. Check overall Synthetic monitoring health If you're using synthetic monitoring to measure your website, you can define the number of unsuccessful health checks that will trigger a violation. This query lets your site reliability team track your unsuccessful health checks. SELECT count(*) FROM SyntheticCheck WHERE result != 'SUCCESS' since since 10 minutes FACET monitorName Copy Know when violation-related traffic for an application drops This query tracks the number of transactions on the entity with a condition violation, using the custom variable entity.name: SELECT count(*) FROM Transaction WHERE appName = '{{entity.name}}' since 10 minutes ago Copy This query tracks the latest HTTP status code response, filtered by the entity that violated the condition’s threshold: From Transaction select latest(httpResponsepre), average(duration) where appName = '{{entity.name}}' Copy This query gets the number and ingest time by product running within a Kubernetes pod so you can find a potential remedy: SELECT uniqueCount(displayName), sum(nr.ingestTimeMs) from K8sServiceSample where entityName = '{{entity.name}}' since 1 hour ago Copy Add custom variables to your query Custom variables are properties you can add to violations when you configure a workflow action. You can get information about the alert, such as condition, violation, and entity, using double curly brackets: {{variable_name}}. To get information about the entity that violated a condition, you can use custom variables as part of the WHERE statement of the query. For example, here's a query using an entity.name variable to get the state of an Amazon EC2 instance: SELECT latest(ec2State) FROM ComputeSample where provider = 'Ec2Instance' where entityName = '{{entity.name}}' Copy This query has a single value result (stopped) because it only selects a single field. The entity.name is the entity identifier. You can also use entity.id and any other entity properties like this. Step 4. Create notification actions You can use the monitoring platforms ServiceNow, Atlassian Jira Cloud, and AWS EventBridge with workflows. You can also configure a webhook to other destinations. Every workflow requires at least one notification action. To create an action: Configure the notifier Build the message Test the notifier Configure the notifier To configure your notifier, choose a notification platform, and then configure its destination fields. Click Add an action, and then under Notify your channels, click Add. Choose your notification platform. Complete the destination fields based on your notification platform. To acknowledge and close an alerts incident with Jira or ServiceNow, check Allow two-way integration. For example configurations, see Jira and ServiceNow. Configure your notification message The notification message is delivered to your notification platform. A notification message includes one or more key-value fields. Tip When using Jira and ServiceNow, you must map a workflows field name value to its corresponding field in your notification platform. A field’s value can be any combination of the following: Free text Output enriched with NRQL queries results Output enriched with Custom variables In each notifier, the payload is populated with your query results and some custom variables. You can remove those and add other custom variables, using the # sign. Type # to see a list of available outputs and custom variables. You can also write the custom variables manually: {{enricher_name.result}} is replaced with its result. {{variable_name}} is replaced with the variable’s value. Choose the variable name from a list of common fields or create a custom string. ServiceNow notification message example Optional: Test the notifier Send a notification message to verify that you have a good connection to your platform. A workflow test creates a ticket with placeholders for the final values. You get live results from the NRQL queries used to enrich the notifications, but N/A when referring to violations-related data. This is expected behavior. Updated variables are rendered on your notification platform when a real violation triggers the workflow. These values are part of the violation event. If you use variables as part of the notification message, the variables value uses the variable name (for example, entity.name) as a placeholder. If the notifier test fails, check the following: Make sure to use the proper domain, username, and password/token for your platform. Confirm your destination is live/awake. Make sure to use different names for your notifiers. Notifier configuration examples Here are some examples of specific notifier configurations. Atlassian Jira notifier Using Jira as a notifier enables you to push valuable violation data into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira endpoint Jira API key A user with write permission Optional: Assignee and watchers for the ticket A notification message where every field name of the message has a corresponding field name in the project schema (text field or multi-line text field) An example Jira configuration with two-way notification enabled. AWS EventBridge notifier Use workflows to hook New Relic events into AWS services with EventBridge, Amazon's serverless event bus. Then use EventBridge to deliver notification messages to route data to targets like AWS Lambda, SNS queues, CloudWatch logs, etc. Configure an EventBridge integration: Complete the AWS account ID, the AWS region, the name of the event bus, and the notification message (JSON). Send a test notification, which creates a partner event source in your EventBridge service page. On Partner event sources, select Associate with event bus. The Associate with event bus button. Set an event rule to forward the events to whatever AWS service you need: Select the custom or partner event bus option, and then select the name of the event bus. Choose an AWS service to run when triggered by a workflow. ServiceNow notifier Using ServiceNow as a notifier enables you to push valuable violation data into a new ServiceNow Incidents tickets. With two-way integrations, you can also make sure that status updates are mirrored back to New Relic. ServiceNow notifier needs: Notifier name ServiceNow endpoint A user with write permission A workflow notification where every field name has a matching field name in the ServiceNow incident table A comprehensive example of a ServiceNow notification message configuration. Here's what that configuration would look like in ServiceNow: ServiceNow ticket created when testing the above example (populated with text placeholders when testing) Here are some notes about this example: We used ServiceNow’s default field incident configuration, you or your company may have configured additional fields and values. Default configurations: Severity, Impact, Urgency are numeric values 1/2/3 that correspond with High/Medium/Low. State field: new, in progress, on hold, resolved, closed, canceled. The Category and Subcategory fields are text fields with a limited value set. See ServiceNow for more detail. Description, Short-Description, and Work_notes are free text fields and can be enriched as part of the notification message ServiceNow two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic alerts incident state. To enable auto-sync between the ServiceNow incident state and a workflow incident: When you enable two-way integration, changes to ServiceNow incidents will update Alerts' incident state. Check Allow two-way integration when you create the Notifier. Open and download this XML file (which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. After you enable the auto-sync process, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. For any state other than New, the workflow incident state changes to Acknowledged. Webhook notifier Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A channel name The endpoint of the target application Authorization Custom headers (if needed) The notification message Make sure to use valid JSON payloads. As suggested above, type \"#\" to add variables to the payload. This is an example of a webhook configuration you might use. Slack You can use a webhook to send workflows content to Slack. Read Slack documentation on how to set up incoming webhooks. You can send a basic webhook. { “text”: “The {{violation.id}}\\n led to this result:{{enricher.result}} ” } Copy You can also send enriched webhooks. { \"text\": \"Example for larger block example - for {{alert.id}}\", \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"{{alert.description}} - {{alert.threshold}}\" } }, { \"type\": \"section\", \"block_id\": \"section567\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"<https: 72nfswczfve=youtu.be> \\n :star: \\n {{violation.threshold}}\" }, \"accessory\": { \"type\": \"image\", \"image_url\": \"https://usercontent2.hubstatic.com/13785369.jpg\", \"alt_text\": \"Troubled cat image, or a PNG image for your NRQL chart\" } }, { \"type\": \"section\", \"block_id\": \"section789\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*bolded text*\" } ] } ] } Copy Microsoft Teams You can use a webhook to send workflows content to Microsoft Teams. Read Microsoft documentation on how to create an incoming webhook. Use your Microsoft Teams URL as the webhook domain name. You can use this payload example JSON for testing. { \"summary\": \"{{violation.title}} - New Relic Alert Test Policy\", \"themeColor\": \"0076D7\", \"@type\": \"MessageCard\", \"potentialAction\": [ { \"@type\": \"openUri\", \"name\": \"Go To Alert Details\", \"targets\": [ { \"os\": \"default\", \"uri\": \"{{alert.link}}\" } ] }, { \"@type\": \"openUri\", \"name\": \"Go To Condition (deep link)\", \"targets\": [ { \"os\": \"default\", \"uri\": \"{{condition.deep_link_url}}\" } ] }, { \"@type\": \"openUri\", \"name\": \"Go To Alert Condition (definition)\", \"targets\": [ { \"os\": \"default\", \"uri\": \"{{alert.condition}}\" } ] }, { \"@type\": \"openUri\", \"name\": \"Go To Violation Details\", \"targets\": [ { \"os\": \"default\", \"uri\": \"{{violation.detail_url}}\" } ] }, { \"@type\": \"openUri\", \"name\": \"Go To Runbook\", \"targets\": [ { \"os\": \"default\", \"uri\": \"{{violation.runbook_url}}\" } ] }, { \"@type\": \"openUri\", \"name\": \"Application Dashboard\", \"targets\": [ { \"os\": \"default\", \"uri\": \"http://…\" } ] }, { \"@type\": \"ActionCard\", \"name\": \"Add a comment\", \"inputs\": [ { \"@type\": \"TextInput\", \"id\": \"comment\", \"title\": \"Enter your comment\", \"isMultiline\": true } ], \"actions\": [ { \"@type\": \"HttpPOST\", \"name\": \"OK\", \"target\": \"http://…\" } ] } ], \"@context\": \"http://schema.org/extensions\", \"sections\": [ { \"activitySubtitle\": \"{{alert.message}}\", \"activityTitle\": \"New Relic Alert: {{alert.description}}\" }, { \"images\": [ { \"image\": \"https://embed-ssl.wistia.com/deliveries/7d647fc03b31bafcfe1e88146629c5d8379d76c5.png?image_resize=580x114%3E\" } ] }, { \"markdown\": true, \"facts\": [ { \"name\": \"Assigned to\", \"value\": \"harry@potter.com\" }, { \"name\": \"Due date\", \"value\": \"Mon May 01 2017 17:07:18 GMT-0700 (Pacific Daylight Time)\" }, { \"name\": \"Status\", \"value\": \"Not started yet, but maybe later\" }, { \"name\": \"Severity\", \"value\": \"1.1\" }, { \"name\": \"Account ID\", \"value\": \"{{account.id}}\" }, { \"name\": \"alert.description\", \"value\": \"{{alert.description}}\" }, { \"name\": \"alert.id\", \"value\": \"{{alert.id}}\" }, { \"name\": \"alert.labels\", \"value\": \"{{alert.labels}}\" }, { \"name\": \"alert.link\", \"value\": \"{{alert.link}}\" }, { \"name\": \"alert.message\", \"value\": \"{{alert.message}}\" }, { \"name\": \"alert.metric_name\", \"value\": \"{{alert.metric_name}}\" }, { \"name\": \"alert.name\", \"value\": \"{{alert.name}}\" }, { \"name\": \"alert.priority\", \"value\": \"{{alert.priority}}\" }, { \"name\": \"alert.state\", \"value\": \"{{alert.state}}\" }, { \"name\": \"alert.threshold\", \"value\": \"{{alert.threshold}}\" }, { \"name\": \"condition.deep_link_url\", \"value\": \"{{condition.deep_link_url}}\" }, { \"name\": \"condition.id\", \"value\": \"{{condition.id}}\" }, { \"name\": \"condition.name\", \"value\": \"{{condition.name}}\" }, { \"name\": \"entity.id\", \"value\": \"{{entity.id}}\" }, { \"name\": \"entity.kind\", \"value\": \"{{entity.kind}}\" }, { \"name\": \"entity.name\", \"value\": \"{{entity.name}}\" }, { \"name\": \"entity.type\", \"value\": \"{{entity.type}}\" }, { \"name\": \"evaluation.analyzer\", \"value\": \"{{evaluation.analyzer}}\" }, { \"name\": \"evaluation.expected_groups\", \"value\": \"{{evaluation.expected_groups}}\" }, { \"name\": \"evaluation.label\", \"value\": \"{{evaluation.label}}\" }, { \"name\": \"evaluation.name\", \"value\": \"{{evaluation.name}}\" }, { \"name\": \"evaluation.operator\", \"value\": \"{{evaluation.operator}}\" }, { \"name\": \"evaluation.threshold\", \"value\": \"{{evaluation.threshold}}\" }, { \"name\": \"evaluation.threshold_duration_seconds\", \"value\": \"{{evaluation.threshold_duration_seconds}}\" }, { \"name\": \"evaluation.threshold_occurrences\", \"value\": \"{{evaluation.threshold_occurrences}}\" }, { \"name\": \"evaluation.value_function\", \"value\": \"{{evaluation.value_function}}\" }, { \"name\": \"evaluation.violate_on_overlap\", \"value\": \"{{evaluation.violate_on_overlap}}\" }, { \"name\": \"health_check.id\", \"value\": \"{{health_check.id}}\" }, { \"name\": \"health_check.name\", \"value\": \"{{health_check.name}}\" }, { \"name\": \"host.id\", \"value\": \"{{host.id}}\" }, { \"name\": \"host.name\", \"value\": \"{{host.name}}\" }, { \"name\": \"nrql.event_type\", \"value\": \"{{nrql.event_type}}\" }, { \"name\": \"policy.id\", \"value\": \"{{policy.id}}\" }, { \"name\": \"policy.name\", \"value\": \"{{policy.name}}\" }, { \"name\": \"product\", \"value\": \"{{product}}\" }, { \"name\": \"signal.nrql.query\", \"value\": \"{{signal.nrql.query}}\" }, { \"name\": \"signal.units\", \"value\": \"{{signal.units}}\" }, { \"name\": \"source\", \"value\": \"{{source}}\" }, { \"name\": \"system\", \"value\": \"{{system}}\" }, { \"name\": \"templatized_title\", \"value\": \"{{templatized_title}}\" }, { \"name\": \"violation.close_time\", \"value\": \"{{violation.close_time}}\" }, { \"name\": \"violation.degradation_time\", \"value\": \"{{violation.degradation_time}}\" }, { \"name\": \"violation.detail_url\", \"value\": \"{{violation.detail_url}}\" }, { \"name\": \"violation.incident_key\", \"value\": \"{{violation.incident_key}}\" }, { \"name\": \"violation.muted\", \"value\": \"{{violation.muted}}\" }, { \"name\": \"violation.open_time\", \"value\": \"{{violation.open_time}}\" }, { \"name\": \"violation.policy.id\", \"value\": \"{{violation.policy.id}}\" }, { \"name\": \"violation.policy.name\", \"value\": \"{{violation.policy.name}}\" }, { \"name\": \"violation.priority\", \"value\": \"{{violation.priority}}\" }, { \"name\": \"violation.recovery_time\", \"value\": \"{{violation.recovery_time}}\" }, { \"name\": \"violation.runbook_url\", \"value\": \"{{violation.runbook_url}}\" }, { \"name\": \"violation.status\", \"value\": \"{{violation.status}}\" }, { \"name\": \"violation.time_limit\", \"value\": \"{{violation.time_limit}}\" }, { \"name\": \"violation.title\", \"value\": \"{{violation.title}}\" }, { \"name\": \"violation.chart_url\", \"value\": \"{{violation.chart_url}}\" { \"name\": \"label.owning_team\", \"value\": \"{{label.owning_team}}\" }, { \"name\": \"label.product\", \"value\": \"{{label.product}}\" }, { \"name\": \"label.service_name\", \"value\": \"{{label.service_name}}\" }, { \"name\": \"tag.account\", \"value\": \"{{tag.account}}\" }, { \"name\": \"tag.cluster_name\", \"value\": \"{{tag.cluster_name}}\" }, { \"name\": \"tag.cluster_role\", \"value\": \"{{tag.cluster_role}}\" }, { \"name\": \"tag.display_name\", \"value\": \"{{tag.display_name}}\" }, { \"name\": \"tag.full_hostname\", \"value\": \"{{tag.full_hostname}}\" }, { \"name\": \"tag.hostname\", \"value\": \"{{tag.hostname}}\" }, { \"name\": \"aws.ec2.instance_type\", \"value\": \"{{aws.ec2.instance_type}}\" }, { \"name\": \"enricher\", \"value\": \"{{enricher-200716-1010.result}}\" } ] } ] } Copy Step 5. Optional: Test your workflow When you test the workflow, it runs NRQL queries to enrich your notifications and send test notification messages to your notification platforms. If your workflow test fails, check the following: There's a unique name for your workflow and notifiers. The queries are valid (without error messages in the NRQL query). The notifiers passed their test. Step 6. Activate your workflow Make sure your workflow has at least one trigger and one notification channel, then save and activate the workflow.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.98157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>workflows</em>",
        "sections": "<em>Incident</em> <em>workflows</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Incident</em> <em>workflows</em> (or &quot;<em>workflows</em>&quot;) is a flexible notification system that works within <em>Applied</em> <em>Intelligence</em> to enhance and enrich <em>alert</em> notifications. <em>Incident</em> <em>workflows</em> use a friendly user interface to build rich notification message templates and customize how, when, and where they’re sent. Tip"
      },
      "id": "603e967664441f7e6f4e889b"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Tip",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Tip To use Incident Intelligence and Applied Intelligence, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Set up Incident Intelligence To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.99133,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " and correlations from what you&#x27;re monitoring. To get data from <em>alerts</em>: From one.newrelic.com, click <em>Alerts</em>. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click <em>Alerts</em>. Select the policies you want to connect to <em>Applied</em> <em>Intelligence</em>, and click Connect. You can add additional <em>alerts</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.99133,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Custom variables for Incident Workflows",
        "Use custom variables in a filter statement",
        "Workflow data enrichment examples",
        "Query for when application traffic drops",
        "Query for transaction failures",
        "Query for Kubernetes consumption overview",
        "Full variables list by category"
      ],
      "title": "Custom variables for Incident Workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "48f9db1f21750574985a1563c6b2dad8f4dcb2ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows/",
      "published_at": "2021-07-02T09:44:41Z",
      "updated_at": "2021-03-16T08:06:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Incident Workflows, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the workflow, and violation attributes are transferred into the notification creation. Custom variables are violation-related properties you can use as part of the configuration of a workflow action. You can retrieve Information about the alert, condition, violation, and entity by using double curly brackets:: {{variable_name}}. Use custom variables in a filter statement To get information about the entity that violated a condition, you can use custom variables as part of the where statement of the query. For example, to get the state of the EC2 instance use: SELECT latest(ec2State) FROM ComputeSample where provider = 'Ec2Instance' where entityName = `{{entity.name}}' Copy This query returns a single value (for example, stopped), as the query only uses a single field. The variable entity.name is the identifier of the entity. You can use any other entity properties in the same way. Workflow data enrichment examples You can use custom variables to enrich your workflow data queries in different ways: Query for when application traffic drops There are times when you want to know when traffic to your application drops. You can use the { { entity.name}} variable in place of your application's name. SELECT count(*) FROM Transaction WHERE appName = '{{entity.name}}' since 10 minutes ago Copy Query for transaction failures There are times when you want to know when your application transactions have failed. This query shows the latest HTTP status code responses filtered by the { { entity.name}} variable that violated your alert policy threshold. From Transaction select latest(httpResponseCode), average(duration) where appName = '{{entity.name}}' Copy Query for Kubernetes consumption overview Use a query like this to get the number of entities and their ingest times within a Kubernetes pod. By identifying what entities have large ingest times, you can begin to address that issue and find a potential remedy. SELECT uniqueCount(displayName), sum(nr.ingestTimeMs) from K8sServiceSample where entityName = '{{entity.name}}' since 1 hour ago. Copy Full variables list by category We'll be updating this table frequently as we make updates to Applied Intelligence. Key Name Display Name alert/account_id alert.account_id Alert Account ID internal alert. * ALL alert/description alert.description Alert Description alert/label_names alert.labels Alert Labels alert/deep_link alert.link Alert Link alert/message alert.message Alert Message alert/policy_name alert.name Alert Name alert/policy_id alert.id Alert Policy ID alert/priority alert.priority Alert Priority alert/state alert.state Alert State internal * ALL internal aws. * ALL internal condition. * ALL newrelic/violation/condition_name condition.name Condition Name newrelic/product condition.product Condition Product newrelic/evaluation/threshold condition.threshold Condition Threshold newrelic/evaluation/threshold_duration_seconds condition.threshold_duration Condition Threshold Duration newrelic/evaluation/threshold_occurrences condition.threshold_occurrences Condition Threshold Occurrences internal entity. * (queries both entity.name and entity.type) ALL newrelic/entity/name entity.name Entity Name newrelic/entity/type entity.type Entity Type newrelic/violation/close_time violation.close_time Violation Close Time internal violation. * ALL newrelic/signal/nrql/query condition.nrql.query Signal NRQL Query newrelic/violation/deep_link_url violation.deep_link_url Violation Deep Link URL newrelic/violation/degradation_time violation.degradation_time Violation Degradation Time newrelic/violation/event violation.event Violation Event Status host/id violation.host.id Violation Host ID host/name violation.host.name Violation Host Name newrelic/violation/id violation.id Violation ID newrelic/violation/muted violation.muted Violation Muted newrelic/violation/open_time violation.open_time Violation Open Time newrelic/violation/priority violation.priority Violation Priority newrelic/violation/recovery_time violation.recovery_time Violation Recovery Time newrelic/violation/runbook_url violation.runbook_url Violation Runbook URL newrelic/violation/time_limit violation.time_limit Violation Time Limit newrelic/violation/title violation.title Violation Title internal workflow.id Workflow Id internal workflow.name Workflow Name",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.98157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Custom variables for <em>Incident</em> <em>Workflows</em>",
        "sections": "Custom variables for <em>Incident</em> <em>Workflows</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>Incident</em> <em>Workflows</em>, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the <em>workflow</em>, and violation attributes are transferred into the notification creation. Custom variables are violation-related properties you can use as part"
      },
      "id": "603e7a6528ccbcad47eba77f"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/expanded-anomaly-detection": [
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.23392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use Incident <em>Intelligence</em>",
        "sections": "Use Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application&#x27;s anomalies page. This is only available for applications that are set up for <em>Proactive</em> <em>Detection</em>. There are two types of deployment events: deployments"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Tip",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Tip To use Incident Intelligence and Applied Intelligence, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Set up Incident Intelligence To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 331.85425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with Incident <em>Intelligence</em>",
        "sections": "Get started with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em> policies, from <em>Alerts</em> &amp; AI, click Sources, then <em>Alerts</em>. Tip Adding anomalies as a source won&#x27;t affect your current <em>Proactive</em> <em>Detection</em> configurations or notifications. AWS You can"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Tip",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-07-02T10:57:50Z",
      "updated_at": "2021-03-30T07:40:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your New Relic APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Tip Proactive Detection is automatically enabled and available at no additional cost. All that's required is data from your APM-monitored applications flowing into New Relic. To signup and take advantage of this and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the Applied Intelligence application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.92596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Proactive</em> <em>Detection</em> with <em>Applied</em> <em>Intelligence</em>",
        "sections": "<em>Proactive</em> <em>Detection</em> with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>Applied</em> <em>Intelligence</em>&#x27;s <em>Proactive</em> <em>Detection</em>, anomalies from your New Relic APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered"
      },
      "id": "603e9d68196a67dc21a83dd2"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence": [
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.23392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use Incident <em>Intelligence</em>",
        "sections": "Use Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application&#x27;s anomalies page. This is only available for applications that are set up for <em>Proactive</em> <em>Detection</em>. There are two types of deployment events: deployments"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Tip",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Tip To use Incident Intelligence and Applied Intelligence, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Set up Incident Intelligence To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 331.85425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with Incident <em>Intelligence</em>",
        "sections": "Get started with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em> policies, from <em>Alerts</em> &amp; AI, click Sources, then <em>Alerts</em>. Tip Adding anomalies as a source won&#x27;t affect your current <em>Proactive</em> <em>Detection</em> configurations or notifications. AWS You can"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Expanded anomaly detection",
        "Requirements",
        "Why it matters",
        "Get started with anomaly detection",
        "Detect anomalies with a faceted NRQL query",
        "See your anomalies in one place",
        "Tip",
        "Query anomaly data",
        "Reduce the number of detected anomalies"
      ],
      "title": "Expanded anomaly detection",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "0b07c0b6ce27f39b5edb3e112a0f949835cbb8c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/expanded-anomaly-detection/",
      "published_at": "2021-07-02T09:44:40Z",
      "updated_at": "2021-05-31T16:43:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We’ve expanded anomaly detection coverage beyond your APM applications. Configure anomaly detection for your browser applications, mobile applications, infrastructure hosts, and nearly anything you want to monitor. Requirements Expanded anomaly detection is available as a limited beta. You can request access here. Why it matters When starting to configure alert conditions for a variety of applications and hosts, it can be difficult to know what you’ll want to be notified about ahead of time. Anomaly detection helps you distinguish between what’s typical performance in your system and where you’re starting to have trouble. Instead of creating your alert conditions manually, you can simply tell us what you want to monitor. Anomaly detection will help you identify baseline performance in your system and flags anomalous activity in your system. Get started with anomaly detection To get started with expanded anomaly detection: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab, and then click + Add a configuration. Select the account you want to use to record anomaly data, then select the workload or entities you’d like to monitor. Select the detection sensitivity. We recommend Low sensitivity so that you don’t see too many anomalies. Finally, name your configuration and save. Detect anomalies with a faceted NRQL query To detect anomalies with a faceted NRQL query: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab, and then click + Add a configuration. Click Use a query instead. You may need to select an account, if you have more than one. Add one or more queries with a FACET clause. Name the query and confirm the facets you want to monitor for anomalies. Select the detection sensitivity. We recommend Low sensitivity so that you don’t see too many anomalies. Finally, name the configuration and save. See your anomalies in one place When you set up anomaly detection, New Relic starts analyzing the golden signals of your entities and workloads. Anomalies appear in your activity feeds throughout New Relic One and the Anomalies tab as soon as they’re detected. Click any anomaly to get more detail about it, including analysis and context for the anomaly. Tip For this limited release, anomaly detection won’t generate notifications. However, you can configure a NRQL alert condition for the NrAiAnomaly event. To view anomalies, from one.newrelic.com, go to Alerts & AI > Issues & activity > Anomalies. Query anomaly data Detected anomalies are written to the NrAiAnomaly event in your NRDB account. You can learn more about this event and how to query it here. Reduce the number of detected anomalies If you’re seeing too many anomalies, the first step is to make sure your sensitivity level is set to Low. If it’s already set to Low, you can define specific thresholds to distinguish between normal and anomalous behavior. To define custom thresholds: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab and the configuration you want to modify. Select an entity or workload, and then change the sensitivity level. You can use custom sensitivity to define specific thresholds for different entity types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 279.53732,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Expanded anomaly <em>detection</em>",
        "sections": "Expanded anomaly <em>detection</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the <em>detection</em> sensitivity. We recommend Low sensitivity so that you don’t see too many anomalies. Finally, name your configuration and save. <em>Detect</em> anomalies with a faceted NRQL query To <em>detect</em> anomalies with a faceted NRQL query: From one.newrelic.com, go to <em>Alerts</em> &amp; AI &gt; <em>Proactive</em> <em>Detection</em>"
      },
      "id": "60b5124064441ff965e2cb01"
    }
  ],
  "/docs/alerts-applied-intelligence/index": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Tip",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Tip To use Incident Intelligence and Applied Intelligence, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Set up Incident Intelligence To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2029.8933,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with Incident <em>Intelligence</em>",
        "sections": "Get started with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em> policies, from <em>Alerts</em> &amp; AI, click Sources, then <em>Alerts</em>. Tip Adding anomalies as a source won&#x27;t affect your current Proactive Detection configurations or notifications. AWS You can"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2029.8933,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use Incident <em>Intelligence</em>",
        "sections": "Use Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your incident notification tools, Incident <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1751.0869,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/alert-custom-violation-descriptions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.8683,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.9369,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> <em>conditions</em>: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.42685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL <em>conditions</em>. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/apm-metric-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.8683,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.9369,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> <em>conditions</em>: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.42685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL <em>conditions</em>. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.8681,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.9367,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> <em>conditions</em>: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.4267,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL <em>conditions</em>. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-baseline-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.8681,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.9367,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> <em>conditions</em>: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.4267,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL <em>conditions</em>. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions": [
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.93652,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> <em>conditions</em>: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.4265,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL <em>conditions</em>. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "a144b0cc3c5eed1c31dbfcd079959bbd5496346a",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-baseline-alert-conditions/",
      "published_at": "2021-07-02T10:57:50Z",
      "updated_at": "2021-06-25T18:59:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.93817,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> <em>conditions</em>",
        "sections": "Create baseline <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> <em>conditions</em> give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6044095ee7b9d214955799e9"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/define-custom-metrics-alert-condition": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.86792,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.93652,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> <em>conditions</em>: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.4265,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL <em>conditions</em>. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/multi-location-synthetic-monitoring-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.86774,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.9363,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> <em>conditions</em>: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.42636,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL <em>conditions</em>. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/outlier-detection-nrql-alert": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.86774,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.9363,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> <em>conditions</em>: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.42636,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL <em>conditions</em>. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/provide-runbook-instructions-alert-activity": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.86755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.93613,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> <em>conditions</em>: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.4262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL <em>conditions</em>. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/scope-alert-thresholds-specific-instances": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.86755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.93613,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> <em>conditions</em>: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.4262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL <em>conditions</em>. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/select-product-targets-alert-condition": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.86737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.93594,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> <em>conditions</em>: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.42603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL <em>conditions</em>. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/set-thresholds-alert-condition": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.86737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.93594,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> <em>conditions</em>: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.42603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL <em>conditions</em>. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/view-entity-health-status-find-entities-without-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.8672,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.93576,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> <em>conditions</em>: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.42584,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL <em>conditions</em>. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-incidents/acknowledge-alert-incidents": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.66806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.65723,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.06004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-incidents/view-events-their-products": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.66792,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.6571,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.0599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-incidents/view-violation-event-details-incidents": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.66792,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.6571,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.0599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/customize-your-webhook-payload": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.40897,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the list of user names and emails: Go to one.newrelic.com, in the top nav click <em>Alerts</em> &amp; AI, then click Notification channels. In the search field, search for &#x27;user&#x27;. Add or update user channels Users can&#x27;t unsubscribe from <em>alerts</em> email <em>notifications</em>. The account Owner or Admin must remove them from"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.67184,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.13359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/delete-alert-notification-channels": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.40878,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the list of user names and emails: Go to one.newrelic.com, in the top nav click <em>Alerts</em> &amp; AI, then click Notification channels. In the search field, search for &#x27;user&#x27;. Add or update user channels Users can&#x27;t unsubscribe from <em>alerts</em> email <em>notifications</em>. The account Owner or Admin must remove them from"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.67174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.13348,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/muting-rules-suppress-notifications": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.40878,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the list of user names and emails: Go to one.newrelic.com, in the top nav click <em>Alerts</em> &amp; AI, then click Notification channels. In the search field, search for &#x27;user&#x27;. Add or update user channels Users can&#x27;t unsubscribe from <em>alerts</em> email <em>notifications</em>. The account Owner or Admin must remove them from"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.67174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.13348,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/notification-channels-control-where-send-alerts": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.4086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the list of user names and emails: Go to one.newrelic.com, in the top nav click <em>Alerts</em> &amp; AI, then click Notification channels. In the search field, search for &#x27;user&#x27;. Add or update user channels Users can&#x27;t unsubscribe from <em>alerts</em> email <em>notifications</em>. The account Owner or Admin must remove them from"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.67162,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.13336,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/test-alert-notification-channels": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.4086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the list of user names and emails: Go to one.newrelic.com, in the top nav click <em>Alerts</em> &amp; AI, then click Notification channels. In the search field, search for &#x27;user&#x27;. Add or update user channels Users can&#x27;t unsubscribe from <em>alerts</em> email <em>notifications</em>. The account Owner or Admin must remove them from"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.67162,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.13336,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/update-alert-notification-channels": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.40845,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the list of user names and emails: Go to one.newrelic.com, in the top nav click <em>Alerts</em> &amp; AI, then click Notification channels. In the search field, search for &#x27;user&#x27;. Add or update user channels Users can&#x27;t unsubscribe from <em>alerts</em> email <em>notifications</em>. The account Owner or Admin must remove them from"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.67151,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.13324,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.67151,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.13324,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.68118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> conditions: Condition"
      },
      "id": "60442974196a678217960f33"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/create-edit-or-find-alert-policy": [
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.78094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> <em>policies</em>: <em>Alert</em> policy name 1 character 64 characters <em>Policies</em> per account n&#x2F;a 10000 <em>policies</em> Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> conditions: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.6674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the policy&#x27;s notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click <em>Alerts</em> &amp; AI, click <em>Policies</em>, and then choose the policy you want to change. Optional: You can update notification channels for specific users"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.65659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click <em>Policies</em>. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/specify-when-alerts-create-incidents": [
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.78094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> <em>policies</em>: <em>Alert</em> policy name 1 character 64 characters <em>Policies</em> per account n&#x2F;a 10000 <em>policies</em> Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> conditions: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.6674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the policy&#x27;s notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click <em>Alerts</em> &amp; AI, click <em>Policies</em>, and then choose the policy you want to change. Optional: You can update notification channels for specific users"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.65659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click <em>Policies</em>. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions": [
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.78076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> <em>policies</em>: <em>Alert</em> policy name 1 character 64 characters <em>Policies</em> per account n&#x2F;a 10000 <em>policies</em> Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> conditions: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.66727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the policy&#x27;s notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click <em>Alerts</em> &amp; AI, click <em>Policies</em>, and then choose the policy you want to change. Optional: You can update notification channels for specific users"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.65646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click <em>Policies</em>. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/view-policies-conditions-our-products": [
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.78076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> <em>policies</em>: <em>Alert</em> policy name 1 character 64 characters <em>Policies</em> per account n&#x2F;a 10000 <em>policies</em> Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> conditions: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.66727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the policy&#x27;s notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click <em>Alerts</em> &amp; AI, click <em>Policies</em>, and then choose the policy you want to change. Optional: You can update notification channels for specific users"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.65646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click <em>Policies</em>. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed": [
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.72693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> conditions: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.66727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.65646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/view-alert-violations-our-products": [
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.72675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> conditions: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.66714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.65633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/violation-event-attributes": [
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "a5154d652daafb8177c0427198c2df1fc4bf1125",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/rules-limits-glossary/rules-limits-alerts/",
      "published_at": "2021-07-02T09:24:54Z",
      "updated_at": "2021-07-02T09:24:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, Mobile, Synthetics, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.72675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, Mobile, Synthetics, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em> conditions: Condition"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.66714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.65633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alerts-nerdgraph/nerdgraph-api-alerts-policies": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.66702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.65619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.059,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alerts-nerdgraph/nerdgraph-api-examples": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.66702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.65619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.059,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.66689,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.65607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.05887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.66689,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.65607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " For more information on signal loss, see <em>NerdGraph</em> API: Loss of signal and gap filling. Nested queries containing &#x27;WITH METRIC_FORMAT&#x27; in the inner query are not currently supported You can&#x27;t use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL <em>alert</em> conditions. NRQL"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.05887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.66675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.65593,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.05875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/get-started/alerts-ai-overview-page": [
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.9689,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    },
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.68054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.67079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/get-started/alerts-concepts-workflow": [
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.9689,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    },
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.68054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.67079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-alerts": [
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.96875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    },
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.68042,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.67068,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence": [
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.96875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    },
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.68042,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.67068,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.68031,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.67056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-07-02T09:43:24Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.95975,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use Incident <em>Intelligence</em>",
        "sections": "Use Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or <em>New</em> <em>Relic</em> <em>alerts</em> violations as your incident notification tools, Incident <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/rest-api-alerts/alerts-conditions-api-field-names": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.68031,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.67056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.13231,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/rest-api-alerts/disable-enable-alerts-conditions-using-api": [
    {
      "sections": [
        "View or update user email channels",
        "View account email channels",
        "Add or update user channels"
      ],
      "title": "View or update user email channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "e8cf8c9003d35a35ced0c4e55fa3127cda811757",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/view-or-update-user-email-channels/",
      "published_at": "2021-07-02T09:47:32Z",
      "updated_at": "2021-07-02T09:47:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update user channels Users can't unsubscribe from alerts email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.6802,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. View account email channels To view or search"
      },
      "id": "6043fc8064441f080f378ef6"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-07-02T09:46:09Z",
      "updated_at": "2021-07-02T09:46:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation . These control how loss of signal violations will be handled for the condition. Newly opened lost signal violations will close immediately when new data is evaluated. Make sure you name your condition before you save it. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is the preferred API but if you are using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.67044,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Tip",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Streaming alerts tools",
        "Loss of signal detection",
        "Gap filling",
        "Aggregation window",
        "Offset evaluation"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "1e971c3a992c0fed2c73d582fa78ee61dd369cbb",
      "image": "https://docs.newrelic.com/static/645db5809686be52fdc9e95f24f05ea6/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-07-02T08:29:23Z",
      "updated_at": "2021-07-02T08:29:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in the stream of data coming into New Relic. The stream of data that comes into New Relic is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL condition alerts are processed by the streaming algorithm. The NRQL query provides the signal filter for all of your incoming data. Tip You can read more about the streaming alerts platform in this Explorers Hub post. Why it matters Alerts violations are easy when they're caused by a specific event happening, but trickier when looking for events not happening. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional offset delay allows for slower data to come through before it's processed. Once the aggregation window plus the offset time have elapsed, New Relic groups the aggregated data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation isn't triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation window A specific amount of time when the filtered data (or its absence) can accumulate in this window. Evaluation offset A time delay to ensure data points are placed in the correct aggregation window. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Streaming alerts tools Streaming alerts provide a set of tools you can use to more effectively alert on your streaming data, giving you greater control and reducing the number of false alerts notifications. They are: Loss of signal detection Gap filling Aggregation window duration customization Offset evaluation Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Aggregation window In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before using the aggregation function to evaluate the data. A longer aggregation window gives straggling data points more time to arrive before evaluating that data. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 1 second and 15 minutes. The default is 1 minute. Offset evaluation For data that consistently takes longer to arrive, you can use offset evaluation to consistently delay the NRQL condition evaluation. Waiting longer increases accuracy, but also increases latency. The offset time value is the number of aggregation windows you want to use. The duration for each window is set in the Aggregation window field. For example, if your aggregation window is 1 minute and your Offset evaluation is 3, then a straggling data point will have about 3 minutes to arrive before it might be dropped. In other words, streaming alerts will always keep 3 aggregation windows in the queue, waiting 1 minute before evaluating each window and adding a new one. The current default is 3.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.1322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in the stream of data coming into <em>New</em> <em>Relic</em>. The stream of data that comes into <em>New</em> <em>Relic</em> is called a signal. You can control what part of the signal is alerted on through NRQL conditions. These NRQL"
      },
      "id": "604427ca28ccbc87142c60a5"
    }
  ]
}