{
  "/docs/style-guide/processes-procedures/embed-images": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-06-14T18:15:23Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.05603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and <em>style</em> of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-06-14T18:13:18Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.84404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or Docs site contributor"
      },
      "id": "604220b2196a6775f5a83dc0"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-06-14T19:13:57Z",
      "updated_at": "2021-03-16T14:19:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based on its filename and filepath in the GitHub repository. For example, this is the filename and path for Rename or redirect a document: /docs/style-guide/processes-procedures/rename-or-redirect-document.mdx Copy The URL is: https://docs.newrelic.com/style-guide/processes-procedures/rename-or-redirect-document Copy If you rename a document's filename or change its path by moving it to a new directory, make sure to add a redirect to its old filepath. To change the document's location in the left navigation, update the navigation configuration file. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update the title in the left navigation, edit the yml file for the section that you're in. For example, the Style guide docs use /src/nav/style-guide.yml. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.98468,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " a document: &#x2F;docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-<em>procedures</em>&#x2F;rename-or-redirect-document.mdx Copy The URL is: https:&#x2F;&#x2F;docs.newrelic.com&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-<em>procedures</em>&#x2F;rename-or-redirect-document Copy If you rename a document&#x27;s filename or change its path by moving it to a new directory, make sure to add"
      },
      "id": "604220ec196a670d0ba83dd4"
    }
  ],
  "/docs/style-guide/processes-procedures/embed-videos": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-06-14T18:15:23Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.05603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and <em>style</em> of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-06-14T18:13:18Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.75829,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures you would use the docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures&#x2F;images directory. If the images directory does"
      },
      "id": "604220ec196a67105da83dc2"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-06-14T18:13:18Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.84404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or Docs site contributor"
      },
      "id": "604220b2196a6775f5a83dc0"
    }
  ],
  "/docs/style-guide/processes-procedures/include-a-doc-in-multiple-menus": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/five-questions-help-write-docs/",
      "sections": [
        "Five questions to help write docs",
        "There's really only 1Q",
        "5Qs and sub-questions",
        "1. Did you use or observe the thing you are writing about?",
        "2. Is this the best place to put this information?",
        "3. Can readers tell in ten seconds if they are in the right place?",
        "4. Is the information in the best possible format?",
        "5. Is the language approachable, expert, and visionary?"
      ],
      "published_at": "2021-06-14T18:19:44Z",
      "title": "Five questions to help write docs",
      "updated_at": "2021-06-14T18:19:44Z",
      "type": "docs",
      "external_id": "14fd5c4efd0e8aa26e04d97ae61da33eef9489ee",
      "document_type": "page",
      "popularity": 1,
      "body": "Our five questions form the core of how our Tech Docs team thinks about writing excellent technical documentation. Informally, we call these our 5Qs. Anyone can contribute to our Docs site. We want you to feel confident and proud that your contributions provide valuable content and quality. We also want our readers to trust and easily use the information in our docs. To help you plan, write, and edit excellent docs, ask yourself the questions in this doc. There's really only 1Q The 5Qs exist to help answer one question. Whenever you write a doc, ask yourself: What problem are we trying to solve? It's critical you know what you're trying to do and why that goal matters to your readers. Asking the five questions (and the sub-questions!) will help you ensure you're building the right thing. 5Qs and sub-questions Each of the five questions includes sub-questions to help guide your thinking. 1. Did you use or observe the thing you are writing about? Think about who your audience is and the level of complexity they need. End users' point of view Ask yourself: Audience Do you know who is reading your document (dev/ops teams, support personnel, non-technical staff, etc.)? Can you articulate what this thing is (feature, procedure) and why it matters to our customers? For conceptual info, did you interview multiple stakeholders? Testing Put yourself in the user's shoes. For example: Did you use the thing on your own? Did you watch a subject matter expert use the thing? If you can't do it on your own or observe, did you send the draft to at least three SMEs? Before publishing Did you compare the final version of your text against the thing you're writing about? 2. Is this the best place to put this information? Think about where this information belongs. Where does this information belong? Ask yourself: What problem are you trying to solve? Is text always the best answer? Does this doc need to exist at all? For example: Are we duplicating content from somewhere else in the Docs site? Are we duplicating content already in the UI? Could customers have a better experience if we modified the UI design or copy instead of creating a doc? Would another web property be a better home for this information? For example: The Explorers Hub? NRU course? NRU video embedded into the doc? The public New Relic blog? The public New Relic website? 3. Can readers tell in ten seconds if they are in the right place? Think about what the content is and what you can do to make the information easy to skim to find information. Can users skim to find information? Ask yourself: Title and headings Does the title accurately represent what's in the doc? Do the headings accurately represent what's in the doc? Do the title and headings use words the way your readers do? Do the title and headings avoid New Relic jargon? Structure Does the overall structure of the doc help readers find what they're looking for? Is the doc trying to address too many topics? When you glance at the doc, do you see short paragraphs, short sentences, and other visual aids? Or do you see a dense wall of text? Introduction Does the intro give a concise synopsis of what's in the doc? Does the intro give readers an alternate path if they're in the wrong place? 4. Is the information in the best possible format? Think about how to present the information visually. Presentation of information Ask yourself: Visual formats Did you use visual formats appropriately? Would a screenshot make any of the information easier to understand? Does your image caption clearly explain what matters so that the user does not necessarily even need to read the surrounding text? Would a diagram make any of the information easier to understand? Is there a video we could embed to make things clearer? Can step-by-step UI procedures be replaced with a \"show me\" video? Procedures Are your procedures well-structured? Do step-by-step UI procedures even need to be documented? Did you limit the procedural text to action steps and omit detailed explanatory text or edge cases? If detailed explanations need to enhance a procedure, have you organized the info in a way that expert users can skip the details? Text flow Read your draft more than once. Is the documentation direct and to the point? Did you use bullets, tables, or clamshells to improve flow? 5. Is the language approachable, expert, and visionary? Think about why the information matters and why readers will trust and use it. For tips to make it easier for users to read, understand, and use documentation, go to plainlanguage.gov. Also, if you are a New Relic employee, we encourage you to review the corporate brand guidelines. For more information, contact Marketing. Effective language Ask yourself: Readers' point of view Did you tell users why as well as how? Can you articulate not only what this thing is (feature, procedure) and also why it matters to our customers? Did you include useful examples or use cases? Did you include information about relationships this feature has to other New Relic platform tools? Style guide resources Did you follow our style guide? Did you use our edit checklist? Did you use pronouns, contractions, and a conversational tone throughout? Did you review the usage dictionary and other resources in the style guide to make sure that terms are used correctly? Readability Is the text easy to read? Is the language clear? Do you have to reread any sentences or paragraphs to understand them? If so, can you simplify the wording and sentence structure? Does the doc score 40 or better on the Flesch-Kinkaid reading ease scale? If not, try taking another pass at the prose. But don't chase the Flesch-Kincaid score in itself: we're not out to frustrate ourselves, but to write docs that are a pleasure to read. Where to go from here Did you offer readers a clear \"next step\" in each section? If it is necessary to tell a user not to do something, did you also tell them what to do instead? Is the topic complete? Is the doc actionable?",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.564575,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Five questions to help write <em>docs</em>",
        "sections": "3. Can readers tell <em>in</em> ten seconds if they <em>are</em> <em>in</em> the right place?",
        "body": " want our readers to trust and easily use the information in our docs. To help you plan, write, and edit excellent docs, ask yourself the questions in this <em>doc</em>. There&#x27;s really only 1Q The 5Qs exist to help answer one question. Whenever you write a <em>doc</em>, ask yourself: What problem are we trying"
      },
      "id": "60421ef3196a676926a83d81"
    },
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-14T18:17:04Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.554955,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A <em>multiple</em>-step procedure may be an ordered list. And for something buried"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "ba7c99eb79d6fa7ad574db5768a742a4d2084a41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-06-14T18:12:27Z",
      "updated_at": "2021-05-10T03:34:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.70631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting <em>docs</em> guide",
        "sections": "Troubleshooting <em>docs</em> guide",
        "tags": "<em>Article</em> templates",
        "body": " the user is trying to solve. <em>Include</em> steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this <em>doc</em> via Google. If the problem text is very short, you can <em>include</em> the cause text here. Solution Generally"
      },
      "id": "6043f591196a675446960f74"
    }
  ],
  "/docs/style-guide/processes-procedures/rename-or-redirect-document": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-06-14T18:15:23Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.05603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and <em>style</em> of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-06-14T18:13:18Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.75829,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures you would use the docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures&#x2F;images directory. If the images directory does"
      },
      "id": "604220ec196a67105da83dc2"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-06-14T18:13:18Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.84404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or Docs site contributor"
      },
      "id": "604220b2196a6775f5a83dc0"
    }
  ],
  "/docs/style-guide/processes-procedures/update-left-navigation-pane": [
    {
      "sections": [
        "Monitor services running on Amazon ECS",
        "Requirements",
        "How to enable",
        "Step 1: Enable EC2 to install the infrastructure agent",
        "For CentOS 6, RHEL 6, Amazon Linux 1",
        "CentOS 7, RHEL 7, Amazon Linux 2",
        "Step 2: Enable monitoring of services"
      ],
      "title": "Monitor services running on Amazon ECS",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "dc178f5c162c1979019d97819db2cc77e0ce220a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs/",
      "published_at": "2021-06-15T11:57:52Z",
      "updated_at": "2021-06-15T11:57:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have services that run on Docker containers in Amazon ECS (like Cassandra, Redis, MySQL, and other supported services), you can use New Relic to report data from those services, from the host, and from the containers. Requirements To monitor services running on ECS, you must meet these requirements: An auto-scaling ECS cluster running Amazon Linux, CentOS, or RHEL that meets the infrastructure agent compatibility and requirements. ECS tasks must have network mode set to none or bridge (awsvpc and host not supported). A supported service running on ECS that meets our integration requirements: Apache (does not report inventory data) Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ (does not report inventory data) Redis SNMP How to enable Before explaining how to enable monitoring of services running in ECS, here's an overview of the process: Enable Amazon EC2 to install our infrastructure agent on your ECS clusters. Enable monitoring of services using a service-specific configuration file. Step 1: Enable EC2 to install the infrastructure agent First, you must enable Amazon EC2 to install our infrastructure agent on ECS clusters. To do this, you'll first need to update your user data to install the infrastructure agent on launch. Here are instructions for changing EC2 launch configuration (taken from Amazon EC2 documentation): Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. Replace user data with one of the following snippets: For CentOS 6, RHEL 6, Amazon Linux 1 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy CentOS 7, RHEL 7, Amazon Linux 2 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_ECS_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop-down menu for Launch configuration, select the new launch configuration created. Click Save. To test if the agent is automatically detecting instances, terminate an EC2 instance in the auto scaling group: the replacement instance will now be launched with the new user data. After five minutes, you should see data from the new host on the Hosts page. Next, move on to enabling the monitoring of services. Step 2: Enable monitoring of services Once you've enabled EC2 to run the infrastructure agent, the agent starts monitoring the containers running on that host. Next, we'll explain how to monitor services deployed on ECS. For example, you can monitor an ECS task containing an NGINX instance that sits in front of your application server. Here's a brief overview of how you'd monitor a supported service deployed on ECS: Create a YAML configuration file for the service you want to monitor. This will eventually be placed in the EC2 user data section via the AWS console. But before doing that, you can test that the config is working by placing that file in the infrastructure agent folder (etc/newrelic-infra/integrations.d) in EC2. That config file must use our container auto-discovery format, which allows it to automatically find containers. The exact config options will depend on the specific integration. Check to see that data from the service is being reported to New Relic. If you are satisfied with the data you see, you can then use the EC2 console to add that configuration to the appropriate launch configuration, in the write_files section, and then update the auto scaling group. In the runcmd section, add the yum command to install the integration to the appropriate launch configuration. Here's a detailed example of doing the above procedure for NGINX: Ensure you have SSH access to the server or access to AWS Systems Manager Session Manager. Log in to the host running the infrastructure agent. Via the command line, change the directory to the integrations configuration folder: cd /etc/newrelic-infra/integrations.d Copy Create a file called nginx-config.yml and add the following snippet: --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 Copy This configuration causes the infrastructure agent to look for containers in ECS that contain nginx. Once a container matches, it then connects to the NGINX status page. For details on how the discovery.ip snippet works, see auto-discovery. For details on general NGINX configuration, see the NGINX integration. If your NGINX status page is set to serve requests from the STATUS_URL on port 80, the infrastructure agent starts monitoring it. After five minutes, verify that NGINX data is appearing in the Infrastructure UI (either: one.newrelic.com > Infrastructure > Third party services, or one.newrelic.com > Explorer > On-host). If the configuration works, place it in the EC2 launch configuration: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. In the User data section, edit the write_files section (in the part marked text/cloud-config). Add a new file/content entry: - content: | --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 path: /etc/newrelic-infra/integrations.d/nginx-config.yml Copy Also edit the runcmd section to include the yum command to install nri-nginx: runcmd: - [ yum, install, newrelic-infra, -y ] - [ yum, install, nri-nginx, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop down menu for Launch configuration, select the new launch configuration created. Click Save. When an EC2 instance is terminated, it is replaced with a new one that automatically looks for new NGINX containers.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.68097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " agent on ECS clusters. To do this, you&#x27;ll first need to <em>update</em> your user data to install the infrastructure agent on launch. Here are instructions for changing EC2 launch configuration (taken from Amazon EC2 documentation): Open the Amazon EC2 console. On the <em>navigation</em> <em>pane</em>, under Auto scaling"
      },
      "id": "60450959e7b9d2475c579a0f"
    },
    {
      "sections": [
        "OneLogin SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Create authentication domain and enable SCIM",
        "Step 2. Set up OneLogin's New Relic app",
        "Step 3. Configure SCIM/SSO application",
        "Fill in the configuration form",
        "Fill in the rules form",
        "A rule that only uses actions",
        "Fill in the provisioning form",
        "Tip",
        "Fill in the Parameters form",
        "Save your changes",
        "Step 4. Assign users",
        "Step 5. Downgrade some users to basic",
        "Step 6. Assign access grants",
        "Step 7. Configure SAML SSO"
      ],
      "title": "OneLogin SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "d298162c055490c99117f564c3ea9c2ea5dfd8d1",
      "image": "https://docs.newrelic.com/static/8f585557ea58f70d94a746e6439bf1ad/c1b63/onelogin_rules_conditions_actions.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/onelogin-scimsso-application-configuration/",
      "published_at": "2021-06-14T19:29:45Z",
      "updated_at": "2021-06-14T19:29:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides OneLogin-specific details on how to configure the New Relic OneLogin SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create authentication domain and enable SCIM To get to the New Relic authentication domain UI: from the account dropdown, click Organization and access, and then click Authentication domains. If you don't already have one, create a new authentication domain to be used for your SCIM-provisioned users. Under Source of users, enable SCIM. Step 2. Set up OneLogin's New Relic app Add the New Relic SCIM/SSO application to your OneLogin applications: Go to the OneLogin web site and sign in with an account that has administrator permissions. From the OneLogin home page, click on Administration. From the OneLogin Administration page, choose the Applications menu. From the OneLogin Applications page, click on Add App. In the search field on the OneLogin Find Applications page, enter \"New Relic by organization\" (not \"New Relic by account\") and then click on the application when it shows in the search results. From the Add New Relic by Organization page, click on Save. Step 3. Configure SCIM/SSO application Configuration for the New Relic SCIM/SSO application is split across several forms. This section describes the different forms that need to be configured. From the New Relic by organization application page, fill in the following forms: Fill in the configuration form In the left pane, select Configuration and complete the following: Get the authentication domain ID (top of New Relic's authentication domain UI and SCIM bearer token (in authentication domain UI as \"SAML 2.0 endpoint) and input them into the appropriate fields in the OneLogin app. Leave the API Connection disabled until all the configuration described in the following sections is completed. After completing all the configuration, enable the connection. Fill in the rules form Configure the user groups to send to New Relic using rules. OneLogin provides this documentation which describes how to use rules to provision groups for users. Decide what type of groups to send along with your users to New Relic. If your organization is using Active Directory or LDAP, you might choose to use security groups to define your users capabilities at New Relic. Another reasonable group choice is OneLogin role. On the New Relic side, your user's groups define their capabilities. The groups that are sent with users will be mapped to New Relic capability groups. Note that at the moment, there is no way to delete a group from the OneLogin side. This is a known limitation from OneLogin. Removing or changing rules does not delete groups already sent to New Relic. If you wish to no longer use a group, removing all the users from the group will prevent it from being used at New Relic. A rule that only uses actions Here's an example rule configuration does not use any conditions. The conditions are left empty to avoid applying any filtering logic to the users. All users will be sent in this example. If you want to send only a subset of users, you need to specify conditions to select the subset. The actions describe where to retrieve the value for the group name and how to parse the value. In this example, we retrieve the group name from the OneLogin role field. The OneLogin role field only has a single value, but sometimes the source for the group name contains other fields besides group name. In other words, some sources give you a list of fields and values and only one of those fields has the value you want to use. In this case, you can insert a regular expression in with value that matches field to find and extract the value for the group name. This example uses the entire value of the For each field for the group name. Fill in the provisioning form In the left pane, select Provisioning and complete the following: Check Enable provisioning. Under Require admin approval before this action is performed, uncheck these options: Create user Delete user Update user Tip If you do not uncheck these options, SCIM provisioning requests will not be sent until an administrator approves them. Set When users are deleted in OneLogin, or the user's app access is removed, perform the below action to Delete. Set When user accounts are suspended in OneLogin, perform the following action to Suspend. Fill in the Parameters form In the left pane, select Parameters and complete the following: Click Groups field. Check Include in User Provisioning. Click Save. Save your changes After you complete the above forms, click Save. Then, return to the Configuration form and enable the API connection. Step 4. Assign users After New Relic SCIM/SSO application configuration is finished and New Relic side configuration is finished, you can begin to assign users to the application. Assign the New Relic SCIM/SSO application to a user: Go to the OneLogin web site and sign in with an account that has administrator permissions. From the OneLogin home page, click Administration. From the OneLogin Administration page, choose the Users menu Users item. From the OneLogin Users page, click the user you want to assign the application to. From the user's page, click Applications. From the user's application page, click the plus sign and select the \"New Relic by Organization\" application. Important: Updating users' time zones is important, as charts and other user assets display times. Default is UMT. From the Edit New Relic by Organization login for user page, enter the user's time zone in IANA Time Zone database format (also known as the Olson time zone database format) and click Save. If you're using Roles to define your New Relic capability groups, from the user's application page, click the proper role(s) for the user and then click Save User. Step 5. Downgrade some users to basic When your users are provisioned in New Relic, you should be able to see them in the User management UI. Users provisioned via your identity provider start out as full users. If your organization is on New Relic One pricing, these users are billable. To convert users to free basic users, use the User management UI. Step 6. Assign access grants Once your users are in New Relic, you need to grant them access to specific New Relic accounts, specific groups, and specific roles. Without doing this, your users have no access to New Relic accounts. To learn how to do this, see: How access grants work The user management tutorial Step 7. Configure SAML SSO To enable SAML SSO for your users, see the SAML instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.44894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " across several forms. This section describes the different forms that need to be configured. From the New Relic by organization application page, fill in the following forms: Fill in the configuration form In the <em>left</em> <em>pane</em>, select Configuration and complete the following: Get the authentication"
      },
      "id": "6043f34228ccbccafb2c606a"
    },
    {
      "sections": [
        "Azure AD SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Create authentication domain and enable SCIM",
        "Step 2. Set up Azure's New Relic app",
        "Step 3. Configure connection",
        "Step 4. Configure provisioning rules",
        "Tip",
        "Step 5. Downgrade some users to basic",
        "Step 6. Assign access grants",
        "Step 7. Configure SAML SSO"
      ],
      "title": "Azure AD SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "d6e7f7e95daa833451159a3db4e2c4257270b5e9",
      "image": "https://docs.newrelic.com/static/0a9a32fd5041e6e2ea37cc5f032b6910/8c557/Azure_AD_Provisioning_Attribute_Mapping_2_0.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/azure-ad-scimsso-application-configuration/",
      "published_at": "2021-06-14T19:28:16Z",
      "updated_at": "2021-06-14T19:28:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Azure AD-specific details on how to configure the New Relic Azure AD SCIM/SSO application. Requirements Before using this guide, read the requirements and procedure overview. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create authentication domain and enable SCIM To get to the New Relic authentication domain UI: from the account dropdown, click Organization and access, and then click Authentication domains. If you don't already have one, create a new authentication domain to be used for your SCIM-provisioned users. Under Source of users, enable SCIM. Step 2. Set up Azure's New Relic app Azure AD provides an application gallery, which includes various integrations for Azure AD, including the ones that New Relic offers. Add the New Relic SCIM/SSO application to your list of applications. Go to the Azure Active Directory admin center, and sign in if necessary. aad.portal.azure.com/ Click on All services in the left hand menu. In the main pane, click on Enterprise applications. Click on +New Application. Find our SCIM/SSO application by entering New Relic in the name search box, and click on the application New Relic by organization (not New Relic by account). Click on Add. Step 3. Configure connection Configure the New Relic SCIM/SSO application to automatically provision your users to New Relic. From the New Relic SCIM/SSO application page, click on the Provisioning link in the sidebar. In the main pane, click on Get started. In the Provisioning Mode pick-list, choose Automatic. In New Relic's authentication domain UI, set up a new domain with SCIM enabled. In Azure AD's New Relic SCIM/SSO app, in the Admin credentials section, fill out the Tenant URL and Secret token fields with the values provided in New Relic's authentication domain UI. To verify you can connect to New Relic, click Test Connection. When you see a message indicating verification success, click Save. The New Relic SCIM/SSO application can now connect with New Relic. Continue with the following section to configure the provisioning rules. Step 4. Configure provisioning rules Initially, nothing is configured to be sent to New Relic. You must configure Azure AD to send changes for user creation, updates, and deactivation. Go to the Provisioning page and complete the following: Expand the Mappings section. Click Provision Azure Active Directory Users. Verify the Target Object Actions Create Update and Delete checkboxes are all checked. Verify the Attribute Mappings look correct for your environment. Each of the New Relic attributes shown in the list must receive a value. Tip Ensure that the Azure Active Directory attributes shown in the list on the left are good sources for the information to send to New Relic. In particular, not all environments set the mail attribute. If your environment does not set the mail attribute, userPrincipalName could be a good alternative. Leave the switch for Enabled set to Off until you're done with the user and group configuration in the next section. Once all configuration is ready, return to this page and set the switch to On. Click Save. Here's an example of a filled-in attribute mapping page with the default values. Your values may be configured differently depending on your situation. After saving the provisioning rules, the New Relic SCIM/SSO application is ready to provision any changes made to users assigned to the application. Continue with the following section to assign users and groups to the New Relic SCIM/SSO application. Step 5. Downgrade some users to basic When your users are provisioned in New Relic, you should be able to see them in the User management UI. Users provisioned via your identity provider start out as full users. If your organization is on New Relic One pricing, these users are billable. To convert users to free basic users, use the User management UI. Step 6. Assign access grants Once your users are in New Relic, you need to grant them access to specific New Relic accounts, specific groups, and specific roles. Without doing this, your users have no access to New Relic accounts. To learn how to do this, see: How access grants work The user management tutorial Step 7. Configure SAML SSO To enable SAML SSO for your users, see the SAML instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.64182,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " for Azure AD, including the ones that New Relic offers. Add the New Relic SCIM&#x2F;SSO application to your list of applications. Go to the Azure Active Directory admin center, and sign in if necessary. aad.portal.azure.com&#x2F; Click on All services in the <em>left</em> hand menu. In the main <em>pane</em>, click on Enterprise"
      },
      "id": "6043f5c964441fcfb0378ef3"
    }
  ],
  "/docs/style-guide/processes-procedures/use-content-types-text-formats": [
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-06-14T18:13:18Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.75827,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures you would use the docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures&#x2F;images directory. If the images directory does"
      },
      "id": "604220ec196a67105da83dc2"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-06-14T18:13:18Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.84402,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or Docs site contributor"
      },
      "id": "604220b2196a6775f5a83dc0"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-06-14T19:13:57Z",
      "updated_at": "2021-03-16T14:19:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based on its filename and filepath in the GitHub repository. For example, this is the filename and path for Rename or redirect a document: /docs/style-guide/processes-procedures/rename-or-redirect-document.mdx Copy The URL is: https://docs.newrelic.com/style-guide/processes-procedures/rename-or-redirect-document Copy If you rename a document's filename or change its path by moving it to a new directory, make sure to add a redirect to its old filepath. To change the document's location in the left navigation, update the navigation configuration file. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update the title in the left navigation, edit the yml file for the section that you're in. For example, the Style guide docs use /src/nav/style-guide.yml. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.98466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " a document: &#x2F;docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-<em>procedures</em>&#x2F;rename-or-redirect-document.mdx Copy The URL is: https:&#x2F;&#x2F;docs.newrelic.com&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-<em>procedures</em>&#x2F;rename-or-redirect-document Copy If you rename a document&#x27;s filename or change its path by moving it to a new directory, make sure to add"
      },
      "id": "604220ec196a670d0ba83dd4"
    }
  ],
  "/docs/style-guide/quick-reference/bold-or-code-not-italics": [
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-14T18:17:04Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 346.86737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-14T19:15:01Z",
      "updated_at": "2021-05-28T02:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.06146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ". If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-14T19:16:07Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.32764,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    }
  ],
  "/docs/style-guide/quick-reference/callouts": [
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-14T18:17:04Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 346.86737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-14T19:15:01Z",
      "updated_at": "2021-05-28T02:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.06146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ". If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-14T19:16:07Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.32764,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    }
  ],
  "/docs/style-guide/quick-reference/capitalization": [
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-14T18:17:04Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 346.8673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-14T19:16:07Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.32764,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    },
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-06-14T18:18:03Z",
      "updated_at": "2021-05-06T04:01:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right-click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also mouse over. collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account The primary account in a New Relic account with sub-accounts. Refer to a master's subordinate accounts as sub-accounts, not children or slaves. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account Don't use. See master account. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of Browser docs. Often abbreviated as RUM, this is a generic industry term for Browser monitoring. New Relic refers to this as page load timing (in Browser docs) or New Relic Browser (in non-Browser docs). Within Browser docs, use this term only for SEO or clarification, never to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures. However, avoid using generic “you” or “your” when permissions are involved, because we can't assume what permissions the user has. For example, we can't just say “you can add and remove users from your account settings” when that is actually an Owner or Admin level capability. When permissions are relevant, use a permissions callout.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.58563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " with &quot;New Relic&quot;. For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>"
      },
      "id": "60421ec1196a676986a83d87"
    }
  ],
  "/docs/style-guide/quick-reference/code-examples": [
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-14T18:17:04Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 346.8673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-14T19:15:01Z",
      "updated_at": "2021-05-28T02:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.0614,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ". If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-14T19:16:07Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.32764,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    }
  ],
  "/docs/style-guide/quick-reference/collapsers": [
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-14T18:17:04Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 346.8673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-14T19:15:01Z",
      "updated_at": "2021-05-28T02:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.0614,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ". If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-06-14T18:18:03Z",
      "updated_at": "2021-05-06T04:01:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right-click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also mouse over. collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account The primary account in a New Relic account with sub-accounts. Refer to a master's subordinate accounts as sub-accounts, not children or slaves. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account Don't use. See master account. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of Browser docs. Often abbreviated as RUM, this is a generic industry term for Browser monitoring. New Relic refers to this as page load timing (in Browser docs) or New Relic Browser (in non-Browser docs). Within Browser docs, use this term only for SEO or clarification, never to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures. However, avoid using generic “you” or “your” when permissions are involved, because we can't assume what permissions the user has. For example, we can't just say “you can add and remove users from your account settings” when that is actually an Owner or Admin level capability. When permissions are relevant, use a permissions callout.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.58563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " with &quot;New Relic&quot;. For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>"
      },
      "id": "60421ec1196a676986a83d87"
    }
  ],
  "/docs/style-guide/quick-reference/lists": [
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-14T18:17:04Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 346.86725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-14T19:15:01Z",
      "updated_at": "2021-05-28T02:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.06137,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ". If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-14T19:16:07Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.32758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    }
  ],
  "/docs/style-guide/quick-reference/tables": [
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-14T18:17:04Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 346.86725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-14T19:15:01Z",
      "updated_at": "2021-05-28T02:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.06137,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ". If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-14T19:16:07Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.32758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    }
  ],
  "/docs/style-guide/quick-reference/titles": [
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-06-14T19:13:57Z",
      "updated_at": "2021-03-16T14:19:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based on its filename and filepath in the GitHub repository. For example, this is the filename and path for Rename or redirect a document: /docs/style-guide/processes-procedures/rename-or-redirect-document.mdx Copy The URL is: https://docs.newrelic.com/style-guide/processes-procedures/rename-or-redirect-document Copy If you rename a document's filename or change its path by moving it to a new directory, make sure to add a redirect to its old filepath. To change the document's location in the left navigation, update the navigation configuration file. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update the title in the left navigation, edit the yml file for the section that you're in. For example, the Style guide docs use /src/nav/style-guide.yml. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.05737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rename or <em>redirect</em> a document",
        "sections": "Rename or <em>redirect</em> a document",
        "body": "This document describes how to change the title of a document and how to create, edit, and delete <em>redirects</em>. Procedures are the same for both standard docs (&quot;basic pages&quot;) and release notes. Caution Changing <em>titles</em> or updating <em>redirects</em> can create issues with finding content. If you need to change"
      },
      "id": "604220ec196a670d0ba83dd4"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/levels-headings/",
      "sections": [
        "Levels of headings",
        "Use parallel construction",
        "Keep it short, avoid -ing words",
        "Do not use h1 headings",
        "Use level two headings to identify chunks of information",
        "Important",
        "Avoid using level three headings"
      ],
      "published_at": "2021-06-14T18:20:46Z",
      "title": "Levels of headings",
      "updated_at": "2021-05-21T14:31:50Z",
      "type": "docs",
      "external_id": "981282f676b2697e24f69ad23bce7e3412bb1d22",
      "document_type": "page",
      "popularity": 1,
      "body": "Taking some time to consider your headings and document titles will be time well spent. Titles and headings are not only important for search results, but they can make your docs easier to skim. For all headings and document titles, use sentence case. Use parallel construction Use parallel construction when naming headers. For example, use all nouns (\"Organization,\" \"Tone\"), all verbs (\"Create,\" \"Delete\"), etc. Keep it short, avoid -ing words For all headers, keep the title as short as possible. In particular, avoid headers that are more than a line long. As with all our writing, you should feel free to address the reader directly: Install the agent, for example, rather than Agent installation. You should also avoid -ing words, which add to character count without contributing clarity. Do not use h1 headings After you publish your doc, the Docs site will automatically use what you added to the Title field as the doc's level one heading (h1). To ensure that your doc is properly indexed for search, do not manually create additional h1 headings. If your doc's title is long and you would like a shorter title to appear in the sidebar menu, create a GitHub issue and we'll help you with that change. Use level two headings to identify chunks of information Organize chunks of information into sections with level two headings (##). For example: ## Create a new user [#create-new-user] Copy Important If you don't specify an ID manually, the site will use your header text as that header's ID (also known as anchor link). Create a manual ID to preserve links to that header if you change the header text. If you have too many level sections, consider splitting the document into multiple pages. Avoid using level three headings Avoid using ### headings unless it makes sense for the content or if the content is lengthy. Collapsers, tables, and other structural elements are often a better choice. Be particularly careful about level three headings that make a level two section longer than a single screen height. Here are two examples of good scenarios for using level three headings: Example #1: Events-to-metrics API doc Example #2: Infrastructure integration doc",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.76566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Keep it <em>short</em>, avoid -ing words",
        "body": "Taking some time to consider your headings and document <em>titles</em> will be time well spent. <em>Titles</em> and headings are not only important for search results, but they can make your docs easier to skim. For all headings and document <em>titles</em>, use sentence case. Use parallel construction Use parallel"
      },
      "id": "604221d3196a677e3aa83db4"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-14T19:15:01Z",
      "updated_at": "2021-05-28T02:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.28525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "UI elements and UI page <em>paths</em>",
        "body": " and document <em>titles</em>. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it&#x27;s used in the code; for example: noticeError"
      },
      "id": "60421e50196a67d785a83d97"
    }
  ],
  "/docs/style-guide/quick-reference/ui-paths": [
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-14T19:15:01Z",
      "updated_at": "2021-05-28T02:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.06134,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ". If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-14T19:16:07Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.32758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    },
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-06-14T18:18:03Z",
      "updated_at": "2021-05-06T04:01:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right-click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also mouse over. collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account The primary account in a New Relic account with sub-accounts. Refer to a master's subordinate accounts as sub-accounts, not children or slaves. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account Don't use. See master account. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of Browser docs. Often abbreviated as RUM, this is a generic industry term for Browser monitoring. New Relic refers to this as page load timing (in Browser docs) or New Relic Browser (in non-Browser docs). Within Browser docs, use this term only for SEO or clarification, never to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures. However, avoid using generic “you” or “your” when permissions are involved, because we can't assume what permissions the user has. For example, we can't just say “you can add and remove users from your account settings” when that is actually an Owner or Admin level capability. When permissions are relevant, use a permissions callout.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.5856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " with &quot;New Relic&quot;. For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>"
      },
      "id": "60421ec1196a676986a83d87"
    }
  ],
  "/docs/style-guide/quick-reference/usage-dictionary": [
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-14T18:17:04Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 346.8671,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-14T19:15:01Z",
      "updated_at": "2021-05-28T02:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.0613,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ". If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-14T19:16:07Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.32755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    }
  ],
  "/docs/style-guide/writer-workflow/github-intro": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/tech-writer-workflow/",
      "sections": [
        "Tech Writer workflow",
        "Resources",
        "Edit in the UI vs local build",
        "Work on a branch, not a fork",
        "Set up your local environment",
        "Run the site locally",
        "Prerequisites",
        "Build the site",
        "Edit a doc",
        "Commit your changes",
        "Publish your commits",
        "Open your pull request",
        "Preview a doc",
        "Revise and publish a doc",
        "Revert merging"
      ],
      "published_at": "2021-06-14T18:18:38Z",
      "title": "Tech Writer workflow",
      "updated_at": "2021-06-14T00:55:51Z",
      "type": "docs",
      "external_id": "074905b02af0ab6eb53640c1c80e83296a8a0b02",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the UI vs local build Need to edit a doc? Use this table to decide where to work! Use the UI for: Use the local build for: Adding content to one doc: Rewriting sentences, or 1-2 lines Editing small amounts of content: updating URLs, deleting typos, etc. Brand new docs Rewrites of more than 1 or 2 lines Any updates to doc frontmatter Title changes Taxonomy changes Metadescription updates Redirects Updating images Editing multiple docs at once Continue reading for instructions on how to edit a doc locally. Work on a branch, not a fork Some teams work on branches, some teams work on forks; the docs team works in branches. As long as a branch has been pushed upstream, this allows us to work collaboratively and ensure that no work is ever lost when someone goes on vacation. To create a branch on the docs-website repo: Open GitHub Desktop Click on Current branch: xxx Click on New Branch You will be prompted to name your new branch. Descriptive names are best. It's a great way to quickly clue people in to what your work is all about. For example, if you are working on What’s New pages, you might name the branch Whats-new-updates. When you create a new branch, don't forget to add the Jira issue's key (DOC-1234) to the branch name and the PR title. Set up your local environment Install GitHub Desktop, and then navigate to GitHub Desktop's preferences. On Macs, click on GitHub Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Once GitHub Desktop is set up, navigate to the Docs Site repository on GitHub. Click the green Code button and then select Open with GitHub Desktop. Choose the location where you want the repo, and this will clone the entire repository to your local machine at the designated path. You can ensure the repo was cloned by navigating to your local GitHub folder (the default is ~/Documents/github). Once you have cloned the repo, you don't need to clone it again in the future. Run the site locally Build the site locally using the terminal to preview changes before opening a Pull Request. While it's highly recommended to build the site locally, this is technically an optional step. The site will automatically reflect any local changes once build. Node and Yarn are tools used to build the site on your local machine. Prerequisites Install Node Install Yarn npm install -g yarn Build the site In your terminal, go to your cloned repo, docs-website. cd ~/Documents/github/docs-website Run yarn with the following commands: yarn && yarn start The site will take a few minutes to build. Make yourself some tea or coffee. Once it's built, you can access your preview site in your browser by navigating to http://localhost:8000/ Edit a doc Once your local environment and branch are set up, you're ready to edit a doc. Check out the style guide for writing guidelines. First, ensure your Current Branch in GitHub Desktop is set to the correct branch, not Develop. Navigate to the doc you want to edit in Finder. If I wanted to edit a Python agent doc, I would navigate to: ~/Documents/github/docs-website/src/content/docs/agents/python-agent/hosting-services/python-agent-stackato.mdx Edit the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help with formatting markdown Save the file with your edits, then follow the same process for any other docs you wish to edit. Commit your changes Once your edits are done, you can commit them. This stages your changes, which you will later push upstream to Github. By pushing your changes, everyone will have access to your branch and commits. Navigate to GitHub Desktop. The left column should have a record of all the edits you have made to docs. In the bottom left corner, name your commit and add a good description of your edits. It should be descriptive enough to ensure that someone can understand all the changes made by simply scanning this description. Click Commit to [yourbranchname] Publish your commits Once you have committed your changes, you're almost ready to open your Pull Request. First, you need to ensure your branch is pushed upstream. On GitHub desktop, click the blue Publish Branch button if available. If you don't see the Publish Branch, click the blue Push Origin button. This will push all your commits upstream and make them available to everyone else through the GitHub repository. Open your pull request Now that your commits are available to everyone, you need to notify people that your changes are ready to be merged into the develop branch. To do this, you open a pull request: On GitHub Desktop, click the blue Create Pull Request button. This will open GitHub in your browser, and prompt you to fill in your pull request. Ensure you are merging from your branch into either the main or develop branch. If you scroll down, you can review all your commits to ensure they reflect all your changes. Just like your commit description, your pull request description should be detailed and give the full context of your changes. Feel free to add any additional context here (issue or Jira number, SMEs, etc.) Once you are satisfied with your pull request, click the green Create pull request button. You can either publish the changes directly by approving the pull request yourself, or you can request for another Tech Writer to peer edit it. To request a review from another Tech Writer: in GitHub open the PR, navigate to the conversation Conversation, and then select or type in a reviewer name in the Reviewer section. At the bottom the pull request page, you will see a Checks section. These checks ensure your PR does not break the build process of the site. Ensure all these checks pass before proceeding. The checks should finish within twenty minutes. If the Pull Request is urgent, you can skip the AWS Amplify Console Web Preview check. Once the pull request has passed the checks and it has been approved by another tech writer (or you are confident the changes are ready to be published), click the green Merge pull request button. This will merge your branch and commits into the repository and will begin the build process. Preview a doc There are two main ways to preview branches you’ve already published and run commits on: Local: Quicker, but requires a semi-substantial amount of setup and familiarity with a terminal. Amplify: Full preview of the live site with no overhead, although it takes a long time (from 30 minutes tp up to 1.5 hours!) to build on a PR. It's easily shareable with SMEs and others. Revise and publish a doc If you’re notified that a reviewer has submitted a review to your file, go to your PR and review the changes. You might see them in the diff view, if they’re part of a review with comments; otherwise, they might appear as copy edits in the file. Respond to any comments in the file. Either reply with follow up discussion, or click Resolve conversation. When you’ve resolved all the comments, and all of the automatic checks have passed, you can merge the pull request. Merging the pull request sets in motion the automated build process and your changes will be published shortly. Note: You will only be able to merge when the Merge pull request button is green. If it’s not green, review for any comments you missed, or other messages that indicate why GitHub is blocking you from merging. Revert merging Remember that you can almost always undo things. If you merge a PR, and then find that you shouldn’t have, you can unmerge with the Revert button. On the Pull requests tab in GitHub, click Closed on the tally bar to see all the issues and PRs that have alredy been merged. Locate the PR you merged, and locate the Revert button. Click Revert. That creates a new PR, which needs to be merged. If you want to reopen it, you need to follow the link back to the original PR and either revert that or reopen it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.0489,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great <em>GitHub</em> integrations <em>GitHub</em> account <em>GitHub</em> Desktop Edit in the UI vs local build Need to edit a doc? Use"
      },
      "id": "60c6a91764441f404d91f8c6"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/peer-editor-workflow/",
      "sections": [
        "Peer editor workflow",
        "Peer editing workflow in GitHub",
        "Developmental edit pass",
        "Copy edit workflow"
      ],
      "published_at": "2021-06-14T18:18:38Z",
      "title": "Peer editor workflow",
      "updated_at": "2021-06-14T00:56:46Z",
      "type": "docs",
      "external_id": "c5cade26eea3b846e8c6cc5f3b89552147d724be",
      "document_type": "page",
      "popularity": 1,
      "body": "Use this document to learn how to review and peer edit docs for you fellow writers in GitHub. Check the Tech Writer workflow doc for info on how to set up your local environment. To troubleshoot GitHub issues, see our guide. Peer editing workflow in GitHub If you’re peer editing a doc or have been otherwise assigned to a PR as a reviewer, you have a few choices for how and where to do the work. The most streamlined and open-source approach is to do the edit using GitHub options, rather than copying the file to Google Docs and editing there. Developmental edit pass For cases where you have questions and suggestions rather than straight copy edits, follow these steps. Open the PR that you’re assigned to review. On the Files changed tab, you can either: Click Review changes and then select one of the following: Comment - use if you have a comment that doesn’t require follow up. Approve - use if you just want to approve the PR. You can request changes in the Leave a comment area, and select Approve if you want to let the writer make the edits and merge the file without a follow-up review from you. Request changes - use for times when you want to make sure the changes you request are included. You’ll be notified with any updates that the writer makes. OR, start making comments on lines or sections of the doc. To do this, click the add comment icon , and leave an edit or comment for that specific line in the page. With this option, you get the choice between adding a single comment or starting a review. If you’re going to make comments throughout a doc, choose Start a review so the comments will all be rolled into one commit. Click Finish your review to complete your review. This triggers a notification to the writer alerting them that you’ve made suggestions. Copy edit workflow If you have copy edits for a file rather than comments and suggestions, you can make the changes to the file in different ways. Here are two main options: Edit using the GitHub browser: On the Files changed tab, in the diff window click the editing button (three dots). When you finish your edits, add a comment at the bottom of the file and choose to either commit the changes directly, or create a branch and start a pull request. Choose to branch and start a pull request if you expect a writer to review the diff and accept or revise your edits. Edit locally: Check out the branch containing the file you want to edit. In GitHub Desktop, click the Current branch down arrow and select the branch. Then, make the edits on your local drive, save, and commit your changes to the branch. Note that this approach adds your edits to the open pull request. You can now see the changes you added to the file on the Files changed tab in the PR. These are just a few of many editing options. You’ll find your preferred way, just as with any other tool.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.21954,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Peer editing workflow in <em>GitHub</em>",
        "body": "Use this document to learn how to review and peer edit docs for you fellow writers in <em>GitHub</em>. Check the Tech Writer workflow doc for info on how to set up your local environment. To troubleshoot <em>GitHub</em> issues, see our guide. Peer editing workflow in <em>GitHub</em> If you’re peer editing a doc or have been"
      },
      "id": "60c6a94ee7b9d21cd1d6779f"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/github-troubleshooting/",
      "sections": [
        "GitHub troubleshooting",
        "GitHub authentication fails",
        "My build is failing mysteriously",
        "Issues with the local site",
        "Stop and restart yarn",
        "Ensure the problem isn't with your branch",
        "Clean your local cache",
        "Remove corrupted cache files",
        "Start a build from start",
        "Run your local build in private mode",
        "My redirect throws a 404 error when testing it locally",
        "A check fails in the PR",
        "Reset the Gatsby build check",
        "Caution",
        "Troubleshoot merging conflicts",
        "What’s new related merge conflicts"
      ],
      "published_at": "2021-06-14T18:18:02Z",
      "title": "GitHub troubleshooting",
      "updated_at": "2021-06-14T00:56:47Z",
      "type": "docs",
      "external_id": "09ae591aa87a3d512d1c62005589dbd88f23f699",
      "document_type": "page",
      "popularity": 1,
      "body": "Are you having problems working on a doc in GitHub? Check out the following common issues. GitHub authentication fails If you suddenly find that you can no longer push to your remote branch in GitHub Desktop, you may have developed a problem with SSH. If logging out of GitHub Desktop via Preferences doesn’t seem to help, you can confirm if you have an SSH issue by switching to the command line and trying to push manually. For example: git push --set-upstream origin second-kafka-pr-for-issue-1123 If this command prompts you for a passphrase, your SSH was somehow confused. By entering your passphrase, you should be back in business. If you can’t remember your passphrase, check out this article. My build is failing mysteriously Here’s a few things you can check if your build is failing: Indenting in the nav files Front matter If there's apostrophes and colons in frontmatter fields, surround them with quotes to avoid problems. Missing closed brackets or tags Poorly formatted image links Be careful when renaming images and their filename paths. A mismatch can cause the entire local build to fail. Be especially careful when dealing with image files that are imported. Image filenames Image filenames are case-sensitive. Using the wrong capitalization results in a missing image in the doc. Images with encoded values (like %) in the filename can be especially tricky, try to avoid them. Issues with the local site If you're running with issues with your local build, try these options: Stop and restart yarn In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to interrupt the yarn process, if necessary. Run yarn && yarn start. Ensure the problem isn't with your branch In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. In GitHub Desktop, commit any changes needed on your branch, and then switch to the Develop branch. 4 Back in the terminal, run yarn && yarn start. If the site now builds correctly, the issue is with the changes in your branch. Stop Yarn again, go back to your branch, and troubleshoot. Clean your local cache Run yarn clean to blow away your local cache. This will make your next build slower, so make sure you have time! In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. Begin a new build by running yarn clean && yarn && yarn start. Remove corrupted cache files There may be times when your .cache directory has been corrupted. This directory is ignored by Git, which means that it travels with you from branch to branch. This might be the problem if your local builds are failing regardless of which branch you’re on. To solve this, run rm -rf .cache. Start a build from start Blow away all your node modules, hidden .cache folder, and local cache and start a build from scratch. This takes a long time to run, around 10–20 minutes. In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. Blow away modules and cache and start from scratch running rm -rf node_modules && rm -rf .cache && yarn && yarn clean. When everything completes, start the site yarn start. You may need to add sudo at the start of the rm commands. Run your local build in private mode Sometimes the local site builds, but pages within the site don't. Running the local build in a private/incognito session may to fix this issue. You can also try clearing out your browser's cache. My redirect throws a 404 error when testing it locally Redirects are a bit strange on local builds. To test them, navigate to the page that is being redirected, wait until it throws a 404, and then wait ~1-2 minutes. It should redirect you after a while. If it doesn’t, ensure you set up the redirect correctly. A check fails in the PR Rarely, a build or check will fail due to some internal error. You can re-run the check by going to the PR, clicking Details, and then clicking Re-run jobs. If that doesn't fix it, you probably have genuine build errors. Pull down locally and troubleshoot. Reset the Gatsby build check Caution This adds a LOT of time to the build check. There are times the Gatsby Build check fails. If this happens after your local builds have built successfully, you may need to force a rebuild of the cache. In your local repo, find the file gatsby-config.js (use CMD-P to jump to it fast in VSCode). Swap the first and second line of code. It doesn’t matter what order these lines are in, except to make the Gatsby Build check rebuild the cache. const fs = require('fs'); const parse = require('rehype-parse'); Save the file and commit the change to your PR. Re-run the build checks. Wait a LOOOOONG time. Troubleshoot merging conflicts Merge conflicts can seem pretty scary, but it’s ultimately just deciding between two different versions of a doc. Here are some tips on how to get through it. Fix your merge conflict as soon as possible. Especially if you’re working on taxonomy changes. If your branch lingers for a while it can get outdated from develop pretty fast and that can cause some unexpected issues. Check your fix locally to make sure that it looks good there. Ask your PR approver to review your PR after you fix the merge conflict. Here are two options to resolve conflicts: When you see the conflicts in GitHub desktop, click the option to resolve these in VS Code. Use the GitHub website editor (click the Resolve conflict button) to fix these. What’s new related merge conflicts Merge conflicts pop up pretty often with what’s new posts because the whats-new-ids.json file that’s automatically updated when the site builds can get out-of-date pretty fast. If you see changes to this file show up in GitHub Desktop, make sure to discard them, rather than push them up to your branch. This will make it less likely that other people will have to deal with merge conflicts related to this file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.88739,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>GitHub</em> troubleshooting",
        "sections": "<em>GitHub</em> troubleshooting",
        "body": "Are you having problems working on a doc in <em>GitHub</em>? Check out the following common issues. <em>GitHub</em> authentication fails If you suddenly find that you can no longer push to your remote branch in <em>GitHub</em> Desktop, you may have developed a problem with SSH. If logging out of <em>GitHub</em> Desktop via"
      },
      "id": "60c6a94f64441f5ac491f8a7"
    }
  ],
  "/docs/style-guide/writer-workflow/github-troubleshooting": [
    {
      "sections": [
        "Diagnostics CLI (nrdiag)",
        "Compatibility",
        "Get started"
      ],
      "title": "Diagnostics CLI (nrdiag)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "973501f4752e56caf3d68e37bf21b823d0e42078",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/cross-product-functions/diagnostics-cli-nrdiag/diagnostics-cli-nrdiag/",
      "published_at": "2021-06-15T03:28:00Z",
      "updated_at": "2021-03-13T05:45:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download latest version The Diagnostics CLI (nrdiag) is a utility that automatically detects common problems with New Relic products. If the Diagnostics CLI detects a problem, it suggests troubleshooting steps. The Diagnostics CLI can also automatically attach troubleshooting data to a New Relic Support ticket. The Diagnostics CLI is open source and is located in GitHub. For additional troubleshooting steps for your agent, check out Not seeing data. Here's an example of the Diagnostics CLI running on Ubuntu Linux. The program checks your New Relic agent configurations for issues and generates zipped troubleshooting logs that are ready to be attached to support tickets. Compatibility The Diagnostics CLI is available for Linux, macOS, and Windows. It can detect common configuration issues for: APM: Available for all APM agents except C SDK. For the Go agent, only basic connectivity checks are available. Browser monitoring: Browser agent detection Infrastructure monitoring: Linux and Windows agents Mobile agents: iOS and Android Synthetic monitoring: Containerized private minions (CPM) The Diagnostics CLI does not require superuser or admin permissions to run, although we recommend those permissions for some checks. It will return an error if it does not have permissions to read the files it scans. Get started To use the Diagnostics CLI: Run the Diagnostics CLI, including task suites and command line options as needed. Include an attachment key when you upload the results to your Support ticket. Optional: Validate your config file settings. Interpret the output. Like any other New Relic tool, the Diagnostics CLI service is designed to protect you and your customers' data privacy. For detailed information, see our Diagnostics CLI licensing and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 722.4174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " Support ticket. The Diagnostics CLI is open source and is located in <em>GitHub</em>. For additional <em>troubleshooting</em> steps for your agent, check out Not seeing data. Here&#x27;s an example of the Diagnostics CLI running on Ubuntu Linux. The program checks your New Relic agent configurations for issues and generates"
      },
      "id": "604469f8e7b9d2abb65799f0"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/tech-writer-workflow/",
      "sections": [
        "Tech Writer workflow",
        "Resources",
        "Edit in the UI vs local build",
        "Work on a branch, not a fork",
        "Set up your local environment",
        "Run the site locally",
        "Prerequisites",
        "Build the site",
        "Edit a doc",
        "Commit your changes",
        "Publish your commits",
        "Open your pull request",
        "Preview a doc",
        "Revise and publish a doc",
        "Revert merging"
      ],
      "published_at": "2021-06-14T18:18:38Z",
      "title": "Tech Writer workflow",
      "updated_at": "2021-06-14T00:55:51Z",
      "type": "docs",
      "external_id": "074905b02af0ab6eb53640c1c80e83296a8a0b02",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the UI vs local build Need to edit a doc? Use this table to decide where to work! Use the UI for: Use the local build for: Adding content to one doc: Rewriting sentences, or 1-2 lines Editing small amounts of content: updating URLs, deleting typos, etc. Brand new docs Rewrites of more than 1 or 2 lines Any updates to doc frontmatter Title changes Taxonomy changes Metadescription updates Redirects Updating images Editing multiple docs at once Continue reading for instructions on how to edit a doc locally. Work on a branch, not a fork Some teams work on branches, some teams work on forks; the docs team works in branches. As long as a branch has been pushed upstream, this allows us to work collaboratively and ensure that no work is ever lost when someone goes on vacation. To create a branch on the docs-website repo: Open GitHub Desktop Click on Current branch: xxx Click on New Branch You will be prompted to name your new branch. Descriptive names are best. It's a great way to quickly clue people in to what your work is all about. For example, if you are working on What’s New pages, you might name the branch Whats-new-updates. When you create a new branch, don't forget to add the Jira issue's key (DOC-1234) to the branch name and the PR title. Set up your local environment Install GitHub Desktop, and then navigate to GitHub Desktop's preferences. On Macs, click on GitHub Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Once GitHub Desktop is set up, navigate to the Docs Site repository on GitHub. Click the green Code button and then select Open with GitHub Desktop. Choose the location where you want the repo, and this will clone the entire repository to your local machine at the designated path. You can ensure the repo was cloned by navigating to your local GitHub folder (the default is ~/Documents/github). Once you have cloned the repo, you don't need to clone it again in the future. Run the site locally Build the site locally using the terminal to preview changes before opening a Pull Request. While it's highly recommended to build the site locally, this is technically an optional step. The site will automatically reflect any local changes once build. Node and Yarn are tools used to build the site on your local machine. Prerequisites Install Node Install Yarn npm install -g yarn Build the site In your terminal, go to your cloned repo, docs-website. cd ~/Documents/github/docs-website Run yarn with the following commands: yarn && yarn start The site will take a few minutes to build. Make yourself some tea or coffee. Once it's built, you can access your preview site in your browser by navigating to http://localhost:8000/ Edit a doc Once your local environment and branch are set up, you're ready to edit a doc. Check out the style guide for writing guidelines. First, ensure your Current Branch in GitHub Desktop is set to the correct branch, not Develop. Navigate to the doc you want to edit in Finder. If I wanted to edit a Python agent doc, I would navigate to: ~/Documents/github/docs-website/src/content/docs/agents/python-agent/hosting-services/python-agent-stackato.mdx Edit the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help with formatting markdown Save the file with your edits, then follow the same process for any other docs you wish to edit. Commit your changes Once your edits are done, you can commit them. This stages your changes, which you will later push upstream to Github. By pushing your changes, everyone will have access to your branch and commits. Navigate to GitHub Desktop. The left column should have a record of all the edits you have made to docs. In the bottom left corner, name your commit and add a good description of your edits. It should be descriptive enough to ensure that someone can understand all the changes made by simply scanning this description. Click Commit to [yourbranchname] Publish your commits Once you have committed your changes, you're almost ready to open your Pull Request. First, you need to ensure your branch is pushed upstream. On GitHub desktop, click the blue Publish Branch button if available. If you don't see the Publish Branch, click the blue Push Origin button. This will push all your commits upstream and make them available to everyone else through the GitHub repository. Open your pull request Now that your commits are available to everyone, you need to notify people that your changes are ready to be merged into the develop branch. To do this, you open a pull request: On GitHub Desktop, click the blue Create Pull Request button. This will open GitHub in your browser, and prompt you to fill in your pull request. Ensure you are merging from your branch into either the main or develop branch. If you scroll down, you can review all your commits to ensure they reflect all your changes. Just like your commit description, your pull request description should be detailed and give the full context of your changes. Feel free to add any additional context here (issue or Jira number, SMEs, etc.) Once you are satisfied with your pull request, click the green Create pull request button. You can either publish the changes directly by approving the pull request yourself, or you can request for another Tech Writer to peer edit it. To request a review from another Tech Writer: in GitHub open the PR, navigate to the conversation Conversation, and then select or type in a reviewer name in the Reviewer section. At the bottom the pull request page, you will see a Checks section. These checks ensure your PR does not break the build process of the site. Ensure all these checks pass before proceeding. The checks should finish within twenty minutes. If the Pull Request is urgent, you can skip the AWS Amplify Console Web Preview check. Once the pull request has passed the checks and it has been approved by another tech writer (or you are confident the changes are ready to be published), click the green Merge pull request button. This will merge your branch and commits into the repository and will begin the build process. Preview a doc There are two main ways to preview branches you’ve already published and run commits on: Local: Quicker, but requires a semi-substantial amount of setup and familiarity with a terminal. Amplify: Full preview of the live site with no overhead, although it takes a long time (from 30 minutes tp up to 1.5 hours!) to build on a PR. It's easily shareable with SMEs and others. Revise and publish a doc If you’re notified that a reviewer has submitted a review to your file, go to your PR and review the changes. You might see them in the diff view, if they’re part of a review with comments; otherwise, they might appear as copy edits in the file. Respond to any comments in the file. Either reply with follow up discussion, or click Resolve conversation. When you’ve resolved all the comments, and all of the automatic checks have passed, you can merge the pull request. Merging the pull request sets in motion the automated build process and your changes will be published shortly. Note: You will only be able to merge when the Merge pull request button is green. If it’s not green, review for any comments you missed, or other messages that indicate why GitHub is blocking you from merging. Revert merging Remember that you can almost always undo things. If you merge a PR, and then find that you shouldn’t have, you can unmerge with the Revert button. On the Pull requests tab in GitHub, click Closed on the tally bar to see all the issues and PRs that have alredy been merged. Locate the PR you merged, and locate the Revert button. Click Revert. That creates a new PR, which needs to be merged. If you want to reopen it, you need to follow the link back to the original PR and either revert that or reopen it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.0487,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great <em>GitHub</em> integrations <em>GitHub</em> account <em>GitHub</em> Desktop Edit in the UI vs local build Need to edit a doc? Use"
      },
      "id": "60c6a91764441f404d91f8c6"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/peer-editor-workflow/",
      "sections": [
        "Peer editor workflow",
        "Peer editing workflow in GitHub",
        "Developmental edit pass",
        "Copy edit workflow"
      ],
      "published_at": "2021-06-14T18:18:38Z",
      "title": "Peer editor workflow",
      "updated_at": "2021-06-14T00:56:46Z",
      "type": "docs",
      "external_id": "c5cade26eea3b846e8c6cc5f3b89552147d724be",
      "document_type": "page",
      "popularity": 1,
      "body": "Use this document to learn how to review and peer edit docs for you fellow writers in GitHub. Check the Tech Writer workflow doc for info on how to set up your local environment. To troubleshoot GitHub issues, see our guide. Peer editing workflow in GitHub If you’re peer editing a doc or have been otherwise assigned to a PR as a reviewer, you have a few choices for how and where to do the work. The most streamlined and open-source approach is to do the edit using GitHub options, rather than copying the file to Google Docs and editing there. Developmental edit pass For cases where you have questions and suggestions rather than straight copy edits, follow these steps. Open the PR that you’re assigned to review. On the Files changed tab, you can either: Click Review changes and then select one of the following: Comment - use if you have a comment that doesn’t require follow up. Approve - use if you just want to approve the PR. You can request changes in the Leave a comment area, and select Approve if you want to let the writer make the edits and merge the file without a follow-up review from you. Request changes - use for times when you want to make sure the changes you request are included. You’ll be notified with any updates that the writer makes. OR, start making comments on lines or sections of the doc. To do this, click the add comment icon , and leave an edit or comment for that specific line in the page. With this option, you get the choice between adding a single comment or starting a review. If you’re going to make comments throughout a doc, choose Start a review so the comments will all be rolled into one commit. Click Finish your review to complete your review. This triggers a notification to the writer alerting them that you’ve made suggestions. Copy edit workflow If you have copy edits for a file rather than comments and suggestions, you can make the changes to the file in different ways. Here are two main options: Edit using the GitHub browser: On the Files changed tab, in the diff window click the editing button (three dots). When you finish your edits, add a comment at the bottom of the file and choose to either commit the changes directly, or create a branch and start a pull request. Choose to branch and start a pull request if you expect a writer to review the diff and accept or revise your edits. Edit locally: Check out the branch containing the file you want to edit. In GitHub Desktop, click the Current branch down arrow and select the branch. Then, make the edits on your local drive, save, and commit your changes to the branch. Note that this approach adds your edits to the open pull request. You can now see the changes you added to the file on the Files changed tab in the PR. These are just a few of many editing options. You’ll find your preferred way, just as with any other tool.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 259.24637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Peer editing workflow in <em>GitHub</em>",
        "body": "Use this document to learn how to review and peer edit docs for you fellow writers in <em>GitHub</em>. Check the Tech Writer workflow doc for info on how to set up your local environment. To <em>troubleshoot</em> <em>GitHub</em> issues, see our guide. Peer editing workflow in <em>GitHub</em> If you’re peer editing a doc or have been"
      },
      "id": "60c6a94ee7b9d21cd1d6779f"
    }
  ],
  "/docs/style-guide/writer-workflow/peer-editor-workflow": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/tech-writer-workflow/",
      "sections": [
        "Tech Writer workflow",
        "Resources",
        "Edit in the UI vs local build",
        "Work on a branch, not a fork",
        "Set up your local environment",
        "Run the site locally",
        "Prerequisites",
        "Build the site",
        "Edit a doc",
        "Commit your changes",
        "Publish your commits",
        "Open your pull request",
        "Preview a doc",
        "Revise and publish a doc",
        "Revert merging"
      ],
      "published_at": "2021-06-14T18:18:38Z",
      "title": "Tech Writer workflow",
      "updated_at": "2021-06-14T00:55:51Z",
      "type": "docs",
      "external_id": "074905b02af0ab6eb53640c1c80e83296a8a0b02",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the UI vs local build Need to edit a doc? Use this table to decide where to work! Use the UI for: Use the local build for: Adding content to one doc: Rewriting sentences, or 1-2 lines Editing small amounts of content: updating URLs, deleting typos, etc. Brand new docs Rewrites of more than 1 or 2 lines Any updates to doc frontmatter Title changes Taxonomy changes Metadescription updates Redirects Updating images Editing multiple docs at once Continue reading for instructions on how to edit a doc locally. Work on a branch, not a fork Some teams work on branches, some teams work on forks; the docs team works in branches. As long as a branch has been pushed upstream, this allows us to work collaboratively and ensure that no work is ever lost when someone goes on vacation. To create a branch on the docs-website repo: Open GitHub Desktop Click on Current branch: xxx Click on New Branch You will be prompted to name your new branch. Descriptive names are best. It's a great way to quickly clue people in to what your work is all about. For example, if you are working on What’s New pages, you might name the branch Whats-new-updates. When you create a new branch, don't forget to add the Jira issue's key (DOC-1234) to the branch name and the PR title. Set up your local environment Install GitHub Desktop, and then navigate to GitHub Desktop's preferences. On Macs, click on GitHub Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Once GitHub Desktop is set up, navigate to the Docs Site repository on GitHub. Click the green Code button and then select Open with GitHub Desktop. Choose the location where you want the repo, and this will clone the entire repository to your local machine at the designated path. You can ensure the repo was cloned by navigating to your local GitHub folder (the default is ~/Documents/github). Once you have cloned the repo, you don't need to clone it again in the future. Run the site locally Build the site locally using the terminal to preview changes before opening a Pull Request. While it's highly recommended to build the site locally, this is technically an optional step. The site will automatically reflect any local changes once build. Node and Yarn are tools used to build the site on your local machine. Prerequisites Install Node Install Yarn npm install -g yarn Build the site In your terminal, go to your cloned repo, docs-website. cd ~/Documents/github/docs-website Run yarn with the following commands: yarn && yarn start The site will take a few minutes to build. Make yourself some tea or coffee. Once it's built, you can access your preview site in your browser by navigating to http://localhost:8000/ Edit a doc Once your local environment and branch are set up, you're ready to edit a doc. Check out the style guide for writing guidelines. First, ensure your Current Branch in GitHub Desktop is set to the correct branch, not Develop. Navigate to the doc you want to edit in Finder. If I wanted to edit a Python agent doc, I would navigate to: ~/Documents/github/docs-website/src/content/docs/agents/python-agent/hosting-services/python-agent-stackato.mdx Edit the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help with formatting markdown Save the file with your edits, then follow the same process for any other docs you wish to edit. Commit your changes Once your edits are done, you can commit them. This stages your changes, which you will later push upstream to Github. By pushing your changes, everyone will have access to your branch and commits. Navigate to GitHub Desktop. The left column should have a record of all the edits you have made to docs. In the bottom left corner, name your commit and add a good description of your edits. It should be descriptive enough to ensure that someone can understand all the changes made by simply scanning this description. Click Commit to [yourbranchname] Publish your commits Once you have committed your changes, you're almost ready to open your Pull Request. First, you need to ensure your branch is pushed upstream. On GitHub desktop, click the blue Publish Branch button if available. If you don't see the Publish Branch, click the blue Push Origin button. This will push all your commits upstream and make them available to everyone else through the GitHub repository. Open your pull request Now that your commits are available to everyone, you need to notify people that your changes are ready to be merged into the develop branch. To do this, you open a pull request: On GitHub Desktop, click the blue Create Pull Request button. This will open GitHub in your browser, and prompt you to fill in your pull request. Ensure you are merging from your branch into either the main or develop branch. If you scroll down, you can review all your commits to ensure they reflect all your changes. Just like your commit description, your pull request description should be detailed and give the full context of your changes. Feel free to add any additional context here (issue or Jira number, SMEs, etc.) Once you are satisfied with your pull request, click the green Create pull request button. You can either publish the changes directly by approving the pull request yourself, or you can request for another Tech Writer to peer edit it. To request a review from another Tech Writer: in GitHub open the PR, navigate to the conversation Conversation, and then select or type in a reviewer name in the Reviewer section. At the bottom the pull request page, you will see a Checks section. These checks ensure your PR does not break the build process of the site. Ensure all these checks pass before proceeding. The checks should finish within twenty minutes. If the Pull Request is urgent, you can skip the AWS Amplify Console Web Preview check. Once the pull request has passed the checks and it has been approved by another tech writer (or you are confident the changes are ready to be published), click the green Merge pull request button. This will merge your branch and commits into the repository and will begin the build process. Preview a doc There are two main ways to preview branches you’ve already published and run commits on: Local: Quicker, but requires a semi-substantial amount of setup and familiarity with a terminal. Amplify: Full preview of the live site with no overhead, although it takes a long time (from 30 minutes tp up to 1.5 hours!) to build on a PR. It's easily shareable with SMEs and others. Revise and publish a doc If you’re notified that a reviewer has submitted a review to your file, go to your PR and review the changes. You might see them in the diff view, if they’re part of a review with comments; otherwise, they might appear as copy edits in the file. Respond to any comments in the file. Either reply with follow up discussion, or click Resolve conversation. When you’ve resolved all the comments, and all of the automatic checks have passed, you can merge the pull request. Merging the pull request sets in motion the automated build process and your changes will be published shortly. Note: You will only be able to merge when the Merge pull request button is green. If it’s not green, review for any comments you missed, or other messages that indicate why GitHub is blocking you from merging. Revert merging Remember that you can almost always undo things. If you merge a PR, and then find that you shouldn’t have, you can unmerge with the Revert button. On the Pull requests tab in GitHub, click Closed on the tally bar to see all the issues and PRs that have alredy been merged. Locate the PR you merged, and locate the Revert button. Click Revert. That creates a new PR, which needs to be merged. If you want to reopen it, you need to follow the link back to the original PR and either revert that or reopen it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.408646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tech Writer <em>workflow</em>",
        "sections": "Tech Writer <em>workflow</em>",
        "body": "This document will guide you through the entire <em>workflow</em> for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text <em>editor</em>) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the UI vs local build Need to edit a doc? Use"
      },
      "id": "60c6a91764441f404d91f8c6"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/github-intro/",
      "sections": [
        "Get around GitHub",
        "Who is who in an issue/PR?",
        "Track issues in the board",
        "Deal with references in GitHub (and the style guide)",
        "Merge from develop into main work (or, when do we publish?)",
        "Check the edit history of a doc or file"
      ],
      "published_at": "2021-06-14T18:18:02Z",
      "title": "Get around GitHub",
      "updated_at": "2021-06-14T00:55:50Z",
      "type": "docs",
      "external_id": "d691040a18c70d6cd84f6a12546e39099547ab5e",
      "document_type": "page",
      "popularity": 1,
      "body": "As tech doc writers (TW) we edit docs, do peer edits, or use the Docs Team GitHub board to track the status of issues and pull requests (PR). Who is who in an issue/PR? GitHub keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR is filed, check on the filer’s username and see if they're listed as a member of our organization. If you're not sure, treat someone as external until you know otherwise. People in an issue/PR include: Creator: The person who opened the issue or PR. This could be a writer, a Relic, or an external user. We'll label the issue or PR differently depending on who created it. If you're not sure if a user is a Relic, a good trick is to click on their profile and see if they're a member of the New Relic GitHub org. Assignee: The person taking responsibility for a PR or issue. This will usually be used by the Hero or Sidekick to assign non-TW PRs and issues to themselves. It can also be used to take a TW’s PR or issue over from them. Reviewer: The person who reviews or peer edits the code/document and approves the changes. Not necessarily the person responsible for that area or responsible for merging the commit. You can pre-assign up to 100 reviewers to a given issue. Track issues in the board The docs board has the following columns: Column Description Needs triage The Hero or Sidekick review issues and PRs in this column, then drag them to the appropriate column. If the issue/PR is labeled eng, go ahead and click its ellipses icon to archive it. For other issues and PRs, add these labels as applicable: content from_internal, when issued by a New Relic employee. If you open an PR based on an external issue, label that PR as internal since you're doing the work. from_external, when issued by someone outside New Relic, or you're not sure they are an employee. Jira’d, if you create a Jira from the issue. When you create a Jira, don't close the original issue/PR. However, feel free to remove it from the board until you work on it again. You can also add the product group the issue/PR belongs to using the tags pg_(as in pg_GPE, pg_TDP...). Hero: to do PRs that the Hero needs to review, publish, and follow up with SMEs as needed. Hero: Assign yourself as Assignee. In review (Hero or any TW) Drag PRs to this column when they are being reviewed. This shows who is reviewing and what is being reviewed, so two writers don’t mistakenly work on the same PR. Any TW: Writer needs PR review PRs from Tech Docs team members that need a light edit pass to make sure everything in GitHub is correct. This should be checked by other writers every few hours so PRs don’t get stale. If you have a PR that’s been lingering here too long, ask for a reviewer in #doc_sprint_talk. Whoever takes it: assign yourself as Reviewer. Any TW: needs peer edit Like our Needs Peer Edit column in Jira: A writer has requested a review of their PR. Review their PR in GitHub and leave comments. Whoever takes it: assign yourself as Reviewer. Waiting on SME/Blocked For PRs that are blocked by need for SME info or confirmation (for example, as Hero you are waiting on an answer from the person who sent in a Hero pull request). Waiting on TW to merge All reviews are complete. The TW who created the PR (or who is assigned the issue) needs to merge this work into develop. Drafts A draft is a way to open a PR while indicating that the work is still in progress, and not necessarily ready to merge immediately. You can't merge a Draft PR directly—you have to move it out of draft first. When you see a draft PR (especially from outside the team!), treat it as though it's a working draft and reach out to the creator to discuss. Read more on GitHub's drafts. As a Hero or Sidekick, make sure you attend to the following throughout your day: Check in with the Hero/Sidekick at the start of your day (especially on Monday at the start of the week). Don’t forget to sync with the BCN hero if necessary. Watch for incoming PRs in #docs_deploys, and review everything in the Needs triage column. Drag cards from that column to the appropriate column. Work through the cards in the Hero: to do column. Everyone on the team helps keep things moving: All writers should keep an eye on both Any TW columns. There's one column for PRs that need a simpler review before merging (typo fixes, drive-by edits, etc), and another column for PRs that need a peer edit. There are also two blocked columns: One for PRs blocked on a SME, and another column where we're waiting on the TW who created the PR to review feedback and/or merge. After merging, remove your ticket from the board. Deal with references in GitHub (and the style guide) Don't link to anything non-public from a public place. You can reference Jiras, but reference Jiras by issue key (DOC-1234 is ok) rather than a link (https://newrelic.atlassian.net/browse/DOC-1234 is not). Don't mention traffic or usage numbers publicly. Don't reference internal people by name. If they have a GH account, @mention their GH handle. If they don't, talk instead about teams (\"talk to a Browser team engineer\" or \"Support Engineer\") rather than people. You can mention the #documentation channel and hero. Merge from develop into main work (or, when do we publish?) The Hero currently merges three times a day: At 9 AM, noon, and 3 PM Pacific. Slackbot will remind us about this in #docs_deploys. The hero (or delegate) is the one who should create a PR for this and merge it. Check the edit history of a doc or file There are two options two check the history of a file: Option 1: githistory.xy Go to a specific file in GitHub itself. Example: https://github.com/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx In the url, replace github.com with github.githistory.xyz. Example: https://github.githistory.xyz/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx It will take you to a site with the visual history of that specific file. You can view changes by clicking through the commit history at the top of your page. Option 2: Git blame Follow Github's documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.90643,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "As tech doc writers (TW) we edit docs, do <em>peer</em> edits, or use the Docs Team GitHub board to track the status of issues and pull requests (PR). Who is who in an issue&#x2F;PR? GitHub keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR"
      },
      "id": "60c6a916196a67e82b5e1604"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 93.92973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "::ERR_SSL_NO_RENEGOTIATION, &quot;<em>Peer</em> sent an SSL no_renegotiation alert message&quot; -138 net::ERR_ACCESS_DENIED, &quot;Access denied&quot; -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, &quot;Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate&#x27;s private key&quot; -145 net"
      },
      "id": "6045276ee7b9d22729579a22"
    }
  ],
  "/docs/style-guide/writer-workflow/tech-writer-workflow": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/peer-editor-workflow/",
      "sections": [
        "Peer editor workflow",
        "Peer editing workflow in GitHub",
        "Developmental edit pass",
        "Copy edit workflow"
      ],
      "published_at": "2021-06-14T18:18:38Z",
      "title": "Peer editor workflow",
      "updated_at": "2021-06-14T00:56:46Z",
      "type": "docs",
      "external_id": "c5cade26eea3b846e8c6cc5f3b89552147d724be",
      "document_type": "page",
      "popularity": 1,
      "body": "Use this document to learn how to review and peer edit docs for you fellow writers in GitHub. Check the Tech Writer workflow doc for info on how to set up your local environment. To troubleshoot GitHub issues, see our guide. Peer editing workflow in GitHub If you’re peer editing a doc or have been otherwise assigned to a PR as a reviewer, you have a few choices for how and where to do the work. The most streamlined and open-source approach is to do the edit using GitHub options, rather than copying the file to Google Docs and editing there. Developmental edit pass For cases where you have questions and suggestions rather than straight copy edits, follow these steps. Open the PR that you’re assigned to review. On the Files changed tab, you can either: Click Review changes and then select one of the following: Comment - use if you have a comment that doesn’t require follow up. Approve - use if you just want to approve the PR. You can request changes in the Leave a comment area, and select Approve if you want to let the writer make the edits and merge the file without a follow-up review from you. Request changes - use for times when you want to make sure the changes you request are included. You’ll be notified with any updates that the writer makes. OR, start making comments on lines or sections of the doc. To do this, click the add comment icon , and leave an edit or comment for that specific line in the page. With this option, you get the choice between adding a single comment or starting a review. If you’re going to make comments throughout a doc, choose Start a review so the comments will all be rolled into one commit. Click Finish your review to complete your review. This triggers a notification to the writer alerting them that you’ve made suggestions. Copy edit workflow If you have copy edits for a file rather than comments and suggestions, you can make the changes to the file in different ways. Here are two main options: Edit using the GitHub browser: On the Files changed tab, in the diff window click the editing button (three dots). When you finish your edits, add a comment at the bottom of the file and choose to either commit the changes directly, or create a branch and start a pull request. Choose to branch and start a pull request if you expect a writer to review the diff and accept or revise your edits. Edit locally: Check out the branch containing the file you want to edit. In GitHub Desktop, click the Current branch down arrow and select the branch. Then, make the edits on your local drive, save, and commit your changes to the branch. Note that this approach adds your edits to the open pull request. You can now see the changes you added to the file on the Files changed tab in the PR. These are just a few of many editing options. You’ll find your preferred way, just as with any other tool.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1713.1467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Peer editor <em>workflow</em>",
        "sections": "Peer editor <em>workflow</em>",
        "body": "Use this document to learn how to review and peer edit docs for you fellow writers in GitHub. Check the <em>Tech</em> <em>Writer</em> <em>workflow</em> doc for info on how to set up your local environment. To troubleshoot GitHub issues, see our guide. Peer editing <em>workflow</em> in GitHub If you’re peer editing a doc or have been"
      },
      "id": "60c6a94ee7b9d21cd1d6779f"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-06-14T18:15:23Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.73126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> style guide"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "ba7c99eb79d6fa7ad574db5768a742a4d2084a41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-06-14T18:12:27Z",
      "updated_at": "2021-05-10T03:34:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.51387,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> style guide"
      },
      "id": "6043f591196a675446960f74"
    }
  ],
  "/docs/style-guide/writing-guidelines/code-formatting-guidelines-var-mark": [
    {
      "sections": [
        "Code examples",
        "For inline code or data (<code>)",
        "For multi-line code blocks (<pre>)",
        "Highlight user input with <var>",
        "Highlight important sections with <mark>",
        "Add syntax highlighting",
        "Link to other docs"
      ],
      "title": "Code examples",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c8690ad4669d2a9b3eadad8a7bcbc1e05ff9093c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/code-examples/",
      "published_at": "2021-06-14T19:15:01Z",
      "updated_at": "2021-03-16T09:10:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use a variety of formatting to highlight code or other technical language. You can use the <code>, <pre>, and <var> tags to indicate \"raw\" technical content such as excerpts from a config file, an API method name, or a file path. For inline code or data (<code>) To surround small blocks of code or data (single words or lines), mark as code: Source: Use <code> tags. Markdown: Surround the text with backtick ` characters. For multi-line code blocks (<pre>) To surround longer blocks of data that run multiple lines, mark as preformatted text: Source: Use <pre> tags. Markdown: Do not use Markdown-style indented code formatting, as this can cause unexpected formatting problems. Highlight user input with <var> Use the <var> tag to highlight areas of a code block where a user is expected to supply their own value. For more context on when to use <var> tags, see < var> formatting guidelines. Follow these guidelines when you use <var> tags: Address the reader directly Use all caps and underscores _ to separate words (also known as SCREAMING_SNAKE_CASE). Don't use other punctuation (such as wrapping the text in angle brackets). Exception: REST API examples use a ${VARNAME} syntax inspired by Bash conventions. Standard examples: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/APP_ID Copy REST API v2 example: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=average_call_time&values[]=call_count&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy Highlight important sections with <mark> Use the <mark> tag to highlight areas of a code block that are particularly important. Most commonly, <mark> is used to highlight New Relic API methods in sample code that contains a lot of \"other logic.\" When you use <mark>, you should usually follow the code block with a list of bullets that explain what each API call is doing and link to method syntax. For more context on when to use <mark> tags, see < mark> formatting guidelines. Examples: Example of using the <mark> tag private void storeItem(long id) { Segment segment = NewRelic.getAgent().getTransaction(). startSegment(\"storeItem\") ; segment. reportAsExternal(DatastoreParameters .product(\"H2\") .collection(null) .operation(\"insert\") .instance(\"localhost\", 8080) .databaseName(\"test\") .build()) ; // fire and forget DB_POOL.submit(() -> { segment.end() ; insertData(id); }); } Copy The agent API calls in this sample are: startSegment(...): Begins the segment that will time the code. For method syntax, see the Javadoc. reportAsExternal(DatastoreParameters()): Associates the time with a datastore external call This will show up in New Relic APM with datastore data. For more information, see reportAsExternal API. For method syntax, see the Javadoc. segment.end(): Stops timing this segment. For method syntax, see the Javadoc. Add syntax highlighting To add syntax highlighting to a code block, add class=\"highlight\" to the <pre> tag. The syntax highlighter tries to auto-detect the language. If it's not working as expected, ensure the language is supported and specify the language by adding the a lang-LANG-NAME class (for example: lang-html). View a full list of supported languages for syntax highlighting. Element colors and themes are fully customizable. Link to other docs You can add <a href> tags inside a <pre> blocks, just as you would any other content. However, make sure to use them judiciously since they can be easy to miss. A good example is the Infrastructure config file template, where each config element links to the relevant section of the main config doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.83647,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Code</em> examples",
        "sections": "<em>Code</em> examples",
        "body": " Markdown-style indented <em>code</em> <em>formatting</em>, as this can cause unexpected <em>formatting</em> problems. Highlight user input with &lt;<em>var</em>&gt; Use the &lt;<em>var</em>&gt; tag to highlight areas of a <em>code</em> block where a user is expected to supply their own value. For more context on when to use &lt;<em>var</em>&gt; tags, see &lt; <em>var</em>&gt; <em>formatting</em> <em>guidelines</em>"
      },
      "id": "6042212b28ccbc7c9eeba772"
    },
    {
      "sections": [
        "Bold or code, not italics",
        "Tip"
      ],
      "title": "Bold or code, not italics",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c4d55d70ca7e6d5a8359be160059ea2e1190cf27",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/bold-or-code-not-italics/",
      "published_at": "2021-06-14T19:15:01Z",
      "updated_at": "2021-03-16T14:49:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you'd like to emphasize text in our docs, please follow these simple guidelines: Use code for things the user is likely to copy and paste, like a file path or a command line example. Use bold for anything else you need to emphasize, like a UI name or to highlight an important word. We don't format text in our docs with italics. Here are more specific guidelines our team uses. For this... Bold Code Example APM Agent lists C SDK Go Java .NET Node.js PHP Python Ruby Command line utility names To install the utility, use apt. Emphasis Stop IIS before running the installer. File paths and file names The agent looks for newrelic.config in the %ALLUSERSPROFILE%\\New Relic\\.NET Agent directory. Insights event names and attributes To analyze APM errors, use the TransactionError event. Method names To initialize the APM agent, use startAgent(). Non-clickable URLs In your web browser, navigate to the minion Overview page at http://MINION_IP_ADDRESS. The <var> formatting automatically applies color coding and italics in this situation. Pages, paths, fields, etc. in the user interface Go to one.newrelic.com > APM > (select an app) > Transactions. For more information, see UI paths. Tip If you have a UI object (page, tab, etc.) that also has link formatting, then you don't need to add the bold formatting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.00542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Bold or <em>code</em>, not italics",
        "sections": "Bold or <em>code</em>, not italics",
        "body": " <em>format</em> text in our docs with italics. Here are more specific <em>guidelines</em> our team uses. For this... Bold <em>Code</em> Example APM Agent lists C SDK Go Java .NET Node.js PHP Python Ruby Command line utility names To install the utility, use apt. Emphasis Stop IIS before running the installer. File paths and file"
      },
      "id": "60421e1de7b9d2eadb2a0800"
    },
    {
      "sections": [
        "Java agent error configuration",
        "Common reported error examples",
        "Configure error reporting",
        "Important",
        "YAML-based configuration for error collection",
        "Enabling error collection",
        "Ignoring specific errors",
        "Preventing expected errors from affecting error rate and Apdex",
        "Error configuration precedence",
        "Ignore error classes (YAML overrides API)",
        "Report expected errors (YAML and API)",
        "Report expected errors (no YAML)",
        "YAML ignore_classes overrides API expected parameter",
        "API expected parameter overrides YAML expected_classes",
        "Ignore overrides expected in YAML",
        "Configure ignored and expected errors via UI"
      ],
      "title": "Java agent error configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "Configuration"
      ],
      "external_id": "203f95ba834e798a07dce0af8ec2de55d58f8545",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/java-agent/configuration/java-agent-error-configuration/",
      "published_at": "2021-06-14T17:20:58Z",
      "updated_at": "2021-06-14T17:20:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "APM's Java agent reports detailed information about errors that occur within your application. This gives you insight into problematic areas that may be affecting your application’s performance or the end user’s experience. With Java agent versions 3.40.0 or higher, there are several configuration options that let you control how errors are reported, including: Configuring expected errors so that they won't affect error rate or Apdex Ignoring errors Reporting errors that are not reported automatically For more information on viewing your error data, see Error analytics. For an overview of error data in all agents, see Manage errors in APM. Common reported error examples The Java agent reports errors in the following scenarios: Error reporting Comments Unhandled errors (includes stack trace) If an unhandled error occurs within a transaction that the Java agent was tracing, the error will be reported with the full stack trace. HTTP status codes (no stack trace) If a transaction results in an HTTP status code, the error will be reported without the stack trace. This is because: The application server detected an error condition and explicitly set the status code. OR The error condition was detected by program logic, and thus there was no exception object or stack. In order to include the stack trace with these types of transactions, you must use a noticeError(...) API call. noticeError(...) API calls If the Java agent makes an explicit call using the noticeError(...) API call, the error will be reported regardless of whether or not it occurs within a transaction. The reported information depends on the parameters used in the noticeError(...) API call, as described in the Javadocs. Unscoped errors reporting over 100% The Java agent can report unscoped errors, which are errors that are not tied to any transaction. Because of this, it is possible to have one transaction in a timeslice and multiple errors in the same timeslice. In this situation, New Relic would then show an error rate over 100%. Configure error reporting Important In order to use this feature, upgrade to the latest release (Java agent 3.40.0 or higher). The Java agent provides several flexible configuration options to control how errors are reported. Config options Details Configure errors via the UI. You can ignore errors or mark them as expected via server-side config. Configure as expected errors via newrelic.yml. Errors reported by these versions of noticeError can be configured as expected errors in the newrelic.yml. Calls to this API will be overridden if the error is configured as ignored in newrelic.yml. For details, see Error configuration precedence. Use these noticeError() API calls to report errors that are not reported automatically and configure them as expected errors in newrelic.yml: noticeError(String message) Copy noticeError(String message, Map<String, String> params) Copy noticeError(Throwable throwable) Copy noticeError(Throwable throwable, Map<String, String> params) Copy Override expected errors via newrelic.yml. Errors reported by these versions of noticeError will override the newrelic.yml expected error configuration. Calls to this API will be overridden if the error is configured as ignored in the yml. For details, see Error configuration precedence. Use these noticeError(...) API calls to report errors that are not reported automatically and configure them as expected errors with the API (overrides yml expected error configuration): noticeError(String message, boolean expected) Copy noticeError(String message, Map<String, String> params, boolean expected) Copy noticeError(Throwable throwable, boolean expected) Copy noticeError(Throwable throwable, Map<String, String> params, boolean expected) Copy Ignore or expect errors via config file. In versions 3.40.0 or higher, you can control how errors are reported by using the YAML-based configuration. This allows you to ignore errors or expect errors based on HTTP status codes or based on a list of exception class names plus an optional error message. Ignoring errors prevents the specified exception classes or codes from being reported to APM at all. Expecting errors prevents the specified exception classes or codes from affecting your application's error rate and Apdex score. This allows you to retain the error information for troubleshooting purposes while avoiding alerts based on error rate or Apdex score. These settings are dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. For more information and examples, see the Java agent config file. YAML-based configuration for error collection YAML-based configuration for error collection allows you to entirely ignore specific errors or exempt expected errors from affecting your application’s error rate and Apdex score. You can mark errors as ignored or expected based on the following criteria: A given range of HTTP status codes, presented as a comma-separated list or dashed range A comma-separated list using the fully qualified name of a package/class and an optionally provided error message string Enabling error collection By default, the Java agent includes an error_collector stanza under which all YAML-based error configuration options will be found. Error collection can be enabled or disabled as follows: error_collector: enabled: true Copy Ignoring specific errors Errors that are not of any particular interest can be ignored entirely. By identifying errors to ignore: They will not be reported to APM. They will not affect your application's error rate or Apdex score Here is an example showing the YAML-based configuration options for ignoring errors: error_collector: enabled: true ignore_classes: - \"com.example.ErrorClassToIgnore\" ignore_messages: com.example.OtherErrorClassToIgnore: - \"some error message to ignore\" ignore_status_codes: 404,507-511 Copy Preventing expected errors from affecting error rate and Apdex Errors that are expected as part of an application's business logic can be prevented from affecting error rate or Apdex score yet still be reported to APM. This allows you to retain the error information in the UI for troubleshooting purposes while avoiding alerts (based on error rate and Apdex score) caused by these errors. Here is an example showing the YAML-based configuration options for expected errors: error_collector: enabled: true expected_classes: - \"com.example.ExpectedErrorClass\" expected_messages: com.example.OtherExpectedErrorClass: - \"some expected error message\" expected_status_codes: 406,500-504 Copy Error configuration precedence The priority for errors configuration is: Server-side configuration (overlays values onto YAML file) ignore_* config in the YAML expected parameter in the noticeError(..) API call expected_* config in the YAML Here are examples of the results when combining various API calls and YAML configurations. Ignore error classes (YAML overrides API) YAML configuration: error_collector: ignore_classes: - \"com.example.ErrorClass\" Copy and API call: noticeError(com.example.ErrorClass) Copy Result: The YAML ignore_classes overrides the noticeError API call, and the error is ignored. Report expected errors (YAML and API) YAML configuration: error_collector: expected_classes: - \"com.example.ErrorClass\" Copy AND API call: noticeError(com.newrelic.Exception) Copy Result: The expected parameter in the noticeError API call is true by default, and the YAML expected_classes configuration contains an error class. Therefore, the error is reported and marked as expected. Report expected errors (no YAML) No YAML configuration AND API call: noticeError(com.newrelic.Exception, expected = true) Copy Result: The error is reported and marked as expected. YAML ignore_classes overrides API expected parameter YAML configuration: error_collector: ignore_classes: - \"com.example.ErrorClass\" Copy AND API call: noticeError(com.newrelic.Exception, expected = true) Copy Result: The YAML ignore_classesoverrides the expected parameter in the noticeError API call, so the error is ignored. API expected parameter overrides YAML expected_classes YAML configuration: error_collector: expected_classes: - \"com.example.ErrorClass\" Copy AND API call: noticeError(com.newrelic.Exception, expected = false) Copy Result: The expected parameter in the noticeError API call overrides expected_classes in the YAML. Therefore, the error is reported as normal (not marked as expected). Ignore overrides expected in YAML YAML configuration: error_collector: ignore_classes: - \"com.example.ErrorClass\" Copy AND Additional YAML configuration: error_collector: expected_classes: - \"com.example.ErrorClass\" Copy Result: The YAML ignore_classes/ignore_messages overrides the YAML expected_classes/expected_messages, so the error is ignored. This same principle applies to ignore_status_codes and expected_status_codes. Configure ignored and expected errors via UI To configure expected errors via the APM UI: If it is not already enabled, enable server-side configuration. Go to the server-side configuration menu for the application with errors you want to mark as expected. Under Error collection, for either Ignore or Exclude expected errors, enter the HTTP code or the error class for errors you want to configure. Select Save. For information on how to view expected errors in the UI, see View expected errors.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 74.537415,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Preventing expected errors from affecting error rate <em>and</em> Apdex",
        "body": ", enable server-side configuration. Go to the server-side configuration menu for the application with errors you want to <em>mark</em> as expected. Under Error collection, for either Ignore or Exclude expected errors, enter the HTTP <em>code</em> or the error class for errors you want to configure. Select Save. For information on how to view expected errors in the UI, see View expected errors."
      },
      "id": "603eb58f196a677167a83d92"
    }
  ],
  "/docs/style-guide/writing-guidelines/create-edit-content": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/get-started/introduction-style-guide/",
      "sections": [
        "Introduction to the style guide",
        "Organize your doc to make it easier to read",
        "Use action-oriented titles",
        "Start the document with an introductory paragraph",
        "Keep documents short",
        "Use the New Relic voice",
        "Change doc titles and anchors",
        "Create and edit categories",
        "Start writing and editing docs"
      ],
      "published_at": "2021-06-14T18:12:28Z",
      "title": "Introduction to the style guide",
      "updated_at": "2021-04-12T11:26:22Z",
      "type": "docs",
      "external_id": "b0bfbe0b3791c4feb00fe86a41e49312cd9e82cd",
      "document_type": "page",
      "popularity": 1,
      "body": "We've written these guidelines to make it easier for you to contribute to our docs, as well as to give you some insight into how we think about good technical writing. We, the Tech Docs team, rely on your expertise to keep New Relic's documentation updated and useful. Thank you for your willingness to share your knowledge! Our style guide focuses on style and usage that's particular to our site. Our site follows American English conventions. For topics that aren't covered, please refer to the Microsoft Writing Style Guide (for guidelines on technical terminology) or the Chicago Manual of Style (for general writing and editing guidelines). Organize your doc to make it easier to read Consider these organization guidelines when thinking about the order of information in a doc. By following these guidelines, you'll make it easier for readers to skim and find what they need. How to organize information Comments Separate what and why from how. Define any necessary prerequisites, policies, or background information (the what and the why) before you step through the how (step-by-step procedures). Examples: Explain what the feature is and why it matters before telling readers how to use it. Describe any limitations with user permissions or subscription levels that would prevent them from using the feature. If the feature is available for any user or subscription level, don't bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting a procedure that they have everything they need. Front-load directions with context. Make sure readers know where they need to be, before telling them what to do. In general, use (select an app) to describe what users select from the product index. Examples: Go to one.newrelic.com > Explorer > (select an app or service). Select (account dropdown) > User preferences. On the command line, type gitk. Also, structure steps by front-loading context from the user's point of view. For example, instead of \"Go to x to do y,\" structure the step as \"To do y, go to x.\" Separate requirements from options. Example: Type the Email you use to sign in and to receive information from New Relic. Optional: Type additional user emails, separated by commas. Follow the \"five to nine\" guideline. Depending on the topic, organize the information so there is a maximum of five to nine chunks of information. For example, readers may start to get lost or overwhelmed after about five h2 sections or seven steps into a procedure. If you have more than nine h2 sections or steps, you might need to create an additional doc or procedure. Other organization tools to consider: Levels of headings Lists Collapsers Callouts Tables Code examples For more help section Use action-oriented titles Wherever possible, give your document or h2 heading a task- or action-oriented title. Focus on what users are trying to accomplish or the problem they're trying to solve. Use present-tense verbs, rather than \"-ing\" verbs. Quality Title example Bad The query history Okay View query history Good Query history: Create and edit NRQL queries Start the document with an introductory paragraph Unless the document is less than a single screen in length, begin with a brief paragraph that introduces the topic or summarizes the important points. Not sure where to start? Try writing all the content for your document first, and then add the introduction to the top to summarize your key points. Or use the introduction to expand on the text in your metaDescription in the metadata. Keep documents short The amount of content needed can help you decide whether you need one or more documents for the topic. If all of the document's contents apply directly to the title, then everything belongs in the same document. If several related sections could be logically split into individual documents, and the overall length of your document is more than about two screenfuls, split those sections into other documents. Be sure to include links to the related contents. If a large document needs to be broken into multiple smaller documents, consider whether they might be best grouped together in their own sub-category. Use the New Relic voice We strive for a voice that's approachable, expert, and visionary. Check out our voice guidelines for how to write content with these qualities. And keep in mind these essential writing tips that apply to any type of documentation. Guidelines Comments Be clear and direct. Remember to: Use present tense. Use active voice; avoid passive voice. Tell users what to do, not what they \"should\" do. If absolutely necessary, tell users what not to do in situations where unexpected results may occur. Whenever possible, provide an alternative suggestion when telling users what not to do. Example: Using active voice with an alternative suggestion for what not to do Do not use your config file to change this setting, because this could affect other processes. Instead, go to one.newrelic.com > APM > (select an app or service) > Settings > Application. Write to aid localization and translation. Do not use euphemisms, idioms, jargon, or slang. Use the same terms and wording consistently. If you need to include an abbreviation or acronym, spell it out the first time it appears in the document. Always take a moment to ask yourself whether people will really understand the terms you are using in the way you're using them. Change doc titles and anchors Because changes to doc titles, anchors, and redirects can break links to other docs, please create an issue to request these types of changes and we'll help you out with that. Create and edit categories Because changes to categories can affect large groups of docs at once, please create an issue to request these types of changes and we'll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see Create and edit content. To learn how to create and publish release notes, see Create release notes. To make it even easier to start a new doc, use templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 430.06024,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Create</em> <em>and</em> <em>edit</em> categories",
        "body": " large groups of docs at once, please <em>create</em> an issue to request these types of changes and we&#x27;ll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see <em>Create</em> and <em>edit</em> <em>content</em>. To learn how to <em>create</em> and publish release notes, see <em>Create</em> release notes. To make it even easier to start a new doc, use templates."
      },
      "id": "60415293e7b9d262f32a07d7"
    },
    {
      "sections": [
        "Monitor services running on Amazon ECS",
        "Requirements",
        "How to enable",
        "Step 1: Enable EC2 to install the infrastructure agent",
        "For CentOS 6, RHEL 6, Amazon Linux 1",
        "CentOS 7, RHEL 7, Amazon Linux 2",
        "Step 2: Enable monitoring of services"
      ],
      "title": "Monitor services running on Amazon ECS",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "dc178f5c162c1979019d97819db2cc77e0ce220a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs/",
      "published_at": "2021-06-15T11:57:52Z",
      "updated_at": "2021-06-15T11:57:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have services that run on Docker containers in Amazon ECS (like Cassandra, Redis, MySQL, and other supported services), you can use New Relic to report data from those services, from the host, and from the containers. Requirements To monitor services running on ECS, you must meet these requirements: An auto-scaling ECS cluster running Amazon Linux, CentOS, or RHEL that meets the infrastructure agent compatibility and requirements. ECS tasks must have network mode set to none or bridge (awsvpc and host not supported). A supported service running on ECS that meets our integration requirements: Apache (does not report inventory data) Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ (does not report inventory data) Redis SNMP How to enable Before explaining how to enable monitoring of services running in ECS, here's an overview of the process: Enable Amazon EC2 to install our infrastructure agent on your ECS clusters. Enable monitoring of services using a service-specific configuration file. Step 1: Enable EC2 to install the infrastructure agent First, you must enable Amazon EC2 to install our infrastructure agent on ECS clusters. To do this, you'll first need to update your user data to install the infrastructure agent on launch. Here are instructions for changing EC2 launch configuration (taken from Amazon EC2 documentation): Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. Replace user data with one of the following snippets: For CentOS 6, RHEL 6, Amazon Linux 1 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy CentOS 7, RHEL 7, Amazon Linux 2 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_ECS_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop-down menu for Launch configuration, select the new launch configuration created. Click Save. To test if the agent is automatically detecting instances, terminate an EC2 instance in the auto scaling group: the replacement instance will now be launched with the new user data. After five minutes, you should see data from the new host on the Hosts page. Next, move on to enabling the monitoring of services. Step 2: Enable monitoring of services Once you've enabled EC2 to run the infrastructure agent, the agent starts monitoring the containers running on that host. Next, we'll explain how to monitor services deployed on ECS. For example, you can monitor an ECS task containing an NGINX instance that sits in front of your application server. Here's a brief overview of how you'd monitor a supported service deployed on ECS: Create a YAML configuration file for the service you want to monitor. This will eventually be placed in the EC2 user data section via the AWS console. But before doing that, you can test that the config is working by placing that file in the infrastructure agent folder (etc/newrelic-infra/integrations.d) in EC2. That config file must use our container auto-discovery format, which allows it to automatically find containers. The exact config options will depend on the specific integration. Check to see that data from the service is being reported to New Relic. If you are satisfied with the data you see, you can then use the EC2 console to add that configuration to the appropriate launch configuration, in the write_files section, and then update the auto scaling group. In the runcmd section, add the yum command to install the integration to the appropriate launch configuration. Here's a detailed example of doing the above procedure for NGINX: Ensure you have SSH access to the server or access to AWS Systems Manager Session Manager. Log in to the host running the infrastructure agent. Via the command line, change the directory to the integrations configuration folder: cd /etc/newrelic-infra/integrations.d Copy Create a file called nginx-config.yml and add the following snippet: --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 Copy This configuration causes the infrastructure agent to look for containers in ECS that contain nginx. Once a container matches, it then connects to the NGINX status page. For details on how the discovery.ip snippet works, see auto-discovery. For details on general NGINX configuration, see the NGINX integration. If your NGINX status page is set to serve requests from the STATUS_URL on port 80, the infrastructure agent starts monitoring it. After five minutes, verify that NGINX data is appearing in the Infrastructure UI (either: one.newrelic.com > Infrastructure > Third party services, or one.newrelic.com > Explorer > On-host). If the configuration works, place it in the EC2 launch configuration: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. In the User data section, edit the write_files section (in the part marked text/cloud-config). Add a new file/content entry: - content: | --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 path: /etc/newrelic-infra/integrations.d/nginx-config.yml Copy Also edit the runcmd section to include the yum command to install nri-nginx: runcmd: - [ yum, install, newrelic-infra, -y ] - [ yum, install, nri-nginx, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop down menu for Launch configuration, select the new launch configuration created. Click Save. When an EC2 instance is terminated, it is replaced with a new one that automatically looks for new NGINX containers.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.72974,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click <em>Edit</em> details. In the User data section, <em>edit</em> the write_files section (in the part marked text&#x2F;cloud-config). Add a new file&#x2F;<em>content</em> entry: - <em>content</em>: | --- discovery: docker: match: image: &#x2F;nginx"
      },
      "id": "60450959e7b9d2475c579a0f"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/tech-writer-workflow/",
      "sections": [
        "Tech Writer workflow",
        "Resources",
        "Edit in the UI vs local build",
        "Work on a branch, not a fork",
        "Set up your local environment",
        "Run the site locally",
        "Prerequisites",
        "Build the site",
        "Edit a doc",
        "Commit your changes",
        "Publish your commits",
        "Open your pull request",
        "Preview a doc",
        "Revise and publish a doc",
        "Revert merging"
      ],
      "published_at": "2021-06-14T18:18:38Z",
      "title": "Tech Writer workflow",
      "updated_at": "2021-06-14T00:55:51Z",
      "type": "docs",
      "external_id": "074905b02af0ab6eb53640c1c80e83296a8a0b02",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the UI vs local build Need to edit a doc? Use this table to decide where to work! Use the UI for: Use the local build for: Adding content to one doc: Rewriting sentences, or 1-2 lines Editing small amounts of content: updating URLs, deleting typos, etc. Brand new docs Rewrites of more than 1 or 2 lines Any updates to doc frontmatter Title changes Taxonomy changes Metadescription updates Redirects Updating images Editing multiple docs at once Continue reading for instructions on how to edit a doc locally. Work on a branch, not a fork Some teams work on branches, some teams work on forks; the docs team works in branches. As long as a branch has been pushed upstream, this allows us to work collaboratively and ensure that no work is ever lost when someone goes on vacation. To create a branch on the docs-website repo: Open GitHub Desktop Click on Current branch: xxx Click on New Branch You will be prompted to name your new branch. Descriptive names are best. It's a great way to quickly clue people in to what your work is all about. For example, if you are working on What’s New pages, you might name the branch Whats-new-updates. When you create a new branch, don't forget to add the Jira issue's key (DOC-1234) to the branch name and the PR title. Set up your local environment Install GitHub Desktop, and then navigate to GitHub Desktop's preferences. On Macs, click on GitHub Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Once GitHub Desktop is set up, navigate to the Docs Site repository on GitHub. Click the green Code button and then select Open with GitHub Desktop. Choose the location where you want the repo, and this will clone the entire repository to your local machine at the designated path. You can ensure the repo was cloned by navigating to your local GitHub folder (the default is ~/Documents/github). Once you have cloned the repo, you don't need to clone it again in the future. Run the site locally Build the site locally using the terminal to preview changes before opening a Pull Request. While it's highly recommended to build the site locally, this is technically an optional step. The site will automatically reflect any local changes once build. Node and Yarn are tools used to build the site on your local machine. Prerequisites Install Node Install Yarn npm install -g yarn Build the site In your terminal, go to your cloned repo, docs-website. cd ~/Documents/github/docs-website Run yarn with the following commands: yarn && yarn start The site will take a few minutes to build. Make yourself some tea or coffee. Once it's built, you can access your preview site in your browser by navigating to http://localhost:8000/ Edit a doc Once your local environment and branch are set up, you're ready to edit a doc. Check out the style guide for writing guidelines. First, ensure your Current Branch in GitHub Desktop is set to the correct branch, not Develop. Navigate to the doc you want to edit in Finder. If I wanted to edit a Python agent doc, I would navigate to: ~/Documents/github/docs-website/src/content/docs/agents/python-agent/hosting-services/python-agent-stackato.mdx Edit the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help with formatting markdown Save the file with your edits, then follow the same process for any other docs you wish to edit. Commit your changes Once your edits are done, you can commit them. This stages your changes, which you will later push upstream to Github. By pushing your changes, everyone will have access to your branch and commits. Navigate to GitHub Desktop. The left column should have a record of all the edits you have made to docs. In the bottom left corner, name your commit and add a good description of your edits. It should be descriptive enough to ensure that someone can understand all the changes made by simply scanning this description. Click Commit to [yourbranchname] Publish your commits Once you have committed your changes, you're almost ready to open your Pull Request. First, you need to ensure your branch is pushed upstream. On GitHub desktop, click the blue Publish Branch button if available. If you don't see the Publish Branch, click the blue Push Origin button. This will push all your commits upstream and make them available to everyone else through the GitHub repository. Open your pull request Now that your commits are available to everyone, you need to notify people that your changes are ready to be merged into the develop branch. To do this, you open a pull request: On GitHub Desktop, click the blue Create Pull Request button. This will open GitHub in your browser, and prompt you to fill in your pull request. Ensure you are merging from your branch into either the main or develop branch. If you scroll down, you can review all your commits to ensure they reflect all your changes. Just like your commit description, your pull request description should be detailed and give the full context of your changes. Feel free to add any additional context here (issue or Jira number, SMEs, etc.) Once you are satisfied with your pull request, click the green Create pull request button. You can either publish the changes directly by approving the pull request yourself, or you can request for another Tech Writer to peer edit it. To request a review from another Tech Writer: in GitHub open the PR, navigate to the conversation Conversation, and then select or type in a reviewer name in the Reviewer section. At the bottom the pull request page, you will see a Checks section. These checks ensure your PR does not break the build process of the site. Ensure all these checks pass before proceeding. The checks should finish within twenty minutes. If the Pull Request is urgent, you can skip the AWS Amplify Console Web Preview check. Once the pull request has passed the checks and it has been approved by another tech writer (or you are confident the changes are ready to be published), click the green Merge pull request button. This will merge your branch and commits into the repository and will begin the build process. Preview a doc There are two main ways to preview branches you’ve already published and run commits on: Local: Quicker, but requires a semi-substantial amount of setup and familiarity with a terminal. Amplify: Full preview of the live site with no overhead, although it takes a long time (from 30 minutes tp up to 1.5 hours!) to build on a PR. It's easily shareable with SMEs and others. Revise and publish a doc If you’re notified that a reviewer has submitted a review to your file, go to your PR and review the changes. You might see them in the diff view, if they’re part of a review with comments; otherwise, they might appear as copy edits in the file. Respond to any comments in the file. Either reply with follow up discussion, or click Resolve conversation. When you’ve resolved all the comments, and all of the automatic checks have passed, you can merge the pull request. Merging the pull request sets in motion the automated build process and your changes will be published shortly. Note: You will only be able to merge when the Merge pull request button is green. If it’s not green, review for any comments you missed, or other messages that indicate why GitHub is blocking you from merging. Revert merging Remember that you can almost always undo things. If you merge a PR, and then find that you shouldn’t have, you can unmerge with the Revert button. On the Pull requests tab in GitHub, click Closed on the tally bar to see all the issues and PRs that have alredy been merged. Locate the PR you merged, and locate the Revert button. Click Revert. That creates a new PR, which needs to be merged. If you want to reopen it, you need to follow the link back to the original PR and either revert that or reopen it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.425865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Edit</em> in the UI vs local build",
        "body": ". If I wanted to <em>edit</em> a Python agent doc, I would navigate to: ~&#x2F;Documents&#x2F;github&#x2F;docs-website&#x2F;src&#x2F;<em>content</em>&#x2F;docs&#x2F;agents&#x2F;python-agent&#x2F;hosting-services&#x2F;python-agent-stackato.mdx <em>Edit</em> the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help"
      },
      "id": "60c6a91764441f404d91f8c6"
    }
  ],
  "/docs/style-guide/writing-guidelines/docs-translation": [
    {
      "sections": [
        "Create smoother charts with sliding windows",
        "When to use sliding windows",
        "Valid NRQL syntax for SLIDE BY",
        "Translation from PromQL-style queries",
        "Use SLIDE BY with MAX and AUTO",
        "Tip"
      ],
      "title": "Create smoother charts with sliding windows",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "97fe07b51e5f2c6a2868c924d1c829d82fd8f585",
      "image": "https://docs.newrelic.com/static/9d882293c1b7b04e65b4bcf6f3ae4bbf/e5166/SlidingWindow2.jpg",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows/",
      "published_at": "2021-06-15T16:36:58Z",
      "updated_at": "2021-03-16T13:22:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Sliding windows are a technique for generating charts using the SLIDE BY clause in conjunction with the TIMESERIES clause. With sliding windows, data is gathered in time \"windows\" that overlap with each other. For example, in the image below, a query gathers data with 5 minute windows. The windows \"slide\" by 1 minute. Each window overlaps with the previous window by 4 minutes. 5-minute windows with 1-minute \"slide\" In contrast, with \"tumbling\" or \"cascading\" windows, the windows do not overlap. For example, in this TIMESERIES 3 minutes NRQL query, the windows are 3 minutes in length, with each beginning when the other ends. There is no overlap in the measurement interval. 3-minute windows with no overlap or \"slide\". When to use sliding windows Sliding windows are helpful when you need to smooth out \"spiky\" charts. One common use case is to use sliding windows to smooth line graphs that have a lot of variation over short periods of time in cases where the rolling aggregate (for example a rolling mean) is more important than aggregates from narrow windows of time. In the example below, data varies greatly from one minute to another, so the 1-minute tumbling window chart shows many high peaks and low valleys. TIMESERIES query without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The query returns similar data but creates a much smoother chart. TIMESERIES query with SLIDE BY clause Valid NRQL syntax for SLIDE BY Valid NRQL syntax for the SLIDE BY clause will follow the format below. SELECT ... TIMESERIES integer1 units SLIDE BY integer2 units Copy integer1 specifies the sliding window width and integer2 specifies the SLIDE BY interval. units is a time unit, such as second, minute, hour, or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy Translation from PromQL-style queries When applicable, a PromQL-style query is translated into a NRQL sliding window query. For example, if your PromQL style query uses rate(request_count[5m]) for the past 60 minutes with a 1-minute window overlap, the NRQL translation would be the query below. SELECT rate(sum(request_count), 1 SECONDS) FROM Metric SINCE 3600 SECONDS AGO UNTIL NOW FACET dimensions() LIMIT 100 TIMESERIES 300000 SLIDE BY 60000 Copy In the translation output, the default unit of millisecond is used for TIMESERIES and SLIDE BY clauses. For TIMESERIES, 300000 ms is 300 seconds, or 5 minutes, specifying a window size of 5 minutes. For SLIDE BY, 60000 ms is 60 seconds, specifying a slide interval of 1 minute. Use SLIDE BY with MAX and AUTO You can combine SLIDE BY with MAX and AUTO arguments to further tailor query results, as shown in the examples below. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy Tip When paired with SLIDE BY, TIMESERIES does not support AUTO or MAX. The TIMESERIES value must be an integer time unit value. In other words, SLIDE BY AUTO or SLIDE BY MAX will work, but TIMESERIES AUTO or TIMESERIES MAX followed by SLIDE BY and MAX, AUTO, or a specific integer time unit is not supported. Tip The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which will show up as gaps and unexpected results. If you experience these issues with query results, consider checking for instances of SLIDE BY where the step interval exceeds the window size.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 60.076992,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Translation</em> from PromQL-style queries",
        "body": ", or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy <em>Translation</em> from PromQL-style queries When applicable"
      },
      "id": "603e8a2528ccbc56e5eba774"
    },
    {
      "sections": [
        "Update the home page",
        "Update a link's URL",
        "Add a new tile to the home page",
        "Add a new section to the home page"
      ],
      "title": "Update the home page",
      "type": "docs",
      "tags": [
        "home page",
        "landing pages"
      ],
      "external_id": "d637697a72493d8dbe0c9538e5b35f13f62d7474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/edit-homepage/",
      "published_at": "2021-06-14T18:13:18Z",
      "updated_at": "2021-04-11T08:27:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can't just hit the edit button docs.newrelic.com to make edits to the home page. The page that opens is index.js, the file that manages the parts of the home page, but not the content. It's rare that you'll need to make changes to this file. Most home page changes will be to add a new tile or section to the page, or update links. These types of changes are handled in two files: src/data/homepage.yml - contains home page section titles, section descriptions, and the URLs for tiles. src/i18n/translations/en/translation.json - contains tile info, including the title and short description of tiles. Update a link's URL Change or add new links using homepage.yml. In homepage.yml, search for the link you want to change. Edit the URL, save, commit, and PR the change. Add a new tile to the home page You'll make changes to both homepage.yml and translations.json On the translations.json doc, find the spot where you want to add the new tile (which section, and in what order you want it to appear), and add a new entry with this format: \"t#\": { \"title\": \"tile name\", \"description\": \"Short description.\" }, Copy Make sure you update the number on the tile. If you want to insert it in the middle of a group, update all the subsequent tile numbers as well. Save the file. Open homepage.yml, find the spot where the new tile will be, and add a new line with the relative link for the new tile. For example, - /docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster Save and check that your new tile builds properly on a local build. Commit, push, PR when you're ready. Add a new section to the home page On the translations.json page, add a new section modeled in the spot where you want the new section to appear. Include at least one title. For example, here's the TDP entry, with one tile: \"tdp\": { \"title\": \"Telemetry Data Platform\", \"description\": \"Ingest, visualize, and alert on all your telemetry data in one place.\", \"t1\": { \"title\": \"Introduction to Telemetry Data Platform\", \"description\": \"How to manage all your monitoring in one place.\" }, Copy When you're done creating the info, save the file. In the homepage.yml page, find the corresponding location for the new section, and add the short name you provided in the translation.json file, title, description, and tile URLs. For example, here's the corresponding TDP section on homepage.yml. tdp: title: Telemetry Data Platform description: Ingest, visualize, and alert on all your telemetry data in one place. tiles: - /docs/data-ingest-apis/get-data-new-relic/getting-started/get-started-telemetry-data-platform Copy Save, build locally, commit, PR.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 55.768562,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "You can&#x27;t just hit the edit button <em>docs</em>.newrelic.com to make edits to the home page. The page that opens is index.js, the file that manages the parts of the home page, but not the content. It&#x27;s rare that you&#x27;ll need to make changes to this file. Most home page changes will be to add a new tile"
      },
      "id": "6072b300e7b9d231b2a5c663"
    },
    {
      "sections": [
        "iOS and tvOS crash reporting",
        "dSYM files",
        "Debug the crash reporter",
        "Disable crash reporting"
      ],
      "title": "iOS and tvOS crash reporting",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Configuration"
      ],
      "external_id": "b2b79e6f9e78f6113bb20032c674996c746e14d4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/configuration/ios-tvos-crash-reporting/",
      "published_at": "2021-06-14T21:38:56Z",
      "updated_at": "2021-03-16T09:52:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For Mobile version 4 or higher, New Relic produces crash reports for your mobile applications. When an iOS or tvOS application crashes, the operating system creates a crash report and stores it on the device. New Relic uploads this report the next time the app launches. Using this report and any relevant dSYM files, the crash report includes the complete stack trace with human-readable information. You can then log into New Relic and see each crash, including the method and line where it crashed, plus device and environment details. dSYM files When you create a release build of an iOS or tvOS application, the names of methods and classes are stripped, leaving only machine-readable memory addresses. When the application crashes, the stack trace consists of this machine-readable code. A dSYM file is an Xcode project file for debug symbols. It contains the debugging symbols that allow for translation of the initial crash report to human-readable information. This process is known as symbolication. New Relic has dynamic framework support for dSYM uploading. If your app uses a dynamic framework with multiple dSYM files, New Relic automatically uploads and uses those files. For more information, see Retrieve and download dSYMs or Upload dSYM files. Debug the crash reporter Crash reporting is enabled by default, but there are some circumstances where it will be disabled: If the debugger is enabled: There can only be one uncaught exception handler registered at a time per application. If running with the debugger attached, New Relic will not capture and report crashes. If another crash reporter is enabled: If another uncaught exception handler is registered after New Relic starts, this error message is logged: The New Relic exception handler has been replaced. This may result in crashes no longer reporting to New Relic. Copy Disable crash reporting To disable New Relic crash reporting, call the following API method: Language Procedure Objective-C Call prior to [NewRelic startWithApplicationToken:...]; [NewRelic disableFeatures:NRFeatureFlag_CrashReporting]; Copy Swift Call prior to NewRelic.start(withApplicationToken:) NewRelic.disableFeatures(NRMAFeatureFlags.NRFeatureFlag_CrashReporting) Copy For more information about this call, see the NewRelic.h file. For more on applicable feature flags, see the NewRelicFeatureFlags.h file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 43.313297,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " for <em>translation</em> of the initial crash report to human-readable information. This process is known as symbolication. New Relic has dynamic framework support for dSYM uploading. If your app uses a dynamic framework with multiple dSYM files, New Relic automatically uploads and uses those files. For more"
      },
      "id": "603ec58128ccbc9b51eba7d2"
    }
  ],
  "/docs/style-guide/writing-guidelines/five-questions-help-write-docs": [
    {
      "sections": [
        "Monitor services running on Amazon ECS",
        "Requirements",
        "How to enable",
        "Step 1: Enable EC2 to install the infrastructure agent",
        "For CentOS 6, RHEL 6, Amazon Linux 1",
        "CentOS 7, RHEL 7, Amazon Linux 2",
        "Step 2: Enable monitoring of services"
      ],
      "title": "Monitor services running on Amazon ECS",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "dc178f5c162c1979019d97819db2cc77e0ce220a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs/",
      "published_at": "2021-06-15T11:57:52Z",
      "updated_at": "2021-06-15T11:57:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have services that run on Docker containers in Amazon ECS (like Cassandra, Redis, MySQL, and other supported services), you can use New Relic to report data from those services, from the host, and from the containers. Requirements To monitor services running on ECS, you must meet these requirements: An auto-scaling ECS cluster running Amazon Linux, CentOS, or RHEL that meets the infrastructure agent compatibility and requirements. ECS tasks must have network mode set to none or bridge (awsvpc and host not supported). A supported service running on ECS that meets our integration requirements: Apache (does not report inventory data) Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ (does not report inventory data) Redis SNMP How to enable Before explaining how to enable monitoring of services running in ECS, here's an overview of the process: Enable Amazon EC2 to install our infrastructure agent on your ECS clusters. Enable monitoring of services using a service-specific configuration file. Step 1: Enable EC2 to install the infrastructure agent First, you must enable Amazon EC2 to install our infrastructure agent on ECS clusters. To do this, you'll first need to update your user data to install the infrastructure agent on launch. Here are instructions for changing EC2 launch configuration (taken from Amazon EC2 documentation): Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. Replace user data with one of the following snippets: For CentOS 6, RHEL 6, Amazon Linux 1 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy CentOS 7, RHEL 7, Amazon Linux 2 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_ECS_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop-down menu for Launch configuration, select the new launch configuration created. Click Save. To test if the agent is automatically detecting instances, terminate an EC2 instance in the auto scaling group: the replacement instance will now be launched with the new user data. After five minutes, you should see data from the new host on the Hosts page. Next, move on to enabling the monitoring of services. Step 2: Enable monitoring of services Once you've enabled EC2 to run the infrastructure agent, the agent starts monitoring the containers running on that host. Next, we'll explain how to monitor services deployed on ECS. For example, you can monitor an ECS task containing an NGINX instance that sits in front of your application server. Here's a brief overview of how you'd monitor a supported service deployed on ECS: Create a YAML configuration file for the service you want to monitor. This will eventually be placed in the EC2 user data section via the AWS console. But before doing that, you can test that the config is working by placing that file in the infrastructure agent folder (etc/newrelic-infra/integrations.d) in EC2. That config file must use our container auto-discovery format, which allows it to automatically find containers. The exact config options will depend on the specific integration. Check to see that data from the service is being reported to New Relic. If you are satisfied with the data you see, you can then use the EC2 console to add that configuration to the appropriate launch configuration, in the write_files section, and then update the auto scaling group. In the runcmd section, add the yum command to install the integration to the appropriate launch configuration. Here's a detailed example of doing the above procedure for NGINX: Ensure you have SSH access to the server or access to AWS Systems Manager Session Manager. Log in to the host running the infrastructure agent. Via the command line, change the directory to the integrations configuration folder: cd /etc/newrelic-infra/integrations.d Copy Create a file called nginx-config.yml and add the following snippet: --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 Copy This configuration causes the infrastructure agent to look for containers in ECS that contain nginx. Once a container matches, it then connects to the NGINX status page. For details on how the discovery.ip snippet works, see auto-discovery. For details on general NGINX configuration, see the NGINX integration. If your NGINX status page is set to serve requests from the STATUS_URL on port 80, the infrastructure agent starts monitoring it. After five minutes, verify that NGINX data is appearing in the Infrastructure UI (either: one.newrelic.com > Infrastructure > Third party services, or one.newrelic.com > Explorer > On-host). If the configuration works, place it in the EC2 launch configuration: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. In the User data section, edit the write_files section (in the part marked text/cloud-config). Add a new file/content entry: - content: | --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 path: /etc/newrelic-infra/integrations.d/nginx-config.yml Copy Also edit the runcmd section to include the yum command to install nri-nginx: runcmd: - [ yum, install, newrelic-infra, -y ] - [ yum, install, nri-nginx, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop down menu for Launch configuration, select the new launch configuration created. Click Save. When an EC2 instance is terminated, it is replaced with a new one that automatically looks for new NGINX containers.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.38326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "How <em>to</em> enable",
        "body": ": baseurl: https:&#x2F;&#x2F;download.newrelic.com&#x2F;infrastructure_agent&#x2F;linux&#x2F;yum&#x2F;el&#x2F;6&#x2F;x86_64 gpgkey: https:&#x2F;&#x2F;download.newrelic.com&#x2F;infrastructure_agent&#x2F;gpg&#x2F;newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure <em>write</em>_files: - content: | --- # New Relic config file"
      },
      "id": "60450959e7b9d2475c579a0f"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/prometheus-remote-write-integration/",
      "sections": [
        "Prometheus remote write integration",
        "Why it matters",
        "Compatibility",
        "Scale your data and get moving quickly",
        "What's next",
        "For more help"
      ],
      "published_at": "2021-06-14T17:56:38Z",
      "title": "Prometheus remote write integration",
      "updated_at": "2021-03-16T13:34:27Z",
      "type": "docs",
      "external_id": "d8ceefcb13b66e0a17973b0aca68ea3cc71ca403",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the Prometheus remote write integration to get data flowing into New Relic. Once you integrate, your data will be visible in query-based dashboards (and other query results), often within about five minutes. Why it matters Unlike Kubernetes and Docker OpenMetrics integrations, which scrape data from Prometheus endpoints, the remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. You can leverage the full range of options for setup and management, from raw data to queries and dashboards and beyond. With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional) Compatibility New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Scale your data and get moving quickly Once logged in to New Relic, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. View your data. What's next Ready to get started? Read the setup documentation. Configure a Prometheus data source in Grafana. Set up the integration on New Relic US EU For more help Recommendations for learning more: See the Docs site's landing page for Infrastructure integrations documentation. Browse New Relic's Explorers Hub for community discussions about our Infrastructure integrations. Find additional help or file a support ticket. Review New Relic's licenses, attributions, data usage limits, and other notices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 68.810196,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Prometheus remote <em>write</em> integration",
        "sections": "Prometheus remote <em>write</em> integration",
        "body": "You can use the Prometheus remote <em>write</em> integration to get data flowing into New Relic. Once you integrate, your data will be visible in query-based dashboards (and other query results), often within about <em>five</em> minutes. Why it matters Unlike Kubernetes and Docker OpenMetrics integrations, which"
      },
      "id": "603e94dee7b9d2dfd22a07f9"
    },
    {
      "sections": [
        "On-host integrations metrics",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-06-15T01:04:56Z",
      "updated_at": "2021-06-15T01:04:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentShared locks.oplogAcquireIntentShared MongoDB mongo",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 64.77888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.disk<em>Write</em>UtilizationPercent disk<em>Write</em>UtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverage<em>Five</em>Minute loadAverage<em>Five</em>Minute Agent"
      },
      "id": "603e8a8a64441f69a34e8841"
    }
  ],
  "/docs/style-guide/writing-guidelines/formatting-terminal-commands": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/tech-writer-workflow/",
      "sections": [
        "Tech Writer workflow",
        "Resources",
        "Edit in the UI vs local build",
        "Work on a branch, not a fork",
        "Set up your local environment",
        "Run the site locally",
        "Prerequisites",
        "Build the site",
        "Edit a doc",
        "Commit your changes",
        "Publish your commits",
        "Open your pull request",
        "Preview a doc",
        "Revise and publish a doc",
        "Revert merging"
      ],
      "published_at": "2021-06-14T18:18:38Z",
      "title": "Tech Writer workflow",
      "updated_at": "2021-06-14T00:55:51Z",
      "type": "docs",
      "external_id": "074905b02af0ab6eb53640c1c80e83296a8a0b02",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the UI vs local build Need to edit a doc? Use this table to decide where to work! Use the UI for: Use the local build for: Adding content to one doc: Rewriting sentences, or 1-2 lines Editing small amounts of content: updating URLs, deleting typos, etc. Brand new docs Rewrites of more than 1 or 2 lines Any updates to doc frontmatter Title changes Taxonomy changes Metadescription updates Redirects Updating images Editing multiple docs at once Continue reading for instructions on how to edit a doc locally. Work on a branch, not a fork Some teams work on branches, some teams work on forks; the docs team works in branches. As long as a branch has been pushed upstream, this allows us to work collaboratively and ensure that no work is ever lost when someone goes on vacation. To create a branch on the docs-website repo: Open GitHub Desktop Click on Current branch: xxx Click on New Branch You will be prompted to name your new branch. Descriptive names are best. It's a great way to quickly clue people in to what your work is all about. For example, if you are working on What’s New pages, you might name the branch Whats-new-updates. When you create a new branch, don't forget to add the Jira issue's key (DOC-1234) to the branch name and the PR title. Set up your local environment Install GitHub Desktop, and then navigate to GitHub Desktop's preferences. On Macs, click on GitHub Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Once GitHub Desktop is set up, navigate to the Docs Site repository on GitHub. Click the green Code button and then select Open with GitHub Desktop. Choose the location where you want the repo, and this will clone the entire repository to your local machine at the designated path. You can ensure the repo was cloned by navigating to your local GitHub folder (the default is ~/Documents/github). Once you have cloned the repo, you don't need to clone it again in the future. Run the site locally Build the site locally using the terminal to preview changes before opening a Pull Request. While it's highly recommended to build the site locally, this is technically an optional step. The site will automatically reflect any local changes once build. Node and Yarn are tools used to build the site on your local machine. Prerequisites Install Node Install Yarn npm install -g yarn Build the site In your terminal, go to your cloned repo, docs-website. cd ~/Documents/github/docs-website Run yarn with the following commands: yarn && yarn start The site will take a few minutes to build. Make yourself some tea or coffee. Once it's built, you can access your preview site in your browser by navigating to http://localhost:8000/ Edit a doc Once your local environment and branch are set up, you're ready to edit a doc. Check out the style guide for writing guidelines. First, ensure your Current Branch in GitHub Desktop is set to the correct branch, not Develop. Navigate to the doc you want to edit in Finder. If I wanted to edit a Python agent doc, I would navigate to: ~/Documents/github/docs-website/src/content/docs/agents/python-agent/hosting-services/python-agent-stackato.mdx Edit the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help with formatting markdown Save the file with your edits, then follow the same process for any other docs you wish to edit. Commit your changes Once your edits are done, you can commit them. This stages your changes, which you will later push upstream to Github. By pushing your changes, everyone will have access to your branch and commits. Navigate to GitHub Desktop. The left column should have a record of all the edits you have made to docs. In the bottom left corner, name your commit and add a good description of your edits. It should be descriptive enough to ensure that someone can understand all the changes made by simply scanning this description. Click Commit to [yourbranchname] Publish your commits Once you have committed your changes, you're almost ready to open your Pull Request. First, you need to ensure your branch is pushed upstream. On GitHub desktop, click the blue Publish Branch button if available. If you don't see the Publish Branch, click the blue Push Origin button. This will push all your commits upstream and make them available to everyone else through the GitHub repository. Open your pull request Now that your commits are available to everyone, you need to notify people that your changes are ready to be merged into the develop branch. To do this, you open a pull request: On GitHub Desktop, click the blue Create Pull Request button. This will open GitHub in your browser, and prompt you to fill in your pull request. Ensure you are merging from your branch into either the main or develop branch. If you scroll down, you can review all your commits to ensure they reflect all your changes. Just like your commit description, your pull request description should be detailed and give the full context of your changes. Feel free to add any additional context here (issue or Jira number, SMEs, etc.) Once you are satisfied with your pull request, click the green Create pull request button. You can either publish the changes directly by approving the pull request yourself, or you can request for another Tech Writer to peer edit it. To request a review from another Tech Writer: in GitHub open the PR, navigate to the conversation Conversation, and then select or type in a reviewer name in the Reviewer section. At the bottom the pull request page, you will see a Checks section. These checks ensure your PR does not break the build process of the site. Ensure all these checks pass before proceeding. The checks should finish within twenty minutes. If the Pull Request is urgent, you can skip the AWS Amplify Console Web Preview check. Once the pull request has passed the checks and it has been approved by another tech writer (or you are confident the changes are ready to be published), click the green Merge pull request button. This will merge your branch and commits into the repository and will begin the build process. Preview a doc There are two main ways to preview branches you’ve already published and run commits on: Local: Quicker, but requires a semi-substantial amount of setup and familiarity with a terminal. Amplify: Full preview of the live site with no overhead, although it takes a long time (from 30 minutes tp up to 1.5 hours!) to build on a PR. It's easily shareable with SMEs and others. Revise and publish a doc If you’re notified that a reviewer has submitted a review to your file, go to your PR and review the changes. You might see them in the diff view, if they’re part of a review with comments; otherwise, they might appear as copy edits in the file. Respond to any comments in the file. Either reply with follow up discussion, or click Resolve conversation. When you’ve resolved all the comments, and all of the automatic checks have passed, you can merge the pull request. Merging the pull request sets in motion the automated build process and your changes will be published shortly. Note: You will only be able to merge when the Merge pull request button is green. If it’s not green, review for any comments you missed, or other messages that indicate why GitHub is blocking you from merging. Revert merging Remember that you can almost always undo things. If you merge a PR, and then find that you shouldn’t have, you can unmerge with the Revert button. On the Pull requests tab in GitHub, click Closed on the tally bar to see all the issues and PRs that have alredy been merged. Locate the PR you merged, and locate the Revert button. Click Revert. That creates a new PR, which needs to be merged. If you want to reopen it, you need to follow the link back to the original PR and either revert that or reopen it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.00777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " was cloned by navigating to your local GitHub folder (the default is ~&#x2F;Documents&#x2F;github). Once you have cloned the repo, you don&#x27;t need to clone it again in the future. Run the site locally Build the site locally using the <em>terminal</em> to preview changes before opening a Pull Request. While it&#x27;s highly"
      },
      "id": "60c6a91764441f404d91f8c6"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/github-troubleshooting/",
      "sections": [
        "GitHub troubleshooting",
        "GitHub authentication fails",
        "My build is failing mysteriously",
        "Issues with the local site",
        "Stop and restart yarn",
        "Ensure the problem isn't with your branch",
        "Clean your local cache",
        "Remove corrupted cache files",
        "Start a build from start",
        "Run your local build in private mode",
        "My redirect throws a 404 error when testing it locally",
        "A check fails in the PR",
        "Reset the Gatsby build check",
        "Caution",
        "Troubleshoot merging conflicts",
        "What’s new related merge conflicts"
      ],
      "published_at": "2021-06-14T18:18:02Z",
      "title": "GitHub troubleshooting",
      "updated_at": "2021-06-14T00:56:47Z",
      "type": "docs",
      "external_id": "09ae591aa87a3d512d1c62005589dbd88f23f699",
      "document_type": "page",
      "popularity": 1,
      "body": "Are you having problems working on a doc in GitHub? Check out the following common issues. GitHub authentication fails If you suddenly find that you can no longer push to your remote branch in GitHub Desktop, you may have developed a problem with SSH. If logging out of GitHub Desktop via Preferences doesn’t seem to help, you can confirm if you have an SSH issue by switching to the command line and trying to push manually. For example: git push --set-upstream origin second-kafka-pr-for-issue-1123 If this command prompts you for a passphrase, your SSH was somehow confused. By entering your passphrase, you should be back in business. If you can’t remember your passphrase, check out this article. My build is failing mysteriously Here’s a few things you can check if your build is failing: Indenting in the nav files Front matter If there's apostrophes and colons in frontmatter fields, surround them with quotes to avoid problems. Missing closed brackets or tags Poorly formatted image links Be careful when renaming images and their filename paths. A mismatch can cause the entire local build to fail. Be especially careful when dealing with image files that are imported. Image filenames Image filenames are case-sensitive. Using the wrong capitalization results in a missing image in the doc. Images with encoded values (like %) in the filename can be especially tricky, try to avoid them. Issues with the local site If you're running with issues with your local build, try these options: Stop and restart yarn In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to interrupt the yarn process, if necessary. Run yarn && yarn start. Ensure the problem isn't with your branch In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. In GitHub Desktop, commit any changes needed on your branch, and then switch to the Develop branch. 4 Back in the terminal, run yarn && yarn start. If the site now builds correctly, the issue is with the changes in your branch. Stop Yarn again, go back to your branch, and troubleshoot. Clean your local cache Run yarn clean to blow away your local cache. This will make your next build slower, so make sure you have time! In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. Begin a new build by running yarn clean && yarn && yarn start. Remove corrupted cache files There may be times when your .cache directory has been corrupted. This directory is ignored by Git, which means that it travels with you from branch to branch. This might be the problem if your local builds are failing regardless of which branch you’re on. To solve this, run rm -rf .cache. Start a build from start Blow away all your node modules, hidden .cache folder, and local cache and start a build from scratch. This takes a long time to run, around 10–20 minutes. In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. Blow away modules and cache and start from scratch running rm -rf node_modules && rm -rf .cache && yarn && yarn clean. When everything completes, start the site yarn start. You may need to add sudo at the start of the rm commands. Run your local build in private mode Sometimes the local site builds, but pages within the site don't. Running the local build in a private/incognito session may to fix this issue. You can also try clearing out your browser's cache. My redirect throws a 404 error when testing it locally Redirects are a bit strange on local builds. To test them, navigate to the page that is being redirected, wait until it throws a 404, and then wait ~1-2 minutes. It should redirect you after a while. If it doesn’t, ensure you set up the redirect correctly. A check fails in the PR Rarely, a build or check will fail due to some internal error. You can re-run the check by going to the PR, clicking Details, and then clicking Re-run jobs. If that doesn't fix it, you probably have genuine build errors. Pull down locally and troubleshoot. Reset the Gatsby build check Caution This adds a LOT of time to the build check. There are times the Gatsby Build check fails. If this happens after your local builds have built successfully, you may need to force a rebuild of the cache. In your local repo, find the file gatsby-config.js (use CMD-P to jump to it fast in VSCode). Swap the first and second line of code. It doesn’t matter what order these lines are in, except to make the Gatsby Build check rebuild the cache. const fs = require('fs'); const parse = require('rehype-parse'); Save the file and commit the change to your PR. Re-run the build checks. Wait a LOOOOONG time. Troubleshoot merging conflicts Merge conflicts can seem pretty scary, but it’s ultimately just deciding between two different versions of a doc. Here are some tips on how to get through it. Fix your merge conflict as soon as possible. Especially if you’re working on taxonomy changes. If your branch lingers for a while it can get outdated from develop pretty fast and that can cause some unexpected issues. Check your fix locally to make sure that it looks good there. Ask your PR approver to review your PR after you fix the merge conflict. Here are two options to resolve conflicts: When you see the conflicts in GitHub desktop, click the option to resolve these in VS Code. Use the GitHub website editor (click the Resolve conflict button) to fix these. What’s new related merge conflicts Merge conflicts pop up pretty often with what’s new posts because the whats-new-ids.json file that’s automatically updated when the site builds can get out-of-date pretty fast. If you see changes to this file show up in GitHub Desktop, make sure to discard them, rather than push them up to your branch. This will make it less likely that other people will have to deal with merge conflicts related to this file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.450714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " Preferences doesn’t seem to help, you can confirm if you have an SSH issue by switching to the <em>command</em> line and trying to push manually. For example: git push --set-upstream origin second-kafka-pr-for-issue-1123 If this <em>command</em> prompts you for a passphrase, your SSH was somehow confused. By entering your"
      },
      "id": "60c6a94f64441f5ac491f8a7"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/code-formatting-guidelines-var-mark/",
      "sections": [
        "Code formatting guidelines: var and mark",
        "var: Highlight user-specific values in procedural code snippets",
        "var format examples",
        "Important",
        "mark: Emphasize non-procedure code snippets"
      ],
      "published_at": "2021-06-14T18:18:38Z",
      "title": "Code formatting guidelines: var and mark",
      "updated_at": "2021-05-16T11:16:42Z",
      "type": "docs",
      "external_id": "dc9b222917947481942168f4004e4401f517b9dd",
      "document_type": "page",
      "popularity": 1,
      "body": "This document serves as a supplement to the basic <var> and <mark> documentation. It gives a longer explanation of when to use the <var> and <mark> formatting styles, and reasons for not using them. var: Highlight user-specific values in procedural code snippets The <var> tag is used for user-input values in code snippets that customers would be using in procedural/functional ways. For example, you would use the <var> tag when explaining how to do some specific task. A <var> tag would not be used for: Example code: If the code is meant to be an example, to show the format/structure of the code, and there is not an actual procedure the customer is following, var tags are not needed. Examples: Example configuration file (or this Java agent config template): if you are showing an example config file that isn't part of a procedure, you shouldn't use the <var> tag. Several reasons for this: 1) The important part of showing an example config file is to show the overall structure of the file, 2) Usually the number of config options present in a file will vary based on whatever the customer wishes to use, so using <var> tags can actually be confusing as it implies that these values must be present. Instrumentation procedure (at bottom of the Java section): the var tag wouldn't be necessary because it's an example, not part of a procedure, and the main goal is seeing the general structure. Also, because it's an example of app code, the concept of user-specific values doesn't have much meaning, because the entire code will vary dependent on how the customer has written their code. (If anything, this would be a potential for using <mark> format to emphasize the New Relic functions.) Response/output code: If the code is meant to show an expected return, and is not related to a procedure, then var tags shouldn't be used. Here's a doc section (the returned JSON) where var tags are not needed. For an example of a doc section with both <var> formatting and without it, see the Synthetics monitors REST API example. The first block shows a command they might choose to run, hence it uses a <var> tag. The second block is just an example output, showing the structure that would be returned; it doesn't require a <var> tag. For some use cases, highlighting may be a better choice than a var tag. var format examples Below are some general style recommendations for formatting user-specific <var> values. <var> tag formatting may vary based on language- or system-specific expectations, so be sure check the style used in the documentation section in question, and to ask relevant SMEs what they think of the style. Account IDs and other IDs/#s: YOUR_ACCOUNT_ID, YOUR_API_CODE, etc. This should be the general style used. URLs: example.com, or maybe YOUR_URL Paths: PATH/TO/SOMETHING.exe or maybe PATH_TO_FILE Emails: datanerd@example.com or maybe YOUR_EMAIL Bash variables for REST API code: Some <var> tagged code values on the docs site have the form $ { API_KEY}. This is a format used for variables in bash scripts, where users assign values to specific variable names and then call those variables later in the script by using the $VARIABLE_NAME. For more info, see this explanation of bash variables. Important The bash variable style is currently used in the REST API docs and in some Synthetics docs and that's fine. But going forward we should use the general variable style (without the $ and &lt; >). mark: Emphasize non-procedure code snippets Highlighting (<mark>) is used for when you want to draw attention to a variable or value, but it's not something directly procedural related. Here are two examples of highlighting: Highlighting values in code response that are meant for later use: Activate Azure integrations doc. Highlighting the commands in a large code block example that are New Relic-specific commands, with explanations below: Java API doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.021416,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Code <em>formatting</em> guidelines: var and mark",
        "sections": "Code <em>formatting</em> guidelines: var and mark",
        "body": " to a procedure, then var tags shouldn&#x27;t be used. Here&#x27;s a doc section (the returned JSON) where var tags are not needed. For an example of a doc section with both &lt;var&gt; <em>formatting</em> and without it, see the Synthetics monitors REST API example. The first block shows a <em>command</em> they might choose to run, hence"
      },
      "id": "6042219c64441f52d94e889e"
    }
  ],
  "/docs/style-guide/writing-guidelines/hyperlinks": [
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-06-14T18:13:18Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 74.85139,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ".). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes <em>hyperlinks</em> in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (&quot;do this&quot;). Avoid burying tips or extra details in the steps"
      },
      "id": "604220b2196a6775f5a83dc0"
    }
  ],
  "/docs/style-guide/writing-guidelines/levels-headings": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/get-started/introduction-style-guide/",
      "sections": [
        "Introduction to the style guide",
        "Organize your doc to make it easier to read",
        "Use action-oriented titles",
        "Start the document with an introductory paragraph",
        "Keep documents short",
        "Use the New Relic voice",
        "Change doc titles and anchors",
        "Create and edit categories",
        "Start writing and editing docs"
      ],
      "published_at": "2021-06-14T18:12:28Z",
      "title": "Introduction to the style guide",
      "updated_at": "2021-04-12T11:26:22Z",
      "type": "docs",
      "external_id": "b0bfbe0b3791c4feb00fe86a41e49312cd9e82cd",
      "document_type": "page",
      "popularity": 1,
      "body": "We've written these guidelines to make it easier for you to contribute to our docs, as well as to give you some insight into how we think about good technical writing. We, the Tech Docs team, rely on your expertise to keep New Relic's documentation updated and useful. Thank you for your willingness to share your knowledge! Our style guide focuses on style and usage that's particular to our site. Our site follows American English conventions. For topics that aren't covered, please refer to the Microsoft Writing Style Guide (for guidelines on technical terminology) or the Chicago Manual of Style (for general writing and editing guidelines). Organize your doc to make it easier to read Consider these organization guidelines when thinking about the order of information in a doc. By following these guidelines, you'll make it easier for readers to skim and find what they need. How to organize information Comments Separate what and why from how. Define any necessary prerequisites, policies, or background information (the what and the why) before you step through the how (step-by-step procedures). Examples: Explain what the feature is and why it matters before telling readers how to use it. Describe any limitations with user permissions or subscription levels that would prevent them from using the feature. If the feature is available for any user or subscription level, don't bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting a procedure that they have everything they need. Front-load directions with context. Make sure readers know where they need to be, before telling them what to do. In general, use (select an app) to describe what users select from the product index. Examples: Go to one.newrelic.com > Explorer > (select an app or service). Select (account dropdown) > User preferences. On the command line, type gitk. Also, structure steps by front-loading context from the user's point of view. For example, instead of \"Go to x to do y,\" structure the step as \"To do y, go to x.\" Separate requirements from options. Example: Type the Email you use to sign in and to receive information from New Relic. Optional: Type additional user emails, separated by commas. Follow the \"five to nine\" guideline. Depending on the topic, organize the information so there is a maximum of five to nine chunks of information. For example, readers may start to get lost or overwhelmed after about five h2 sections or seven steps into a procedure. If you have more than nine h2 sections or steps, you might need to create an additional doc or procedure. Other organization tools to consider: Levels of headings Lists Collapsers Callouts Tables Code examples For more help section Use action-oriented titles Wherever possible, give your document or h2 heading a task- or action-oriented title. Focus on what users are trying to accomplish or the problem they're trying to solve. Use present-tense verbs, rather than \"-ing\" verbs. Quality Title example Bad The query history Okay View query history Good Query history: Create and edit NRQL queries Start the document with an introductory paragraph Unless the document is less than a single screen in length, begin with a brief paragraph that introduces the topic or summarizes the important points. Not sure where to start? Try writing all the content for your document first, and then add the introduction to the top to summarize your key points. Or use the introduction to expand on the text in your metaDescription in the metadata. Keep documents short The amount of content needed can help you decide whether you need one or more documents for the topic. If all of the document's contents apply directly to the title, then everything belongs in the same document. If several related sections could be logically split into individual documents, and the overall length of your document is more than about two screenfuls, split those sections into other documents. Be sure to include links to the related contents. If a large document needs to be broken into multiple smaller documents, consider whether they might be best grouped together in their own sub-category. Use the New Relic voice We strive for a voice that's approachable, expert, and visionary. Check out our voice guidelines for how to write content with these qualities. And keep in mind these essential writing tips that apply to any type of documentation. Guidelines Comments Be clear and direct. Remember to: Use present tense. Use active voice; avoid passive voice. Tell users what to do, not what they \"should\" do. If absolutely necessary, tell users what not to do in situations where unexpected results may occur. Whenever possible, provide an alternative suggestion when telling users what not to do. Example: Using active voice with an alternative suggestion for what not to do Do not use your config file to change this setting, because this could affect other processes. Instead, go to one.newrelic.com > APM > (select an app or service) > Settings > Application. Write to aid localization and translation. Do not use euphemisms, idioms, jargon, or slang. Use the same terms and wording consistently. If you need to include an abbreviation or acronym, spell it out the first time it appears in the document. Always take a moment to ask yourself whether people will really understand the terms you are using in the way you're using them. Change doc titles and anchors Because changes to doc titles, anchors, and redirects can break links to other docs, please create an issue to request these types of changes and we'll help you out with that. Create and edit categories Because changes to categories can affect large groups of docs at once, please create an issue to request these types of changes and we'll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see Create and edit content. To learn how to create and publish release notes, see Create release notes. To make it even easier to start a new doc, use templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 474.05994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " it. Describe any limitations with user permissions or subscription <em>levels</em> that would prevent them from using the feature. If the feature is available for any user or subscription <em>level</em>, don&#x27;t bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting"
      },
      "id": "60415293e7b9d262f32a07d7"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/five-questions-help-write-docs/",
      "sections": [
        "Five questions to help write docs",
        "There's really only 1Q",
        "5Qs and sub-questions",
        "1. Did you use or observe the thing you are writing about?",
        "2. Is this the best place to put this information?",
        "3. Can readers tell in ten seconds if they are in the right place?",
        "4. Is the information in the best possible format?",
        "5. Is the language approachable, expert, and visionary?"
      ],
      "published_at": "2021-06-14T18:19:44Z",
      "title": "Five questions to help write docs",
      "updated_at": "2021-06-14T18:19:44Z",
      "type": "docs",
      "external_id": "14fd5c4efd0e8aa26e04d97ae61da33eef9489ee",
      "document_type": "page",
      "popularity": 1,
      "body": "Our five questions form the core of how our Tech Docs team thinks about writing excellent technical documentation. Informally, we call these our 5Qs. Anyone can contribute to our Docs site. We want you to feel confident and proud that your contributions provide valuable content and quality. We also want our readers to trust and easily use the information in our docs. To help you plan, write, and edit excellent docs, ask yourself the questions in this doc. There's really only 1Q The 5Qs exist to help answer one question. Whenever you write a doc, ask yourself: What problem are we trying to solve? It's critical you know what you're trying to do and why that goal matters to your readers. Asking the five questions (and the sub-questions!) will help you ensure you're building the right thing. 5Qs and sub-questions Each of the five questions includes sub-questions to help guide your thinking. 1. Did you use or observe the thing you are writing about? Think about who your audience is and the level of complexity they need. End users' point of view Ask yourself: Audience Do you know who is reading your document (dev/ops teams, support personnel, non-technical staff, etc.)? Can you articulate what this thing is (feature, procedure) and why it matters to our customers? For conceptual info, did you interview multiple stakeholders? Testing Put yourself in the user's shoes. For example: Did you use the thing on your own? Did you watch a subject matter expert use the thing? If you can't do it on your own or observe, did you send the draft to at least three SMEs? Before publishing Did you compare the final version of your text against the thing you're writing about? 2. Is this the best place to put this information? Think about where this information belongs. Where does this information belong? Ask yourself: What problem are you trying to solve? Is text always the best answer? Does this doc need to exist at all? For example: Are we duplicating content from somewhere else in the Docs site? Are we duplicating content already in the UI? Could customers have a better experience if we modified the UI design or copy instead of creating a doc? Would another web property be a better home for this information? For example: The Explorers Hub? NRU course? NRU video embedded into the doc? The public New Relic blog? The public New Relic website? 3. Can readers tell in ten seconds if they are in the right place? Think about what the content is and what you can do to make the information easy to skim to find information. Can users skim to find information? Ask yourself: Title and headings Does the title accurately represent what's in the doc? Do the headings accurately represent what's in the doc? Do the title and headings use words the way your readers do? Do the title and headings avoid New Relic jargon? Structure Does the overall structure of the doc help readers find what they're looking for? Is the doc trying to address too many topics? When you glance at the doc, do you see short paragraphs, short sentences, and other visual aids? Or do you see a dense wall of text? Introduction Does the intro give a concise synopsis of what's in the doc? Does the intro give readers an alternate path if they're in the wrong place? 4. Is the information in the best possible format? Think about how to present the information visually. Presentation of information Ask yourself: Visual formats Did you use visual formats appropriately? Would a screenshot make any of the information easier to understand? Does your image caption clearly explain what matters so that the user does not necessarily even need to read the surrounding text? Would a diagram make any of the information easier to understand? Is there a video we could embed to make things clearer? Can step-by-step UI procedures be replaced with a \"show me\" video? Procedures Are your procedures well-structured? Do step-by-step UI procedures even need to be documented? Did you limit the procedural text to action steps and omit detailed explanatory text or edge cases? If detailed explanations need to enhance a procedure, have you organized the info in a way that expert users can skip the details? Text flow Read your draft more than once. Is the documentation direct and to the point? Did you use bullets, tables, or clamshells to improve flow? 5. Is the language approachable, expert, and visionary? Think about why the information matters and why readers will trust and use it. For tips to make it easier for users to read, understand, and use documentation, go to plainlanguage.gov. Also, if you are a New Relic employee, we encourage you to review the corporate brand guidelines. For more information, contact Marketing. Effective language Ask yourself: Readers' point of view Did you tell users why as well as how? Can you articulate not only what this thing is (feature, procedure) and also why it matters to our customers? Did you include useful examples or use cases? Did you include information about relationships this feature has to other New Relic platform tools? Style guide resources Did you follow our style guide? Did you use our edit checklist? Did you use pronouns, contractions, and a conversational tone throughout? Did you review the usage dictionary and other resources in the style guide to make sure that terms are used correctly? Readability Is the text easy to read? Is the language clear? Do you have to reread any sentences or paragraphs to understand them? If so, can you simplify the wording and sentence structure? Does the doc score 40 or better on the Flesch-Kinkaid reading ease scale? If not, try taking another pass at the prose. But don't chase the Flesch-Kincaid score in itself: we're not out to frustrate ourselves, but to write docs that are a pleasure to read. Where to go from here Did you offer readers a clear \"next step\" in each section? If it is necessary to tell a user not to do something, did you also tell them what to do instead? Is the topic complete? Is the doc actionable?",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.61316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ". 1. Did you use or observe the thing you are writing about? Think about who your audience is and the <em>level</em> of complexity they need. End users&#x27; point of view Ask yourself: Audience Do you know who is reading your document (dev&#x2F;ops teams, support personnel, non-technical staff, etc.)? Can you"
      },
      "id": "60421ef3196a676926a83d81"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-14T19:15:01Z",
      "updated_at": "2021-05-28T02:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.45173,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Use sentence case in <em>headings</em>",
        "body": "In general, we only capitalize things when we need to. Read on for some guidelines on how to decide what to capitalize in a document&#x27;s title, <em>headings</em>, products, features, and other elements of the page. Use sentence case in <em>headings</em> Use sentence case for <em>headings</em>. This includes category <em>headings</em>"
      },
      "id": "60421e50196a67d785a83d97"
    }
  ],
  "/docs/style-guide/writing-guidelines/more-help-section": [
    {
      "sections": [
        "Install the browser monitoring agent",
        "Tip",
        "Select a deployment option",
        "Important",
        "Enable an APM-monitored app",
        "Enable with copy/paste",
        "Instrument webpages using the APM agent",
        "Troubleshoot Browser agent installation"
      ],
      "title": "Install the browser monitoring agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Installation"
      ],
      "external_id": "bc45bbc86cd4d8b81367ad0904907ddc735717f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/installation/install-browser-monitoring-agent/",
      "published_at": "2021-06-14T21:26:03Z",
      "updated_at": "2021-06-14T21:26:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser uses a JavaScript snippet (or \"agent\") to instrument your app's webpages. The JavaScript collects data for browser monitoring. To install the browser agent, you can choose from a number of deployment options. Tip To use Browser and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Select a deployment option No matter which option you use to deploy browser monitoring, the end result is to inject the browser agent's JavaScript snippet into your pages for browser monitoring. The method you select depends on your preferences and business needs. To view the procedure to install and enable the browser agent, click the link for the option you want to use. You can also use the Browser Application settings page to update settings. Important The following configuration options refer only to the browser monitoring agent. These are not the same as the New Relic user roles and editions. Browser deployment option Description Use the APM agent to inject the JavaScript You can use an APM agent to automatically inject the browser monitoring JavaScript snippet for you. This is the easiest way to install the agent for an app that already is being monitored by APM. (APM-monitored apps are listed on your APM Applications index.) Paste the JavaScript snippet into a webpage This allows you to control the exact placement of the JavaScript into your app's webpage(s) by copying and pasting the browser agent's JavaScript snippet. This is useful for: Standalone apps, static sites, and cached pages delivered by CDN APM apps that are not as closely coupled to the browser app as with a standard server-side app (for example, when your client-side app talks to a REST API back end) Enable single-page app (SPA) monitoring Enabling SPA requires a Pro + SPA browser agent subscription, and you may need to re-deploy the browser JavaScript agent. Use the REST API The REST API lets you manage deployment outside the browser UI. This is useful for large organizations deploying multiple apps. Use an APM agent API to manually instrument the JavaScript snippet For apps that are monitored by APM, you can use the APM agent's API to inject the JavaScript manually instead of automatically. Enable an APM-monitored app Use this procedure to automatically deploy the browser agent on an app that is monitored by APM: Go to one.newrelic.com, select Browser, and then select Add more data. In the Back-end, front-end, and mobile applications section, select the New Relic Browser tile. When prompted to select the account you want to add this instrumentation to, choose your account, and click Continue. From the Get started with New Relic Browser page, in the Choose a deployment method section, select Enable via New Relic APM. In the Choose your instrumentation section, select Lite, Pro, or Pro + SPA. In the Configure your instrumentation section, make the selections you want. In the Select your application section, type or use the search window to find an app's name. Click Enable. Important Node.js: To finish enabling the browser agent for a Node.js app, follow the additional procedure to insert the JavaScript header into the beginning of your HTML page's head tag. Generate some traffic for your app. Wait a few minutes for Browser to start collecting data, then select your app from the Browser applications index. Enable with copy/paste Use this procedure to insert browser's JavaScript snippet for browser monitoring into your app's webpages yourself. This option is useful for monitoring static sites (such as Jekyll) or cached pages delivered by CDN. Tip Near the bottom of the generated JavaScript is your browser license key and application ID. This is useful with the REST API and API Explorer. Go to one.newrelic.com, select Browser, and then select Add more data. In the Back-end, front-end, and mobile applications section, select the New Relic Browser tile. When prompted to select the account you want to add this instrumentation to, choose your account, and click Continue. From the Get started with New Relic Browser page, in the Choose a deployment method section, select Copy/Paste JavaScript Code. In the Choose your instrumentation section, select the type of agent: Lite, Pro, or Pro + SPA. In the Configure your instrumentation section, make the selections you want. In the Name your app section, name your app: If your app is monitored by APM, select Yes, then type or use the search window to find the app's name. If you have a standalone app for Browser (not monitored by APM), select No, then type the app's name. Click Enable. A new section, Instrument the agent, opens on the page with JavaScript code for your project. Copy the code snippet, then paste it inline into your pages as close to the top of the <head> element as possible, but after any position-sensitive <meta> tags (for example, X-UA-Compatible or charset information). For more information on the inline head placement, see JavaScript placement requirements. Generate some traffic for your app. Wait a few minutes for Browser to start collecting data, then select your app from the Browser applications index. If you use the copy/paste method, but don't finish the setup process, you can still view and copy the generated JavaScript snippet from your app's Browser Application settings page or by using the REST API (v2). Instrument webpages using the APM agent This information applies to apps that are also monitored by APM. New Relic's agents can instrument webpages with the required JavaScript for page load timing. If you use the APM agent to add the JavaScript snippet to your webpages, insert the instrumentation snippet as close to the top as possible. This allows you to take advantage of detailed information about browser's AJAX calls and JavaScript errors. For more information, see the instructions for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby Troubleshoot Browser agent installation When you enable browser Pro features for session traces, AJAX calls, or JavaScript errors, it may take approximately five minutes before information becomes available. If you have problems with your browser installation or if no data appears after five minutes, refer to the troubleshooting tips, and restart your agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.02027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " the browser agent on an app that is monitored by APM: Go to one.newrelic.com, select Browser, and then select Add <em>more</em> data. In the Back-end, front-end, and mobile applications <em>section</em>, select the New Relic Browser tile. When prompted to select the account you want to add this instrumentation"
      },
      "id": "604429e628ccbcb80b2c60d0"
    },
    {
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "Explorer: Get the big picture along with the details",
        "Summary page",
        "Distributed Tracing",
        "Tip",
        "Transactions",
        "Databases",
        "Externals",
        "Errors",
        "Metrics Explorer",
        "Data explorer and query builder"
      ],
      "title": "View your OpenTelemetry data in New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "a5213cb2206f4c161dd97c015a7c6679b08e867b",
      "image": "https://docs.newrelic.com/static/2f8a3baa6793edf958ecb9db5346efa7/c1b63/explorer_otel_services.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-06-15T13:27:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you import OpenTelemetry data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know more about, and if you need help understanding the data, see the explanations below. Summary page The opening page of the explorer is the Summary page listing various golden signals about your entity. Golden signals are key monitoring details such as response time, throughput, and error rate. By using this information, you can quickly decide if you need to dig deeper. Distributed Tracing When you access distributed tracing through the explorer, you are looking at traces that include that service. Once you’re in that service, you can filter spans to find the ones you want. For example, to query service.name or trace.id, you can use the following: service.name = YOUR_SERVICE_NAME trace.id = YOUR_TRACE_ID For more ways to filter and analyze your spans, see our distributed tracing UI page. Tip If you prefer to search traces across all New Relic accounts in your organization, you can go outside explorer: one.newrelic.com > Apps > Favorites > Distributed tracing. Transactions Use Transactions to identify slow or error transactions that might be causing a spike in the response time of your application. From the transaction summary page, you can get a list of transactions by selecting See transactions table. Databases The Databases page shows an application's database and cache data. The page shows individual database transactions as a sortable table, and shows operations, throughput, and response time as charts. Externals Externals captures calls to out-of-process services such as web services, resources in the cloud, and other network entities. Errors On this page, you can see total errors, as well as charts showing error count and error rate. Metrics Explorer For selected OpenTelemetry languages, you can see information about your metrics in this section. Also, if you are using the Prometheus exporter with OpenTelemetry, you can view your metric data here. Data explorer and query builder Explore your metrics and traces using the data explorer, or write your own queries in query builder using NRQL. For more on how to query your data once it's in New Relic, see Query your data and Introduction to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 69.96418,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know <em>more</em> about, and if you need <em>help</em> understanding the data"
      },
      "id": "6044e5dfe7b9d283d3579a04"
    },
    {
      "sections": [
        "Azure AD SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Create authentication domain and enable SCIM",
        "Step 2. Set up Azure's New Relic app",
        "Step 3. Configure connection",
        "Step 4. Configure provisioning rules",
        "Tip",
        "Step 5. Downgrade some users to basic",
        "Step 6. Assign access grants",
        "Step 7. Configure SAML SSO"
      ],
      "title": "Azure AD SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "d6e7f7e95daa833451159a3db4e2c4257270b5e9",
      "image": "https://docs.newrelic.com/static/0a9a32fd5041e6e2ea37cc5f032b6910/8c557/Azure_AD_Provisioning_Attribute_Mapping_2_0.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/azure-ad-scimsso-application-configuration/",
      "published_at": "2021-06-14T19:28:16Z",
      "updated_at": "2021-06-14T19:28:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Azure AD-specific details on how to configure the New Relic Azure AD SCIM/SSO application. Requirements Before using this guide, read the requirements and procedure overview. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create authentication domain and enable SCIM To get to the New Relic authentication domain UI: from the account dropdown, click Organization and access, and then click Authentication domains. If you don't already have one, create a new authentication domain to be used for your SCIM-provisioned users. Under Source of users, enable SCIM. Step 2. Set up Azure's New Relic app Azure AD provides an application gallery, which includes various integrations for Azure AD, including the ones that New Relic offers. Add the New Relic SCIM/SSO application to your list of applications. Go to the Azure Active Directory admin center, and sign in if necessary. aad.portal.azure.com/ Click on All services in the left hand menu. In the main pane, click on Enterprise applications. Click on +New Application. Find our SCIM/SSO application by entering New Relic in the name search box, and click on the application New Relic by organization (not New Relic by account). Click on Add. Step 3. Configure connection Configure the New Relic SCIM/SSO application to automatically provision your users to New Relic. From the New Relic SCIM/SSO application page, click on the Provisioning link in the sidebar. In the main pane, click on Get started. In the Provisioning Mode pick-list, choose Automatic. In New Relic's authentication domain UI, set up a new domain with SCIM enabled. In Azure AD's New Relic SCIM/SSO app, in the Admin credentials section, fill out the Tenant URL and Secret token fields with the values provided in New Relic's authentication domain UI. To verify you can connect to New Relic, click Test Connection. When you see a message indicating verification success, click Save. The New Relic SCIM/SSO application can now connect with New Relic. Continue with the following section to configure the provisioning rules. Step 4. Configure provisioning rules Initially, nothing is configured to be sent to New Relic. You must configure Azure AD to send changes for user creation, updates, and deactivation. Go to the Provisioning page and complete the following: Expand the Mappings section. Click Provision Azure Active Directory Users. Verify the Target Object Actions Create Update and Delete checkboxes are all checked. Verify the Attribute Mappings look correct for your environment. Each of the New Relic attributes shown in the list must receive a value. Tip Ensure that the Azure Active Directory attributes shown in the list on the left are good sources for the information to send to New Relic. In particular, not all environments set the mail attribute. If your environment does not set the mail attribute, userPrincipalName could be a good alternative. Leave the switch for Enabled set to Off until you're done with the user and group configuration in the next section. Once all configuration is ready, return to this page and set the switch to On. Click Save. Here's an example of a filled-in attribute mapping page with the default values. Your values may be configured differently depending on your situation. After saving the provisioning rules, the New Relic SCIM/SSO application is ready to provision any changes made to users assigned to the application. Continue with the following section to assign users and groups to the New Relic SCIM/SSO application. Step 5. Downgrade some users to basic When your users are provisioned in New Relic, you should be able to see them in the User management UI. Users provisioned via your identity provider start out as full users. If your organization is on New Relic One pricing, these users are billable. To convert users to free basic users, use the User management UI. Step 6. Assign access grants Once your users are in New Relic, you need to grant them access to specific New Relic accounts, specific groups, and specific roles. Without doing this, your users have no access to New Relic accounts. To learn how to do this, see: How access grants work The user management tutorial Step 7. Configure SAML SSO To enable SAML SSO for your users, see the SAML instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 60.651783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " enabled. In Azure AD&#x27;s New Relic SCIM&#x2F;SSO app, in the Admin credentials <em>section</em>, fill out the Tenant URL and Secret token fields with the values provided in New Relic&#x27;s authentication domain UI. To verify you can connect to New Relic, click Test Connection. When you see a message indicating"
      },
      "id": "6043f5c964441fcfb0378ef3"
    }
  ],
  "/docs/style-guide/writing-guidelines/screenshots-images": [
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-06-14T18:13:18Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 689.56934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "Processes <em>and</em> procedures",
        "body": " sentences, or long paragraphs. Useful <em>images</em> For <em>screenshots</em> and <em>images</em>, check that: Full size <em>images</em> always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped <em>images</em> clearly show their relevance, with or without captions. In addition, make sure"
      },
      "id": "604220b2196a6775f5a83dc0"
    },
    {
      "sections": [
        "Update your Nerdpack's catalog information",
        "Update your CLI",
        "Check your permissions",
        "Publish your Nerdpack",
        "Update your Nerdpack's catalog metadata",
        "Update your Nerdpack's icons",
        "Resolve issues with submitting catalog information",
        "Resize your images",
        "Check the length of your strings"
      ],
      "title": "Update your Nerdpack's catalog information",
      "type": "developer",
      "tags": [
        "nerdpack",
        "catalog"
      ],
      "external_id": "dfee75ddee87a216eb9454abcaeabcc1ee0a8c7d",
      "image": "https://developer.newrelic.com/static/4560bce9c6a1165799e6eaf9d10f4868/0086b/nav-to-apps.png",
      "url": "https://developer.newrelic.com/build-apps/publish-deploy/catalog/",
      "published_at": "2021-06-16T01:52:35Z",
      "updated_at": "2021-05-21T01:48:59Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Learn to describe your Nerdpack in the catalog",
      "body": "Add screenshots, descriptions, and other metadata to your Nerdpack, and upload it all to the New Relic One catalog. Update your CLI Before you run any commands, ensure that you have the latest version of the CLI: bash Copy $ nr1 update Check your permissions To publish your Nerdpack and update its catalog information, you need: Access to the account that published it The necessary permissions for managing Nerdpacks Publish your Nerdpack You need to publish Nerdpacks that you create before you can update their catalog information. Update your Nerdpack's catalog metadata After you've published your Nerdpack to the New Relic One catalog, update the Nerdpack's metadata to let users know all about your Nerdlets or visualizations. Step 1 of 9 Go to New Relic: Step 2 of 9 Navigate to Apps: Step 3 of 9 Find your published Nerdpack under New Relic One catalog: Notice that there is no information on the Apps or details page other than the Nerdpack's name and the brief description found in nr1.json: There are no screenshots, icons, details, or what's new features. To add these, your Nerdpack needs a catalog directory. Step 4 of 9 From the root of your Nerdpack, create a catalog directory to house your Nerdpack's screenshots and metadata: bash Copy $ nr1 create --type catalog ✔ Component created successfully! catalog is available at \"./catalog\" Inside your catalog directory, you'll find specific files and directories for portraying information about your Nerdpack to your users: bash Copy $ ls catalog README.md additionalInfo.md config.json documentation.md screenshots File Description README.md A markdown file that instructs you how to use the information and metadata in catalog config.json A JSON file that contains the following fields: tagline: A brief headline for the application. This cannot exceed 30 characters. repository: The URL for the Nerdpack's remote repository. This cannot exceed 1000 characters. details: The purpose of the Nerdpack and how to use it. This cannot exceed 1000 characters. Use newlines for formatting, and don't include any markdown or HTML. support: An object that contains: issues: A URL for the repository's issues list. For example, the Issues tab if using GitHub. email: A valid email address for the team supporting the application community: A URL for a support thread, forum, or website for troubleshooting and usage support whatsNew: A bulleted list of changes in the current release version. This cannot exceed 500 characters. Use newlines for formatting, and don't include markdown or HTML. Check out our Pageview Map application's config.json to see a real-life implementation. documentation.md A markdown file that tells users how to use the Nerdpack's Nerdlets or visualizations. This shows in the detail view's Documentation tab. additionalInfo.md An optional markdown file for any additional information about using your application screenshots A directory that contains screenshots of your Nerdlets or visualizations. This can contain no more than 6 images. All screenshots must meet the following criteria: 3:2 aspect ratio PNG format landscape orientation 1600 to 2400 pixels wide Step 5 of 9 Update your Nerdpack's documentation.md file: documentation.md config.json 1 Enter your first and last name into the fields provided. When you're done, press **Submit** to see a personalized \"Hello!\" message. catalog/documentation.md Copy 1 { 2 \"tagline\": \"\", 3 \"details\": \"\", 4 \"repository\": \"\", 5 \"whatsNew\": \"\", 6 \"support\": { 7 \"email\": { 8 \"address\": \"\" 9 }, 10 \"issues\": { 11 \"url\": \"\" 12 }, 13 \"community\": { 14 \"url\": \"\" 15 } 16 } 17 } catalog/config.json Copy Step 6 of 9 Update your config.json file: documentation.md config.json 1 Enter your first and last name into the fields provided. When you're done, press **Submit** to see a personalized \"Hello!\" message. catalog/documentation.md Copy 1 { 2 \"tagline\": \"Say hi!\", 3 \"details\": \"DemoApp says Hello to a user.\", 4 \"repository\": \"https://github.com/newrelic/developer-website\", 5 \"whatsNew\": \"feat: Initial commit\" 6 } catalog/config.json Copy Step 7 of 9 Include screenshots in your screenshots directory. Step 8 of 9 Submit the information to the New Relic One catalog: bash Copy $ nr1 catalog:submit Uploading screenshots... ✔ Screenshots uploaded ✔ Updated metadata for DemoApp 1.0.0 Step 9 of 9 Go to the catalog to see your changes: Click your Nerdpack to see the new details: Update your Nerdpack's icons Within a Nerdpack, you can set two types of icons: One for your entire Nerdpack, which represents your Nerdpack in the catalog One for each of your launchers, which represents your Nerdlets Replace these icons and publish your Nerdpack to see the changes. Step 1 of 7 Update the icon.png in the root of your Nerdpack. This icon is used in the catalog and the Nerdpack's detail page. Step 2 of 7 If you're building a Nerdpack with one or more launchers, update the icon.png in each of your launcher's subfolders. Step 3 of 7 Update your package.json version: { \"private\": true, \"name\": \"demo-app\", \"version\": \"1.0.1\", \"scripts\": { \"start\": \"nr1 nerdpack:serve\", \"test\": \"exit 0\" }, \"nr1\": { \"uuid\": \"f2dbc999-e9a3-49b9-933d-5a704c6750bd\" }, \"dependencies\": { \"prop-types\": \"^15.6.2\", \"react\": \"^16.6.3\", \"react-dom\": \"^16.6.3\" }, \"browserslist\": [\"last 2 versions\", \"not ie < 11\", \"not dead\"] } package.json Copy This allows you to publish a new version of your Nerdpack. Step 4 of 7 Publish your Nerdpack: bash Copy $ nr1 nerdpack:publish Step 5 of 7 Update your whatsNew string in catalog/config.json: documentation.md config.json 1 Enter your first and last name into the fields provided. When you're done, press **Submit** to see a personalized \"Hello!\" message. catalog/documentation.md Copy 1 { 2 \"tagline\": \"Say hi!\", 3 \"details\": \"DemoApp says Hello to a user.\", 4 \"repository\": \"https://github.com/newrelic/developer-website\", 5 \"whatsNew\": \"feat: Add new icons\" 6 } catalog/config.json Copy This will tell users what you added in the latest version of your Nerdpack. Step 6 of 7 Submit this new metadata to the catalog: bash Copy $ nr1 catalog:submit Uploading screenshots... ✔ Screenshots uploaded ✔ Updated metadata for DemoApp 1.0.1 Step 7 of 7 Go to the catalog and subscribe to your Nerdpack to see your new icon: Resolve issues with submitting catalog information Sometimes, when you work with catalog metadata, you may run into issues. Consider some common solutions for resolving these issues. Publish your Nerdpack Remember that you can only submit catalog metadata for Nerdpacks that have already been published. If you try to submit information for a Nerdpack that hasn't been published, the CLI will try to help: bash Copy $ nr1 catalog:submit Uploading screenshots... › Error: 1 error while updating DemoApp 1.0.0 › › Invalid Version: Nerdpack version 1.0.0 not found. Have you run `nr1 nerdpack:publish` yet? › Code: UNKNOWN Resize your images Screenshots for the catalog must meet the criteria specified previously in this guide. If they don't, the CLI will try to help: bash Copy $ nr1 catalog:submit Uploading screenshots... › Error: 2 errors while updating DemoApp 1.0.1 › › catalog/screenshots/screenshot.png › Invalid Screenshot: screenshot.png has a size ratio of 4:2. Update size ratio to 3:2. › › catalog/screenshots/screenshot.png › Invalid Screenshot: screenshot.png has a width of 3054px. Update size to be between 1600px and 2400px. › Code: UNKNOWN Check the length of your strings Most of the content in config.json has string-length requirements. Make sure you review those requirements and adhere to them when you update your config.json file. Otherwise, you'll see errors when you try to submit your configuration to the catalog: bash Copy $ nr1 catalog:submit Uploading screenshots... ✔ Screenshots uploaded › Error: 2 errors while updating DemoApp 1.0.1 › › catalog/config.json › Invalid Metadata: `details` has a character length of 2204. Must be no longer than 1000 characters › › catalog/config.json › Invalid Metadata: `tagline` has a character length of 266. Must be no longer than 30 characters › Code: UNKNOWN",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.05775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Resize your <em>images</em>",
        "body": " <em>images</em> <em>Screenshots</em> for the catalog must meet the criteria specified previously in this guide. If they don&#x27;t, the CLI will try to help: bash Copy $ nr1 catalog:submit Uploading <em>screenshots</em>... › Error: 2 errors while updating DemoApp 1.0.1 › › catalog&#x2F;<em>screenshots</em>&#x2F;<em>screenshot</em>.png › Invalid <em>Screenshot</em>"
      },
      "id": "609c868664441f2bf22f3706"
    },
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-06-14T18:13:18Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 55.09901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Embed <em>images</em>",
        "sections": "Embed <em>images</em>",
        "tags": "Processes <em>and</em> procedures",
        "body": "A well-chosen <em>screenshot</em> or image can greatly improve the readability and clarity of a doc. Too many <em>images</em> or an image that&#x27;s tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you&#x27;re not part of the Docs team"
      },
      "id": "604220ec196a67105da83dc2"
    }
  ],
  "/docs/style-guide/writing-guidelines/voice-strategies-docs-sound-new-relic": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Collect data - any source",
        "Create custom events",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-06-16T01:41:23Z",
      "title": "Collect data",
      "updated_at": "2021-06-11T01:39:06Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes   Use custom attributes for deeper analysis Collect data - any source 15 min APIs, agents, OS emitters - get any data Create custom events 5 min Define, visualize, and get alerts on the data you want using custom events Build queries with NerdGraph 25 min Try NerdGraph and build the queries you need Query data with NRQL 10 min Query default data, custom events, and attributes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 74.67338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "Through our opensource agents or APIs, <em>New</em> <em>Relic</em> makes it easy to collect data from any source. The guides in this section provide <em>strategies</em> for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "image": "https://developer.newrelic.com/static/developer-champions-c61b7fb3b08d228679edab34b2d15a0e.jpg",
      "url": "https://developer.newrelic.com/developer-champion/",
      "sections": [
        "New Relic Developer Champions",
        "What do Developer Champions do?",
        "Open-source contributions",
        "Content creation",
        "Community engagement",
        "Why should you join and how will we support?",
        "Developer Champions benefits:"
      ],
      "published_at": "2021-06-16T01:47:26Z",
      "title": "New Relic Developers",
      "updated_at": "2020-12-04T01:45:02Z",
      "type": "developer",
      "external_id": "2cef9996dadc081ed4331e85992a4af9defc87ff",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Champions are the voice of the developer community. As experts and innovators, they are given the resources to not only share the newest product innovations and updates but also to provide feedback of the community back to New Relic product and engineering teams. Champions solve big problems using New Relic as their toolkit and are recognized as experts and leaders in the New Relic technical community. Nominate a developer champion What do Developer Champions do? New Relic Champions demonstrate expertise in using New Relic products by solving large problems and positioning New Relic as a central force in their strategies. The New Relic Champions is a recognition and partnership program designed to acknowledge the developers that are driving innovation within their companies and making top contributions to the developer community.They also commit to making their work public by: Open-source contributions Serving as an open-source author or maintainer for an accepted public project related to New Relic One Content creation Authoring two pieces of content in the New Relic Explorers Hub / Dev website Community engagement Delivering and/or organizing two events focused on an observability platform theme in which New Relic plays a crucial role Nominate a Developer Champion Why should you join and how will we support? As a benefit of being a Developer Champion, New Relic provides unique access to our Developer Advocacy team and the resources of our product organization, as well as specialized recognition and rewards. Developer Champions benefits: Formal, specialized access to the New Relic Product organization Champions have direct access to the New Relic’s Developer Ecosystem team Custom badge to wear with pride at events Public recognition on the New Relic Developer website and badging in the New Relic Explorers Hub as a Champion Exclusive Champion-only swag Early access program for some of our products (under NDA) Priority access to off-site FutureHack events (including when Lew is participating) Increased Explorer’s Hub support SLA Access to private Developer Champion Explorer’s Hub group",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 73.5671,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Developers",
        "sections": "<em>New</em> <em>Relic</em> Developer Champions",
        "body": "<em>New</em> <em>Relic</em> Champions are the <em>voice</em> of the developer community. As experts and innovators, they are given the resources to not only share the newest product innovations and updates but also to provide feedback of the community back to <em>New</em> <em>Relic</em> product and engineering teams. Champions solve big"
      },
      "id": "5efa993c64441fc2a25f7e65"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/whats-new/2020/10/alerting-loss-signal-detection-configurable-gap-filling-strategies/",
      "sections": [
        "Alerting: Loss of signal detection and configurable gap-filling strategies"
      ],
      "published_at": "2021-06-15T04:14:01Z",
      "title": "Alerting: Loss of signal detection and configurable gap-filling strategies",
      "updated_at": "2021-05-28T14:25:54Z",
      "type": "docs",
      "external_id": "f8a390c435267f78c9c0b82e709accb5371f6be3",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "At times, for a variety of reasons, an incoming signal can be lost and it’s important to know if this is a delay or if it’s the beginning of a much larger problem. New Relic One now provides official support for loss of signal detection on any NRQL Alert Condition. To see if it’s simply a delay in signal or something worse, you can now configure loss of signal detection by specifying how many seconds the system should wait, from the time the last data point was detected, before considering the signal to be lost. If the signal does not return before your specified time expires, you can choose to be notified that the signal has been lost, or you can simply choose to close any related open violations if you expected the entity or signal to disappear. We know that not all signals or time series that are being monitored have a consistent flow of data points. Because New Relic evaluates incoming data in specific windows of time, in many cases, the telemetry signals you send to New Relic can have gaps, meaning that some time windows will not have data. You now have the option to implement multiple strategies for how those gaps should be filled–sometimes called extrapolation strategies–including setting a static value, using the previously detected value, or not doing anything. When editing a NRQL Alert Condition, you can configure loss of signal detection under Condition settings > Set your condition thresholds and gap filling under Condition settings > Fine-tune advanced signal settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 62.8892,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alerting: Loss of signal detection and configurable gap-filling <em>strategies</em>",
        "sections": "Alerting: Loss of signal detection and configurable gap-filling <em>strategies</em>",
        "body": " incoming data in specific windows of time, in many cases, the telemetry signals you send to <em>New</em> <em>Relic</em> can have gaps, meaning that some time windows will not have data. You now have the option to implement multiple <em>strategies</em> for how those gaps should be filled–sometimes called extrapolation <em>strategies</em>"
      },
      "id": "60446a7c196a67d20b960f38"
    }
  ],
  "/docs/synthetics/index": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 80.36008,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> monitors",
        "sections": "Types of <em>synthetic</em> monitors",
        "tags": "<em>Synthetics</em>",
        "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 77.47299,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> monitoring response codes",
        "sections": "<em>Synthetic</em> monitoring response codes",
        "tags": "<em>Synthetics</em>",
        "body": " timed out&quot; -9999 &quot;unknown error, error not mapped&quot; For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic <em>Synthetics</em> monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-15T15:16:28Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 61.577248,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetics</em>",
        "body": ", otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in <em>Synthetics</em>. To set up the modules: Create a directory which contains"
      },
      "id": "603ea540196a67e50da83d95"
    }
  ],
  "/docs/synthetics/new-relic-synthetics/pages/synthetics-results-access-individual-monitor-runs": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19232,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25749,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources <em>page</em>. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-15T15:15:34Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.08795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    }
  ],
  "/docs/synthetics/new-relic-synthetics/synthetics-api/synthetics-rest-api-version-1": [
    {
      "sections": [
        "Payload attributes for the Synthetics REST API",
        "Synthetic monitoring attributes",
        "Specific monitor endpoint",
        "For more help"
      ],
      "title": "Payload attributes for the Synthetics REST API",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "ed3202f6715ae367d5c7c58d63a332d073535995",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/payload-attributes-synthetics-rest-api/",
      "published_at": "2021-06-14T23:09:30Z",
      "updated_at": "2021-03-11T11:46:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For REST API requirements for synthetics, see Use the API. Synthetic monitoring attributes Here are the attributes that can be used when creating and managing monitors with the Synthetics REST API: Synthetics API attribute Definition apiVersion String: The version number. count Integer: The number of monitors returned. emails Array of strings: Email addresses for alert notifications with New Relic. frequency Integer: Number of minutes between checks. Valid values include 1, 5, 15, 30, 60, 360, 720, and 1440. id The UUID for the specific synthetic monitor. locations Array of strings: Array of locations by full label. name String: The monitor's name. scriptLocations String: The name and hmac values for private locations using Verified Script Execution. scriptText String: The BASE64 encoded text for scripted monitors. slaThreshold Double: Value for the Synthetics SLA report, in seconds. status String: Valid values include ENABLED, MUTED, and DISABLED. type String: Type of monitor. Valid values include: SIMPLE (Ping) BROWSER SCRIPT_BROWSER SCRIPT_API uri String: The URI for SIMPLE and BROWSER monitor types; for example, http://my-site.com. Optional for SCRIPT_BROWSER and SCRIPT_API. userID Integer: The specific user ID. options Object: options for SIMPLE and BROWSER monitor types. Options include: validationString: string verifySSL: boolean (true, false) bypassHEADRequest: boolean (true, false) treatRedirectAsFailure: boolean (true, false) Specific monitor endpoint When making REST API calls for a specific monitor, include the monitor_uuid as part of the endpoint. The monitor_uuid is the GUID which is part of the URL. For example, a selected synthetic monitor has this URL: https://synthetics.newrelic.com/accounts/nnnn/monitors/ab123-c456d-e78-90123-f45g Copy The monitor_uuid is the value that follows /monitors/. For more help Additional documentation resources include: Manage synthetic monitors via the REST API (API procedures for synthetic simple and scripted monitors) Manage synthetic alert notifications via the REST API (REST API calls for email alerts for synthetic monitors) Use synthetics label APIs (REST API calls for labels and categories used by synthetic monitors)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.20956,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Payload attributes for the <em>Synthetics</em> <em>REST</em> <em>API</em>",
        "sections": "Payload attributes for the <em>Synthetics</em> <em>REST</em> <em>API</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " The <em>monitor</em>_uuid is the value that follows &#x2F;monitors&#x2F;. For more help Additional documentation resources include: Manage synthetic monitors via the <em>REST</em> <em>API</em> (<em>API</em> procedures for synthetic simple and scripted monitors) Manage synthetic alert notifications via the <em>REST</em> <em>API</em> (<em>REST</em> <em>API</em> calls for email alerts for synthetic monitors) Use <em>synthetics</em> label <em>APIs</em> (<em>REST</em> <em>API</em> calls for labels and categories used by synthetic monitors)"
      },
      "id": "6043f9ae28ccbc98002c607a"
    },
    {
      "sections": [
        "Manage synthetic monitors via REST API",
        "Features",
        "Monitor types in API",
        "Use the API",
        "Caution",
        "Get all monitors",
        "Get a specific monitor",
        "Create a monitor",
        "Update an existing monitor",
        "Patch an existing monitor",
        "Delete an existing monitor",
        "Get a list of valid locations",
        "Script API for scripted browser and API test monitors",
        "Get monitor script",
        "Add scripted monitor",
        "Update monitor script",
        "Using private location scripts with verified script execution",
        "Important",
        "Scripted browser example",
        "Scripted browser API example",
        "Bash script example",
        "Tip"
      ],
      "title": "Manage synthetic monitors via REST API",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "83a3e8ad751c7f0865785a1c2fad193604a7f7da",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/manage-synthetics-monitors-rest-api/",
      "published_at": "2021-06-14T23:09:30Z",
      "updated_at": "2021-03-11T10:41:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Synthetics REST API to create and manage synthetic monitors of all types: ping, simple browser, scripted browser, and API test monitors. All synthetic monitoring data is available via the REST API. To use the Synthetics REST API, you must have a user role that allows that capability and a user key. For an overview of all available New Relic APIs, see Intro to APIs. Features The newest version of the Synthetics API (v3) adds these features: Synthetics API (v3) Features Options field for POST and PUT request You can specify the options for SIMPLE and BROWSER type monitors, similar to the way these options are available in the UI. PATCH request You can update only the fields of a monitor you want to change, rather than having to specify the entire monitor entity in a PUT. You can also specify the OPTION, assuming you are using the appropriate type of monitor. More detail with 400 Bad Request errors As of v3, the Synthetics API attempts to return as much information as possible when a validation failure occurs. This will help you figure out what might be wrong with the request. The API runs all validations and returns any failed validation messages, rather than failing on the first validation error as occurred in previous API versions. Pagination Large API responses are properly paginated. You can also use NRQL queries to analyze past changes made via the API. Monitor types in API These are the monitor types and how they're referred to in the API: Monitor type API name Ping SIMPLE Simple browser BROWSER Scripted browser SCRIPT_BROWSER API test SCRIPT_API Use the API To use the Synthetics REST API, you must have the ability to manage synthetics monitors and use a user key (the REST API key won't work). This API can be used for all Synthetics monitors. (Additional API methods for scripted browser and API test monitors are also available to update the script associated with those monitors.) All Synthetics data is available via the API. API examples show cURL commands. For US-based accounts, use the following endpoint: https://synthetics.newrelic.com/synthetics/api Copy For EU-based accounts, use the following endpoint: https://synthetics.eu.newrelic.com/synthetics/api Copy Caution The Synthetics REST API limits an account's rate of requests to three requests per second. Requests made in excess of this threshold will return a 429 response code. Get all monitors To view a list of all the monitors in your New Relic account, send a GET request to $API_ENDPOINT/v3/monitors. For example: curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"monitors\": [ { \"id\": \"2a1bc369-7654-489d-918e-f6g135h7i2jk\", \"name\": \"monitor1\", \"type\": \"BROWSER\", \"frequency\": 60, \"uri\": \"http://example.com\", \"locations\": [ \"AWS_US_WEST_1\" ], \"status\": \"DISABLED\", \"slaThreshold\": 7, \"options\": {}, \"modifiedAt\": \"2016-09-26T23:12:46.981+0000\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"userId\": 0, \"apiVersion\": \"0.2.2\" } ], \"count\": 1 } Copy Query arguments: offset: The monitor count offset. Defaults to 0. For example, if you have 40 monitors and you use an offset value of 20, it will return monitors 21-40. limit: The number of results per page, maximum 100. Defaults to 20. You can include these in your cURL command as follows: curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors \\ -G -d 'offset=20&limit=100' Copy The headers include a Link to help you easily page your monitors. For example: <https://synthetics.newrelic.com/synthetics/api/v3/monitors/?offset=0&limit=20>; rel=\"first\", <https://synthetics.newrelic.com/synthetics/api/v3/monitors/?offset=40&limit=20>; rel=\"last\" Copy Get a specific monitor To view a single Synthetics monitor, send a GET request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors/$MONITOR_ID Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"id\": UUID, \"name\": string, \"type\": string, \"frequency\": integer, \"uri\": string, \"locations\": array of strings, \"status\": string, \"slaThreshold\": double, \"userId\": integer, \"apiVersion\": string } Copy An invalid monitor ID will return 404 Not Found: The specified monitor doesn't exist. Create a monitor To add a new monitor to your Synthetics account, send a POST request to $API_ENDPOINT/v3/monitors with a JSON payload that describes the monitor. All fields in the following example are required unless stated otherwise: { \"name\": string [required], \"type\": string (SIMPLE, BROWSER, SCRIPT_API, SCRIPT_BROWSER) [required], \"frequency\": integer (minutes) [required, must be one of 1, 5, 10, 15, 30, 60, 360, 720, or 1440], \"uri\": string [required for SIMPLE and BROWSER type], \"locations\": array of strings [at least one required], \"status\": string (ENABLED, MUTED, DISABLED) [required], \"slaThreshold\": double, \"options\": { \"validationString\": string [only valid for SIMPLE and BROWSER types], \"verifySSL\": boolean (true, false) [only valid for SIMPLE and BROWSER types], \"bypassHEADRequest\": boolean (true, false) [only valid for SIMPLE types], \"treatRedirectAsFailure\": boolean (true, false) [only valid for SIMPLE types] } } Copy In addition, to add the script for a scripted monitor via the REST API, call an additional API endpoint to send the script for the monitor just created. If you are using private locations with verified script execution enabled, see script locations with verified script execution. Replace the Synthetics REST API attributes in the following example with your specific values: curl -v \\ -X POST -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors \\ -d '{ \"name\" : \"monitor1\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"type\" : \"browser\", \"status\" : \"enabled\", \"slaThreshold\" : \"1.0\"}' Copy A successful request will return a 201 Created response, with the URI of the newly-created monitor specified in the location header. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example: the frequency is out of bounds or one or more of the specified locations is invalid. (See the error message in the body of the response.) 402 Payment Required: Creating the monitor will increase your scheduled checks past your account's purchased check limit. Update an existing monitor To update an existing monitor in New Relic, send a PUT request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. In addition, for scripted monitors, follow the procedures to update the BASE64 encoded script. All fields are required. However, the TYPE of the monitor cannot be changed. Use a specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PUT -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors/$MONITOR_ID \\ -d '{ \"name\" : \"updated monitor name\", \"type\": \"monitor type\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com/\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"status\" : \"enabled\", \"slaThreshold\": \"7.0\" }' Copy PUT requests are intended to replace target entities, so all attributes required in the JSON payload when creating a new monitor are also required when updating an existing monitor. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds or one or more of the specified locations is invalid. (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Patch an existing monitor To patch an existing monitor in New Relic, send a PATCH request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. Use a specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PATCH -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors/$MONITOR_ID \\ -d '{ \"name\" : \"updated monitor name\" }' Copy PATCH requests are intended to update individual attributes of your New Relic Synthetics monitor rather than updating the entire entity, so you may provide only the attributes you want to update. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds, or one or more of the specified locations is invalid. (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Delete an existing monitor To delete an existing monitor in New Relic Synthetics, send a DELETE request to $API_ENDPOINT/v3/monitors/$MONITOR_ID: curl -v \\ -H 'Api-Key:$API_KEY' \\ -X DELETE $API_ENDPOINT/v3/monitors/$MONITOR_ID Copy A successful request will return a 204 No Content response, with an empty body. An unsuccessful request will return the response 404 Not Found: The specified monitor does not exist. Get a list of valid locations To retrieve the list of valid locations in New Relic Synthetics, use the following command: curl -v \\ -X GET -H 'Api-Key:$API_KEY' $API_ENDPOINT/v1/locations Copy Script API for scripted browser and API test monitors In addition to the general API, there are several API methods for the scripted Browsers (SCRIPT_BROWSER) and API test browsers (SCRIPT_API). These examples show cURL commands. Get monitor script To view the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic Synthetics for your account, send a GET request to $API_ENDPOINT/v3/monitors/$MONITOR_ID/script. For example: curl -v -H 'Api-Key: $API_KEY' $API_ENDPOINT/v3/monitors/$MONITOR_ID/script Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"scriptText\": BASE64 encoded string } Copy Possible error codes include: 403 Forbidden: The specified monitor is not of type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor doesn't exist or the script associated with the monitor doesn't exist. Add scripted monitor To add a new scripted monitor to New Relic Synthetics with the REST API: Follow standard API procedures to add a new monitor, and identify the type as a SCRIPT_BROWSER or SCRIPT_API. Update the new monitor with a BASE64 encoded version of the script to the $MONITOR_UUID/script endpoint. For more information, refer to the example. If you are using private locations with verified script execution enabled, see script locations with verified script execution. Update monitor script To update the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic Synthetics for your account, send a PUT request to $API_ENDPOINT/v3/monitors/$MONITOR_ID/script with a JSON payload that contains the scriptText (required). scriptPayload='{\"scriptText\":BASE64 encoded string}' curl -v -X PUT \\ -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' \\ $API_ENDPOINT/v3/monitors/$MONITOR_UUID/script \\ -d $scriptPayload Copy If you are using private locations with verified script execution enabled, see script locations with verified script execution. A successful request will return a 204 No Content response with an empty body. Possible error codes include: 400 Bad Request: Invalid BASE64 encoded string for scriptText or hmac. 403 Forbidden: The specified monitor is not of the type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor does not exist. Using private location scripts with verified script execution When creating or updating monitors for private locations that have verified script execution turned on, you must use scriptLocations to set the password: { \"scriptText\": BASE64 encoded String, \"scriptLocations\": [ { \"name\": Location name, \"hmac\" BASE64 encoded String of SHA256 HMAC for location } ] } Copy The password used to generate the HMAC string must match the password set for the private location. If you have multiple locations with Verified script execution enabled each location must have the HMAC calculated. When generating the HMAC string, use the SHA256 algorithm with the script and password. Here's an example for the script: var assert = require('assert'); assert.equal('1', '1'); Copy This example uses password as the password for the scriptLocation: curl -v -X PUT -H 'Api-Key: '$API_KEY' -H 'content-type: application/json' $API_ENDPOINT}/v3/monitors/$MONITOR_ID/script -d '{ \"scriptText\": \"dmFyIGFzc2VydCA9IHJlcXVpcmUoJ2Fzc2VydCcpOw0KYXNzZXJ0LmVxdWFsKCcxJywgJzEnKTs=\",\"scriptLocations\": [ { \"name\": \"my_vse_enabled_location\", \"hmac\": \"MjhiNGE4MjVlMDE1N2M4NDQ4MjNjNDFkZDEyYTRjMmUzZDE3NGJlNjU0MWFmOTJlMzNiODExOGU2ZjhkZTY4ZQ==\"} ]}' Copy Important You must remove the last newline character from both the script and the calculated HMAC value before encoding in BASE64. Calculation steps: Calculate the HMAC value from the script. One way is to use: cat script | openssl dgst -sha256 -hmac \"password\" > hmac Remove the newline character if one was added by openssl. Encode the HMAC in BASE64 without line breaks. Scripted browser example Here is an example of using New Relic's REST API and the bash script to create a scripted browser monitor. Scripted browser API example The following example shows cURL commands to create a scripted browser monitor. At the top of the script, replace the variables with your specific values. For the scriptfile variable, identify the filename for the script to be created. Here is a sample script that can be saved as sample_synth_script.js to use in the example: var assert = require(\"assert\"); $browser.get(\"http://example.com\").then(function(){ // Check the H1 title matches \"Example Domain\" return $browser.findElement($driver.By.css(\"h1\")).then(function(element){ return element.getText().then(function(text){ assert.equal(\"Example Domain\", text, \"Page H1 title did not match\"); }); }); }).then(function(){ // Check that the external link matches \"http://www.iana.org/domains/example\" return $browser.findElement($driver.By.css(\"div > p > a\")).then(function(element){ return element.getAttribute(\"href\").then(function(link){ assert.equal(\"http://www.iana.org/domains/example\", link, \"More information link did not match\"); }); }); }); Copy Bash script example This example shows the bash script that will create the SCRIPTED_BROWSER monitor. Tip In some cases you may want to use -w 0, which will disable line wrapping: base64 -w 0 $scriptfile #!/bin/bash # API key from your account settings API_KEY='' # Other attributes found at https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/attributes-synthetics-rest-api#api-attributes monitorName='Test API Script' monitorType='SCRIPT_BROWSER' frequency=1440 locations='\"AWS_US_WEST_1\", \"AWS_US_EAST_1\"' slaThreshold=7.0 # Location of the file with your script scriptfile=sample_synth_script.js # Test that the script file exists (does not validate content) if [ -e \"$scriptfile\" ] then script=$(cat \"$scriptfile\") payload=\"{ \\\"name\\\" : \\\"$monitorName\\\", \\\"frequency\\\" : $frequency, \\\"locations\\\" : [ $locations ], \\\"status\\\" : \\\"ENABLED\\\", \\\"type\\\" : \\\"$monitorType\\\", \\\"slaThreshold\\\" : $slaThreshold, \\\"uri\\\":\\\"\\\"}\" echo \"Creating monitor\" # Make cURL call to API and parse response headers to get monitor UUID shopt -s extglob # Required to trim whitespace; see below while IFS=':' read key value; do # trim whitespace in \"value\" value=${value##+([[:space:]])}; value=${value%%+([[:space:]])} case \"$key\" in location) LOCATION=\"$value\" ;; HTTP*) read PROTO STATUS MSG <<< \"$key{$value:+:$value}\" ;; esac done < <(curl -sS -i -X POST -H \"Api-Key:$API_KEY\" -H 'Content-Type:application/json' https://synthetics.newrelic.com/synthetics/api/v3/monitors -d \"$payload\") # Validate monitor creation & add script unless it failed if [ $STATUS = 201 ]; then echo \"Monitor created, $LOCATION \" echo \"Uploading script\" # base64 encode script encoded=`echo \"$script\" | base64` scriptPayload=\"{\\\"scriptText\\\":\\\"$encoded\\\"}\" curl -s -X PUT -H \"Api-Key:$API_KEY\" -H 'Content-Type:application/json' \"$LOCATION/script\" -d $scriptPayload echo \"Script uploaded\" else echo \"Monitor creation failed\" fi else echo \"script file not found, not creating monitor\" fi Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.20297,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>synthetic</em> <em>monitors</em> via <em>REST</em> <em>API</em>",
        "sections": "Manage <em>synthetic</em> <em>monitors</em> via <em>REST</em> <em>API</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " will disable line wrapping: base64 -w 0 $scriptfile #!&#x2F;bin&#x2F;bash # <em>API</em> key from your account settings <em>API</em>_KEY=&#x27;&#x27; # Other attributes found at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>apis</em>&#x2F;<em>synthetics</em>-<em>rest</em>-<em>api</em>&#x2F;<em>monitor</em>-<em>examples</em>&#x2F;attributes-<em>synthetics</em>-<em>rest</em>-<em>api</em>#<em>api</em>-attributes <em>monitor</em>Name=&#x27;Test <em>API</em> Script&#x27; <em>monitor</em>"
      },
      "id": "60440d4628ccbc74532c606a"
    },
    {
      "sections": [
        "Introduction to New Relic APIs",
        "Tip",
        "NerdGraph (GraphQL)",
        "REST APIs by capability",
        "Alerts",
        "APM",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Synthetic monitoring",
        "Telemetry APIs for core data types",
        "Account management, admin, and usage APIs",
        "Other APIs",
        "Insights",
        "Plugins",
        "See APIs in action"
      ],
      "title": "Introduction to New Relic APIs",
      "type": "docs",
      "tags": [
        "APIs",
        "Get started",
        "Intro to APIs"
      ],
      "external_id": "01e9799a214baad5de04de6146483f6dbbc198aa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/intro-apis/introduction-new-relic-apis/",
      "published_at": "2021-06-14T18:02:47Z",
      "updated_at": "2021-06-02T16:33:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a variety of APIs and SDKs you can use to: Retrieve data from New Relic. Send data to New Relic. Adjust settings. This document provides examples and reference information for our API endpoints. For developer-focused content on how to use and customize New Relic, see developer.newrelic.com. Tip To use APIs and SDKs, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. NerdGraph (GraphQL) NerdGraph is New Relic's GraphQL-format API, an efficient and flexible query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph is the preferred API for querying New Relic data and making a range of feature configurations. To get started, see Introduction to NerdGraph. REST APIs by capability New Relic capabilities, like APM, infrastructure monitoring, or alerts, are often used together, and sometimes they overlap in functionality. This is why multiple APIs may be relevant to each area. Some API functionality will depend on your access to features and data. Tip To learn more about different API key types, see Understand New Relic API keys. Alerts Use the REST API for alerts and the API Explorer to: Create and manage policies, conditions, and notification channels. Create alert conditions based on NRQL queries. Create alert conditions based on data from other New Relic capabilities. APM API resources for application monitoring include: Resource Details REST API REST API features include: Retrieve APM data, including metrics, Apdex, error rates, and host data. Report deployments. Change the app name in the UI. Agent APIs Every APM language agent has an API that lets you customize the agent's default behavior, including reporting custom data. APM agent APIs include: C SDK API Go agent API Java agent API .NET agent API Node.js agent API PHP agent API Python agent API Ruby agent API Query API To query APM data, use the Query API. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Browser monitoring The Browser API resources include: Resource Details Browser agent API Use the Browser agent API for tasks such as: Report custom end user data to browser monitoring. Monitor asynchronous browser activity using SPA API calls. Insert custom data into New Relic dashboards . Manage source maps. REST API With the REST API you can: Retrieve page load timing data and throughput. Add or list apps monitored by browser monitoring. Manage alerts conditions for your browser data. Query API To retrieve browser monitoring data, use the Query API. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Infrastructure monitoring The Infrastructure API resources include: Resource Details Query API To retrieve infrastructure data, use the Query API. This API can also be used to retrieve subscription usage data. Infrastructure alert API To manage your infrastructure alerts, use the Infrastructure alert API. Integrations SDK To make your own custom integrations for reporting data to infrastructure monitoring, use the Integrations SDK. NerdGraph You can use NerdGraph (our GraphQL API) to query your cloud integration data and make changes to cloud integration settings. Mobile monitoring Mobile API resources include: Resource Details Mobile agent APIs Mobile APIs let you custom instrument your own code and send events to New Relic. See the platform-specific documentation: iOS Android Unity REST API Use the REST API for such tasks as: Retrieve a list of monitored apps. Get subscription usage data. Get metric names and data. Get crash count and crash rate data. Manage New Relic alerts conditions for your mobile apps. Query API To retrieve Mobile data from New Relic, use the Query API. Account management APIs For account-related APIs, see Account APIs. Synthetic monitoring Synthetics API resources include: Resource Details Synthetics REST API The Synthetics REST API functionality includes: Create and manage synthetics monitors. Manage synthetics alert notifications. Add labels to monitors, and retrieve monitors with specific labels. Query API To retrieve synthetics event data, use the Query API. Alerts API To create and manage alert conditions that target synthetics monitors, use the Alerts API. Telemetry APIs for core data types We offer several APIs that allow you to get our core data types (metrics, logs, traces, and events) into New Relic without the use of an installed agent. Data type Description Trace API Send distributed tracing data to New Relic. Event API Send event data to New Relic. Metric API Send metrics to New Relic from any source (including other telemetry monitoring services). Log API Send your log data to New Relic. Account management, admin, and usage APIs Like any other New Relic product or service, you want to be confident that your APIs protect you and your customers' data privacy. The following are API resources related to New Relic account administration and usage. For more information about API capabilities, see the specific New Relic API. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. Resource Details REST API REST API features include: Find your API keys, account ID, and information needed to use the REST API. Return a list of account users (original user model only). Get SLA report data for browser and application monitoring. Subscription usage You can use the Query API to retrieve subscription usage data. This can be helpful to see how usage compares to your current subscription level, or for doing departmental chargebacks. Partner API To retrieve information about your New Relic partner account, sub-accounts, and users, use the Partner API. Other APIs Insights New Relic Insights was the name of our original product that governed custom event reporting and querying. The features associated with Insights have been rolled into our New Relic One platform (learn more), but there are still some APIs and original pricing plans that use the term \"Insights\" for these historical reasons. Insights-related APIs include: Resource Details Event API To report custom events, use the Event API. Query API To query your data using NRQL-format queries, you can use the Query API. Note that this API is deprecated and NerdGraph is preferred for querying your data. Dashboard API See the Insights Dashboard API. Plugins Use the REST API for New Relic plugins and the API Explorer to: Get a list of plugins, including their names, IDs, and GUIDs. List one or more plugin components, their output, and their metric timeslice data. Developers and New Relic partners can also use New Relic's Plugin API to write an agent in any language that can work directly with the API for plugins. This allows you to send your own metric data to our plugins and view data received from the API in New Relic. See APIs in action For more on how you as a developer can optimize your ability to solve problems using New Relic, go to developer.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.36244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>APIs</em>",
        "sections": "<em>REST</em> <em>APIs</em> by capability",
        "tags": "<em>APIs</em>",
        "body": " New Relic, use the Query <em>API</em>. Account management <em>APIs</em> For account-related <em>APIs</em>, see Account <em>APIs</em>. Synthetic monitoring <em>Synthetics</em> <em>API</em> resources include: Resource Details <em>Synthetics</em> <em>REST</em> <em>API</em> The <em>Synthetics</em> <em>REST</em> <em>API</em> functionality includes: Create and manage <em>synthetics</em> monitors. Manage <em>synthetics</em> alert"
      },
      "id": "609fa5cf196a67066022b194"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/compare-page-load-performance-browser-synthetic-monitoring": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.63461,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.50427,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-15T15:12:03Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.9685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/identify-synthetic-monitoring-requests-your-app": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.63461,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.50427,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-15T15:12:03Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.9685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.63461,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.50427,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-15T15:12:03Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.9685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/synthetic-monitoring-audit-log-track-changes-made-users": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.63449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.50415,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-15T15:12:03Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.9685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.63449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.50415,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Upcoming synthetic monitor public minion IP addresses",
        "US public minions: Upcoming IP addresses",
        "EU public minions: Upcoming IP addresses"
      ],
      "title": "Upcoming synthetic monitor public minion IP addresses",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "81c0e0d3f87a627ad01f220f215f7b848f54608d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips/",
      "published_at": "2021-06-15T15:12:03Z",
      "updated_at": "2021-04-04T20:14:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On July 15 2021, we'll be adding new IP addresses for several synthetics locations for both US locations and EU locations. To ensure your monitors are not affected by these changes, please add the appropriate IP addresses to your firewalls allow list. For the current list of IP addresses and more about this topic, see Synthetic monitor public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 54.250.11.193 3.113.102.86 52.193.74.189 18.177.40.17 ec2-54-250-11-193.ap-northeast-1.compute.amazonaws.com ec2-3-113-102-86.ap-northeast-1.compute.amazonaws.com ec2-52-193-74-189.ap-northeast-1.compute.amazonaws.com ec2-18-177-40-17.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 3.34.173.249 52.79.48.153 ec2-3-34-173-249.ap-northeast-2.compute.amazonaws.com ec2-52-79-48-153.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 65.1.222.35 ec2-65-1-222-35.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 52.76.41.181 54.179.195.220 18.138.16.42 ec2-52-76-41-181.ap-southeast-1.compute.amazonaws.com ec2-54-179-195-220.ap-southeast-1.compute.amazonaws.com ec2-18-138-16-42.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 3.96.243.128 3.97.226.155 ec2-3-96-243-128.ca-central-1.compute.amazonaws.com ec2-3-97-226-155.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.94.27.80 18.229.241.206 ec2-54-94-27-80.sa-east-1.compute.amazonaws.com ec2-18-229-241-206.sa-east-1.compute.amazonaws.com AWS_US_WEST_2 \"Portland, OR, USA\" 44.236.111.66 54.203.108.135 ec2-44-236-111-66.us-west-2.compute.amazonaws.com ec2-54-203-108-135.us-west-2.compute.amazonaws.com EU public minions: Upcoming IP addresses The following table lists the upcoming IP addresses that will be added to public minions on July 15 2021 for EU customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 35.72.129.240 35.73.187.89 ec2-35-72-129-240.ap-northeast-1.compute.amazonaws.com ec2-35-73-187-89.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 13.125.155.211 15.164.119.0 ec2-13-125-155-211.ap-northeast-2.compute.amazonaws.com ec2-15-164-119-0.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 15.207.93.61 ec2-15-207-93-61.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 3.0.28.216 ec2-3-0-28-216.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 99.79.17.185 ec2-99-79-17-185.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.207.198.234 ec2-54-207-198-234.sa-east-1.compute.amazonaws.com",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.73865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "sections": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " about this topic, see <em>Synthetic</em> <em>monitor</em> public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses"
      },
      "id": "606a1e4364441fbec2617a7c"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/user-roles-synthetic-monitoring": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.63435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.50404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-15T15:12:03Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.9685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.9495,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.50404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-15T15:16:28Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.75163,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "User-defined environment variables for scripted <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/security-synthetic-monitoring": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.94931,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.50394,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-15T15:16:28Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.75159,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "User-defined environment variables for scripted <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.50394,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-15T15:16:28Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.75159,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "User-defined environment variables for scripted <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Tip",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2021-06-15T15:12:59Z",
      "updated_at": "2021-03-09T03:46:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.194046,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>Synthetic</em> <em>monitoring</em> stores every single run of your <em>monitor</em> for 13 months, so you can view a detailed breakdown of each and every check. You can <em>get</em> a snapshot of your website&#x27;s performance and availability, or hunt down specific problems. Comparative charts with browser <em>monitoring</em> Use New Relic"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-aggregate-monitor-metrics": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19183,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources <em>page</em>. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-15T15:15:34Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.08795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25696,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources <em>page</em>. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-15T15:15:34Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.08795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-troubleshoot-downtime": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19159,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources <em>page</em>. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-15T15:15:34Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.08795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-understand-load-times": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19159,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources <em>page</em>. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-15T15:15:34Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.08795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19159,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources <em>page</em>. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-06-15T15:14:46Z",
      "updated_at": "2021-03-30T19:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Synthetics > (select a monitor). You can also access it from one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (New Relic Browser) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.08783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration": [
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-15T15:17:18Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.55742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    },
    {
      "sections": [
        "Containerized private minion (CPM) maintenance and monitoring",
        "Tip",
        "Check CPM status using HTTP",
        "Check if your private location requires more minions",
        "Review logs",
        "Review Docker logs",
        "Review Kubernetes logs",
        "Enable debug logs",
        "Enable Docker debug logs",
        "Enable Kubernetes debug logs",
        "Retrieve Kubernetes debugging information",
        "Monitor CPMs with New Relic Infrastructure"
      ],
      "title": "Containerized private minion (CPM) maintenance and monitoring ",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "414f8966a290006d662010c910fc540018c0bf51",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring/",
      "published_at": "2021-06-15T15:16:27Z",
      "updated_at": "2021-05-09T18:11:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After installing your containerized private minion (CPM), you can keep track of its maintenance and monitoring in several ways: Check if the CPM is healthy and working with the CPM status endpoint. See if a private location is under-provisioned and needs more minions. Review your Docker logs or Kubernetes logs. Tip You can also get notified of monitor failures with New Relic's alerts. Check CPM status using HTTP Connecting to a running CPM using HTTP is the easiest way to check if it's healthy and working. The container exposes two ports: 8080 and 8180. You can check the CPM with the following endpoints: :8080/status/check: provides details about internal health checks that the minion performs. HTTP 200 means the status is healthy. :8080/status: provides details about a minion's status, which is the same data published in Insights as SyntheticsPrivateMinion event. :8180/: provides JVM application admin endpoints. This is an advanced view of a minion's Java Development Kit (JDK) internal state. Check if your private location requires more minions If your private location has multiple monitor checks queued up and you experience delays, you may need more minions available to execute the monitor checks. To learn how to verify this, see Does my private location need more minions? Review logs You can monitor your minion's health by looking at CPM container logs. Review Docker logs This is an example of a CPM log indicating that the minion is working properly in a Docker container system environment: $docker logs [YOUR_CONTAINER_NAME] 2018-10-10 11:33:29,856 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2018-10-10 11:33:29,869 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2018-10-10 11:33:40,527 - Minion is configured, checking if it is healthy... 2018-10-10 11:33:43,471 - Launching in PRIVATE Location: 123456-example_private_loc-480 2018-10-10 11:33:43,723 - Configured 2 heavy worker threads, and 50 light worker threads 2018-10-10 11:33:43,796 - 2018-10-10 11:33:43,796 - ************************************************************************** 2018-10-10 11:33:43,796 - * Synthetics Minion is ready and servicing location 'example_private_location' 2018-10-10 11:33:43,796 - ************************************************************************** ... logging continues ... Copy Review Kubernetes logs This is an example of a CPM log indicating that the minion is working properly in a Kubernetes container orchestration system environment: First, get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: $ kubectl logs -n YOUR_NAMESPACE YOUR_CPM_NAME 2020-05-11 22:57:24,084 - Minion will use 2 heavy workers 2020-05-11 22:57:24,149 - Minion will use 50 lightweight workers 2020-05-11 22:57:27,973 - Minion Container System: KUBERNETES 2020-05-11 22:57:30,158 - Minion deployment mode: PRIVATE_MINION_POD_KUBERNETES 2020-05-11 22:57:30,178 - No volume mounted at '/var/lib/newrelic/synthetics' in ':rw' mode: Private Minion's ID will change with each boot 2020-05-11 22:57:30,284 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2020-05-11 22:57:30,654 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2020-05-11 22:57:31,595 - Minion is configured, checking if it is healthy... 2020-05-11 22:57:35,457 - Launching in PRIVATE Location: 123456-example_private_loc-480 2020-05-11 22:57:36,060 - Executor for async-worker-* threads configured with a max pool size of 16 2020-05-11 22:57:36,072 - Configured 2 heavy worker threads, and 50 lightweight worker threads 2020-05-11 22:57:36,087 - 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - * Synthetics Minion 3.0.1 is ready and servicing location 'example_private_location' 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - ... logging continues ... Copy Enable debug logs If you experience issues with your CPM, you can enable debug logs to help troubleshoot issues. The default level of logging is set to only inform the user of key information and actionable errors. If this is insufficient, you can enable a more verbose logging by using the MINION_LOG_LEVEL environment variable. Enable Docker debug logs Tip Adding -f to the Docker logs makes the command follow logs. docker run ... -e MINION_LOG_LEVEL=DEBUG ... docker logs -f YOUR_CONTAINER_NAME ... verbose logging continues ... Copy Enable Kubernetes debug logs Tip Adding -f to the Kubernetes logs makes the command follow logs. To enable DEBUG logs add the --set synthetics.minionLogLevel=DEBUG option when running your helm install: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionLogLevel=DEBUG Copy Get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: kubectl logs -f -n YOUR_NAMESPACE YOUR_CPM_POD_NAME ... verbose logging continues ... Copy Retrieve Kubernetes debugging information If you experience issues with your CPM in a Kubernetes container orchestration system environment, you can retrieve information about the CPM pod and the node it is running on to help troubleshoot. To retrieve information for the CPM pod: kubectl describe pod -n YOUR_NAMESPACE YOUR_CPM_POD_NAME Copy To retrieve information for the node the CPM pod is running on, identify the node, and then: kubectl describe node NODE_ASSOCIATED_WITH_YOUR_CPM_POD_NAME Copy Monitor CPMs with New Relic Infrastructure New Relic's infrastructure monitoring supports advanced Docker monitoring and advanced Kubernetes monitoring. To add support for this, synthetic monitoring labels the containers spawned by CPM with a series of informative labels, all prefixed with synthetics-minion-. The CPM spawns containers called \"runners\" which process non-ping monitors like: simple browser, scripted browser, api test, and step function. You can use these labels to identify these runner containers. Example labels include: synthetics-minion-runner-role synthetics-minion-runner-version synthetics-minion-container-id synthetics-minion-id synthetics-minion-build-number synthetics-minion-job synthetics-minion-account synthetics-minion-monitor synthetics-minion-monitor-version synthetics-minion-monitor-type synthetics-minion-monitor-type-label Runner containers last a short time. One runner container is created to process one non-ping monitor job. The runner is created, processes the job, and is quickly deleted. A runner container exists for only a few seconds and will be created only if there is a non-ping monitor job to process. Ping monitors will not trigger runner container creation, so the above labels will not be present. If you are using the infrastructure agent to monitor these runner containers, configure at least one monitor to run each minute. The infrastructure agent will have more opportunity to notice and collect the above labels from the docker inspect of the container before it is deleted. Note: the synthetics-minion-id label refers to the ID of the minion which spawned this particular runner container. The ID of the runner itself is not tracked.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.01398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em> ",
        "sections": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " CPMs with New Relic Infrastructure New Relic&#x27;s infrastructure <em>monitoring</em> supports advanced Docker <em>monitoring</em> and advanced Kubernetes <em>monitoring</em>. To add support for this, <em>synthetic</em> <em>monitoring</em> labels the containers spawned by CPM with a series of informative labels, all prefixed with <em>synthetics</em>-minion"
      },
      "id": "603eac96196a67a833a83db8"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-15T15:16:29Z",
      "updated_at": "2021-05-04T17:59:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.3403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring": [
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-15T15:16:28Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.88452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-15T15:17:18Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.55742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-15T15:16:29Z",
      "updated_at": "2021-05-04T17:59:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.3403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms": [
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-15T15:16:28Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.88443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-15T15:17:18Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.55737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    },
    {
      "sections": [
        "Containerized private minion (CPM) maintenance and monitoring",
        "Tip",
        "Check CPM status using HTTP",
        "Check if your private location requires more minions",
        "Review logs",
        "Review Docker logs",
        "Review Kubernetes logs",
        "Enable debug logs",
        "Enable Docker debug logs",
        "Enable Kubernetes debug logs",
        "Retrieve Kubernetes debugging information",
        "Monitor CPMs with New Relic Infrastructure"
      ],
      "title": "Containerized private minion (CPM) maintenance and monitoring ",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "414f8966a290006d662010c910fc540018c0bf51",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring/",
      "published_at": "2021-06-15T15:16:27Z",
      "updated_at": "2021-05-09T18:11:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After installing your containerized private minion (CPM), you can keep track of its maintenance and monitoring in several ways: Check if the CPM is healthy and working with the CPM status endpoint. See if a private location is under-provisioned and needs more minions. Review your Docker logs or Kubernetes logs. Tip You can also get notified of monitor failures with New Relic's alerts. Check CPM status using HTTP Connecting to a running CPM using HTTP is the easiest way to check if it's healthy and working. The container exposes two ports: 8080 and 8180. You can check the CPM with the following endpoints: :8080/status/check: provides details about internal health checks that the minion performs. HTTP 200 means the status is healthy. :8080/status: provides details about a minion's status, which is the same data published in Insights as SyntheticsPrivateMinion event. :8180/: provides JVM application admin endpoints. This is an advanced view of a minion's Java Development Kit (JDK) internal state. Check if your private location requires more minions If your private location has multiple monitor checks queued up and you experience delays, you may need more minions available to execute the monitor checks. To learn how to verify this, see Does my private location need more minions? Review logs You can monitor your minion's health by looking at CPM container logs. Review Docker logs This is an example of a CPM log indicating that the minion is working properly in a Docker container system environment: $docker logs [YOUR_CONTAINER_NAME] 2018-10-10 11:33:29,856 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2018-10-10 11:33:29,869 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2018-10-10 11:33:40,527 - Minion is configured, checking if it is healthy... 2018-10-10 11:33:43,471 - Launching in PRIVATE Location: 123456-example_private_loc-480 2018-10-10 11:33:43,723 - Configured 2 heavy worker threads, and 50 light worker threads 2018-10-10 11:33:43,796 - 2018-10-10 11:33:43,796 - ************************************************************************** 2018-10-10 11:33:43,796 - * Synthetics Minion is ready and servicing location 'example_private_location' 2018-10-10 11:33:43,796 - ************************************************************************** ... logging continues ... Copy Review Kubernetes logs This is an example of a CPM log indicating that the minion is working properly in a Kubernetes container orchestration system environment: First, get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: $ kubectl logs -n YOUR_NAMESPACE YOUR_CPM_NAME 2020-05-11 22:57:24,084 - Minion will use 2 heavy workers 2020-05-11 22:57:24,149 - Minion will use 50 lightweight workers 2020-05-11 22:57:27,973 - Minion Container System: KUBERNETES 2020-05-11 22:57:30,158 - Minion deployment mode: PRIVATE_MINION_POD_KUBERNETES 2020-05-11 22:57:30,178 - No volume mounted at '/var/lib/newrelic/synthetics' in ':rw' mode: Private Minion's ID will change with each boot 2020-05-11 22:57:30,284 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2020-05-11 22:57:30,654 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2020-05-11 22:57:31,595 - Minion is configured, checking if it is healthy... 2020-05-11 22:57:35,457 - Launching in PRIVATE Location: 123456-example_private_loc-480 2020-05-11 22:57:36,060 - Executor for async-worker-* threads configured with a max pool size of 16 2020-05-11 22:57:36,072 - Configured 2 heavy worker threads, and 50 lightweight worker threads 2020-05-11 22:57:36,087 - 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - * Synthetics Minion 3.0.1 is ready and servicing location 'example_private_location' 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - ... logging continues ... Copy Enable debug logs If you experience issues with your CPM, you can enable debug logs to help troubleshoot issues. The default level of logging is set to only inform the user of key information and actionable errors. If this is insufficient, you can enable a more verbose logging by using the MINION_LOG_LEVEL environment variable. Enable Docker debug logs Tip Adding -f to the Docker logs makes the command follow logs. docker run ... -e MINION_LOG_LEVEL=DEBUG ... docker logs -f YOUR_CONTAINER_NAME ... verbose logging continues ... Copy Enable Kubernetes debug logs Tip Adding -f to the Kubernetes logs makes the command follow logs. To enable DEBUG logs add the --set synthetics.minionLogLevel=DEBUG option when running your helm install: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionLogLevel=DEBUG Copy Get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: kubectl logs -f -n YOUR_NAMESPACE YOUR_CPM_POD_NAME ... verbose logging continues ... Copy Retrieve Kubernetes debugging information If you experience issues with your CPM in a Kubernetes container orchestration system environment, you can retrieve information about the CPM pod and the node it is running on to help troubleshoot. To retrieve information for the CPM pod: kubectl describe pod -n YOUR_NAMESPACE YOUR_CPM_POD_NAME Copy To retrieve information for the node the CPM pod is running on, identify the node, and then: kubectl describe node NODE_ASSOCIATED_WITH_YOUR_CPM_POD_NAME Copy Monitor CPMs with New Relic Infrastructure New Relic's infrastructure monitoring supports advanced Docker monitoring and advanced Kubernetes monitoring. To add support for this, synthetic monitoring labels the containers spawned by CPM with a series of informative labels, all prefixed with synthetics-minion-. The CPM spawns containers called \"runners\" which process non-ping monitors like: simple browser, scripted browser, api test, and step function. You can use these labels to identify these runner containers. Example labels include: synthetics-minion-runner-role synthetics-minion-runner-version synthetics-minion-container-id synthetics-minion-id synthetics-minion-build-number synthetics-minion-job synthetics-minion-account synthetics-minion-monitor synthetics-minion-monitor-version synthetics-minion-monitor-type synthetics-minion-monitor-type-label Runner containers last a short time. One runner container is created to process one non-ping monitor job. The runner is created, processes the job, and is quickly deleted. A runner container exists for only a few seconds and will be created only if there is a non-ping monitor job to process. Ping monitors will not trigger runner container creation, so the above labels will not be present. If you are using the infrastructure agent to monitor these runner containers, configure at least one monitor to run each minute. The infrastructure agent will have more opportunity to notice and collect the above labels from the docker inspect of the container before it is deleted. Note: the synthetics-minion-id label refers to the ID of the minion which spawned this particular runner container. The ID of the runner itself is not tracked.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.01398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em> ",
        "sections": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " CPMs with New Relic Infrastructure New Relic&#x27;s infrastructure <em>monitoring</em> supports advanced Docker <em>monitoring</em> and advanced Kubernetes <em>monitoring</em>. To add support for this, <em>synthetic</em> <em>monitoring</em> labels the containers spawned by CPM with a series of informative labels, all prefixed with <em>synthetics</em>-minion"
      },
      "id": "603eac96196a67a833a83db8"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations": [
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-15T15:16:28Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.88443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Containerized private minion (CPM) maintenance and monitoring",
        "Tip",
        "Check CPM status using HTTP",
        "Check if your private location requires more minions",
        "Review logs",
        "Review Docker logs",
        "Review Kubernetes logs",
        "Enable debug logs",
        "Enable Docker debug logs",
        "Enable Kubernetes debug logs",
        "Retrieve Kubernetes debugging information",
        "Monitor CPMs with New Relic Infrastructure"
      ],
      "title": "Containerized private minion (CPM) maintenance and monitoring ",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "414f8966a290006d662010c910fc540018c0bf51",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring/",
      "published_at": "2021-06-15T15:16:27Z",
      "updated_at": "2021-05-09T18:11:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After installing your containerized private minion (CPM), you can keep track of its maintenance and monitoring in several ways: Check if the CPM is healthy and working with the CPM status endpoint. See if a private location is under-provisioned and needs more minions. Review your Docker logs or Kubernetes logs. Tip You can also get notified of monitor failures with New Relic's alerts. Check CPM status using HTTP Connecting to a running CPM using HTTP is the easiest way to check if it's healthy and working. The container exposes two ports: 8080 and 8180. You can check the CPM with the following endpoints: :8080/status/check: provides details about internal health checks that the minion performs. HTTP 200 means the status is healthy. :8080/status: provides details about a minion's status, which is the same data published in Insights as SyntheticsPrivateMinion event. :8180/: provides JVM application admin endpoints. This is an advanced view of a minion's Java Development Kit (JDK) internal state. Check if your private location requires more minions If your private location has multiple monitor checks queued up and you experience delays, you may need more minions available to execute the monitor checks. To learn how to verify this, see Does my private location need more minions? Review logs You can monitor your minion's health by looking at CPM container logs. Review Docker logs This is an example of a CPM log indicating that the minion is working properly in a Docker container system environment: $docker logs [YOUR_CONTAINER_NAME] 2018-10-10 11:33:29,856 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2018-10-10 11:33:29,869 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2018-10-10 11:33:40,527 - Minion is configured, checking if it is healthy... 2018-10-10 11:33:43,471 - Launching in PRIVATE Location: 123456-example_private_loc-480 2018-10-10 11:33:43,723 - Configured 2 heavy worker threads, and 50 light worker threads 2018-10-10 11:33:43,796 - 2018-10-10 11:33:43,796 - ************************************************************************** 2018-10-10 11:33:43,796 - * Synthetics Minion is ready and servicing location 'example_private_location' 2018-10-10 11:33:43,796 - ************************************************************************** ... logging continues ... Copy Review Kubernetes logs This is an example of a CPM log indicating that the minion is working properly in a Kubernetes container orchestration system environment: First, get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: $ kubectl logs -n YOUR_NAMESPACE YOUR_CPM_NAME 2020-05-11 22:57:24,084 - Minion will use 2 heavy workers 2020-05-11 22:57:24,149 - Minion will use 50 lightweight workers 2020-05-11 22:57:27,973 - Minion Container System: KUBERNETES 2020-05-11 22:57:30,158 - Minion deployment mode: PRIVATE_MINION_POD_KUBERNETES 2020-05-11 22:57:30,178 - No volume mounted at '/var/lib/newrelic/synthetics' in ':rw' mode: Private Minion's ID will change with each boot 2020-05-11 22:57:30,284 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2020-05-11 22:57:30,654 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2020-05-11 22:57:31,595 - Minion is configured, checking if it is healthy... 2020-05-11 22:57:35,457 - Launching in PRIVATE Location: 123456-example_private_loc-480 2020-05-11 22:57:36,060 - Executor for async-worker-* threads configured with a max pool size of 16 2020-05-11 22:57:36,072 - Configured 2 heavy worker threads, and 50 lightweight worker threads 2020-05-11 22:57:36,087 - 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - * Synthetics Minion 3.0.1 is ready and servicing location 'example_private_location' 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - ... logging continues ... Copy Enable debug logs If you experience issues with your CPM, you can enable debug logs to help troubleshoot issues. The default level of logging is set to only inform the user of key information and actionable errors. If this is insufficient, you can enable a more verbose logging by using the MINION_LOG_LEVEL environment variable. Enable Docker debug logs Tip Adding -f to the Docker logs makes the command follow logs. docker run ... -e MINION_LOG_LEVEL=DEBUG ... docker logs -f YOUR_CONTAINER_NAME ... verbose logging continues ... Copy Enable Kubernetes debug logs Tip Adding -f to the Kubernetes logs makes the command follow logs. To enable DEBUG logs add the --set synthetics.minionLogLevel=DEBUG option when running your helm install: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionLogLevel=DEBUG Copy Get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: kubectl logs -f -n YOUR_NAMESPACE YOUR_CPM_POD_NAME ... verbose logging continues ... Copy Retrieve Kubernetes debugging information If you experience issues with your CPM in a Kubernetes container orchestration system environment, you can retrieve information about the CPM pod and the node it is running on to help troubleshoot. To retrieve information for the CPM pod: kubectl describe pod -n YOUR_NAMESPACE YOUR_CPM_POD_NAME Copy To retrieve information for the node the CPM pod is running on, identify the node, and then: kubectl describe node NODE_ASSOCIATED_WITH_YOUR_CPM_POD_NAME Copy Monitor CPMs with New Relic Infrastructure New Relic's infrastructure monitoring supports advanced Docker monitoring and advanced Kubernetes monitoring. To add support for this, synthetic monitoring labels the containers spawned by CPM with a series of informative labels, all prefixed with synthetics-minion-. The CPM spawns containers called \"runners\" which process non-ping monitors like: simple browser, scripted browser, api test, and step function. You can use these labels to identify these runner containers. Example labels include: synthetics-minion-runner-role synthetics-minion-runner-version synthetics-minion-container-id synthetics-minion-id synthetics-minion-build-number synthetics-minion-job synthetics-minion-account synthetics-minion-monitor synthetics-minion-monitor-version synthetics-minion-monitor-type synthetics-minion-monitor-type-label Runner containers last a short time. One runner container is created to process one non-ping monitor job. The runner is created, processes the job, and is quickly deleted. A runner container exists for only a few seconds and will be created only if there is a non-ping monitor job to process. Ping monitors will not trigger runner container creation, so the above labels will not be present. If you are using the infrastructure agent to monitor these runner containers, configure at least one monitor to run each minute. The infrastructure agent will have more opportunity to notice and collect the above labels from the docker inspect of the container before it is deleted. Note: the synthetics-minion-id label refers to the ID of the minion which spawned this particular runner container. The ID of the runner itself is not tracked.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.01398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em> ",
        "sections": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " CPMs with New Relic Infrastructure New Relic&#x27;s infrastructure <em>monitoring</em> supports advanced Docker <em>monitoring</em> and advanced Kubernetes <em>monitoring</em>. To add support for this, <em>synthetic</em> <em>monitoring</em> labels the containers spawned by CPM with a series of informative labels, all prefixed with <em>synthetics</em>-minion"
      },
      "id": "603eac96196a67a833a83db8"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-15T15:16:29Z",
      "updated_at": "2021-05-04T17:59:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.3403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/private-locations-overview-monitor-internal-sites-add-new-locations": [
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-15T15:16:28Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.88434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-15T15:17:18Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.55733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    },
    {
      "sections": [
        "Containerized private minion (CPM) maintenance and monitoring",
        "Tip",
        "Check CPM status using HTTP",
        "Check if your private location requires more minions",
        "Review logs",
        "Review Docker logs",
        "Review Kubernetes logs",
        "Enable debug logs",
        "Enable Docker debug logs",
        "Enable Kubernetes debug logs",
        "Retrieve Kubernetes debugging information",
        "Monitor CPMs with New Relic Infrastructure"
      ],
      "title": "Containerized private minion (CPM) maintenance and monitoring ",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "414f8966a290006d662010c910fc540018c0bf51",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring/",
      "published_at": "2021-06-15T15:16:27Z",
      "updated_at": "2021-05-09T18:11:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After installing your containerized private minion (CPM), you can keep track of its maintenance and monitoring in several ways: Check if the CPM is healthy and working with the CPM status endpoint. See if a private location is under-provisioned and needs more minions. Review your Docker logs or Kubernetes logs. Tip You can also get notified of monitor failures with New Relic's alerts. Check CPM status using HTTP Connecting to a running CPM using HTTP is the easiest way to check if it's healthy and working. The container exposes two ports: 8080 and 8180. You can check the CPM with the following endpoints: :8080/status/check: provides details about internal health checks that the minion performs. HTTP 200 means the status is healthy. :8080/status: provides details about a minion's status, which is the same data published in Insights as SyntheticsPrivateMinion event. :8180/: provides JVM application admin endpoints. This is an advanced view of a minion's Java Development Kit (JDK) internal state. Check if your private location requires more minions If your private location has multiple monitor checks queued up and you experience delays, you may need more minions available to execute the monitor checks. To learn how to verify this, see Does my private location need more minions? Review logs You can monitor your minion's health by looking at CPM container logs. Review Docker logs This is an example of a CPM log indicating that the minion is working properly in a Docker container system environment: $docker logs [YOUR_CONTAINER_NAME] 2018-10-10 11:33:29,856 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2018-10-10 11:33:29,869 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2018-10-10 11:33:40,527 - Minion is configured, checking if it is healthy... 2018-10-10 11:33:43,471 - Launching in PRIVATE Location: 123456-example_private_loc-480 2018-10-10 11:33:43,723 - Configured 2 heavy worker threads, and 50 light worker threads 2018-10-10 11:33:43,796 - 2018-10-10 11:33:43,796 - ************************************************************************** 2018-10-10 11:33:43,796 - * Synthetics Minion is ready and servicing location 'example_private_location' 2018-10-10 11:33:43,796 - ************************************************************************** ... logging continues ... Copy Review Kubernetes logs This is an example of a CPM log indicating that the minion is working properly in a Kubernetes container orchestration system environment: First, get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: $ kubectl logs -n YOUR_NAMESPACE YOUR_CPM_NAME 2020-05-11 22:57:24,084 - Minion will use 2 heavy workers 2020-05-11 22:57:24,149 - Minion will use 50 lightweight workers 2020-05-11 22:57:27,973 - Minion Container System: KUBERNETES 2020-05-11 22:57:30,158 - Minion deployment mode: PRIVATE_MINION_POD_KUBERNETES 2020-05-11 22:57:30,178 - No volume mounted at '/var/lib/newrelic/synthetics' in ':rw' mode: Private Minion's ID will change with each boot 2020-05-11 22:57:30,284 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2020-05-11 22:57:30,654 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2020-05-11 22:57:31,595 - Minion is configured, checking if it is healthy... 2020-05-11 22:57:35,457 - Launching in PRIVATE Location: 123456-example_private_loc-480 2020-05-11 22:57:36,060 - Executor for async-worker-* threads configured with a max pool size of 16 2020-05-11 22:57:36,072 - Configured 2 heavy worker threads, and 50 lightweight worker threads 2020-05-11 22:57:36,087 - 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - * Synthetics Minion 3.0.1 is ready and servicing location 'example_private_location' 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - ... logging continues ... Copy Enable debug logs If you experience issues with your CPM, you can enable debug logs to help troubleshoot issues. The default level of logging is set to only inform the user of key information and actionable errors. If this is insufficient, you can enable a more verbose logging by using the MINION_LOG_LEVEL environment variable. Enable Docker debug logs Tip Adding -f to the Docker logs makes the command follow logs. docker run ... -e MINION_LOG_LEVEL=DEBUG ... docker logs -f YOUR_CONTAINER_NAME ... verbose logging continues ... Copy Enable Kubernetes debug logs Tip Adding -f to the Kubernetes logs makes the command follow logs. To enable DEBUG logs add the --set synthetics.minionLogLevel=DEBUG option when running your helm install: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionLogLevel=DEBUG Copy Get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: kubectl logs -f -n YOUR_NAMESPACE YOUR_CPM_POD_NAME ... verbose logging continues ... Copy Retrieve Kubernetes debugging information If you experience issues with your CPM in a Kubernetes container orchestration system environment, you can retrieve information about the CPM pod and the node it is running on to help troubleshoot. To retrieve information for the CPM pod: kubectl describe pod -n YOUR_NAMESPACE YOUR_CPM_POD_NAME Copy To retrieve information for the node the CPM pod is running on, identify the node, and then: kubectl describe node NODE_ASSOCIATED_WITH_YOUR_CPM_POD_NAME Copy Monitor CPMs with New Relic Infrastructure New Relic's infrastructure monitoring supports advanced Docker monitoring and advanced Kubernetes monitoring. To add support for this, synthetic monitoring labels the containers spawned by CPM with a series of informative labels, all prefixed with synthetics-minion-. The CPM spawns containers called \"runners\" which process non-ping monitors like: simple browser, scripted browser, api test, and step function. You can use these labels to identify these runner containers. Example labels include: synthetics-minion-runner-role synthetics-minion-runner-version synthetics-minion-container-id synthetics-minion-id synthetics-minion-build-number synthetics-minion-job synthetics-minion-account synthetics-minion-monitor synthetics-minion-monitor-version synthetics-minion-monitor-type synthetics-minion-monitor-type-label Runner containers last a short time. One runner container is created to process one non-ping monitor job. The runner is created, processes the job, and is quickly deleted. A runner container exists for only a few seconds and will be created only if there is a non-ping monitor job to process. Ping monitors will not trigger runner container creation, so the above labels will not be present. If you are using the infrastructure agent to monitor these runner containers, configure at least one monitor to run each minute. The infrastructure agent will have more opportunity to notice and collect the above labels from the docker inspect of the container before it is deleted. Note: the synthetics-minion-id label refers to the ID of the minion which spawned this particular runner container. The ID of the runner itself is not tracked.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.01396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em> ",
        "sections": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " CPMs with New Relic Infrastructure New Relic&#x27;s infrastructure <em>monitoring</em> supports advanced Docker <em>monitoring</em> and advanced Kubernetes <em>monitoring</em>. To add support for this, <em>synthetic</em> <em>monitoring</em> labels the containers spawned by CPM with a series of informative labels, all prefixed with <em>synthetics</em>-minion"
      },
      "id": "603eac96196a67a833a83db8"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/troubleshoot-private-locations": [
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-15T15:16:28Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.88434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-15T15:17:18Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.55733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    },
    {
      "sections": [
        "Containerized private minion (CPM) maintenance and monitoring",
        "Tip",
        "Check CPM status using HTTP",
        "Check if your private location requires more minions",
        "Review logs",
        "Review Docker logs",
        "Review Kubernetes logs",
        "Enable debug logs",
        "Enable Docker debug logs",
        "Enable Kubernetes debug logs",
        "Retrieve Kubernetes debugging information",
        "Monitor CPMs with New Relic Infrastructure"
      ],
      "title": "Containerized private minion (CPM) maintenance and monitoring ",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "414f8966a290006d662010c910fc540018c0bf51",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring/",
      "published_at": "2021-06-15T15:16:27Z",
      "updated_at": "2021-05-09T18:11:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After installing your containerized private minion (CPM), you can keep track of its maintenance and monitoring in several ways: Check if the CPM is healthy and working with the CPM status endpoint. See if a private location is under-provisioned and needs more minions. Review your Docker logs or Kubernetes logs. Tip You can also get notified of monitor failures with New Relic's alerts. Check CPM status using HTTP Connecting to a running CPM using HTTP is the easiest way to check if it's healthy and working. The container exposes two ports: 8080 and 8180. You can check the CPM with the following endpoints: :8080/status/check: provides details about internal health checks that the minion performs. HTTP 200 means the status is healthy. :8080/status: provides details about a minion's status, which is the same data published in Insights as SyntheticsPrivateMinion event. :8180/: provides JVM application admin endpoints. This is an advanced view of a minion's Java Development Kit (JDK) internal state. Check if your private location requires more minions If your private location has multiple monitor checks queued up and you experience delays, you may need more minions available to execute the monitor checks. To learn how to verify this, see Does my private location need more minions? Review logs You can monitor your minion's health by looking at CPM container logs. Review Docker logs This is an example of a CPM log indicating that the minion is working properly in a Docker container system environment: $docker logs [YOUR_CONTAINER_NAME] 2018-10-10 11:33:29,856 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2018-10-10 11:33:29,869 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2018-10-10 11:33:40,527 - Minion is configured, checking if it is healthy... 2018-10-10 11:33:43,471 - Launching in PRIVATE Location: 123456-example_private_loc-480 2018-10-10 11:33:43,723 - Configured 2 heavy worker threads, and 50 light worker threads 2018-10-10 11:33:43,796 - 2018-10-10 11:33:43,796 - ************************************************************************** 2018-10-10 11:33:43,796 - * Synthetics Minion is ready and servicing location 'example_private_location' 2018-10-10 11:33:43,796 - ************************************************************************** ... logging continues ... Copy Review Kubernetes logs This is an example of a CPM log indicating that the minion is working properly in a Kubernetes container orchestration system environment: First, get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: $ kubectl logs -n YOUR_NAMESPACE YOUR_CPM_NAME 2020-05-11 22:57:24,084 - Minion will use 2 heavy workers 2020-05-11 22:57:24,149 - Minion will use 50 lightweight workers 2020-05-11 22:57:27,973 - Minion Container System: KUBERNETES 2020-05-11 22:57:30,158 - Minion deployment mode: PRIVATE_MINION_POD_KUBERNETES 2020-05-11 22:57:30,178 - No volume mounted at '/var/lib/newrelic/synthetics' in ':rw' mode: Private Minion's ID will change with each boot 2020-05-11 22:57:30,284 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2020-05-11 22:57:30,654 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2020-05-11 22:57:31,595 - Minion is configured, checking if it is healthy... 2020-05-11 22:57:35,457 - Launching in PRIVATE Location: 123456-example_private_loc-480 2020-05-11 22:57:36,060 - Executor for async-worker-* threads configured with a max pool size of 16 2020-05-11 22:57:36,072 - Configured 2 heavy worker threads, and 50 lightweight worker threads 2020-05-11 22:57:36,087 - 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - * Synthetics Minion 3.0.1 is ready and servicing location 'example_private_location' 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - ... logging continues ... Copy Enable debug logs If you experience issues with your CPM, you can enable debug logs to help troubleshoot issues. The default level of logging is set to only inform the user of key information and actionable errors. If this is insufficient, you can enable a more verbose logging by using the MINION_LOG_LEVEL environment variable. Enable Docker debug logs Tip Adding -f to the Docker logs makes the command follow logs. docker run ... -e MINION_LOG_LEVEL=DEBUG ... docker logs -f YOUR_CONTAINER_NAME ... verbose logging continues ... Copy Enable Kubernetes debug logs Tip Adding -f to the Kubernetes logs makes the command follow logs. To enable DEBUG logs add the --set synthetics.minionLogLevel=DEBUG option when running your helm install: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionLogLevel=DEBUG Copy Get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: kubectl logs -f -n YOUR_NAMESPACE YOUR_CPM_POD_NAME ... verbose logging continues ... Copy Retrieve Kubernetes debugging information If you experience issues with your CPM in a Kubernetes container orchestration system environment, you can retrieve information about the CPM pod and the node it is running on to help troubleshoot. To retrieve information for the CPM pod: kubectl describe pod -n YOUR_NAMESPACE YOUR_CPM_POD_NAME Copy To retrieve information for the node the CPM pod is running on, identify the node, and then: kubectl describe node NODE_ASSOCIATED_WITH_YOUR_CPM_POD_NAME Copy Monitor CPMs with New Relic Infrastructure New Relic's infrastructure monitoring supports advanced Docker monitoring and advanced Kubernetes monitoring. To add support for this, synthetic monitoring labels the containers spawned by CPM with a series of informative labels, all prefixed with synthetics-minion-. The CPM spawns containers called \"runners\" which process non-ping monitors like: simple browser, scripted browser, api test, and step function. You can use these labels to identify these runner containers. Example labels include: synthetics-minion-runner-role synthetics-minion-runner-version synthetics-minion-container-id synthetics-minion-id synthetics-minion-build-number synthetics-minion-job synthetics-minion-account synthetics-minion-monitor synthetics-minion-monitor-version synthetics-minion-monitor-type synthetics-minion-monitor-type-label Runner containers last a short time. One runner container is created to process one non-ping monitor job. The runner is created, processes the job, and is quickly deleted. A runner container exists for only a few seconds and will be created only if there is a non-ping monitor job to process. Ping monitors will not trigger runner container creation, so the above labels will not be present. If you are using the infrastructure agent to monitor these runner containers, configure at least one monitor to run each minute. The infrastructure agent will have more opportunity to notice and collect the above labels from the docker inspect of the container before it is deleted. Note: the synthetics-minion-id label refers to the ID of the minion which spawned this particular runner container. The ID of the runner itself is not tracked.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.01396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em> ",
        "sections": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " CPMs with New Relic Infrastructure New Relic&#x27;s infrastructure <em>monitoring</em> supports advanced Docker <em>monitoring</em> and advanced Kubernetes <em>monitoring</em>. To add support for this, <em>synthetic</em> <em>monitoring</em> labels the containers spawned by CPM with a series of informative labels, all prefixed with <em>synthetics</em>-minion"
      },
      "id": "603eac96196a67a833a83db8"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/verified-script-execution-private-locations": [
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-15T15:16:28Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.88425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-15T15:17:18Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.55728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    },
    {
      "sections": [
        "Containerized private minion (CPM) maintenance and monitoring",
        "Tip",
        "Check CPM status using HTTP",
        "Check if your private location requires more minions",
        "Review logs",
        "Review Docker logs",
        "Review Kubernetes logs",
        "Enable debug logs",
        "Enable Docker debug logs",
        "Enable Kubernetes debug logs",
        "Retrieve Kubernetes debugging information",
        "Monitor CPMs with New Relic Infrastructure"
      ],
      "title": "Containerized private minion (CPM) maintenance and monitoring ",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "414f8966a290006d662010c910fc540018c0bf51",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring/",
      "published_at": "2021-06-15T15:16:27Z",
      "updated_at": "2021-05-09T18:11:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After installing your containerized private minion (CPM), you can keep track of its maintenance and monitoring in several ways: Check if the CPM is healthy and working with the CPM status endpoint. See if a private location is under-provisioned and needs more minions. Review your Docker logs or Kubernetes logs. Tip You can also get notified of monitor failures with New Relic's alerts. Check CPM status using HTTP Connecting to a running CPM using HTTP is the easiest way to check if it's healthy and working. The container exposes two ports: 8080 and 8180. You can check the CPM with the following endpoints: :8080/status/check: provides details about internal health checks that the minion performs. HTTP 200 means the status is healthy. :8080/status: provides details about a minion's status, which is the same data published in Insights as SyntheticsPrivateMinion event. :8180/: provides JVM application admin endpoints. This is an advanced view of a minion's Java Development Kit (JDK) internal state. Check if your private location requires more minions If your private location has multiple monitor checks queued up and you experience delays, you may need more minions available to execute the monitor checks. To learn how to verify this, see Does my private location need more minions? Review logs You can monitor your minion's health by looking at CPM container logs. Review Docker logs This is an example of a CPM log indicating that the minion is working properly in a Docker container system environment: $docker logs [YOUR_CONTAINER_NAME] 2018-10-10 11:33:29,856 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2018-10-10 11:33:29,869 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2018-10-10 11:33:40,527 - Minion is configured, checking if it is healthy... 2018-10-10 11:33:43,471 - Launching in PRIVATE Location: 123456-example_private_loc-480 2018-10-10 11:33:43,723 - Configured 2 heavy worker threads, and 50 light worker threads 2018-10-10 11:33:43,796 - 2018-10-10 11:33:43,796 - ************************************************************************** 2018-10-10 11:33:43,796 - * Synthetics Minion is ready and servicing location 'example_private_location' 2018-10-10 11:33:43,796 - ************************************************************************** ... logging continues ... Copy Review Kubernetes logs This is an example of a CPM log indicating that the minion is working properly in a Kubernetes container orchestration system environment: First, get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: $ kubectl logs -n YOUR_NAMESPACE YOUR_CPM_NAME 2020-05-11 22:57:24,084 - Minion will use 2 heavy workers 2020-05-11 22:57:24,149 - Minion will use 50 lightweight workers 2020-05-11 22:57:27,973 - Minion Container System: KUBERNETES 2020-05-11 22:57:30,158 - Minion deployment mode: PRIVATE_MINION_POD_KUBERNETES 2020-05-11 22:57:30,178 - No volume mounted at '/var/lib/newrelic/synthetics' in ':rw' mode: Private Minion's ID will change with each boot 2020-05-11 22:57:30,284 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2020-05-11 22:57:30,654 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2020-05-11 22:57:31,595 - Minion is configured, checking if it is healthy... 2020-05-11 22:57:35,457 - Launching in PRIVATE Location: 123456-example_private_loc-480 2020-05-11 22:57:36,060 - Executor for async-worker-* threads configured with a max pool size of 16 2020-05-11 22:57:36,072 - Configured 2 heavy worker threads, and 50 lightweight worker threads 2020-05-11 22:57:36,087 - 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - * Synthetics Minion 3.0.1 is ready and servicing location 'example_private_location' 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - ... logging continues ... Copy Enable debug logs If you experience issues with your CPM, you can enable debug logs to help troubleshoot issues. The default level of logging is set to only inform the user of key information and actionable errors. If this is insufficient, you can enable a more verbose logging by using the MINION_LOG_LEVEL environment variable. Enable Docker debug logs Tip Adding -f to the Docker logs makes the command follow logs. docker run ... -e MINION_LOG_LEVEL=DEBUG ... docker logs -f YOUR_CONTAINER_NAME ... verbose logging continues ... Copy Enable Kubernetes debug logs Tip Adding -f to the Kubernetes logs makes the command follow logs. To enable DEBUG logs add the --set synthetics.minionLogLevel=DEBUG option when running your helm install: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionLogLevel=DEBUG Copy Get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: kubectl logs -f -n YOUR_NAMESPACE YOUR_CPM_POD_NAME ... verbose logging continues ... Copy Retrieve Kubernetes debugging information If you experience issues with your CPM in a Kubernetes container orchestration system environment, you can retrieve information about the CPM pod and the node it is running on to help troubleshoot. To retrieve information for the CPM pod: kubectl describe pod -n YOUR_NAMESPACE YOUR_CPM_POD_NAME Copy To retrieve information for the node the CPM pod is running on, identify the node, and then: kubectl describe node NODE_ASSOCIATED_WITH_YOUR_CPM_POD_NAME Copy Monitor CPMs with New Relic Infrastructure New Relic's infrastructure monitoring supports advanced Docker monitoring and advanced Kubernetes monitoring. To add support for this, synthetic monitoring labels the containers spawned by CPM with a series of informative labels, all prefixed with synthetics-minion-. The CPM spawns containers called \"runners\" which process non-ping monitors like: simple browser, scripted browser, api test, and step function. You can use these labels to identify these runner containers. Example labels include: synthetics-minion-runner-role synthetics-minion-runner-version synthetics-minion-container-id synthetics-minion-id synthetics-minion-build-number synthetics-minion-job synthetics-minion-account synthetics-minion-monitor synthetics-minion-monitor-version synthetics-minion-monitor-type synthetics-minion-monitor-type-label Runner containers last a short time. One runner container is created to process one non-ping monitor job. The runner is created, processes the job, and is quickly deleted. A runner container exists for only a few seconds and will be created only if there is a non-ping monitor job to process. Ping monitors will not trigger runner container creation, so the above labels will not be present. If you are using the infrastructure agent to monitor these runner containers, configure at least one monitor to run each minute. The infrastructure agent will have more opportunity to notice and collect the above labels from the docker inspect of the container before it is deleted. Note: the synthetics-minion-id label refers to the ID of the minion which spawned this particular runner container. The ID of the runner itself is not tracked.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.01396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em> ",
        "sections": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " CPMs with New Relic Infrastructure New Relic&#x27;s infrastructure <em>monitoring</em> supports advanced Docker <em>monitoring</em> and advanced Kubernetes <em>monitoring</em>. To add support for this, <em>synthetic</em> <em>monitoring</em> labels the containers spawned by CPM with a series of informative labels, all prefixed with <em>synthetics</em>-minion"
      },
      "id": "603eac96196a67a833a83db8"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.1911,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. Use the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-15T14:54:04Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.74991,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/import-nodejs-modules": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.1911,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. Use the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-15T14:54:04Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.74991,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/introduction-scripted-browser-monitors": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. Use the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-15T14:54:04Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.7499,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/scripted-browser-examples": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. Use the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-15T14:54:04Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.7499,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. Use the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2562,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-15T14:54:04Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.7499,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/synthetic-scripted-browser-reference-monitor-versions-04x-or-lower": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. Use the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2562,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-15T14:54:04Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.7499,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/synthetics-scripted-browser-reference-monitor-versions-050": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. Use the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2561,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-15T14:54:04Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.74988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. Use the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2561,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-15T15:19:11Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.2226,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/monitor-produces-no-traffic": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19061,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25598,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-06-15T15:05:05Z",
      "updated_at": "2021-05-15T18:17:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a Synthetics Scripted Browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer Synthetics monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.92522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19061,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25598,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-06-15T15:05:05Z",
      "updated_at": "2021-05-15T18:17:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a Synthetics Scripted Browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer Synthetics monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.92522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/private-location-hmac-errors": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19061,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25598,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-06-15T15:05:05Z",
      "updated_at": "2021-05-15T18:17:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a Synthetics Scripted Browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer Synthetics monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.92522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19049,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25589,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Non-scripted monitor errors",
        "Problem",
        "Solutions",
        "ERROR: Job timed out after 65 seconds",
        "Solution",
        "Cause",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused",
        "HTTPError: Server replied with HTTP XXX response code",
        "SSLVerificationError: (ERROR)",
        "ResponseValidationError: Response did not contain the expected string",
        "NetworkError: Read timed out",
        "NetworkError: Socket is closed",
        "NetworkError: No route to host (Host unreachable)",
        "HTTPError: Server sent us too many redirects (20)",
        "NetworkError: DNS resolution failed for host: (HOST)",
        "BlockedRequestError: (URL)"
      ],
      "title": "Non-scripted monitor errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "156625f0d6481bdcabd07d6101ffbd3db2d184c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors/",
      "published_at": "2021-06-15T08:30:22Z",
      "updated_at": "2021-05-15T18:16:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your synthetic ping or simple monitor reported one of these errors. For scripted monitor errors, see non-ping errors. Solutions These are some of the most common non-scripted monitor error messages. ERROR: Job timed out after 65 seconds Problem Your ping timed out after 65 seconds, the non-configurable check duration time limit. Solution The 65 second time limit is non-configurable. Pings exceeding 65 seconds may be a result of latency from the target server. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause Ping monitors will first perform a HEAD request. If this request fails for any reason, or reaches the 30 second HTTP connect timeout for ping monitors, then a subsequent GET request is performed. This error happens when both the HEAD and GET request exceed 30 seconds, usually due to server latency. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out Problem HTTP requests during the check exceeded the non-configurable 30 second TCP connection timeout limit. Solution The 30 second time limit is non-configurable. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This failure indicates an issue reaching your site from the location where the synthetic's check was performed. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused Problem The target server refused connection from the synthetic ping monitor HTTP client. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause The target server is likely blocking or rate-limiting synthetic's traffic. HTTPError: Server replied with HTTP XXX response code Problem The synthetic monitor encountered an unsuccessful status code, usually a response code that is not in the 2XX/3XX range. Solution Check your server-side logging to determine why the response code was sent. To assist with identifying synthetic's traffic on your server, all synthetic monitoring traffic includes an X-Abuse-Info HTTP request header and we provide a list of origin IP addresses for all synthetic monitoring traffic. Cause The cause depends on the response code sent. SSLVerificationError: (ERROR) Problem Your monitor returns an SSLVerificationError. Solution Go to one.newrelic.com > Synthetics > (select a monitor) > Settings > General > Advanced options, then disable the Verify SSL check. Cause SSLVerificationError failures are a result of the optional Verify SSL check failing against the target host. SSL verification failed during execution for domain <TARGET_URL> failures indicate that the URL provided is not HTTPS or does not redirect to an HTTPS endpoint. SSLVerificationError: (<ERROR CODE>) <ERROR> errors are retrieved directly from the openssl command and often indicate a legitimate SSL configuration issue on the target site. ResponseValidationError: Response did not contain the expected string Problem The string value included in the synthetic monitor’s optional Response Validation field was not found in the target server’s response. Solution To troubleshoot: Check the failed results timeline to ensure the endpoint where the response validation text is expected, is the last endpoint being requested. Attempt a curl request against the target endpoint to see if the expected response body is returned. Ensure your endpoint doesn't have policies that will return different content depending on header content or request activity. If so, use a scripted browser to spoof a specific header string. If you’re using a simple browser to monitor a page whose content is loaded via JavaScript after the page’s load event is fired, consider using a scripted browser monitor instead. You can program scripted browsers to wait for specific elements to appear on a page before interacting with them. Cause The cause depends on the monitor type: Ping monitors: The string value must be present in the first 1MB (10^6 bytes) of the response body. Simple browsers: The string must be visible on the page when the page’s load event is fired. NetworkError: Read timed out Problem The monitor client was able to establish an HTTP connection to the target site, but then exceeded the 30 second read timeout while waiting for a response. Solution To troubleshoot: Investigate the target server's performance during the time period the issue was observed. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This indicates an issue with the target server responding to the synthetic monitor HTTP client, or network latency between your server and ours. NetworkError: Socket is closed Problem The synthetic monitor's HTTP client was able to establish a connection to the target server. The target server then closed the connection without a response. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause Edge infrastructure sometimes implements measures such as this for an application endpoint to handle traffic that violates behavior policies like rate limiting. NetworkError: No route to host (Host unreachable) Problem The synthetic monitoring client was able to resolve the target host’s IP address, but it was unable to find a route to the target host to establish a connection. Solution If the failure is occurring on a public synthetic monitoring's location, ensure that the DNS records for this host are resolving to a reachable IP address. If the failure is occurring on a synthetic monitoring's private location, ensure the private minion’s network configuration is properly configured and that the target hostname is resolvable and reachable via the private minion virtual command line interface. Cause This occurs when the target hostname resolves to a non-routable IP address per RFC 1918. HTTPError: Server sent us too many redirects (20) Problem The synthetic monitor client was redirected (observing 301 or 302 response codes) 20 times when performing a request to the target endpoint. Solution Ensure that the target endpoint redirects client requests less than 20 times. If this is only occurring within New Relic, recreate the issue outside New Relic to troubleshoot the root cause. Use a similar client to perform requests against the target endpoint: Ping monitors: HTTP client similar to curl. Simple/Browser based monitors: Chrome 60 instance in an Ubuntu 14.04.5 VM. Scripted API monitors: Use the request HTTP client for Node.js. Cause This occurs when the monitored endpoint effectively serves a redirect loop to the synthetic monitor: The initial response redirects to another URL which redirects to another URL, etc. NetworkError: DNS resolution failed for host: (HOST) Problem The target hostname was not able to be resolved by the synthetic monitor’s HTTP client. Solution Private synthetic monitoring's locations: Confirm that the network configuration for the minion is correct. If the target hostname is an internal one, ensure that the minion is using your network’s internal DNS service that is able to resolve the host. The containerized private minion and the runner containers it spawns on host (to run non-ping checks) should inherit DNS configuration from the host /etc/resolv.conf. Docker: Network arguments like –dns or -network used in the Docker run command on the containerized private minion will only be used by the minion container but not the runner containers. If the DNS points to the loopback interface such as 127.0.0.1, define a DNS config at the Docker daemon level, or use a tool like dnsmasq to make sure the runner will forward DNS requests on the Docker bridge interface. Public synthetic monitoring locations: Ensure that the target site’s DNS record can be looked up by public DNS services such as Google public DNS and Amazon-provided DNS. Cause Our public synthetic monitoring locations use Google public DNS and Amazon-provided DNS. If DNS resolution of the target host is failing on our public synthetic monitoring locations, this is likely an issue other users are facing. If you are seeing DNS resolution related monitor failures on a synthetic monitoring private location, this is often caused by the private minion for that location having an invalid network configuration. BlockedRequestError: (URL) Problem The target domain is blocked by synthetic monitoring. Solution To unblock domains, you must use a scripted browser monitor and manually make calls in your script. Cause Synthetic monitoring specifically exclude scripts for popular analytics services such as Google Analytics. This ensures your analytics tools continue to receive accurate data, even with thousands of monitors checking your website each month.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.924736,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Non-scripted <em>monitor</em> errors",
        "sections": "Non-scripted <em>monitor</em> errors",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " ADDRESS] failed: Connection refused Problem The target server refused connection from the <em>synthetic</em> ping <em>monitor</em> HTTP client. Solution Add our <em>synthetic</em> <em>monitoring</em> IP addresses to your allow list, to ensure traffic from our <em>synthetic</em> monitors can reach the target server. Cause The target server"
      },
      "id": "603eb369e7b9d20e922a07d6"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/troubleshoot-isolated-monitor-failures": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19049,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.25589,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your monitors. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-06-15T15:05:05Z",
      "updated_at": "2021-05-15T18:17:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a Synthetics Scripted Browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer Synthetics monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.92522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.76443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. <em>Use</em> the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also <em>use</em> the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-15T00:47:24Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/alerts-synthetic-monitoring": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.76443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. <em>Use</em> the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also <em>use</em> the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-15T00:47:24Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/collect-synthetic-transaction-traces": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.76425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19025,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. <em>Use</em> the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also <em>use</em> the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-15T00:47:24Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.76599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/handle-sites-authentication": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.76425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19025,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. <em>Use</em> the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also <em>use</em> the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-15T00:47:24Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.76599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/manage-monitor-runtimes": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.7641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. <em>Use</em> the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also <em>use</em> the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-15T00:47:24Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.76599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.7641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. <em>Use</em> the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also <em>use</em> the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-15T00:47:24Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.76599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/recheck-failed-monitors": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.76395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. <em>Use</em> the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also <em>use</em> the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-15T00:47:24Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.76598,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.76395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. <em>Use</em> the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also <em>use</em> the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-15T00:47:24Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.76598,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.19,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. <em>Use</em> the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also <em>use</em> the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-15T00:47:24Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.76598,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-06-15T00:16:39Z",
      "updated_at": "2021-04-17T02:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your Scripted Browser or API Test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.72263,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.76376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.18987,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. <em>Use</em> the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also <em>use</em> the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-06-15T00:16:39Z",
      "updated_at": "2021-04-17T02:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your Scripted Browser or API Test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.72263,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/view-simple-scripted-monitor-results": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-15T00:51:54Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.76376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.18987,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> <em>monitors</em>. Depending on the type of <em>monitor</em>, you can: Add and edit <em>monitors</em>. <em>Use</em> the <em>Synthetics</em> REST API to manage <em>monitors</em>. Set up <em>monitors</em> from specific locations or for private servers. You can also <em>use</em> the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-15T00:47:24Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.76598,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/telemetry-data-platform/convert-to-metrics/analyze-monitor-data-trends-metrics": [
    {
      "sections": [
        "Creating metric rules: requirements and tips",
        "Metric aggregation",
        "Rule-creation limits",
        "Cardinality limits",
        "Multiple metrics from one rule",
        "Metric naming"
      ],
      "title": "Creating metric rules: requirements and tips",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "2a905f4fc51191fc432fcabfe2657934e052bb5b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/creating-metric-rules-requirements-tips/",
      "published_at": "2021-06-14T18:21:59Z",
      "updated_at": "2021-05-15T10:05:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some limits, requirements, and recommendations when you create metrics from events, logs, or spans. Metric aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate metrics: Function Comments summary Creates a summary metric data point for each time window (currently 1 minute). Use this if your NRQL query uses aggregator functions supported by the summary metric type, such as average, sum, min, or max. Example rule-creation query: SELECT summary(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy uniqueCount Creates a uniqueCount metric data point for each 1-minute time window. Use this if your NRQL query uses the uniqueCount aggregator type. Example rule-creation query: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy distribution Creates a distribution metric data point for each 1-minute time window. Use this if your NRQL query uses aggregator functions such as percentile, histogram, min, max, average, sum, or count. Use only the attribute of interest as the argument, and discard the rest of the arguments from percentile or histogram. The generated metric supports any argument on percentile or histogram. Example of creating a distribution rule: SELECT distribution(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy Simple count: summary(1) and sum If you want a metric that's a simple count of the events, logs, or spans that match a particular WHERE clause, use the summary(1) metric. This metric type counts the number of specified events, logs, or spans per minute. When querying the created metric, use the sum method to see the result. Example: If you want to create a metric named foo.count that counts the transactions named foo, the NRQL would look like this: FROM Transaction SELECT summary(1) AS 'foo.count' WHERE name = 'foo' Copy Then, you would query it like this: FROM Metric SELECT sum(foo.count) SINCE 30 minutes ago Copy For more information about metrics, see our documentation about metric types. Rule-creation limits These limits affect metric rules creation: Limits Comments Account limits An account can have a maximum of 1,000 metric-creation rules. Metric rule limits A rule can: Create a maximum of 10 metrics. Use only one type of data (events, logs, or spans). Select a maximum of 20 attributes (facets) to include on a metric. Time window limits 50K limit on unique metric-name/attribute-value combinations for a single metric in a 24-hour time window. If this limit is exceeded, the rule is disabled and an NrIntegrationError event is created in the account that includes: The rule details A message about having too many facets A newRelicFeature of eventToMetric Limits on metric name and attribute value combinations The limit on total unique metric name/attribute value combinations in a 24-hour time window for an account is: Equal to three times the purchased monthly average data points per minute Up to a maximum of 10M Cardinality limits Rule-creation limits include limits on the number of unique combinations of metric name and attribute values. This limit exists because a large number of attributes and/or attribute values can lead to an exponential increase in the size of data reported. Example metric creation rule that attaches five attributes: FROM ProcessSample SELECT summary(ioTotalReadBytes) WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName, entityName, processId Copy If each of the five attributes reported ten unique values within a one-minute time window, the number of unique metric-name/attribute combinations would theoretically have a maximum of 10x10x10x10x10, or 100,000. Multiple attributes with multiple unique values can lead to a large number of unique metric entries. In practice, this isn't usually the case, because attributes are often related. For example, if one attribute is hostname and another is awsRegion, when you see hostname A, it will always be in AWS region B; you'd never see hostname A and other AWS region values. This is why it's important, during the NRQL creation process, to use the uniqueCount function to verify how many unique metric-name/attribute-value combinations your NRQL query is generating. Multiple metrics from one rule A rule can create up to ten metrics. There are no functional differences between metrics created one at a time and those created with a single rule. Reasons for creating multiple metrics with a single rule: Less likely to reach rules-per-account limit. Easier to add the same attributes to multiple metrics. Example creating multiple metrics with a single rule: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount', summary(duration) AS 'server.duration', summary(totalTime) AS 'server.totalTime' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy Metric naming A metric is given a name with the AS clause, as part of the NRQL rule-creation process. In the following NRQL example, the name of the metric is io.totalread.bytes: FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName Copy If there is no name assigned with the AS clause, the metric name is the name of the queried attribute. In this example, if no name was assigned, the metric name would be ioTotalReadBytes. Metric names Requirements and recommendations Requirements Requirements for naming a metric: Less than or equal to 255 (UTF-16) 16-bit code units. One way to ensure you are under the limit is to keep each string under 127 of whatever is easiest to count. No spaces. Start with a letter. Examples of strong metric names: rubyvm.memory.heap_used redis.container.cpu.percent memcached.process_virtual_memory.bytes Length and structure Decide on a name and structure that makes it easy for others to find, understand, and use this metric. We recommend keeping your metric name under 40 characters for ideal readability. Longer names can get cut off or overlap with other names. Your metric naming scheme will depend on your business logic. You may want to use namespaces to prefix your metric name, or your names may need to be more general. Components within the name If you want to create components within your metric name (like the source of metrics and the thing you’re measuring), we recommend going from broad to specific (left to right): Use a dot to separate those components in order to be consistent with our New Relic metric names. Then, use an underscore to separate words within the dots. Example: application.page_view.duration Copy Attributes Avoid putting attributes in your metric name. Attributes are qualities of your metric that you can use to filter or facet your data, like cluster or availability zone. Example: If you included availability zone in your metric name, it would mean, for that metric, you wouldn’t be able to see results across all availability zones. Changing metric names If you change a metric name, historical data will not be updated to that new name. To query or chart that historical data, you will need to specify the older metric name.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.61835,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "sections": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Here are some limits, requirements, and recommendations when you create <em>metrics</em> from events, logs, or spans. <em>Metric</em> aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate <em>metrics</em>: Function Comments summary Creates a summary <em>metric</em> <em>data</em>"
      },
      "id": "603e9b8164441fbcac4e88a6"
    },
    {
      "sections": [
        "Create metrics from other data types",
        "Create a metrics rule",
        "Step 1. Create NRQL query rule",
        "Tip",
        "Step 2. Create API request",
        "Example NerdGraph API request",
        "Example NerdGraph API response",
        "Step 3. Create a metrics rule with API request",
        "Query and chart your metrics",
        "Summary metric example",
        "Count metric example",
        "Distribution metric example",
        "Troubleshooting"
      ],
      "title": "Create metrics from other data types",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "684976ba0b62b7510db8b856c3f04ea77f9cdcc5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/create-metrics-other-data-types/",
      "published_at": "2021-06-14T18:21:59Z",
      "updated_at": "2021-05-15T10:04:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic's metrics API service to define rules for creating metrics from your other types of data, such as events, logs, or spans. Recommendation: Before you begin, review our requirements and tips for creating rules. Create a metrics rule To create a rule for creating metrics from events, logs, or spans: Construct the metrics rule using NRQL. Construct a NerdGraph (GraphQL format) API request that contains your NRQL rule. Create the metric by making the API request. Once a metric is created, you can query and chart it using NRQL. Step 1. Create NRQL query rule The most important part of creating a metrics rule is constructing the NRQL query that defines the metric for your data from events, logs, or spans. You can create up to 10 metrics with a single NRQL query by following this procedure: Using New Relic's NRQL interface, construct a query for the metric you want to create. For example: FROM ProcessSample SELECT average(ioTotalReadBytes) WHERE nr.entityType = 'HOST' Copy Edit the query to use one of the three available metric types: summary: Use if the query's function is min, max, sum, count, or average. uniqueCount: Use if the query's function is uniqueCount. distribution: Use if the query's function is percentile or histogram. This example query uses average, so use summary: FROM ProcessSample SELECT summary (ioTotalReadBytes) WHERE nr.entityType = 'HOST' Copy This example query uses count on a non-numeric field: FROM ProcessSample SELECT count(hostname) WHERE hostname LIKE '%prod%' Copy For summary on a non-numeric field use summary(1): FROM ProcessSample SELECT summary(1) WHERE hostname LIKE '%prod%' Copy Tip For more detailed information on using these metric types in rules, see Creating metric rules: requirements and tips. Decide on the attributes you want to attach to the metric, following the limits on the cardinality of unique metric-name/attribute-value combinations. Recommendation: Run a separate query to ensure this count isn't over 50,000 for a 24-hour window. For example: FROM ProcessSample SELECT uniqueCount(awsRegion, awsAvailabilityZone, commandName) WHERE nr.entityType = 'HOST' SINCE 1 DAY AGO Copy To be able to aggregate and filter your metrics, add the attributes you want to attach to the metric using the FACET clause. For example: FROM ProcessSample SELECT summary(ioTotalReadBytes) WHERE nr.entityType = 'HOST' FACET awsRegion, awsAvailabilityZone, commandName Copy Set the name of the metric using the AS function. For example: FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'HOST' FACET awsRegion, awsAvailabilityZone, commandName Copy Once your NRQL rule is complete, use it to create the API request. Step 2. Create API request After you build the NRQL rule to convert data from events, logs, or spans to metrics, continue with building the API request. You can use our NerdGraph API tool to explore the data structure and to construct and make your request. To check that the rule was created correctly, you can run a query to return that rule using its ID. For tips on querying the metrics you've created, see Query and chart your metrics. Example NerdGraph API request The following example NerdGraph API request uses the same NRQL rule from step 1. The IO Total Read Bytes Rule creates a metric named io.totalread.bytes. (The rule name can have spaces, which differs from the metric naming rules.) mutation { eventsToMetricsCreateRule(rules: { name: \"io.totalread.bytes for computeSample entities\", description:\"Created by Zach on March 27, 2019. Used by team Network.\", nrql:\"FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName\", accountId: 123456 }) { successes { id name nrql enabled } failures { submitted { name nrql accountId } errors { reason description } } } } Copy In this request: Request elements Description mutation One of the basic API operation types. eventsToMetricsCreateRule The method being called to create a rule. rules Takes four parameters: name: The name of the rule. description: Optional. The description of the rule. We recommend you include information about who created the metric data and who will be using the data. accountId: The New Relic account ID where the events, logs, or spans live and the metrics will be created. nrql: The NRQL query that creates the rule. For more on this, see Create NRQL query. successes and submitted blocks Here you define the data returned by a successful or failed response. Available parameters for these blocks include: id (ruleId for submitted) name description nrql enabled (enabled/disabled status) accountId ruleId and accountId If a failure occurs, then the submitted ruleId and accountId will be returned along with the error reason and error description. Example NerdGraph API response Here's an example of a returned response: { \"data\": { \"eventsToMetricsCreateRule\": { \"failures\": [], \"successes\": [ { \"enabled\": true, \"id\": \"46\", \"name\": \"io.totalread.bytes for computeSample entities\", \"nrql\": \"FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName\" } ] } } } Copy Step 3. Create a metrics rule with API request When your API request is ready, you can use the NerdGraph API to make the request, which will create the metrics. Query and chart your metrics After you create a metrics rule to convert data for your events, logs, or spans, you can view the new metric data in the New Relic UI. To view your data: Go to New Relic's NRQL query interface. Run the following query to see the name of all your metrics: SELECT uniques(metricName) FROM Metric Copy Pick the metric of interest, then run the following query to see the available attributes: SELECT * FROM Metric where metricName = 'yourMetric' Copy If you don't see expected data, follow the troubleshooting procedures. The available NRQL aggregator functions depend on the metric type you created. Here are some examples. Summary metric example If you created a summary metric type, you can use the count, sum, max, min, and average aggregator functions, as shown in the following query: SELECT count(appStartResponseTime), sum(appStartResponseTime), max(appStartResponseTime), min(appStartResponseTime), average(appStartResponseTime) FROM Metric Copy Count metric example If you created a uniqueCount metric type, you can only use the uniqueCount function, as shown in the following query: SELECT uniqueCount(playbackErrorStreamUniqueCount) * 100 / uniqueCount(streamUniqueCount) AS '% of Streams Impacted' FROM Metric Copy Distribution metric example If you created a distribution metric type, use the percentile or histogram functions, as shown in the following queries: SELECT percentile(service.responseTime, 95) FROM Metric Copy OR SELECT histogram(service.responseTime, 10, 20) FROM Metric Copy Troubleshooting If your NerdGraph call is not constructed correctly, you may receive a message like this: Cannot parse the unexpected character \"\\u201C” Copy Verify the quotes in the NerdGraph call are not smart quotes (curly quotes). Our NerdGraph API only accepts straight quotes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.61755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>metrics</em> from other <em>data</em> types",
        "sections": "Create <em>metrics</em> from other <em>data</em> types",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " the NerdGraph API to make the request, which will create the <em>metrics</em>. Query and chart your <em>metrics</em> After you create a <em>metrics</em> rule to <em>convert</em> <em>data</em> for your events, logs, or spans, you can view the new <em>metric</em> <em>data</em> in the New Relic UI. To view your <em>data</em>: Go to New Relic&#x27;s NRQL query interface. Run the following"
      },
      "id": "603ebfc8196a67cab0a83d96"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-14T17:37:59Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.14783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot <em>Metric</em> API with NRIntegrationError events",
        "sections": "Match errors <em>to</em> <em>ingested</em> payloads",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; API keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper API endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_API_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-api.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;<em>Metrics</em>&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/convert-to-metrics/create-metrics-other-data-types": [
    {
      "sections": [
        "Analyze and monitor data trends with metrics",
        "Why create metrics from other data types?",
        "Available operations",
        "Mutations",
        "Create a rule",
        "Delete a rule",
        "Important",
        "Enable or disable a rule",
        "Queries",
        "List all rules for a New Relic account",
        "List rule by rule ID",
        "Use the NerdGraph GraphiQL API tool"
      ],
      "title": "Analyze and monitor data trends with metrics",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "e1cd71a03a83816741471dae4423128472e10fb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/analyze-monitor-data-trends-metrics/",
      "published_at": "2021-06-14T18:21:59Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can generate metric-type data from other types of data in New Relic, including events, logs, and spans. Metrics are aggregates of your data and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How to use our NerdGraph API tool to perform operations Why create metrics from other data types? Using metrics allows for more efficient data storage. This in turn allows you to query your data and build charts more easily. The difference between metrics and other types of data in New Relic is based on time. For more information, see Understand data types. Events, logs, spans: These types of data represent a single record at a specific moment in time. For example, you may have an event for every request to the system. This data is ideal for in-depth troubleshooting and analysis. Metrics: These provide an aggregated view of your events, logs, or spans. Metrics are better for showing trends over longer time ranges. For example, you can aggregate the total number of requests per service to one metric and then examine this information month over month. Why use metrics? Comments Flexibility Metrics are dimensional. You can choose what metadata (like host name or app name) is attached to them. Common metric measurements, like average, sum, minimum, and maximum, are already calculated. Data aggregation and retention The data has already been pre-aggregated into longer-period time buckets. Data retention is 13 months. Query capabilities You can query using the Metric data type. When you create metrics, this does not delete your events or other types of data. However, metrics are better for longer-range querying and charting. To get started converting your data to metrics, create a rule. Available operations To show, create, and delete rules for generating metrics from events, logs, or spans, use NerdGraph, our GraphQL-format API. Before performing any operation, we recommend reading Intro to NerdGraph and exploring your data with the GraphiQL API tool. These operations fall under two basic request types: Mutations, which are operations that make changes to existing rules or settings (for example, creating a new metrics rule). Queries, for fetching existing data (for example, fetching existing metrics rules). All operations are role-based in NerdGraph as the currently logged-in New Relic user. Mutations Mutation operations for events to metrics, logs to metrics, or spans to metrics include: Create a rule See Create metrics. Delete a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To delete a rule, you need the rule ID and the New Relic account ID. Example request: mutation { eventsToMetricsDeleteRule(deletes: {ruleId: \"12\", accountId: 123456}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsDeleteRule The method being called to delete a rule. deletes This takes two parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Example response for the request: { \"data\": { \"eventsToMetricsDeleteRule\": { \"failures\": [], \"successes\": [ { \"id\": \"12\", \"name\": \"Test Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } Copy Enable or disable a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To enable or disable an existing rule for events to metrics, logs to metrics, or spans to metrics, use the same eventsToMetricsUpdateRule operation. The only difference is whether enabled is set to true or false. Example request to enable an existing metrics rule: mutation { eventsToMetricsUpdateRule(updates: {ruleId: \"12\", accountId: 123456, enabled: true}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsUpdateRule The method being called to update an existing rule and either enable it or disable it. updates This takes three required parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. enabled: To enable a disabled rule, set this to true. To disable a rule, set this to false. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Queries Query operations include: List all rules for a New Relic account You can list all rules in a New Relic account or return a specific rule. Example listing all rules for account 123456: query { actor { account(id:123456) { eventsToMetrics{ allRules{ rules{ id name enabled nrql description } } } } } } Copy In this request: Element Description query One of the basic API operation types. Used to query but not make changes. actor This specifies the current New Relic user. account(id: 123456) Specify the ID for the New Relic account where to retrieve data. eventsToMetrics Scope the data only for events-to-metrics, logs-to-metrics, or spans-to-metrics rules. allRules Returns all rules for that account. rules In the rules block, you can define what data you want returned. Available fields include: id name description nrql accountId enabled Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"allRules\": { \"rules\": [ { \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"1\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" }, { \"description\": \"Metric for duration\", \"enabled\": true, \"id\": \"2\", \"name\": \"Duration Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy List rule by rule ID If you know the exact ID for a rule, then you can query for a specific rule. For example, you may have just created a rule and now you want to list its contents so you can review it. Example listing rule 36 for New Relic account 123456: query { actor { account(id: 123456) { eventsToMetrics { rulesById(ruleIds: \"36\") { rules { id name enabled nrql description accountId } } } } } } Copy For more details about the elements in this query, see List all rules. Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"rulesById\": { \"rules\": [ { \"accountId\": 123456, \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"36\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy Use the NerdGraph GraphiQL API tool You can use our GraphiQL tool to explore the data structure. You can also use it to build and run the operations to convert events, logs, and spans to metrics. To use this tool: Create the metrics operation's request with the required parameters. Go to api.newrelic.com/graphiql, and paste your query into the box. To execute the operation, press Play. Or, to get the cURL format, select Copy as cURL.) Validate the response in the response box. Optional: To verify that your rule-creation operation was performed successfully, run a list query for that rule ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.61932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "sections": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "You can generate <em>metric</em>-type <em>data</em> from other types of <em>data</em> in New Relic, including events, logs, and spans. <em>Metrics</em> are aggregates of your <em>data</em> and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How"
      },
      "id": "603eb239e7b9d2b99d2a07bb"
    },
    {
      "sections": [
        "Creating metric rules: requirements and tips",
        "Metric aggregation",
        "Rule-creation limits",
        "Cardinality limits",
        "Multiple metrics from one rule",
        "Metric naming"
      ],
      "title": "Creating metric rules: requirements and tips",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "2a905f4fc51191fc432fcabfe2657934e052bb5b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/creating-metric-rules-requirements-tips/",
      "published_at": "2021-06-14T18:21:59Z",
      "updated_at": "2021-05-15T10:05:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some limits, requirements, and recommendations when you create metrics from events, logs, or spans. Metric aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate metrics: Function Comments summary Creates a summary metric data point for each time window (currently 1 minute). Use this if your NRQL query uses aggregator functions supported by the summary metric type, such as average, sum, min, or max. Example rule-creation query: SELECT summary(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy uniqueCount Creates a uniqueCount metric data point for each 1-minute time window. Use this if your NRQL query uses the uniqueCount aggregator type. Example rule-creation query: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy distribution Creates a distribution metric data point for each 1-minute time window. Use this if your NRQL query uses aggregator functions such as percentile, histogram, min, max, average, sum, or count. Use only the attribute of interest as the argument, and discard the rest of the arguments from percentile or histogram. The generated metric supports any argument on percentile or histogram. Example of creating a distribution rule: SELECT distribution(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy Simple count: summary(1) and sum If you want a metric that's a simple count of the events, logs, or spans that match a particular WHERE clause, use the summary(1) metric. This metric type counts the number of specified events, logs, or spans per minute. When querying the created metric, use the sum method to see the result. Example: If you want to create a metric named foo.count that counts the transactions named foo, the NRQL would look like this: FROM Transaction SELECT summary(1) AS 'foo.count' WHERE name = 'foo' Copy Then, you would query it like this: FROM Metric SELECT sum(foo.count) SINCE 30 minutes ago Copy For more information about metrics, see our documentation about metric types. Rule-creation limits These limits affect metric rules creation: Limits Comments Account limits An account can have a maximum of 1,000 metric-creation rules. Metric rule limits A rule can: Create a maximum of 10 metrics. Use only one type of data (events, logs, or spans). Select a maximum of 20 attributes (facets) to include on a metric. Time window limits 50K limit on unique metric-name/attribute-value combinations for a single metric in a 24-hour time window. If this limit is exceeded, the rule is disabled and an NrIntegrationError event is created in the account that includes: The rule details A message about having too many facets A newRelicFeature of eventToMetric Limits on metric name and attribute value combinations The limit on total unique metric name/attribute value combinations in a 24-hour time window for an account is: Equal to three times the purchased monthly average data points per minute Up to a maximum of 10M Cardinality limits Rule-creation limits include limits on the number of unique combinations of metric name and attribute values. This limit exists because a large number of attributes and/or attribute values can lead to an exponential increase in the size of data reported. Example metric creation rule that attaches five attributes: FROM ProcessSample SELECT summary(ioTotalReadBytes) WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName, entityName, processId Copy If each of the five attributes reported ten unique values within a one-minute time window, the number of unique metric-name/attribute combinations would theoretically have a maximum of 10x10x10x10x10, or 100,000. Multiple attributes with multiple unique values can lead to a large number of unique metric entries. In practice, this isn't usually the case, because attributes are often related. For example, if one attribute is hostname and another is awsRegion, when you see hostname A, it will always be in AWS region B; you'd never see hostname A and other AWS region values. This is why it's important, during the NRQL creation process, to use the uniqueCount function to verify how many unique metric-name/attribute-value combinations your NRQL query is generating. Multiple metrics from one rule A rule can create up to ten metrics. There are no functional differences between metrics created one at a time and those created with a single rule. Reasons for creating multiple metrics with a single rule: Less likely to reach rules-per-account limit. Easier to add the same attributes to multiple metrics. Example creating multiple metrics with a single rule: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount', summary(duration) AS 'server.duration', summary(totalTime) AS 'server.totalTime' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy Metric naming A metric is given a name with the AS clause, as part of the NRQL rule-creation process. In the following NRQL example, the name of the metric is io.totalread.bytes: FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName Copy If there is no name assigned with the AS clause, the metric name is the name of the queried attribute. In this example, if no name was assigned, the metric name would be ioTotalReadBytes. Metric names Requirements and recommendations Requirements Requirements for naming a metric: Less than or equal to 255 (UTF-16) 16-bit code units. One way to ensure you are under the limit is to keep each string under 127 of whatever is easiest to count. No spaces. Start with a letter. Examples of strong metric names: rubyvm.memory.heap_used redis.container.cpu.percent memcached.process_virtual_memory.bytes Length and structure Decide on a name and structure that makes it easy for others to find, understand, and use this metric. We recommend keeping your metric name under 40 characters for ideal readability. Longer names can get cut off or overlap with other names. Your metric naming scheme will depend on your business logic. You may want to use namespaces to prefix your metric name, or your names may need to be more general. Components within the name If you want to create components within your metric name (like the source of metrics and the thing you’re measuring), we recommend going from broad to specific (left to right): Use a dot to separate those components in order to be consistent with our New Relic metric names. Then, use an underscore to separate words within the dots. Example: application.page_view.duration Copy Attributes Avoid putting attributes in your metric name. Attributes are qualities of your metric that you can use to filter or facet your data, like cluster or availability zone. Example: If you included availability zone in your metric name, it would mean, for that metric, you wouldn’t be able to see results across all availability zones. Changing metric names If you change a metric name, historical data will not be updated to that new name. To query or chart that historical data, you will need to specify the older metric name.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.61835,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "sections": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Here are some limits, requirements, and recommendations when you create <em>metrics</em> from events, logs, or spans. <em>Metric</em> aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate <em>metrics</em>: Function Comments summary Creates a summary <em>metric</em> <em>data</em>"
      },
      "id": "603e9b8164441fbcac4e88a6"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-14T17:37:59Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.14783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot <em>Metric</em> API with NRIntegrationError events",
        "sections": "Match errors <em>to</em> <em>ingested</em> payloads",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; API keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper API endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_API_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-api.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;<em>Metrics</em>&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/convert-to-metrics/creating-metric-rules-requirements-tips": [
    {
      "sections": [
        "Analyze and monitor data trends with metrics",
        "Why create metrics from other data types?",
        "Available operations",
        "Mutations",
        "Create a rule",
        "Delete a rule",
        "Important",
        "Enable or disable a rule",
        "Queries",
        "List all rules for a New Relic account",
        "List rule by rule ID",
        "Use the NerdGraph GraphiQL API tool"
      ],
      "title": "Analyze and monitor data trends with metrics",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "e1cd71a03a83816741471dae4423128472e10fb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/analyze-monitor-data-trends-metrics/",
      "published_at": "2021-06-14T18:21:59Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can generate metric-type data from other types of data in New Relic, including events, logs, and spans. Metrics are aggregates of your data and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How to use our NerdGraph API tool to perform operations Why create metrics from other data types? Using metrics allows for more efficient data storage. This in turn allows you to query your data and build charts more easily. The difference between metrics and other types of data in New Relic is based on time. For more information, see Understand data types. Events, logs, spans: These types of data represent a single record at a specific moment in time. For example, you may have an event for every request to the system. This data is ideal for in-depth troubleshooting and analysis. Metrics: These provide an aggregated view of your events, logs, or spans. Metrics are better for showing trends over longer time ranges. For example, you can aggregate the total number of requests per service to one metric and then examine this information month over month. Why use metrics? Comments Flexibility Metrics are dimensional. You can choose what metadata (like host name or app name) is attached to them. Common metric measurements, like average, sum, minimum, and maximum, are already calculated. Data aggregation and retention The data has already been pre-aggregated into longer-period time buckets. Data retention is 13 months. Query capabilities You can query using the Metric data type. When you create metrics, this does not delete your events or other types of data. However, metrics are better for longer-range querying and charting. To get started converting your data to metrics, create a rule. Available operations To show, create, and delete rules for generating metrics from events, logs, or spans, use NerdGraph, our GraphQL-format API. Before performing any operation, we recommend reading Intro to NerdGraph and exploring your data with the GraphiQL API tool. These operations fall under two basic request types: Mutations, which are operations that make changes to existing rules or settings (for example, creating a new metrics rule). Queries, for fetching existing data (for example, fetching existing metrics rules). All operations are role-based in NerdGraph as the currently logged-in New Relic user. Mutations Mutation operations for events to metrics, logs to metrics, or spans to metrics include: Create a rule See Create metrics. Delete a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To delete a rule, you need the rule ID and the New Relic account ID. Example request: mutation { eventsToMetricsDeleteRule(deletes: {ruleId: \"12\", accountId: 123456}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsDeleteRule The method being called to delete a rule. deletes This takes two parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Example response for the request: { \"data\": { \"eventsToMetricsDeleteRule\": { \"failures\": [], \"successes\": [ { \"id\": \"12\", \"name\": \"Test Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } Copy Enable or disable a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To enable or disable an existing rule for events to metrics, logs to metrics, or spans to metrics, use the same eventsToMetricsUpdateRule operation. The only difference is whether enabled is set to true or false. Example request to enable an existing metrics rule: mutation { eventsToMetricsUpdateRule(updates: {ruleId: \"12\", accountId: 123456, enabled: true}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsUpdateRule The method being called to update an existing rule and either enable it or disable it. updates This takes three required parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. enabled: To enable a disabled rule, set this to true. To disable a rule, set this to false. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Queries Query operations include: List all rules for a New Relic account You can list all rules in a New Relic account or return a specific rule. Example listing all rules for account 123456: query { actor { account(id:123456) { eventsToMetrics{ allRules{ rules{ id name enabled nrql description } } } } } } Copy In this request: Element Description query One of the basic API operation types. Used to query but not make changes. actor This specifies the current New Relic user. account(id: 123456) Specify the ID for the New Relic account where to retrieve data. eventsToMetrics Scope the data only for events-to-metrics, logs-to-metrics, or spans-to-metrics rules. allRules Returns all rules for that account. rules In the rules block, you can define what data you want returned. Available fields include: id name description nrql accountId enabled Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"allRules\": { \"rules\": [ { \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"1\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" }, { \"description\": \"Metric for duration\", \"enabled\": true, \"id\": \"2\", \"name\": \"Duration Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy List rule by rule ID If you know the exact ID for a rule, then you can query for a specific rule. For example, you may have just created a rule and now you want to list its contents so you can review it. Example listing rule 36 for New Relic account 123456: query { actor { account(id: 123456) { eventsToMetrics { rulesById(ruleIds: \"36\") { rules { id name enabled nrql description accountId } } } } } } Copy For more details about the elements in this query, see List all rules. Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"rulesById\": { \"rules\": [ { \"accountId\": 123456, \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"36\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy Use the NerdGraph GraphiQL API tool You can use our GraphiQL tool to explore the data structure. You can also use it to build and run the operations to convert events, logs, and spans to metrics. To use this tool: Create the metrics operation's request with the required parameters. Go to api.newrelic.com/graphiql, and paste your query into the box. To execute the operation, press Play. Or, to get the cURL format, select Copy as cURL.) Validate the response in the response box. Optional: To verify that your rule-creation operation was performed successfully, run a list query for that rule ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.6193,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "sections": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "You can generate <em>metric</em>-type <em>data</em> from other types of <em>data</em> in New Relic, including events, logs, and spans. <em>Metrics</em> are aggregates of your <em>data</em> and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How"
      },
      "id": "603eb239e7b9d2b99d2a07bb"
    },
    {
      "sections": [
        "Create metrics from other data types",
        "Create a metrics rule",
        "Step 1. Create NRQL query rule",
        "Tip",
        "Step 2. Create API request",
        "Example NerdGraph API request",
        "Example NerdGraph API response",
        "Step 3. Create a metrics rule with API request",
        "Query and chart your metrics",
        "Summary metric example",
        "Count metric example",
        "Distribution metric example",
        "Troubleshooting"
      ],
      "title": "Create metrics from other data types",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "684976ba0b62b7510db8b856c3f04ea77f9cdcc5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/create-metrics-other-data-types/",
      "published_at": "2021-06-14T18:21:59Z",
      "updated_at": "2021-05-15T10:04:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic's metrics API service to define rules for creating metrics from your other types of data, such as events, logs, or spans. Recommendation: Before you begin, review our requirements and tips for creating rules. Create a metrics rule To create a rule for creating metrics from events, logs, or spans: Construct the metrics rule using NRQL. Construct a NerdGraph (GraphQL format) API request that contains your NRQL rule. Create the metric by making the API request. Once a metric is created, you can query and chart it using NRQL. Step 1. Create NRQL query rule The most important part of creating a metrics rule is constructing the NRQL query that defines the metric for your data from events, logs, or spans. You can create up to 10 metrics with a single NRQL query by following this procedure: Using New Relic's NRQL interface, construct a query for the metric you want to create. For example: FROM ProcessSample SELECT average(ioTotalReadBytes) WHERE nr.entityType = 'HOST' Copy Edit the query to use one of the three available metric types: summary: Use if the query's function is min, max, sum, count, or average. uniqueCount: Use if the query's function is uniqueCount. distribution: Use if the query's function is percentile or histogram. This example query uses average, so use summary: FROM ProcessSample SELECT summary (ioTotalReadBytes) WHERE nr.entityType = 'HOST' Copy This example query uses count on a non-numeric field: FROM ProcessSample SELECT count(hostname) WHERE hostname LIKE '%prod%' Copy For summary on a non-numeric field use summary(1): FROM ProcessSample SELECT summary(1) WHERE hostname LIKE '%prod%' Copy Tip For more detailed information on using these metric types in rules, see Creating metric rules: requirements and tips. Decide on the attributes you want to attach to the metric, following the limits on the cardinality of unique metric-name/attribute-value combinations. Recommendation: Run a separate query to ensure this count isn't over 50,000 for a 24-hour window. For example: FROM ProcessSample SELECT uniqueCount(awsRegion, awsAvailabilityZone, commandName) WHERE nr.entityType = 'HOST' SINCE 1 DAY AGO Copy To be able to aggregate and filter your metrics, add the attributes you want to attach to the metric using the FACET clause. For example: FROM ProcessSample SELECT summary(ioTotalReadBytes) WHERE nr.entityType = 'HOST' FACET awsRegion, awsAvailabilityZone, commandName Copy Set the name of the metric using the AS function. For example: FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'HOST' FACET awsRegion, awsAvailabilityZone, commandName Copy Once your NRQL rule is complete, use it to create the API request. Step 2. Create API request After you build the NRQL rule to convert data from events, logs, or spans to metrics, continue with building the API request. You can use our NerdGraph API tool to explore the data structure and to construct and make your request. To check that the rule was created correctly, you can run a query to return that rule using its ID. For tips on querying the metrics you've created, see Query and chart your metrics. Example NerdGraph API request The following example NerdGraph API request uses the same NRQL rule from step 1. The IO Total Read Bytes Rule creates a metric named io.totalread.bytes. (The rule name can have spaces, which differs from the metric naming rules.) mutation { eventsToMetricsCreateRule(rules: { name: \"io.totalread.bytes for computeSample entities\", description:\"Created by Zach on March 27, 2019. Used by team Network.\", nrql:\"FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName\", accountId: 123456 }) { successes { id name nrql enabled } failures { submitted { name nrql accountId } errors { reason description } } } } Copy In this request: Request elements Description mutation One of the basic API operation types. eventsToMetricsCreateRule The method being called to create a rule. rules Takes four parameters: name: The name of the rule. description: Optional. The description of the rule. We recommend you include information about who created the metric data and who will be using the data. accountId: The New Relic account ID where the events, logs, or spans live and the metrics will be created. nrql: The NRQL query that creates the rule. For more on this, see Create NRQL query. successes and submitted blocks Here you define the data returned by a successful or failed response. Available parameters for these blocks include: id (ruleId for submitted) name description nrql enabled (enabled/disabled status) accountId ruleId and accountId If a failure occurs, then the submitted ruleId and accountId will be returned along with the error reason and error description. Example NerdGraph API response Here's an example of a returned response: { \"data\": { \"eventsToMetricsCreateRule\": { \"failures\": [], \"successes\": [ { \"enabled\": true, \"id\": \"46\", \"name\": \"io.totalread.bytes for computeSample entities\", \"nrql\": \"FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName\" } ] } } } Copy Step 3. Create a metrics rule with API request When your API request is ready, you can use the NerdGraph API to make the request, which will create the metrics. Query and chart your metrics After you create a metrics rule to convert data for your events, logs, or spans, you can view the new metric data in the New Relic UI. To view your data: Go to New Relic's NRQL query interface. Run the following query to see the name of all your metrics: SELECT uniques(metricName) FROM Metric Copy Pick the metric of interest, then run the following query to see the available attributes: SELECT * FROM Metric where metricName = 'yourMetric' Copy If you don't see expected data, follow the troubleshooting procedures. The available NRQL aggregator functions depend on the metric type you created. Here are some examples. Summary metric example If you created a summary metric type, you can use the count, sum, max, min, and average aggregator functions, as shown in the following query: SELECT count(appStartResponseTime), sum(appStartResponseTime), max(appStartResponseTime), min(appStartResponseTime), average(appStartResponseTime) FROM Metric Copy Count metric example If you created a uniqueCount metric type, you can only use the uniqueCount function, as shown in the following query: SELECT uniqueCount(playbackErrorStreamUniqueCount) * 100 / uniqueCount(streamUniqueCount) AS '% of Streams Impacted' FROM Metric Copy Distribution metric example If you created a distribution metric type, use the percentile or histogram functions, as shown in the following queries: SELECT percentile(service.responseTime, 95) FROM Metric Copy OR SELECT histogram(service.responseTime, 10, 20) FROM Metric Copy Troubleshooting If your NerdGraph call is not constructed correctly, you may receive a message like this: Cannot parse the unexpected character \"\\u201C” Copy Verify the quotes in the NerdGraph call are not smart quotes (curly quotes). Our NerdGraph API only accepts straight quotes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 305.61752,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>metrics</em> from other <em>data</em> types",
        "sections": "Create <em>metrics</em> from other <em>data</em> types",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " the NerdGraph API to make the request, which will create the <em>metrics</em>. Query and chart your <em>metrics</em> After you create a <em>metrics</em> rule to <em>convert</em> <em>data</em> for your events, logs, or spans, you can view the new <em>metric</em> <em>data</em> in the New Relic UI. To view your <em>data</em>: Go to New Relic&#x27;s NRQL query interface. Run the following"
      },
      "id": "603ebfc8196a67cab0a83d96"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-14T17:37:59Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.14774,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot <em>Metric</em> API with NRIntegrationError events",
        "sections": "Match errors <em>to</em> <em>ingested</em> payloads",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; API keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper API endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_API_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-api.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;<em>Metrics</em>&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes": [
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-15T00:49:10Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 431.34576,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the Browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-06-15T00:49:11Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.20789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ", timeseries, until, week, weeks, where, with <em>Event</em> type limits The current limit for total number of <em>event</em>Type values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations",
        "Deprecated methods"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "30a7ec0f78ddde237cb20265ab9702582f5bc2ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-06-15T00:50:03Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default Mobile events using the New Relic Mobile SDK. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple Mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the Mobile crash event trail. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default Mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations. Deprecated methods As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create custom events. The recordEvent methods for Android and iOS are deprecated. The deprecated recordEvent events do not have their own event type; they are recorded as a Mobile event type with a category attribute value of custom. recordCustomEvent creates an event with an eventType you can assign. But the eventType should only be used for one or two high-level event types, not for naming events. For example, you might have one event type Gestures, with many different names under that one type. For more context on this, see the recordCustomEvent query example.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.20789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data": [
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-15T00:49:10Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 431.34576,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the Browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-06-15T00:48:18Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your New Relic APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.2093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations",
        "Deprecated methods"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "30a7ec0f78ddde237cb20265ab9702582f5bc2ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-06-15T00:50:03Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default Mobile events using the New Relic Mobile SDK. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple Mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the Mobile crash event trail. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default Mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations. Deprecated methods As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create custom events. The recordEvent methods for Android and iOS are deprecated. The deprecated recordEvent events do not have their own event type; they are recorded as a Mobile event type with a category attribute value of custom. recordCustomEvent creates an event with an eventType you can assign. But the eventType should only be used for one or two high-level event types, not for naming events. For example, you might have one event type Gestures, with many different names under that one type. For more context on this, see the recordCustomEvent query example.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.20789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes": [
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-06-15T00:48:18Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your New Relic APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.20929,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-06-15T00:49:11Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.20786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ", timeseries, until, week, weeks, where, with <em>Event</em> type limits The current limit for total number of <em>event</em>Type values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations",
        "Deprecated methods"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "30a7ec0f78ddde237cb20265ab9702582f5bc2ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-06-15T00:50:03Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default Mobile events using the New Relic Mobile SDK. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple Mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the Mobile crash event trail. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default Mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations. Deprecated methods As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create custom events. The recordEvent methods for Android and iOS are deprecated. The deprecated recordEvent events do not have their own event type; they are recorded as a Mobile event type with a category attribute value of custom. recordCustomEvent creates an event with an eventType you can assign. But the eventType should only be used for one or two high-level event types, not for naming events. For example, you might have one event type Gestures, with many different names under that one type. For more context on this, see the recordCustomEvent query example.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.20786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/report-custom-event-data": [
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-06-15T00:48:18Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your New Relic APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 926.8047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: <em>Report</em> <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "sections": "APM: <em>Report</em> <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "tags": "<em>Custom</em> <em>events</em>",
        "body": ". Record <em>custom</em> <em>events</em> and <em>attributes</em> You can add your own <em>custom</em> APM <em>events</em> and <em>attributes</em>, which you can then use for querying and charting. This is one of several ways to <em>report</em> <em>custom</em> data. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> <em>attributes</em>"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-15T00:49:10Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 532.2044,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Report</em> browser monitoring <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "sections": "<em>Report</em> browser monitoring <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "tags": "<em>Custom</em> <em>events</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and <em>attributes</em>. Page actions and views Use the Browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "iOS SDK API guide",
        "Caution",
        "Install the SDK",
        "Automatically instrumented classes and methods",
        "Instrument your Objective-C code",
        "Important",
        "Create and complete interactions",
        "Rename a default interaction",
        "Set a custom application version",
        "Set a custom build identifier",
        "Create custom metrics",
        "Objective-C: Report custom attributes and events",
        "Objective-C: Track custom network requests",
        "Instrument your Swift code",
        "Create and complete Swift interactions",
        "Rename a default Swift interaction",
        "Set a custom application version with Swift",
        "Set a custom build identifier with Swift",
        "Create custom metrics with Swift",
        "Swift: Report custom attributes and events",
        "Swift: Track custom network requests"
      ],
      "title": "iOS SDK API guide",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "API guides"
      ],
      "external_id": "fe6ba3196a927fb8dee72f8bf777461c95f7505c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/api-guides/ios-sdk-api-guide/",
      "published_at": "2021-06-14T21:38:56Z",
      "updated_at": "2021-06-03T12:15:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the iOS SDK API for New Relic Mobile to add custom data. For example: Instrument your own code. Start and stop interaction traces from events in your mobile app. Record custom metrics. Send custom attributes and events to Insights. Track networking from libraries not supported automatically. Set a custom identifier value with Objective-C or Swift to associate user sessions with analysis events and attributes (iOS SDK version 5.9.0 or higher). Caution Tracing is heavily optimized, but it does impose a performance overhead. Avoid instrumenting methods that are expected to be called hundreds of times. Install the SDK Ensure you have your app instrumented with the latest New Relic Mobile SDK by going to one.newrelic.com > Add more data and following the instructions for iOS. This document contains the iOS SDK instrumentation requirements for: Objective C Swift For details about the available methods for custom attributes and events you can send to to New Relic Insights, see the iOS SDK API reference. You can also configure feature flags for: Objective-C Swift Automatically instrumented classes and methods The following methods (for the listed classes and their sub-classes) are already instrumented by New Relic. You do not need to add custom instrumentation to trace them. Classes Methods automatically instrumented by New Relic UIViewController viewDidLoad: viewWillAppear: viewDidAppear: viewWillDisappear: viewDidDisappear: viewWillLayoutSubviews: viewDidLayoutSubviews: UIImage imageNamed: imageWithContentsOfFile: imageWithData: imageWithData:scale: initWithContentsOfFile: initWithData: initWithData:scale: NSJSONSerialization JSONObjectWithData:options:error: JSONObjectWithStream:options:error: dataWithJSONObject:options:error: writeJSONObject:toStream:options:error: NSManagedObjectContext executeFetchRequest:error: processPendingChanges New Relic Mobile aggregates performance for various methods into summary metrics that appear in New Relic Mobile's Interactions page. Summary categories include: View loading UI layout Database Images JSON Network Instrument your Objective-C code To have your own Objective-C code appear in interaction code breakdowns and timelines, add a _START call to the beginning of your method and a _STOP call to the end of it. Important Always include a _STOP for each _START, and only include one set of these commands in a given method. The trace system will automatically pick up the class and method name, and report performance metrics for your method to New Relic Mobile. - (void)myMethod { NR_TRACE_METHOD_START(0); // … existing code NR_TRACE_METHOD_STOP; } Copy If you are not using ARC, use this version of the _STOP macro to avoid memory leaks: NR_NONARC_TRACE_METHOD_STOP; Copy If you want your method’s performance to be included in the summary data on the APM Overview page, pass one of the NRTraceType enum values into the _START macro; for example: NR_TRACE_METHOD_START(NRTraceTypeDatabase); Copy Create and complete interactions By default, an interaction starts when a view controller is pushed. To manually start an interaction with Objective-C, use these API calls: NSString* uniqueIdentifier = NR_START_NAMED_INTERACTION(@\"name\"); Copy This macro will automatically begin tracking the name interaction trace from the current line. It will also complete any previously running interaction. It returns a unique identifier that can be used to complete that interaction by using this API call: NR_INTERACTION_STOP(uniqueIdentifier); Copy This macro will complete the interaction associated with the uniqueIdentifier if that interaction has not already completed automatically. You do not need to call this method. Rename a default interaction By default, the iOS agent will start an interaction trace when a new view controller is displayed. The interactions are named using the format Display <ViewController>. To change these default names with Objective-C, implement the - (NSString*) customNewRelicInteractionName instance method in your view controller, where the string returned becomes the interaction's name. Set a custom application version The New Relic iOS SDK allows you to set a custom application version string with Objective-C. Instead of using the string defined in CFBundleShortVersionString, call the +[NewRelic setApplicationVersion:] method and pass along the custom application version before calling +[NewRelic startWithApplicationToken:]; [NewRelic setApplicationVersion:(NSString*) appVersion]; Copy Set a custom build identifier As of version 5.1.0 of the New Relic iOS SDK, an API method allows you to set a custom build identifier that is displayed next to the application version in New Relic Mobile's Crash details page. Instead of using the CFBundleVersion string defined in Xcode with Objective-C, call the +[NewRelic setApplicationBuild:] method, and pass along the custom build identifier. [NewRelic setApplicationBuild:(NSString*) buildNumber]; Copy Create custom metrics Custom metrics can help track high level events specific to your application. With the recordMetric API, you can record arbitrary numerical data and named events with Objective-C and Swift. You can also use several API calls to record custom metrics that provide different levels of detail. Objective-C: Report custom attributes and events Use methods in the NewRelic object to report custom attributes and events. For details about the available methods for custom attributes and events with Objective-C, see the iOS SDK API reference. Methods that return BOOL results return YES if they succeed, or NO if the operation did not complete. These methods are available in versions 5.0.0 or higher of the New Relic iOS SDK. The SDK can store up to 128 user-defined custom attributes at a time. If you attempt to store more than 128 attributes, the SDK returns NO. Custom attributes names should use the simplest format needed, and New Relic recommends single word attributes, containing no spaces. Attribute phrases can be formatted in camel case, so My Custom Attribute is better specified as myCustomAttribute. As with custom metrics: Avoid using the characters / ] [ | * when naming things. Avoid multi-byte characters. Objective-C: Track custom network requests If you can express a transactional network request in terms similar to an HTTP request, you can track it in New Relic Mobile. Use URLs that are well-formed and do not include highly variable paths or hostnames. For requests that complete, use this method: [NewRelic noticeNetworkRequestForURL:(NSURL*)url httpMethod:(NSString*)httpMethod withTimer:(NRTimer *)timer responseHeaders:(NSDictionary *)headers statusCode:(NSInteger)httpStatusCode bytesSent:(NSUInteger)bytesSent bytesReceived:(NSUInteger)bytesReceived responseData:(NSData *)responseData andParams:(NSDictionary *)params]; Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request headers A dictionary containing the HTTP response headers, if available httpStatusCode The response status code If the httpStatusCode is greater than or equal to 400, New Relic Mobile will record a server error and may capture the responseData body if provided. bytesSent The size of the request body bytesReceived The size of the responseBody responseData The response body data, captured if New Relic Mobile records server error params params Additional parameters included in an HTTP error metric if the HTTP transaction is an error For requests that fail due to a socket or operating system error, use this method: [NewRelic noticeNetworkFailureForURL:(NSURL *)url httpMethod:(NSString*)httpMethod withTimer:(NRTimer *)timer andFailureCode:(NSInteger)iOSFailureCode]; Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request iOSFailureCode The failure code Failure codes are interpreted as NSURLError* code. To view a complete list of the codes that New Relic Mobile supports, see NRConstants.h. Instrument your Swift code To have your own Swift code appear in interaction code breakdowns and timelines: Add a startTracingMethod() call to the beginning of your method. Add a endTracingMethodWithTimer() call to the end of it. Always include an endTracingMethodWithTimer() call for each startTracingMethod() reference. Include only one set of these commands in a given method. func myMethod(){ let timer = NRTimer(); NewRelic.startTracingMethod(#selector(MyClass.myMethod), object: self, timer: timer, category: NRTraceTypeNone) // … existing code NewRelic.endTracingMethodWithTimer(timer) } Copy If you want your method’s performance to be included in the summary data on the APM Overview page, pass one of the NRTraceType enum values into the startTracingMethod() macro; for example: NewRelic.startTracingMethod(#selector(MyClass.myMethod), object: self, timer: timer, category: NRTraceTypeDatabase) Copy Create and complete Swift interactions By default, an interaction starts when a view controller is pushed. To manually start an interaction, use these API calls: let uniqueIdentifier = NewRelic.startInteraction(withName: \"My Interaction\") Copy This call will automatically begin tracking an interaction trace named My Interaction from the current line. It will also complete any previously running interaction. It returns a unique identifier that can be used to complete that interaction by using this API call: NewRelic.stopCurrentInteraction(uniqueIdentifier) Copy This method will complete the interaction associated with the uniqueIdentifier if that interaction has not already completed automatically. You do not need to call this method. Rename a default Swift interaction By default, the iOS agent will start an interaction trace when a new view controller is displayed. The interactions are named using the format Display <ViewController>. To change these default names, implement the @objc func customNewRelicInteractionName() -> String method in your view controller, where the string returned becomes the interaction's name. Set a custom application version with Swift The New Relic iOS SDK allows you to set a custom application version string. Instead of using the string defined in CFBundleShortVersionString, call the NewRelic.setApplicationVersion() method, and pass along the custom application version before calling NewRelic.startWithApplicationToken();. NewRelic.setApplicationVersion(String appVersion) Copy Set a custom build identifier with Swift As of version 5.1.0 of the New Relic iOS SDK, an API method allows you to set a custom build identifier that is displayed next to the application version in New Relic Mobile's Crash details page. Instead of using the CFBundleVersion string defined in Xcode, call the NewRelic.setApplicationBuild() method, and pass along the custom build identifier. NewRelic.setApplicationBuild(buildNumber) Copy Create custom metrics with Swift Custom metrics can help track high level events specific to your application. With the recordMetric API, you can record arbitrary numerical data and named events with Objective-C and Swift. You can also use several API calls to record custom metrics that provide different levels of detail. Swift: Report custom attributes and events Use methods in the NewRelic object to report custom attributes and events. For details about the available methods for custom attributes and events with Swift, see the iOS SDK API reference. Methods that return BOOL results return YES if they succeed, or NO if the operation did not complete. These methods are available in versions 5.0.0 or higher of the New Relic iOS SDK. The SDK can store up to 128 user-defined custom attributes at a time. If you attempt to store more than 128 attributes, the SDK returns NO. Custom attributes names should use the simplest format needed, and New Relic recommends single word attributes, containing no spaces. Attribute phrases can be formatted in camel case, so My Custom Attribute is better specified as myCustomAttribute. As with custom metrics: Avoid using the characters / ] [ | * when naming things. Avoid multi-byte characters. Swift: Track custom network requests If you can express a transactional network request in terms similar to an HTTP request, you can track it in New Relic Mobile. Use URLs that are well-formed and do not include highly variable paths or hostnames. For requests that complete, use this method: NewRelic.noticeNetworkRequestForURL(url: NSURL!, httpMethod: String!, withTimer: NRTimer!, responseHeaders:[NSObject : AnyObject]!, statusCode: Int, bytesSent: UInt, bytesReceived: UInt, responseData: NSData!, andParams: [NSObject : AnyObject]!) Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request headers A dictionary containing the HTTP response headers, if available httpStatusCode The response status code If the httpStatusCode is greater than or equal to 400, New Relic Mobile will record a server error and may capture the responseData body if provided. bytesSent The size of the request body bytesReceived The size of the responseBody responseData The response body data, captured if New Relic Mobile records Server error params params Additional parameters included in an HTTP error metric if the HTTP transaction is an error For requests that fail due to a socket or operating system error, use this method: NewRelic.noticeNetworkFailureForURL(url: NSURL!, httpMethod: NSString!, withTimer: NRTimer!, andFailureCode: Int) Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request iOSFailureCode The failure code Failure codes are interpreted as NSURLError* code. To view a complete list of the codes that New Relic Mobile supports, see NRConstants.h.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 429.03107,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Objective-C: <em>Report</em> <em>custom</em> <em>attributes</em> <em>and</em> <em>events</em>",
        "body": " record arbitrary numerical data and named <em>events</em> with Objective-C and Swift. You can also use several API calls to record <em>custom</em> metrics that provide different levels of detail. Objective-C: <em>Report</em> <em>custom</em> <em>attributes</em> and <em>events</em> Use methods in the NewRelic object to <em>report</em> <em>custom</em> <em>attributes</em> and <em>events</em>"
      },
      "id": "603eb3a2e7b9d264f02a07a8"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes": [
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-15T00:49:10Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 431.3452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the Browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-06-15T00:48:18Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your New Relic APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.20927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-06-15T00:49:11Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.20786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ", timeseries, until, week, weeks, where, with <em>Event</em> type limits The current limit for total number of <em>event</em>Type values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/intro-custom-data": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-custom-event-data/",
      "sections": [
        "Report custom events and attributes",
        "Requirements",
        "Avoid rate limits",
        "Example use cases",
        "Using custom attributes",
        "Using custom events",
        "Send custom events and attributes",
        "Extend data retention"
      ],
      "published_at": "2021-06-15T00:49:10Z",
      "title": "Report custom events and attributes",
      "updated_at": "2021-05-15T10:44:11Z",
      "type": "docs",
      "external_id": "e50a9be8b3df5859c6307c8642942006f537578d",
      "document_type": "page",
      "popularity": 1,
      "body": "One of the ways to report custom data to New Relic is with custom events and attributes. Have questions about why you'd use custom data? See Introduction to custom data. Requirements For event and attribute formatting requirements and best practices, see Limits and requirements. Avoid rate limits Reporting a large number of custom events and/or attributes can cause degraded query performance. It may also result in approaching or passing data collection rate limits. For optimal performance, first think about what data you want to analyze, and then create only the events and/or attributes necessary to meet these specific goals. Be aware of the following data and subscription requirements for inserting and accessing custom data: Ensure you follow limits and requirements around event/attribute data types, naming syntax, and size. The amount of data you have access to over time depends on your data retention policy. Example use cases Two popular custom data solutions are custom events and custom attributes. There are several ways to accomplish this (more on that later in this doc), depending on your New Relic implementation and tools. Here are some common use cases for implementing custom events and attributes. Using custom attributes Custom attributes are often used to add important business and operational context to existing events. Business context might include: Customer token Customer market segment Customer value classification Workflow control values not obvious in the URIStem User/product/account privilege context Operational context might include: Which feature flags were used What datastore was accessed What cache was accessed What errors were detected and ignored (fault partitioning) Using custom events Event data is one of New Relic's four core data types. We recommend reading that definition to understand what we mean by \"event\" and why that data type is most used for reporting specific types of activity. The use cases for custom events varies widely: basically they are used for any type of activity that an organization deems important and that is not already being monitored. A couple examples: An event might represent an activity involving multiple actions, like a customer purchasing a certain combination of products. An event might record backup activity. For example, they might set up reporting of events that represent production backups of their SOLR instances into an event table, with a timestamp of when it occurred, which cluster, and the duration. Send custom events and attributes Methods for sending custom events and attributes include: Source How to send custom data APM agent Use APM agent APIs to report custom events and custom attributes. Browser monitoring agent Add custom attributes to the PageView event via the Browser API call addCustomAttribute. Send PageAction event and attributes via Browser API. Forward APM agent custom attributes to PageView event. Event API To report custom events not associated with other New Relic products, use the Event API. Infrastructure monitoring agent Add custom attributes to default Infrastructure events. Use the Flex integration tool to report your own custom event data. Mobile monitoring agent Use the mobile agent API to send custom events and attributes. Synthetic monitoring Add custom attributes to the SyntheticCheck event via the $util.insights tools. For ways to report other types of custom data, see: Metric API Logs Trace API Extend data retention To learn how to extend how long events are retained in your account, see our documentation about event data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 579.07794,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report <em>custom</em> events and attributes",
        "sections": "Report <em>custom</em> events and attributes",
        "body": "One of the ways to report <em>custom</em> <em>data</em> to New Relic is with <em>custom</em> events and attributes. Have questions about why you&#x27;d use <em>custom</em> <em>data</em>? See <em>Introduction</em> to <em>custom</em> <em>data</em>. Requirements For event and attribute formatting requirements and best practices, see Limits and requirements. Avoid rate limits"
      },
      "id": "609fa5fb64441f9ebfd2a1db"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-15T00:49:10Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.31076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> events and attributes",
        "sections": "Forward <em>custom</em> attributes from APM <em>data</em>",
        "tags": "Event <em>data</em> sources",
        "body": " that contains the action name and any <em>custom</em> attribute names and values you capture along with it. The PageAction event also contains any <em>custom</em> attributes you added to the PageView event. Add <em>custom</em> attributes to the PageView event so you can query or filter your <em>data</em> to answer more questions about your"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-06-15T00:48:18Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your New Relic APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 85.548485,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> events and attributes",
        "sections": "APM: Report <em>custom</em> events and attributes",
        "tags": "Event <em>data</em> sources",
        "body": "If you have APM, you can report <em>custom</em> event <em>data</em>. You can then query and visualize your <em>data</em> in New Relic. <em>Data</em> considerations New Relic agents send event <em>data</em> to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    }
  ],
  "/docs/telemetry-data-platform/get-started/get-know-telemetry-data-platform": [
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-14T19:27:12Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.8432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric API limits <em>and</em> restricted attributes",
        "sections": "Max <em>data</em> points per minute (DPM)",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic <em>platform</em>. Any values submitted with these keys in the attributes section of a metric <em>data</em> point will cause the <em>data</em> point to be dropped, or the value to be omitted"
      },
      "id": "603ea95128ccbca08eeba7a6"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-14T17:37:59Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.8432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Match errors to <em>ingested</em> payloads",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " per minute. If you <em>get</em> this error, you can either send <em>data</em> less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values"
      },
      "id": "603ea57b64441f44f34e887d"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Tip",
        "Requirements",
        "Basic workflow",
        "Register an Insert API key",
        "Important",
        "Caution",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "0e0f5ad678bc1756a2cf7db88a52df2c2983bbe4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/introduction-event-api/",
      "published_at": "2021-06-14T18:22:55Z",
      "updated_at": "2021-06-09T02:16:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic University’s tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.nr-data.net or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to your New Relic account: Register an Insert API key. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Register an Insert API key You must have the correct user permissions to register Insert API keys. Important Insert API keys are generated for an account. They aren't associated with a specific user. Anyone in the account with access to the Insert API key can use it. You submit multiple event types under a single Insert API key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. To register an Insert API key: From one.newrelic.com, click the account dropdown and then click Account settings. Click API keys and click Insights insert keys. Next to the Insert keys heading, select the symbol and follow the instructions. The Insert key page lists the curl command necessary to add event data for the key. Caution For security reasons, the Insert API key cannot be altered or read using the API. To change or read a key, use the New Relic UI. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. The Insert key page in the Insights UI automatically generates a sample curl query for you to use as a template. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"X-Insert-Key: YOUR_KEY_HERE\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_KEY_HERE\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"X-Insert-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The X-Insert-Key contains the correct Insert API key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, use the Insights data explorer to ensure your events are reporting correctly and to generate queries. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid API key: Invalid Insert key, or the account does not have access to Insights. Register a valid Insert key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To have New Relic Alerts notify you about parsing errors, create a NRQL condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the Insert API key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.7901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Find your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability <em>platform</em>, join the New"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    }
  ],
  "/docs/telemetry-data-platform/get-started/introduction-new-relic-data-ingest-apis-sdks": [
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-14T19:27:12Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.8432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric API limits <em>and</em> restricted attributes",
        "sections": "Max <em>data</em> points per minute (DPM)",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic <em>platform</em>. Any values submitted with these keys in the attributes section of a metric <em>data</em> point will cause the <em>data</em> point to be dropped, or the value to be omitted"
      },
      "id": "603ea95128ccbca08eeba7a6"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-14T17:37:59Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.8432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Match errors to <em>ingested</em> payloads",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " per minute. If you <em>get</em> this error, you can either send <em>data</em> less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values"
      },
      "id": "603ea57b64441f44f34e887d"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Tip",
        "Requirements",
        "Basic workflow",
        "Register an Insert API key",
        "Important",
        "Caution",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "0e0f5ad678bc1756a2cf7db88a52df2c2983bbe4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/introduction-event-api/",
      "published_at": "2021-06-14T18:22:55Z",
      "updated_at": "2021-06-09T02:16:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic University’s tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.nr-data.net or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to your New Relic account: Register an Insert API key. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Register an Insert API key You must have the correct user permissions to register Insert API keys. Important Insert API keys are generated for an account. They aren't associated with a specific user. Anyone in the account with access to the Insert API key can use it. You submit multiple event types under a single Insert API key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. To register an Insert API key: From one.newrelic.com, click the account dropdown and then click Account settings. Click API keys and click Insights insert keys. Next to the Insert keys heading, select the symbol and follow the instructions. The Insert key page lists the curl command necessary to add event data for the key. Caution For security reasons, the Insert API key cannot be altered or read using the API. To change or read a key, use the New Relic UI. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. The Insert key page in the Insights UI automatically generates a sample curl query for you to use as a template. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"X-Insert-Key: YOUR_KEY_HERE\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_KEY_HERE\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"X-Insert-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The X-Insert-Key contains the correct Insert API key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, use the Insights data explorer to ensure your events are reporting correctly and to generate queries. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid API key: Invalid Insert key, or the account does not have access to Insights. Register a valid Insert key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To have New Relic Alerts notify you about parsing errors, create a NRQL condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the Insert API key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.7901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Find your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability <em>platform</em>, join the New"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    }
  ],
  "/docs/telemetry-data-platform/get-started/nrdb-horsepower-under-hood": [
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-14T19:27:12Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.8431,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric API limits <em>and</em> restricted attributes",
        "sections": "Max <em>data</em> points per minute (DPM)",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic <em>platform</em>. Any values submitted with these keys in the attributes section of a metric <em>data</em> point will cause the <em>data</em> point to be dropped, or the value to be omitted"
      },
      "id": "603ea95128ccbca08eeba7a6"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-14T17:37:59Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.8431,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Match errors to <em>ingested</em> payloads",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " per minute. If you <em>get</em> this error, you can either send <em>data</em> less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values"
      },
      "id": "603ea57b64441f44f34e887d"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Tip",
        "Requirements",
        "Basic workflow",
        "Register an Insert API key",
        "Important",
        "Caution",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "0e0f5ad678bc1756a2cf7db88a52df2c2983bbe4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/introduction-event-api/",
      "published_at": "2021-06-14T18:22:55Z",
      "updated_at": "2021-06-09T02:16:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic University’s tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.nr-data.net or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to your New Relic account: Register an Insert API key. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Register an Insert API key You must have the correct user permissions to register Insert API keys. Important Insert API keys are generated for an account. They aren't associated with a specific user. Anyone in the account with access to the Insert API key can use it. You submit multiple event types under a single Insert API key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. To register an Insert API key: From one.newrelic.com, click the account dropdown and then click Account settings. Click API keys and click Insights insert keys. Next to the Insert keys heading, select the symbol and follow the instructions. The Insert key page lists the curl command necessary to add event data for the key. Caution For security reasons, the Insert API key cannot be altered or read using the API. To change or read a key, use the New Relic UI. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. The Insert key page in the Insights UI automatically generates a sample curl query for you to use as a template. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"X-Insert-Key: YOUR_KEY_HERE\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_KEY_HERE\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"X-Insert-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The X-Insert-Key contains the correct Insert API key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, use the Insights data explorer to ensure your events are reporting correctly and to generate queries. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid API key: Invalid Insert key, or the account does not have access to Insights. Register a valid Insert key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To have New Relic Alerts notify you about parsing errors, create a NRQL condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the Insert API key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.79,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Find your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability <em>platform</em>, join the New"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    }
  ],
  "/docs/telemetry-data-platform/index": [
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-14T19:27:12Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1026.9276,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Max <em>data</em> points per minute (DPM)",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic <em>platform</em>. Any values submitted with these keys in the attributes section of a metric <em>data</em> point will cause the <em>data</em> point to be dropped, or the value to be omitted"
      },
      "id": "603ea95128ccbca08eeba7a6"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-14T17:37:59Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1026.9276,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Problem You sent metric <em>data</em> points to the Metric API, and are not seeing what you expect when querying the <em>data</em>. Use the following checklist to determine the root cause: Make sure you are querying the <em>data</em> correctly. Check the HTTP status codes returned by the API. Issues like authorization"
      },
      "id": "603ea57b64441f44f34e887d"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Tip",
        "Requirements",
        "Basic workflow",
        "Register an Insert API key",
        "Important",
        "Caution",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "0e0f5ad678bc1756a2cf7db88a52df2c2983bbe4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/introduction-event-api/",
      "published_at": "2021-06-14T18:22:55Z",
      "updated_at": "2021-06-09T02:16:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic University’s tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.nr-data.net or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to your New Relic account: Register an Insert API key. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Register an Insert API key You must have the correct user permissions to register Insert API keys. Important Insert API keys are generated for an account. They aren't associated with a specific user. Anyone in the account with access to the Insert API key can use it. You submit multiple event types under a single Insert API key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. To register an Insert API key: From one.newrelic.com, click the account dropdown and then click Account settings. Click API keys and click Insights insert keys. Next to the Insert keys heading, select the symbol and follow the instructions. The Insert key page lists the curl command necessary to add event data for the key. Caution For security reasons, the Insert API key cannot be altered or read using the API. To change or read a key, use the New Relic UI. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. The Insert key page in the Insights UI automatically generates a sample curl query for you to use as a template. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"X-Insert-Key: YOUR_KEY_HERE\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_KEY_HERE\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"X-Insert-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The X-Insert-Key contains the correct Insert API key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, use the Insights data explorer to ensure your events are reporting correctly and to generate queries. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid API key: Invalid Insert key, or the account does not have access to Insights. Register a valid Insert key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To have New Relic Alerts notify you about parsing errors, create a NRQL condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the Insert API key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1026.7162,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Find your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability <em>platform</em>, join the New"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/introduction-event-api": [
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-14T19:27:12Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.4416,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>API</em> limits <em>and</em> restricted attributes",
        "sections": "Metric <em>API</em> limits <em>and</em> restricted attributes",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "This document describes <em>data</em> requirements for the Metric <em>API</em>, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric <em>data</em>: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than"
      },
      "id": "603ea95128ccbca08eeba7a6"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-14T17:37:59Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.4416,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    },
    {
      "sections": [
        "Get data into New Relic",
        "New Relic-built agents and integrations",
        "Agent APIs",
        "Telemetry SDKs",
        "APIs for sending metrics, traces, logs, and events",
        "New Relic One applications"
      ],
      "title": "Get data into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "1b20f81fa22784c5d22e4e51eb7c0bf26cbdb0b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-started/introduction-new-relic-data-ingest-apis-sdks/",
      "published_at": "2021-06-14T18:22:55Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are many ways to get data into your New Relic account. Any New Relic user can use any of our data ingest methods to report data to our Telemetry Data Platform. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring, infrastructure monitoring, or any of our wide array of integrations, by default you'll receive data from your monitored applications, hosts, services, or other entities. To browse all New Relic-built tools and solutions, see New Relic integrations. Agent APIs Some of our monitoring solutions come with APIs and/or SDKs that allow you to customize the data reported and how it reports. For more information, see the relevant product: APM agent APIs Browser API Mobile API Infrastructure monitoring: the Flex integration tool Telemetry SDKs If our more curated solutions don't work for you, our open source Telemetry SDKs let you build your own solution. These SDKs are language wrappers for our data-ingest APIs (below) that let you send telemetry data to New Relic without requiring install of an agent. APIs for sending metrics, traces, logs, and events If our more curated solutions don't work for you, we also have data-ingest APIs: Trace API Event API Metric API Log API To learn about the differences between these data types, see Data types. New Relic One applications You can build entirely custom applications that reside in New Relic One and make use of any data you want. You can use existing open source New Relic One apps, or share your own with the open source community. For details, see New Relic One applications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.82196,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get <em>data</em> into New Relic",
        "sections": "<em>APIs</em> for sending metrics, traces, logs, <em>and</em> events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "There are many ways to get <em>data</em> into your New Relic account. Any New Relic user can use any of our <em>data</em> <em>ingest</em> methods to report <em>data</em> to our <em>Telemetry</em> <em>Data</em> <em>Platform</em>. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring"
      },
      "id": "603eae7b196a671ea3a83dc7"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/introduction-metric-api": [
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-14T19:27:12Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.4416,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>API</em> limits <em>and</em> restricted attributes",
        "sections": "Metric <em>API</em> limits <em>and</em> restricted attributes",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "This document describes <em>data</em> requirements for the Metric <em>API</em>, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric <em>data</em>: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than"
      },
      "id": "603ea95128ccbca08eeba7a6"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-14T17:37:59Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.4416,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Tip",
        "Requirements",
        "Basic workflow",
        "Register an Insert API key",
        "Important",
        "Caution",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "0e0f5ad678bc1756a2cf7db88a52df2c2983bbe4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/introduction-event-api/",
      "published_at": "2021-06-14T18:22:55Z",
      "updated_at": "2021-06-09T02:16:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic University’s tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.nr-data.net or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to your New Relic account: Register an Insert API key. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Register an Insert API key You must have the correct user permissions to register Insert API keys. Important Insert API keys are generated for an account. They aren't associated with a specific user. Anyone in the account with access to the Insert API key can use it. You submit multiple event types under a single Insert API key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. To register an Insert API key: From one.newrelic.com, click the account dropdown and then click Account settings. Click API keys and click Insights insert keys. Next to the Insert keys heading, select the symbol and follow the instructions. The Insert key page lists the curl command necessary to add event data for the key. Caution For security reasons, the Insert API key cannot be altered or read using the API. To change or read a key, use the New Relic UI. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. The Insert key page in the Insights UI automatically generates a sample curl query for you to use as a template. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"X-Insert-Key: YOUR_KEY_HERE\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_KEY_HERE\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"X-Insert-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The X-Insert-Key contains the correct Insert API key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, use the Insights data explorer to ensure your events are reporting correctly and to generate queries. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid API key: Invalid Insert key, or the account does not have access to Insights. Register a valid Insert key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To have New Relic Alerts notify you about parsing errors, create a NRQL condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the Insert API key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.37396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Event <em>API</em>",
        "sections": "Introduction to the Event <em>API</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic Event <em>API</em> is one way to report custom events to New Relic. The Event <em>API</em> lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use <em>APIs</em> and the rest of our observability <em>platform</em>, join the New"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes": [
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-14T17:37:59Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.4416,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Tip",
        "Requirements",
        "Basic workflow",
        "Register an Insert API key",
        "Important",
        "Caution",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "0e0f5ad678bc1756a2cf7db88a52df2c2983bbe4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/introduction-event-api/",
      "published_at": "2021-06-14T18:22:55Z",
      "updated_at": "2021-06-09T02:16:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic University’s tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.nr-data.net or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to your New Relic account: Register an Insert API key. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Register an Insert API key You must have the correct user permissions to register Insert API keys. Important Insert API keys are generated for an account. They aren't associated with a specific user. Anyone in the account with access to the Insert API key can use it. You submit multiple event types under a single Insert API key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. To register an Insert API key: From one.newrelic.com, click the account dropdown and then click Account settings. Click API keys and click Insights insert keys. Next to the Insert keys heading, select the symbol and follow the instructions. The Insert key page lists the curl command necessary to add event data for the key. Caution For security reasons, the Insert API key cannot be altered or read using the API. To change or read a key, use the New Relic UI. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. The Insert key page in the Insights UI automatically generates a sample curl query for you to use as a template. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"X-Insert-Key: YOUR_KEY_HERE\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_KEY_HERE\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"X-Insert-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The X-Insert-Key contains the correct Insert API key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, use the Insights data explorer to ensure your events are reporting correctly and to generate queries. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid API key: Invalid Insert key, or the account does not have access to Insights. Register a valid Insert key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To have New Relic Alerts notify you about parsing errors, create a NRQL condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the Insert API key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.37396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Event <em>API</em>",
        "sections": "Introduction to the Event <em>API</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic Event <em>API</em> is one way to report custom events to New Relic. The Event <em>API</em> lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use <em>APIs</em> and the rest of our observability <em>platform</em>, join the New"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    },
    {
      "sections": [
        "Get data into New Relic",
        "New Relic-built agents and integrations",
        "Agent APIs",
        "Telemetry SDKs",
        "APIs for sending metrics, traces, logs, and events",
        "New Relic One applications"
      ],
      "title": "Get data into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "1b20f81fa22784c5d22e4e51eb7c0bf26cbdb0b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-started/introduction-new-relic-data-ingest-apis-sdks/",
      "published_at": "2021-06-14T18:22:55Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are many ways to get data into your New Relic account. Any New Relic user can use any of our data ingest methods to report data to our Telemetry Data Platform. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring, infrastructure monitoring, or any of our wide array of integrations, by default you'll receive data from your monitored applications, hosts, services, or other entities. To browse all New Relic-built tools and solutions, see New Relic integrations. Agent APIs Some of our monitoring solutions come with APIs and/or SDKs that allow you to customize the data reported and how it reports. For more information, see the relevant product: APM agent APIs Browser API Mobile API Infrastructure monitoring: the Flex integration tool Telemetry SDKs If our more curated solutions don't work for you, our open source Telemetry SDKs let you build your own solution. These SDKs are language wrappers for our data-ingest APIs (below) that let you send telemetry data to New Relic without requiring install of an agent. APIs for sending metrics, traces, logs, and events If our more curated solutions don't work for you, we also have data-ingest APIs: Trace API Event API Metric API Log API To learn about the differences between these data types, see Data types. New Relic One applications You can build entirely custom applications that reside in New Relic One and make use of any data you want. You can use existing open source New Relic One apps, or share your own with the open source community. For details, see New Relic One applications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.82196,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get <em>data</em> into New Relic",
        "sections": "<em>APIs</em> for sending metrics, traces, logs, <em>and</em> events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "There are many ways to get <em>data</em> into your New Relic account. Any New Relic user can use any of our <em>data</em> <em>ingest</em> methods to report <em>data</em> to our <em>Telemetry</em> <em>Data</em> <em>Platform</em>. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring"
      },
      "id": "603eae7b196a671ea3a83dc7"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/report-metrics-metric-api": [
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-14T19:27:12Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.44147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>API</em> limits <em>and</em> restricted attributes",
        "sections": "Metric <em>API</em> limits <em>and</em> restricted attributes",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "This document describes <em>data</em> requirements for the Metric <em>API</em>, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric <em>data</em>: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than"
      },
      "id": "603ea95128ccbca08eeba7a6"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-14T17:37:59Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.44147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Tip",
        "Requirements",
        "Basic workflow",
        "Register an Insert API key",
        "Important",
        "Caution",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "0e0f5ad678bc1756a2cf7db88a52df2c2983bbe4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/introduction-event-api/",
      "published_at": "2021-06-14T18:22:55Z",
      "updated_at": "2021-06-09T02:16:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic University’s tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.nr-data.net or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to your New Relic account: Register an Insert API key. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Register an Insert API key You must have the correct user permissions to register Insert API keys. Important Insert API keys are generated for an account. They aren't associated with a specific user. Anyone in the account with access to the Insert API key can use it. You submit multiple event types under a single Insert API key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. To register an Insert API key: From one.newrelic.com, click the account dropdown and then click Account settings. Click API keys and click Insights insert keys. Next to the Insert keys heading, select the symbol and follow the instructions. The Insert key page lists the curl command necessary to add event data for the key. Caution For security reasons, the Insert API key cannot be altered or read using the API. To change or read a key, use the New Relic UI. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. The Insert key page in the Insights UI automatically generates a sample curl query for you to use as a template. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"X-Insert-Key: YOUR_KEY_HERE\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_KEY_HERE\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"X-Insert-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The X-Insert-Key contains the correct Insert API key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, use the Insights data explorer to ensure your events are reporting correctly and to generate queries. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid API key: Invalid Insert key, or the account does not have access to Insights. Register a valid Insert key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To have New Relic Alerts notify you about parsing errors, create a NRQL condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the Insert API key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.37384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Event <em>API</em>",
        "sections": "Introduction to the Event <em>API</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic Event <em>API</em> is one way to report custom events to New Relic. The Event <em>API</em> lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use <em>APIs</em> and the rest of our observability <em>platform</em>, join the New"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/telemetry-sdks-report-custom-telemetry-data": [
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-14T19:27:12Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.44147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>API</em> limits <em>and</em> restricted attributes",
        "sections": "Metric <em>API</em> limits <em>and</em> restricted attributes",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "This document describes <em>data</em> requirements for the Metric <em>API</em>, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric <em>data</em>: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than"
      },
      "id": "603ea95128ccbca08eeba7a6"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-14T17:37:59Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.44147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Tip",
        "Requirements",
        "Basic workflow",
        "Register an Insert API key",
        "Important",
        "Caution",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "0e0f5ad678bc1756a2cf7db88a52df2c2983bbe4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/introduction-event-api/",
      "published_at": "2021-06-14T18:22:55Z",
      "updated_at": "2021-06-09T02:16:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic University’s tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.nr-data.net or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to your New Relic account: Register an Insert API key. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Register an Insert API key You must have the correct user permissions to register Insert API keys. Important Insert API keys are generated for an account. They aren't associated with a specific user. Anyone in the account with access to the Insert API key can use it. You submit multiple event types under a single Insert API key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. To register an Insert API key: From one.newrelic.com, click the account dropdown and then click Account settings. Click API keys and click Insights insert keys. Next to the Insert keys heading, select the symbol and follow the instructions. The Insert key page lists the curl command necessary to add event data for the key. Caution For security reasons, the Insert API key cannot be altered or read using the API. To change or read a key, use the New Relic UI. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. The Insert key page in the Insights UI automatically generates a sample curl query for you to use as a template. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"X-Insert-Key: YOUR_KEY_HERE\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_KEY_HERE\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"X-Insert-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The X-Insert-Key contains the correct Insert API key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, use the Insights data explorer to ensure your events are reporting correctly and to generate queries. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid API key: Invalid Insert key, or the account does not have access to Insights. Register a valid Insert key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To have New Relic Alerts notify you about parsing errors, create a NRQL condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the Insert API key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.37384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Event <em>API</em>",
        "sections": "Introduction to the Event <em>API</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic Event <em>API</em> is one way to report custom events to New Relic. The Event <em>API</em> lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use <em>APIs</em> and the rest of our observability <em>platform</em>, join the New"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events": [
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-14T19:27:12Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.44138,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>API</em> limits <em>and</em> restricted attributes",
        "sections": "Metric <em>API</em> limits <em>and</em> restricted attributes",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "This document describes <em>data</em> requirements for the Metric <em>API</em>, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric <em>data</em>: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than"
      },
      "id": "603ea95128ccbca08eeba7a6"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Tip",
        "Requirements",
        "Basic workflow",
        "Register an Insert API key",
        "Important",
        "Caution",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "0e0f5ad678bc1756a2cf7db88a52df2c2983bbe4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/introduction-event-api/",
      "published_at": "2021-06-14T18:22:55Z",
      "updated_at": "2021-06-09T02:16:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic University’s tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.nr-data.net or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to your New Relic account: Register an Insert API key. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Register an Insert API key You must have the correct user permissions to register Insert API keys. Important Insert API keys are generated for an account. They aren't associated with a specific user. Anyone in the account with access to the Insert API key can use it. You submit multiple event types under a single Insert API key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. To register an Insert API key: From one.newrelic.com, click the account dropdown and then click Account settings. Click API keys and click Insights insert keys. Next to the Insert keys heading, select the symbol and follow the instructions. The Insert key page lists the curl command necessary to add event data for the key. Caution For security reasons, the Insert API key cannot be altered or read using the API. To change or read a key, use the New Relic UI. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. The Insert key page in the Insights UI automatically generates a sample curl query for you to use as a template. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"X-Insert-Key: YOUR_KEY_HERE\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_KEY_HERE\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"X-Insert-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The X-Insert-Key contains the correct Insert API key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, use the Insights data explorer to ensure your events are reporting correctly and to generate queries. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid API key: Invalid Insert key, or the account does not have access to Insights. Register a valid Insert key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To have New Relic Alerts notify you about parsing errors, create a NRQL condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the Insert API key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.37375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Event <em>API</em>",
        "sections": "Introduction to the Event <em>API</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic Event <em>API</em> is one way to report custom events to New Relic. The Event <em>API</em> lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use <em>APIs</em> and the rest of our observability <em>platform</em>, join the New"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    },
    {
      "sections": [
        "Get data into New Relic",
        "New Relic-built agents and integrations",
        "Agent APIs",
        "Telemetry SDKs",
        "APIs for sending metrics, traces, logs, and events",
        "New Relic One applications"
      ],
      "title": "Get data into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "1b20f81fa22784c5d22e4e51eb7c0bf26cbdb0b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-started/introduction-new-relic-data-ingest-apis-sdks/",
      "published_at": "2021-06-14T18:22:55Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are many ways to get data into your New Relic account. Any New Relic user can use any of our data ingest methods to report data to our Telemetry Data Platform. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring, infrastructure monitoring, or any of our wide array of integrations, by default you'll receive data from your monitored applications, hosts, services, or other entities. To browse all New Relic-built tools and solutions, see New Relic integrations. Agent APIs Some of our monitoring solutions come with APIs and/or SDKs that allow you to customize the data reported and how it reports. For more information, see the relevant product: APM agent APIs Browser API Mobile API Infrastructure monitoring: the Flex integration tool Telemetry SDKs If our more curated solutions don't work for you, our open source Telemetry SDKs let you build your own solution. These SDKs are language wrappers for our data-ingest APIs (below) that let you send telemetry data to New Relic without requiring install of an agent. APIs for sending metrics, traces, logs, and events If our more curated solutions don't work for you, we also have data-ingest APIs: Trace API Event API Metric API Log API To learn about the differences between these data types, see Data types. New Relic One applications You can build entirely custom applications that reside in New Relic One and make use of any data you want. You can use existing open source New Relic One apps, or share your own with the open source community. For details, see New Relic One applications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.82193,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get <em>data</em> into New Relic",
        "sections": "<em>APIs</em> for sending metrics, traces, logs, <em>and</em> events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "There are many ways to get <em>data</em> into your New Relic account. Any New Relic user can use any of our <em>data</em> <em>ingest</em> methods to report <em>data</em> to our <em>Telemetry</em> <em>Data</em> <em>Platform</em>. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring"
      },
      "id": "603eae7b196a671ea3a83dc7"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/drop-data-using-nerdgraph": [
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-14T17:48:45Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Data management hub. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1591.2043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage your <em>data</em>",
        "sections": "Manage your <em>data</em>",
        "tags": "Telemetry <em>Data</em> Platform",
        "body": " most essential, we have a strategy for you. Learn about reducing the amount of <em>data</em> that comes into NRDB in Manage <em>data</em> coming into New Relic. Learn about customizing storage so you only store the <em>data</em> you want, for the period you want in Manage <em>data</em> stored in New Relic. Learn about dropping <em>data</em> in <em>Drop</em> <em>data</em> <em>using</em> <em>NerdGraph</em>. And for dropping log <em>data</em>, see <em>Drop</em> <em>data</em> with <em>drop</em> filter rules."
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Data privacy with New Relic",
        "Personal data transfer (Privacy Shield and SCC)",
        "Compliance with legal requirements",
        "Privacy by design and by default",
        "Personal data requests (GDPR, CCPA, etc.)",
        "Events and attributes",
        "Dropping data at ingest",
        "Technical security controls",
        "Organizational security controls",
        "Account security",
        "Retention of your data",
        "New Relic account emails",
        "Account changes (NrAuditEvent)",
        "Account usage (NrDailyUsage)",
        "Security for products and services",
        "Alerts and Applied Intelligence",
        "APIs",
        "APM",
        "Browser monitoring",
        "Diagnostics",
        "Infrastructure monitoring",
        "Insights",
        "Integrations and serverless monitoring",
        "Logs management",
        "Mobile monitoring",
        "New Relic One",
        "Plugins",
        "Synthetic monitoring"
      ],
      "title": "Data privacy with New Relic",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Data privacy"
      ],
      "external_id": "d46953520476285467540433180d483815efecc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/",
      "published_at": "2021-06-15T15:10:09Z",
      "updated_at": "2021-03-16T18:10:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic takes your data privacy seriously. Our principles-based approach aims to go beyond the legal requirements for consent. We understand your concerns when you entrust us with your data, and we always strive to embrace your expectations and preferences. This document provides links to detailed information about the privacy and security measures we take to protect you and your customers' data privacy. Our monitoring tools are data-agnostic; they don't require sensitive materials, and many of them don't require any personal data. You are responsible for ensuring that your systems are appropriately set up and configured so that they don't send inappropriate personal data or sensitive materials to New Relic monitoring tools. For additional information about policies, credentials, audits, and other resources, see our New Relic security website. Personal data transfer (Privacy Shield and SCC) The Schrems case ruling invalidates Privacy Shield. However, it explicitly reaffirms the validity of Standard Contractual Clauses (SCC) as an appropriate legal mechanism to transfer personal data outside of the European Union. You can find more information in How the Demise of Privacy Shield Affects Your New Relic Account. If you want to send personal data from the EU, we offer an appropriate data processing agreement (DPA) with SCC to govern the transfer of that data in accordance with the Schrems decision. For more information, consult our Data Processing Addendum FAQ, or download our pre-signed DPA (PDF|697 KB). Compliance with legal requirements We always strive to comply with all applicable laws as they take effect. This includes the European Union's General Data Protection Regulation (GDPR) and all relevant US State laws, such as the California Consumer Privacy Act (CCPA). Our disk-based encryption provides additional security while your data is at rest (FIPS 140-2 compliant). In addition, we are authorized for Moderate Impact SaaS Services (FedRAMP Authorized Moderate) for accounts that meet specific criteria. For privacy-related details about New Relic's contractual and regulatory commitments for services, see: Terms of Service or Master Subscription Agreement Data Protection Agreement Services Privacy Notice For more information about annual audits, see Regulatory audits for New Relic services. Privacy by design and by default New Relic follows \"privacy by design\" principles as part of our overarching security program. For example, when New Relic agents capture a webpage or referrer URL, all query parameters are stripped by default. Here are examples of how we incorporate privacy considerations into our data and security practices. Personal data requests (GDPR, CCPA, etc.) New Relic strives to comply with all applicable laws as they take effect. This includes the European Union's GDPR and ePrivacy Directive and all applicable privacy laws, such as the California Consumer Privacy Act (CCPA) in the US. For more information about our process when responding to requests to access or delete personal data, see New Relic personal data requests. Events and attributes You can query events and attributes, as well as create charts and alert conditions about this data. For a complete list of all events and attributes tracked by New Relic agents, see our data dictionary. Events and attributes example: If you use the Infrastructure ProcessSample event's commandLine attribute, by default we strip options and arguments from the full command line to prevent accidental leakage of sensitive information. Dropping data at ingest Dropping data gives you control over the data that you send to New Relic, including any personal data that you configured to be collected. By dropping specific events or attributes from events, you determine what data New Relic ultimately stores so that you can query, alert on, and analyze it. For more information, see Drop data using NerdGraph. When our agents refer to data obfuscation, the agent actually removes the data before sending it to New Relic. The data cannot be recovered. For example, with APM queries, the Record SQL? value defaults to obfuscated. This strips the string literals and numeric sequences and then replaces them with the ? character. You can mask sensitive information in HTTP or HTTPS requests. For example, queries about distributed traces and transaction traces are obfuscated by default, in which case they cannot be recovered. For more information, see the documentation for specific New Relic services, including: APM transaction traces Distributed tracing Technical security controls We use a comprehensive set of technical controls to support general security needs as well as security for data we receive. For more information, see our documentation about data security, data encryption, and high security mode for APM agents. Organizational security controls New Relic maintains a number of internal policies and procedures to guide employees in privacy-related subjects such as data classification and handling, data retention, handling of personal data, fulfilling personal data requests, incident response, etc. All employees must complete the security and privacy training upon hiring and renew this training annually. Account security Our role-based account structure gives you direct control over who can access or change your account settings. For more information, see Users and roles. Retention of your data Our Telemetry Data Platform is the single source of truth for all your operational data, empowering you to ask and answer any question in milliseconds. This platform stores different types of data for different periods of time. The Data retention page in our UI provides information on how long your data will be stored in the New Relic database (NRDB). For more information, see Manage data retention. New Relic account emails By default, we communicate with you for a variety of purposes related to your status as New Relic subscribers. This includes product engagement, support, alert notifications, updates, billings, etc. Individual users can unsubscribe from certain communications. General email preferences are managed through the account user interface. For more information, see Account email settings. Alert notification emails are managed through the alerting UI. Account changes (NrAuditEvent) To view changes made to your account's users or to record configuration changes, query NrAuditEvent events. To be notified about account changes, create NRQL alert conditions. For more information about available NrAuditEvent attributes, see our data dictionary. Account usage (NrDailyUsage) To view daily usage of New Relic for your selected account for billing purposes, query NrDailyUsage events. For more information about available NrDailyUsageattributes, see our data dictionary. Security for products and services We publish security bulletins with detailed information about vulnerabilities, remediation strategies, and applicable updates for affected software. To receive notifications for future advisories, use either of these options: Subscribe to our security bulletins RSS feed. Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. The following summarizes how individual New Relic products and components ensure security, with links to additional details. Alerts and Applied Intelligence By default, our alerting services do not record any personal data. In addition, they automatically set default permissions for individual account users and access levels within account structures. For more information, see our documentation about Applied Intelligence, as well as our rules and limits for alerts. APIs APIs simply are interfaces for data exchange automation. APIs have no knowledge of the content being transferred. We require authorized users to provide their API keys to monitor subscription usage, manage account user permissions, query data, and perform other automated tasks. For more information, see Introduction to New Relic APIs. APM APM agents monitor your applications' performance. By default, APM agents do not record any personal data. For more information, see our APM security documentation. Browser monitoring Our browser monitoring agent allows you to monitor the performance of their websites. For more information, see: Browser security documentation Visitor's IP address New Relic cookies used by Browser Enabling or disabling cookie collection for session tracking Diagnostics The New Relic Diagnostics service inspects relevant system information and any other necessary information (such as logs and config files) to perform diagnostic checks that assess configuration and operability. By default, this data is not transmitted to New Relic. You do have the option to upload this information to a support ticket over HTTPS. For more information, see the Diagnostics security documentation. Infrastructure monitoring The Infrastructure agent allows you to monitor the performance of components in your ecosystem, such as servers, platforms, operating systems, databases, etc. Infrastructure may record the userID and username of users connecting to Infrastructure resources. For more information, see the security documentation for infrastructure monitoring. Insights The Insights service reports on data recorded by other New Relic products and services. It doesn’t record data on its own. For more information, see the Insights documentation about default data from other products and services. Integrations and serverless monitoring Our integrations services allow you to retrieve and load data into the New Relic database from a variety of sources, including: Cloud-based integrations On-host integrations in containerized environments, such as Kubernetes On-host integrations built by New Relic On-host integrations built by the open-source community On-host integrations built by you Depending on the integration, different types of data may be recorded so that you can monitor the integrations in New Relic. The integration services are data agnostic. They will have no knowledge of whether the imported data contains any personal information. For more information, see the documentation for the specific integration, including: Amazon Web Services (AWS) Google Cloud Platform (GCP) Kubernetes Microsoft Azure On-host integrations Open source on-host integrations Serverless function monitoring Logs management Due to the nature of our Logs management service, you have direct control over what data is reported to New Relic. To ensure data privacy and to limit the types of information New Relic receives, no customer data is captured except what you supply in your API calls or log forwarder configuration. All data for the Logs service is then reported to New Relic over HTTPS. The Logs service does mask number patterns that appear to be for items such as credit cards or Social Security numbers. For more information, see the Logs security documentation. Mobile monitoring By default, our mobile monitoring service collects two pieces of personal data: The IP address is used to derive high-level geographical data, and then is discarded. A device ID is generated by New Relic and is used for billing purposes. For more information, see our security documentation for mobile monitoring. New Relic One New Relic One is a connected, unified UI that gathers all the data you already monitor with New Relic in one place. It is not a product, but rather, it's a way to interact with all your New Relic data more easily. For more information, see the introduction and security documentation for New Relic One. Plugins The plugins service allows you to publish publicly accessible plugins within (Plugin Central. Anyone who has a New Relic account can install and use these plugins through their New Relic user interface. For some plugins, New Relic, Inc. is the publisher, and will be clearly identified as the publisher in Plugin Central. For plugins in Plugin Central that are not created by New Relic, the plugin publisher must follow specific guidelines. For more information, see the Plugins security documentation. Synthetic monitoring The synthetic monitoring service uses monitors distributed throughout data centers around the world. It captures what is essentially performance data of simulated traffic. By default, it does not capture any personal data. For more information, see the data privacy and security documentation for synthetic monitoring. If you configure the synthetic service to monitor areas of websites that are located behind a login page, take care to create a non-personal login dedicated to this purpose. This will reduce the risk of unintended personal data exposure. For example, to securely store sensitive information, such as passwords, API keys, and user names, you can use secured credentials for scripted browsers and API tests. The synthetic monitoring service also supports a variety of authentication mechanisms. Depending on the type of monitor you choose, this includes Basic, Digest, NTLM, and NTLMv2. You can also control which of your users can access your monitors and private locations. For more information, see our documentation about user role-based permissions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 631.9922,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> privacy with New Relic",
        "sections": "<em>Dropping</em> <em>data</em> at ingest",
        "tags": "<em>Data</em> privacy",
        "body": " <em>data</em> <em>using</em> <em>NerdGraph</em>. When our agents refer to <em>data</em> obfuscation, the agent actually removes the <em>data</em> before sending it to New Relic. The <em>data</em> cannot be recovered. For example, with APM queries, the Record SQL? value defaults to obfuscated. This strips the string literals and numeric sequences"
      },
      "id": "603ec2d4e7b9d22fba2a07c6"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and add tags",
        "Overview",
        "Read tags for an entity",
        "Add tags for an entity",
        "Remove a tag from an entity",
        "Delete specific tag values for an entity",
        "Replace all tag values for an entity"
      ],
      "title": "NerdGraph tutorial: View and add tags",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "b62313b6fa10ab235c031feae23d6fe52163b703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/examples/nerdgraph-tagging-api-tutorial/",
      "published_at": "2021-06-15T06:43:42Z",
      "updated_at": "2021-06-09T05:59:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use our NerdGraph API to add tags to your data to help improve data organization and findability. Overview This doc explains how to use our NerdGraph API to add and manage tags. Note that this is only one way to add tags. For other methods, see How tags are added. For how to automate tags using our CLI tool, see our developer site. Read tags for an entity To construct these queries and see responses: Go to the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. Use entitySearch() to find the entity and then fetch its tags. Use NerdGraph's tag API to read the existing tags and their values. In this example, our entity is a browser app called Cookie Checkout: { actor { entitySearch (query: \"name like 'Cookie Checkout'\") { results { entities { tags { key values } } } } } } Copy The actual values vary depending on your data. Use the New Relic GraphiQL explorer to experiment with queries. Add tags for an entity To add new tags for an entity: Go to the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. Use entitySearch() to locate the GUID for the entity you want to tag. Use the taggingAddTagsToEntity mutation to add a tag with a value to the entity. In this example, we have a browser application called Cookie Checkout owned by a UI team. We want to add a team tag with a ui value to this instance. Once the tag is added, we can filter by the tag team:ui and find the Cookie Checkout app in the New Relic One UI. mutation { taggingAddTagsToEntity ( guid: \"ENTITY_GUID\", tags: { key: \"team\", values: [\"ui\"]}) { errors { message } } } Copy Remove a tag from an entity To delete a tag and all of its associated values from an entity: Go to the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. Use entitySearch() to locate the GUID for the entity with the tag you want to remove. Use the taggingDeleteTagFromEntity mutation. The following example mutation removes the team tag from an entity: mutation { taggingDeleteTagFromEntity ( guid: \"ENTITY_GUID\", tagKeys: [\"team\"]) { errors { message } } } Copy Delete specific tag values for an entity Instead of deleting an entire tag and all of its values, you can delete a single tag value. Go to the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. Use entitySearch() to locate the GUID for the entity with the tag you want to remove. Use the taggingDeleteTagValuesFromEntity mutation. The following example mutation deletes the ui value from the tag key: mutation { taggingDeleteTagValuesFromEntity ( guid: \"ENTITY_GUID\", tagValues : [{key: \"team\" value: \"ui\"}]) { errors { message } } } Copy Because tagValues is an array, you can delete multiple specific values from a single entity in one mutation. Replace all tag values for an entity To replace the entity’s entire set of tags with the provided tag set: Go to the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. Use entitySearch() to locate the GUID for the entity with the tag you want to remove. Use the taggingReplaceTagsOnEntity mutation. In this example, the Cookie Checkout browser application was transferred from the ui team to the cookie-dev team. You can replace the tag values for team with the following mutation: mutation { taggingReplaceTagsOnEntity ( guid: \"ENTITY_GUID\", tags: {key: \"team\" values: [\"cookie-dev\"]}) { errors { message } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 537.70557,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and add tags",
        "sections": "<em>NerdGraph</em> tutorial: View and add tags",
        "tags": "<em>NerdGraph</em>",
        "body": "You can <em>use</em> our <em>NerdGraph</em> API to add tags to your <em>data</em> to help improve <em>data</em> organization and findability. Overview This doc explains how to <em>use</em> our <em>NerdGraph</em> API to add and manage tags. Note that this is only one way to add tags. For other methods, see How tags are added. For how to automate tags"
      },
      "id": "603ec1c6196a67eeada83d9a"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic": [
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-14T17:37:59Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.18958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Match errors to <em>ingested</em> payloads",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": ", like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a <em>data</em> dropping rule to remove attributes at <em>ingest</em> time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries"
      },
      "id": "603ea57b64441f44f34e887d"
    },
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-14T19:27:12Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.18958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric API limits <em>and</em> restricted attributes",
        "sections": "Max <em>data</em> points per minute (DPM)",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic <em>platform</em>. Any values submitted with these keys in the attributes section of a metric <em>data</em> point will cause the <em>data</em> point to be dropped, or the value to be omitted"
      },
      "id": "603ea95128ccbca08eeba7a6"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Tip",
        "Requirements",
        "Basic workflow",
        "Register an Insert API key",
        "Important",
        "Caution",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "0e0f5ad678bc1756a2cf7db88a52df2c2983bbe4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/introduction-event-api/",
      "published_at": "2021-06-14T18:22:55Z",
      "updated_at": "2021-06-09T02:16:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic University’s tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.nr-data.net or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to your New Relic account: Register an Insert API key. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Register an Insert API key You must have the correct user permissions to register Insert API keys. Important Insert API keys are generated for an account. They aren't associated with a specific user. Anyone in the account with access to the Insert API key can use it. You submit multiple event types under a single Insert API key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. To register an Insert API key: From one.newrelic.com, click the account dropdown and then click Account settings. Click API keys and click Insights insert keys. Next to the Insert keys heading, select the symbol and follow the instructions. The Insert key page lists the curl command necessary to add event data for the key. Caution For security reasons, the Insert API key cannot be altered or read using the API. To change or read a key, use the New Relic UI. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. The Insert key page in the Insights UI automatically generates a sample curl query for you to use as a template. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"X-Insert-Key: YOUR_KEY_HERE\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_KEY_HERE\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"X-Insert-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The X-Insert-Key contains the correct Insert API key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, use the Insights data explorer to ensure your events are reporting correctly and to generate queries. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid API key: Invalid Insert key, or the account does not have access to Insights. Register a valid Insert key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To have New Relic Alerts notify you about parsing errors, create a NRQL condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the Insert API key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.12305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Find your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event <em>data</em> to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Tip To use APIs and the rest of our observability <em>platform</em>, join the New"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/manage-data-retention": [
    {
      "sections": [
        "Data privacy with New Relic",
        "Personal data transfer (Privacy Shield and SCC)",
        "Compliance with legal requirements",
        "Privacy by design and by default",
        "Personal data requests (GDPR, CCPA, etc.)",
        "Events and attributes",
        "Dropping data at ingest",
        "Technical security controls",
        "Organizational security controls",
        "Account security",
        "Retention of your data",
        "New Relic account emails",
        "Account changes (NrAuditEvent)",
        "Account usage (NrDailyUsage)",
        "Security for products and services",
        "Alerts and Applied Intelligence",
        "APIs",
        "APM",
        "Browser monitoring",
        "Diagnostics",
        "Infrastructure monitoring",
        "Insights",
        "Integrations and serverless monitoring",
        "Logs management",
        "Mobile monitoring",
        "New Relic One",
        "Plugins",
        "Synthetic monitoring"
      ],
      "title": "Data privacy with New Relic",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Data privacy"
      ],
      "external_id": "d46953520476285467540433180d483815efecc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/",
      "published_at": "2021-06-15T15:10:09Z",
      "updated_at": "2021-03-16T18:10:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic takes your data privacy seriously. Our principles-based approach aims to go beyond the legal requirements for consent. We understand your concerns when you entrust us with your data, and we always strive to embrace your expectations and preferences. This document provides links to detailed information about the privacy and security measures we take to protect you and your customers' data privacy. Our monitoring tools are data-agnostic; they don't require sensitive materials, and many of them don't require any personal data. You are responsible for ensuring that your systems are appropriately set up and configured so that they don't send inappropriate personal data or sensitive materials to New Relic monitoring tools. For additional information about policies, credentials, audits, and other resources, see our New Relic security website. Personal data transfer (Privacy Shield and SCC) The Schrems case ruling invalidates Privacy Shield. However, it explicitly reaffirms the validity of Standard Contractual Clauses (SCC) as an appropriate legal mechanism to transfer personal data outside of the European Union. You can find more information in How the Demise of Privacy Shield Affects Your New Relic Account. If you want to send personal data from the EU, we offer an appropriate data processing agreement (DPA) with SCC to govern the transfer of that data in accordance with the Schrems decision. For more information, consult our Data Processing Addendum FAQ, or download our pre-signed DPA (PDF|697 KB). Compliance with legal requirements We always strive to comply with all applicable laws as they take effect. This includes the European Union's General Data Protection Regulation (GDPR) and all relevant US State laws, such as the California Consumer Privacy Act (CCPA). Our disk-based encryption provides additional security while your data is at rest (FIPS 140-2 compliant). In addition, we are authorized for Moderate Impact SaaS Services (FedRAMP Authorized Moderate) for accounts that meet specific criteria. For privacy-related details about New Relic's contractual and regulatory commitments for services, see: Terms of Service or Master Subscription Agreement Data Protection Agreement Services Privacy Notice For more information about annual audits, see Regulatory audits for New Relic services. Privacy by design and by default New Relic follows \"privacy by design\" principles as part of our overarching security program. For example, when New Relic agents capture a webpage or referrer URL, all query parameters are stripped by default. Here are examples of how we incorporate privacy considerations into our data and security practices. Personal data requests (GDPR, CCPA, etc.) New Relic strives to comply with all applicable laws as they take effect. This includes the European Union's GDPR and ePrivacy Directive and all applicable privacy laws, such as the California Consumer Privacy Act (CCPA) in the US. For more information about our process when responding to requests to access or delete personal data, see New Relic personal data requests. Events and attributes You can query events and attributes, as well as create charts and alert conditions about this data. For a complete list of all events and attributes tracked by New Relic agents, see our data dictionary. Events and attributes example: If you use the Infrastructure ProcessSample event's commandLine attribute, by default we strip options and arguments from the full command line to prevent accidental leakage of sensitive information. Dropping data at ingest Dropping data gives you control over the data that you send to New Relic, including any personal data that you configured to be collected. By dropping specific events or attributes from events, you determine what data New Relic ultimately stores so that you can query, alert on, and analyze it. For more information, see Drop data using NerdGraph. When our agents refer to data obfuscation, the agent actually removes the data before sending it to New Relic. The data cannot be recovered. For example, with APM queries, the Record SQL? value defaults to obfuscated. This strips the string literals and numeric sequences and then replaces them with the ? character. You can mask sensitive information in HTTP or HTTPS requests. For example, queries about distributed traces and transaction traces are obfuscated by default, in which case they cannot be recovered. For more information, see the documentation for specific New Relic services, including: APM transaction traces Distributed tracing Technical security controls We use a comprehensive set of technical controls to support general security needs as well as security for data we receive. For more information, see our documentation about data security, data encryption, and high security mode for APM agents. Organizational security controls New Relic maintains a number of internal policies and procedures to guide employees in privacy-related subjects such as data classification and handling, data retention, handling of personal data, fulfilling personal data requests, incident response, etc. All employees must complete the security and privacy training upon hiring and renew this training annually. Account security Our role-based account structure gives you direct control over who can access or change your account settings. For more information, see Users and roles. Retention of your data Our Telemetry Data Platform is the single source of truth for all your operational data, empowering you to ask and answer any question in milliseconds. This platform stores different types of data for different periods of time. The Data retention page in our UI provides information on how long your data will be stored in the New Relic database (NRDB). For more information, see Manage data retention. New Relic account emails By default, we communicate with you for a variety of purposes related to your status as New Relic subscribers. This includes product engagement, support, alert notifications, updates, billings, etc. Individual users can unsubscribe from certain communications. General email preferences are managed through the account user interface. For more information, see Account email settings. Alert notification emails are managed through the alerting UI. Account changes (NrAuditEvent) To view changes made to your account's users or to record configuration changes, query NrAuditEvent events. To be notified about account changes, create NRQL alert conditions. For more information about available NrAuditEvent attributes, see our data dictionary. Account usage (NrDailyUsage) To view daily usage of New Relic for your selected account for billing purposes, query NrDailyUsage events. For more information about available NrDailyUsageattributes, see our data dictionary. Security for products and services We publish security bulletins with detailed information about vulnerabilities, remediation strategies, and applicable updates for affected software. To receive notifications for future advisories, use either of these options: Subscribe to our security bulletins RSS feed. Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. The following summarizes how individual New Relic products and components ensure security, with links to additional details. Alerts and Applied Intelligence By default, our alerting services do not record any personal data. In addition, they automatically set default permissions for individual account users and access levels within account structures. For more information, see our documentation about Applied Intelligence, as well as our rules and limits for alerts. APIs APIs simply are interfaces for data exchange automation. APIs have no knowledge of the content being transferred. We require authorized users to provide their API keys to monitor subscription usage, manage account user permissions, query data, and perform other automated tasks. For more information, see Introduction to New Relic APIs. APM APM agents monitor your applications' performance. By default, APM agents do not record any personal data. For more information, see our APM security documentation. Browser monitoring Our browser monitoring agent allows you to monitor the performance of their websites. For more information, see: Browser security documentation Visitor's IP address New Relic cookies used by Browser Enabling or disabling cookie collection for session tracking Diagnostics The New Relic Diagnostics service inspects relevant system information and any other necessary information (such as logs and config files) to perform diagnostic checks that assess configuration and operability. By default, this data is not transmitted to New Relic. You do have the option to upload this information to a support ticket over HTTPS. For more information, see the Diagnostics security documentation. Infrastructure monitoring The Infrastructure agent allows you to monitor the performance of components in your ecosystem, such as servers, platforms, operating systems, databases, etc. Infrastructure may record the userID and username of users connecting to Infrastructure resources. For more information, see the security documentation for infrastructure monitoring. Insights The Insights service reports on data recorded by other New Relic products and services. It doesn’t record data on its own. For more information, see the Insights documentation about default data from other products and services. Integrations and serverless monitoring Our integrations services allow you to retrieve and load data into the New Relic database from a variety of sources, including: Cloud-based integrations On-host integrations in containerized environments, such as Kubernetes On-host integrations built by New Relic On-host integrations built by the open-source community On-host integrations built by you Depending on the integration, different types of data may be recorded so that you can monitor the integrations in New Relic. The integration services are data agnostic. They will have no knowledge of whether the imported data contains any personal information. For more information, see the documentation for the specific integration, including: Amazon Web Services (AWS) Google Cloud Platform (GCP) Kubernetes Microsoft Azure On-host integrations Open source on-host integrations Serverless function monitoring Logs management Due to the nature of our Logs management service, you have direct control over what data is reported to New Relic. To ensure data privacy and to limit the types of information New Relic receives, no customer data is captured except what you supply in your API calls or log forwarder configuration. All data for the Logs service is then reported to New Relic over HTTPS. The Logs service does mask number patterns that appear to be for items such as credit cards or Social Security numbers. For more information, see the Logs security documentation. Mobile monitoring By default, our mobile monitoring service collects two pieces of personal data: The IP address is used to derive high-level geographical data, and then is discarded. A device ID is generated by New Relic and is used for billing purposes. For more information, see our security documentation for mobile monitoring. New Relic One New Relic One is a connected, unified UI that gathers all the data you already monitor with New Relic in one place. It is not a product, but rather, it's a way to interact with all your New Relic data more easily. For more information, see the introduction and security documentation for New Relic One. Plugins The plugins service allows you to publish publicly accessible plugins within (Plugin Central. Anyone who has a New Relic account can install and use these plugins through their New Relic user interface. For some plugins, New Relic, Inc. is the publisher, and will be clearly identified as the publisher in Plugin Central. For plugins in Plugin Central that are not created by New Relic, the plugin publisher must follow specific guidelines. For more information, see the Plugins security documentation. Synthetic monitoring The synthetic monitoring service uses monitors distributed throughout data centers around the world. It captures what is essentially performance data of simulated traffic. By default, it does not capture any personal data. For more information, see the data privacy and security documentation for synthetic monitoring. If you configure the synthetic service to monitor areas of websites that are located behind a login page, take care to create a non-personal login dedicated to this purpose. This will reduce the risk of unintended personal data exposure. For example, to securely store sensitive information, such as passwords, API keys, and user names, you can use secured credentials for scripted browsers and API tests. The synthetic monitoring service also supports a variety of authentication mechanisms. Depending on the type of monitor you choose, this includes Basic, Digest, NTLM, and NTLMv2. You can also control which of your users can access your monitors and private locations. For more information, see our documentation about user role-based permissions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.40868,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> privacy with New Relic",
        "sections": "<em>Retention</em> of your <em>data</em>",
        "tags": "<em>Data</em> privacy",
        "body": " information on how long your <em>data</em> will be stored in the New Relic database (NRDB). For more information, see <em>Manage</em> <em>data</em> <em>retention</em>. New Relic account emails By default, we communicate with you for a variety of purposes related to your status as New Relic subscribers. This includes product"
      },
      "id": "603ec2d4e7b9d22fba2a07c6"
    },
    {
      "sections": [
        "Users, roles, permissions (original user model)",
        "Requirements",
        "Updates about our new account/user model",
        "View and manage users in UI",
        "Tip",
        "Add a new user",
        "Important",
        "Update user type (basic vs full)",
        "Determine full user count",
        "Enable SAML SSO and/or SCIM",
        "View pending SAML SSO users",
        "Update account roles",
        "Delete a user",
        "Update the account Owner",
        "User types: basic user and full user",
        "Account roles",
        "Add-on roles",
        "View roles",
        "Assign a managed role",
        "Create a custom role",
        "Assign a custom role",
        "Edit or delete a custom role",
        "Account permissions",
        "Alert permissions",
        "APM permissions",
        "Browser permissions",
        "Infrastructure permissions",
        "Insights permissions",
        "Mobile permissions",
        "Synthetics permissions",
        "Workloads permissions"
      ],
      "title": "Users, roles, permissions (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original users and roles"
      ],
      "external_id": "95ae42f3474b43dec394245cfc3e23628449a1ed",
      "image": "https://docs.newrelic.com/static/7c44fb7de7b71f84f961042e651fd609/75a80/login-multiple-accounts-found.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-users-roles/users-roles-original-user-model/",
      "published_at": "2021-06-14T14:53:44Z",
      "updated_at": "2021-06-14T14:53:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our original user model, an introduction to how the user model works, including user roles and permissions, and how to add and manage users. Requirements This doc and the surrounding section of docs shows you how to manage users who are on our original user model. If you were a New Relic customer before July 30 2020, you likely have users on our original user model (and not the New Relic One user model). One way to quickly check your users' user model: if you can see users in the Users and roles UI, those users are on our original user model. Want to learn more about user model changes? See Overview of user models. Updates about our new account/user model In July of 2020, we released a new account/user model called the New Relic One user model, which offers many benefits in terms of how you manage your organization and users. At first this was only available to new sign-ups but over time we've been migrating more and more pre-existing organizations to the new model. Some organizations with users on the original user model are able to migrate their users on their own. We'll continue working on migrating users to the new model until the original user model is fully deprecated. One impact of the new user model is that it's possible now for users to have multiple logins associated with the same email. For example, a user with access to multiple organizations (like a contractor) may have their user record updated to the new user model in one organization, resulting in them having their original login method and records and a New Relic One user model record. This may result in the user being logged in to New Relic and not being able to find an account they're looking for. For more on that, see Factors affecting access. If a user's email is associated with more than one login, they'll see a \"multiple accounts found\" note when logging in. View and manage users in UI If your New Relic account has users on our original user model, you can use the Users and roles UI. To access this UI: select the account dropdown, select Account settings, and select Users and roles. Some features in the UI are visible only to account Owners and Admins. Tip You can also use the New Relic REST API to obtain a list of everyone and their roles in your New Relic account. Here are some instructions and tips for adding and managing users via the UI: Add a new user Tip Owner or Admins To add a new user to your New Relic account: Go to: account dropdown > Account settings > Users and roles > Users. In the upper right corner, click New user. Enter the appropriate name and email address. Select their base role as either Admin, User, or Restricted. Select Add user. The new user will receive an email notification automatically from New Relic. Important New Relic recommends a maximum of 1,000 accounts per user. Additional accounts may result in limited access to some New Relic features. Update user type (basic vs full) To update a user's type (basic user versus full user): Go to: account dropdown > Account settings > Users and roles > Users. Either select a user and edit their type or bulk update the type for multiple useres. For more about this, see User type. Determine full user count If you're on New Relic One pricing plan, your count of full users is a factor in your billing. To see your count of full users, click the account dropdown and then click View your usage. If you have a master/sub-account structure (including a customer partnership), your count of full users may not match what you see when you go to Account settings > Users and roles. To examine users on a master account's sub-accounts, go to a master account's Account settings UI page, click on a sub-account, and go to their Users and roles UI page. Enable SAML SSO and/or SCIM For an introduction to using SAML SSO and/or SCIM provisioning, see Get started with SAML SSO or SCIM. View pending SAML SSO users New Relic accounts with SAML Single Sign On (SSO) may have a list of Pending users. These are individuals who have been added to the SAML-enabled account but have not yet confirmed. Update account roles Tip Owner or Admins To update a person's role and capabilities: Go to: account dropdown > Account settings > Users and roles > Users. Select the person's name. Under Roles and capabilities, select their base role as Admin, User, or Restricted. The account Owner must update the Owner role. Delete a user Tip Owner or Admins To remove a user from your New Relic account: Go to: account dropdown > Account settings > Users and roles > Users. Click on the name of the person you would like to update. Click Delete User. Tip You can also add, update, or delete users in bulk via CSV file. Update the account Owner A New Relic account can have only one Owner role at any time. You must be the current account Owner to change your role to someone who currently has an Admin role for the account. If the current Owner is unavailable, contact your account representative at New Relic, or get support at support.newrelic.com. You cannot delete or remove your assigned Owner role. However, if the account has one or more Admin role, you can change an Owner to an Admin. Go to: account dropdown > Account settings > Account > Users and roles. Above the Active users list, select Change owner. If an account has no Admins, this button won't be available. Select someone who currently has an Admin role for the account. Refresh the page for changes to take effect. Your previous Owner role automatically changes to an Admin role. To find out who is the current assigned Owner: Go to: account dropdown > Account settings > Account > Users and roles. View the Base role column to locate your account Owner. The Change owner button is only visible to the current account Owner. If the current Owner is unable to change the role (for example, that person no longer is with your organization), contact your account representative at New Relic, or get support at support.newrelic.com. User types: basic user and full user Important This section is for users on our original user model. If you're on our New Relic One user model, see our New Relic One user docs. Starting March 2021, we ended the preview period for these basic users. The preview period gave basic users the same permissions as full users. For more on this, see our Explorers Hub post on user type changes. The user type (basic user or full user) determines what features a user has access to. Below are details on the two user types. Note that billing-related aspects only apply if you're on New Relic One pricing. If you're on our original pricing plan, billing impacts do not apply. Basic user. Details: These users have access to basic features like setting up reporting of data, running queries of data, making custom charts and dashboards, and setting up alerts. They do not have access to Full-Stack Observability features (for more details on feature access, see Capabilities). Basic users can upgrade to become full users in the UI. They will see prompts when attempting to access unavailable features. They cannot self-upgrade; they must request an upgrade. No matter what custom group a basic user is assigned to, they always have the capabilities of a basic user: no more and no less. Full user. Details: Full users have access to our Full-Stack Observability features, which include our curated UI experiences like APM, infrastructure monitoring, browser monitoring, mobile monitoring, and synthetic monitors. For details on what's available, see Capabilities. For organizations on New Relic One pricing: these users are billable. The Standard edition includes one free full user and up to five total. If a user in your organization is set as a basic user in one account and a full user in another, the user has full user access for all accounts. For how to edit user type, see Manage users. Account roles A New Relic account can have only one Owner. To share an account with other users in your organization, create Admins, Users, or Restricted Users. Account role Description Owner The person who initially creates the New Relic account and receives all billing queries. The Owner has complete access to all of the account information. Admin Can add, edit, and delete users, and can enable or set up features. User Can use (and optionally set up) New Relic features. In general, Admins take responsibility for setting up features, and Users and Restricted Users can use them. Restricted User One or more individuals who can view (but not set up or change) any New Relic features. The Restricted User role is useful, for example, for demos. You can change your New Relic session settings so that Restricted User logins do not time out, and then set the user interface to Kiosk mode. Add-on roles With add-on roles, you can grant variable levels of access to all users in your account, across the entire platform of New Relic products. This allows you to tailor your account permissions levels to suit the needs of Users and Restricted Users within your account. Giving a User or Restricted User add-on manager access to a product grants them the equivalent of Admin capabilities within the product. They will continue to have User or Restricted User capabilities for all other New Relic products. For example, you could make a software engineer in your company a User in most products, but assign Admin-level access to APM. For another example, you might assign the Nerdpack manager role to a user, and that gives them the ability to subscribe and unsubscribe New Relic One applications to an account. There are two types of add-on roles: Add-on Manager roles are available to grant permissions on a per-product basis. Giving a User or Restricted User managed add-on access to a product grants them the equivalent of Admin capabilities within the product. Custom add-on roles can grant feature-specific permissions across different New Relic products. For example, a group of Users could have the ability to acknowledge incidents and close violations in New Relic Alerts, but not have the ability to modify your existing alert preferences. Individuals on a master account that has sub-accounts automatically have the same level of access for all sub-accounts. Below are options for managing both managed add-on roles and custom add-on roles: View roles To view the list of individuals assigned to your account and their current roles: Go to account dropdown > Account settings > Users and roles. Assign a managed role Tip Owner and Admins Managed add-on roles are available by default for each New Relic product. Adding a managed role for a user grants them Admin-level permissions for the assigned product. They cannot be edited or deleted. To assign a managed add-on role for a User or Restricted User in your account: Go to account dropdown > Account settings > Users and roles. From the list of users associated with your account, select their name. Under Add-on roles, select the type of manager role for the user. To understand which capabilities may be added, use the Capabilities preview chart. Features in the Capabilities preview chart may not exactly match what features are available for your subscription level. Tip You can also add, update, or delete users in bulk by using a CSV file. Create a custom role To create a custom add-on role for your account: Go to account dropdown > Account settings > Users and roles > Roles. Select New custom add-on role. Select the capabilities necessary for the new custom role, then Create role. Assign a custom role Tip Owners and Admins You must create a custom role before assigning it to a user. To assign a custom add-on role for a User or Restricted User in your account: Go to account dropdown > Account settings > Users and roles > Users. From the list of users associated with your account, select their name ]. Under Add-on roles, select a custom role for the user. Click Update user. Edit or delete a custom role Tip Owners and Admins You cannot edit or delete New Relic's default roles. However, you can edit or delete custom add-on roles for your account: Go to account dropdown > Account settings > Users and roles > Roles. From the Add-on roles list, select the custom add-on role, then select Edit role or Delete role as appropriate. Account permissions Here is a summary of basic user rights for your New Relic account. Individuals on a master account with sub-accounts automatically have the same level of access for all sub-accounts. However, they will not receive email notifications for alerts or weekly reports for sub-accounts unless they are explicitly granted permission on these sub-accounts. Function Owner Admin User Restricted Maintain billing information. Change the account Owner. Add, update, and delete account Admins, Users, and Restricted Users. When the account Owner and Admins add individuals to the account, New Relic automatically sends them an email message. Update users' job titles and roles from Account settings in the New Relic UI. Create, modify and delete sub-accounts from Account settings in the New Relic UI. Update your own account information (name, password change or password reset request, default account, email preferences, etc.) from User preferences in the New Relic UI. Change someone else's password. You cannot reset passwords for anyone else on the account, even if you are an Owner or Admin. Instead, follow standard procedures to request a password reset from New Relic. View the list of individuals on the account from (account dropdown) > Account settings > Account > Summary in the New Relic UI. Manage flexible data retention. Subscribe and unsubscribe applications to New Relic One Alert permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Alerts. To allow a User or Restricted User to execute any of these functions in New Relic Alerts, assign an Alerts add-on manager role. Admin and manager capabilities for Alerts include: Create or name alert policies. Specify incident preferences. Disable or define alert conditions. Provide runbook instructions. Select product targets. Alter alert condition thresholds. Create, modify, or delete notification channels. APM permissions Here is a summary of Admin and Add-on manager capabilities with New Relic APM. To allow a User or Restricted User to execute any of these functions in New Relic APM, assign an APM add-on manager role. Admin and manager capabilities for APM include: Remove applications from the New Relic UI. Delete app traces and error traces. Browser permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Browser. To allow a User or Restricted User to execute any of these functions in New Relic Browser, assign a Browser add-on manager role. Admin and manager capabilities for Browser include: Add, rename, or delete applications. Manage whitelists. Manage domain conditions. Infrastructure permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Infrastructure. To allow a User or Restricted User to execute any of these functions in New Relic Infrastructure, assign an Infrastructure manager role. Admin and manager capabilities for Infrastructure include: Create alert conditions in New Relic Infrastructure, including conditions for host not reporting. Add or modify integrations. Insights permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Insights. To allow a User or Restricted User to execute any of these functions in New Relic Insights, assign an Insights manager role. These functions include: Create, view, modify, or delete Query API keys or Insert API keys. Tip New Relic Insights includes permission levels to share your Insights dashboards with others. Mobile permissions To give permission to delete a mobile app from New Relic, you can assign an Admin or Mobile manager role. Synthetics permissions Here's a summary of Admin and Add-on manager capabilities with New Relic Synthetics. To allow a User or Restricted User to execute any of these functions in New Relic Synthetics, assign a Synthetics add-on manager role. Admin and manager capabilities for Synthetics include: Create, edit, or delete monitors. Edit monitor scripts. Create, edit, or delete private locations. Create, edit, or delete monitor downtimes. Create, view, edit, or delete secure credentials. For more information, see User roles in Synthetics. Workloads permissions Here's a summary of Admin and Add-on manager capabilities with New Relic One workloads: Create, duplicate, modify, or delete workloads. Link dashboards to workloads and save filters. To allow a User or Restricted User to execute these functions, assign the workloads manager add-on role.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.85803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View and <em>manage</em> users in UI",
        "body": " on the account from (account dropdown) &gt; Account settings &gt; Account &gt; Summary in the New Relic UI. <em>Manage</em> flexible <em>data</em> <em>retention</em>. Subscribe and unsubscribe applications to New Relic One Alert permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Alerts. To allow a User"
      },
      "id": "603e88b2e7b9d2a3f12a07d5"
    },
    {
      "sections": [
        "Overview of data retention (original pricing plan)",
        "Important",
        "Limits on editing and deleting data",
        "Product and API data retention policies",
        "APM",
        "APM data retention policies",
        "Legacy APM data retention policies",
        "Browser",
        "Infrastructure",
        "Tip",
        "Infrastructure downsampling and data retention",
        "Integration compute unit event limits",
        "Insights",
        "Logs",
        "Logs in context data retention",
        "Mobile",
        "Mobile data retention policies",
        "Standard Mobile (legacy) data retention policies",
        "Plugins",
        "Plugins data retention",
        "Legacy Plugins data retention",
        "Synthetics",
        "Synthetics data retention policies",
        "Metric API",
        "Trace API",
        "Data components",
        "Event data: reported by most products",
        "Metric timeslice data: reported by APM, Browser, and Mobile",
        "Aggregate metric timeslice data: reported by APM, Browser, and Mobile",
        "Key metrics: reported by APM, Browser, and Mobile",
        "Trace data: reported by APM, Browser, and Mobile"
      ],
      "title": "Overview of data retention (original pricing plan)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original data retention"
      ],
      "external_id": "22d5ab9f4d623ead28ee7bb82c118d91804dee22",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/product-based-pricing/overview-data-retention-components/",
      "published_at": "2021-06-14T18:30:10Z",
      "updated_at": "2021-03-11T13:22:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on our New Relic One pricing plan, see Manage your data. Not sure which you're on? See Overview of pricing plans. If you're on the original product-based pricing plan, you retain your existing subscriptions and data retention values. You manage these existing retention settings from the Data management hub in New Relic One. To manage your retention settings, in New Relic One, click your user name, select Manage your data, and then select Data retention. You'll see your existing retention settings. Adjust retention values by clicking the Edit retention button. New Relic stores different types of data for different periods of time. The retention period for a type of data will vary depending on the product, the subscription level, and the feature. Limits on editing and deleting data Once telemetry data (events, metrics, logs, traces) is reported to New Relic and available for querying, that data cannot be edited or deleted. This is a purposeful design decision that optimizes New Relic's speed and performance. Data will expire after its data retention ends. If you sent unwanted data or sensitive data to New Relic that must be removed, contact your account representative at New Relic, or get support at support.newrelic.com. Product and API data retention policies Select a New Relic product to see details about its data retention: APM Specific retention policies apply to each New Relic APM subscription level, including Lite, Essentials, Pro, and Enterprise. This includes metric timeslice data, key metrics, trace data, and event data. In addition to retention limits, your data is subject to aggregation (averaging) after certain elapsed time periods. For more information, see the aggregate metric data description. APM data retention policies For accounts on our original product-based pricing, APM data retention policies depend on your APM product subscription level. Component Lite Essentials Pro Metric timeslice data 24 hours 3 days 90 days Key metrics none forever forever Distributed tracing and logs in context none none 8 days Other trace data * 1 day 3 days 7 days Event data * * 1 day 3 days 8 days * If you view a transaction trace in the New Relic UI, New Relic stores that trace data for up to one year. * * Learn about how to extend the retention of event data. Legacy APM data retention policies Component Standard Startup Small Business Enterprise Metric timeslice data 7 days 14 days 30 days 90 days Key metrics none none none forever Trace data 7 days 7 days 7 days 7 days Event data none 8 days 8 days 8 days Browser For accounts on our original product-based pricing, Browser data is stored depending on your subscription level: Component Lite Pro Metric data 24 hours 90 days Key metrics 24 hours forever Trace data 7 days 7 days Event data * 1 day 8 days SPA data Unavailable 8 days * Learn about how to extend the retention of event data. Infrastructure For accounts on our original product-based pricing, Infrastructure data retention policies depend on your Infrastructure subscription level and your New Relic Infrastructure compute units pricing model. Data retention rules apply the same whether that data is displayed in the UI or queried. Tip Infrastructure data retention is not governed by your Insights subscription. Infrastructure downsampling and data retention Types of data are stored depending on your subscription level: Component Essentials Pro Infrastructure data 3 months 13 months Host count Host count will stop reflecting a host whose agent is no longer reporting after three minutes. However, host data will be available, subject to other retention criteria. 3 minutes 3 minutes Inventory attributes removed Inventory attributes for a host are retained for 24 hours after the agent stops reporting. 24 hours 24 hours Integration data Not available with Essentials Limit of 2275 integration events per compute unit per month In addition, Infrastructure downsamples your data on the fly, as it's generated. All Infrastructure metric data types (including On-Host Integrations metrics) will display different granularity depending on the age of the data and the size of the time window. The following table illustrates when different downsampled buckets will be used, both in the Infrastructure UI and for queries: Bucket Size Used For Time Windows Covering... Data Retained For... Raw (5, 10 or 15 second) 0 to 59 minutes 7 days 1 minute 60 minutes to 6 hours 30 days 10 minutes 6 hours to 3 days Full account retention period 1 hour 3 days to 14 days Full account retention period 3 hours 14+ days Full account retention period Integration compute unit event limits The 2275 limit on integration events per compute unit per month is a limit on total Infrastructure integration events. It's not a limit of 2275 for each integration's events. Additional details and clarifications about this limit: This limit applies to all events from all integrations (cloud integrations and on-host integrations). The events are all handled the same. Default data received by the Infrastructure agent does not count against the 2275 event per compute unit limit. If you exceed your limit, we do not enforce this limit. If you exceed your limit, we'll review pricing options with you to ensure you get the most cost-effective pricing for your organization's integrations. Insights For accounts on our original product-based pricing, an Insights subscription extends your event data retention. An Insights Pro subscription allows you to customize the length of your event data retention. Logs For accounts on our original product-based pricing, log data can be retained for up to 30 days by New Relic. Shorter retention periods of 8 or 15 days are also available. Logs in context data retention New Relic Logs logs in context data retention policy is based on your current APM product subscription level. For more information, see APM data retention. Mobile For accounts on our original product-based pricing, Mobile data retention policies depend on your New Relic Mobile product subscription level. This includes data components such as metric data, aggregate metrics, key metrics, trace data, and event data. For information about your subscription-related data usage, see Mobile subscription usage. Mobile data retention policies Component Lite Enterprise Overview page data 24 hours 90 days Crash data and stack traces 24 hours 90 days HTTP requests (except errors) as metric data Unavailable 90 days HTTP request errors as metric data Unavailable 3 days Interaction traces Unavailable 90 days Custom events * Unavailable 1 day Mobile events * 1 day 8 days MobileBreadcrumb events * Unavailable 3 days MobileCrash events * 1 day 90 days MobileHandledException events * Unavailable 3 days MobileJSError events (React Native beta) * Unavailable 3 days MobileRequest events * Unavailable 3 days MobileRequestError events * Unavailable 3 days MobileSession events * 1 day 90 days * Learn how to extend retention of event data. Standard Mobile (legacy) data retention policies Unless otherwise noted, Insights event data is unavailable for Standard subscriptions. Component Standard Overview page data 7 days Crash data and stack traces 7 days HTTP requests (except errors) as metric data 7 days HTTP request errors as metric data 3 days Interaction traces Unavailable MobileCrash events 8 days MobileSession events 8 days Plugins The retention period for historical data depends on the product and subscription level. The following data retention periods exist for New Relic Plugins. Important Plugins is not supported with accounts that host data in the EU region data center. Plugins data retention Component Lite Essentials Pro Enterprise Metric data 24 hours 3 days 90 days 90 days Legacy Plugins data retention Component Standard Startup Small Business Metric data 7 days 14 days 30 days Synthetics For accounts on our original product-based pricing, Synthetics data retention policies depend on your Synthetics product subscription level. This includes data components such as metric data, aggregate metrics, key metrics, trace data, and Insights events. Tip Synthetics events do not count against an Insights Pro subscription. Your current subscription level appears in the right column of the Account summary page: Go to synthetics.newrelic.com > (account dropdown) > Account settings > Account > Summary. Synthetics data retention policies Component Lite Pro Synthetics monitor data 2 weeks 13 months Event data 2 weeks 13 months Also see the data retention details for APIs, including: Metric API All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Trace API See Trace API general requirements and limits. Data components For accounts on our original product-based pricing, the section below provides an explanation of some types of data components governed by the data retention rules of specific products: Event data: reported by most products See Event data retention for information on the event data type. Metric timeslice data: reported by APM, Browser, and Mobile Metric timeslice data is a specific type of data that is used for most metric charts and reports in New Relic APM, Mobile, and Browser. Important Note that metric timeslice data differs from other metric data types. All metric timeslice data is aggregated, but New Relic deals with fresh data and old data in different ways. Fresh data has specific policies applied to the data to keep granular views of performance as aggregate metrics. As data ages and becomes less useful in a granular state, we summarize that data and only keep key metrics. Aggregate metric timeslice data: reported by APM, Browser, and Mobile Aggregate metric timeslice data summarizes calls to specific methods in your application: how many times each one was called and response times. In the New Relic UI, you see the class and method names along with their aggregate numbers. Metric data aggregation depends on your subscription level. Subscription Level Aggregate retention Enterprise Aggregates (averages) to 1-hour periods after 8 days. After 90 days, the permanent metric data continues to be stored in 1-hour periods. This means you cannot obtain data granularity of less than 1 hour after 8 days, and only a subset of metrics are available after 90 days. Pro After 8 days Essentials After 3 days. Legacy Small Business, Startup, and Standard After 3 days. Lite After 2 hours. We retain your most recent data in one-minute increments. We also aggregate permanent metric data to day-size increments after 90 days. When looking at older data in small time windows, you may notice that charts show less detail. As data ages, it is aggregated into larger segments. Key metrics: reported by APM, Browser, and Mobile New Relic retains certain \"key\" metric timeslice data aggregations forever for Enterprise and Pro customers, for any number of applications. New Relic aggregates permanent key metric data to hour-size increments after 90 days. Product Key metrics APM Apdex, for app server Throughput and page views Response time, plus breakdown into tiers or categories on your app's main Overview chart Page load time, plus breakdown into segments Error rate CPU usage Memory usage Browser Apdex, for browser Browser page load time Throughput total. After 90 days, there is no breakout by browser type, and only the combined average value is available for the time range requested. Mobile Crash rate: For iOS and for Android Network throughput Network response time Network error rates Interaction traces Trace data: reported by APM, Browser, and Mobile Depending on the product, New Relic retains different types of trace data: Product Trace data APM Types of trace data: Transaction traces Distributed tracing Slow query samples Error details See APM data retention details. Browser Types of trace data: Session traces Browser traces JavaScript errors* See Browser data retention details. Mobile Types of trace data: App crash stack traces Interaction traces See Mobile data retention details. * JavaScript errors in the stack trace UI are saved as trace data. JS errors are also saved as events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.5023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview of <em>data</em> <em>retention</em> (original pricing plan)",
        "sections": "Overview of <em>data</em> <em>retention</em> (original pricing plan)",
        "tags": "Original <em>data</em> <em>retention</em>",
        "body": " <em>retention</em> values. You <em>manage</em> these existing <em>retention</em> settings from the <em>Data</em> management hub in New Relic One. To <em>manage</em> your <em>retention</em> settings, in New Relic One, click your user name, select <em>Manage</em> your <em>data</em>, and then select <em>Data</em> <em>retention</em>. You&#x27;ll see your existing <em>retention</em> settings. Adjust"
      },
      "id": "6043f75364441f6967378ec6"
    }
  ]
}